---
title: "《Operating Systems: Three Easy Pieces》学习笔记(三十五) 日志结构文件系统"
author: Jinkai
date: 2022-06-17 09:01:00 +0800
published: false
categories: [学习笔记]
tags: [Operating Systems, 操作系统导论]
---

文件系统面临的一个主要挑战在于，如何在出现断电（power loss）或系统崩溃（system crash）的情况下，更新持久数据结构。称为`崩溃一致性`问题（crash-consistency problem）。

## 崩溃一致性问题

理想的做法是将文件系统从一个`一致`状态（在文件`被追加`之前），`原子地`（atomically）移动到另一个状态（在 inode、位图和新数据块被写入磁盘之后）。遗憾的是，做到这一点不容易，因为磁盘一次只提交一次写入，而这些更新之间可能会发生崩溃或断电。我们将这个一般问题称为`崩溃一致性`问题（crash-consistency problem，也可以称为一致性更新问题，consistent-update problem）。

## 解决方案1：文件系统检查程序

决定让不一致的事情`发生`，然后再`修复`它们（重启时）。

`fsck` 是一个 UNIX 工具，用于查找这些`不一致`并`修复`它们

以下是 fsck 的基本总结:

- **超级块**：fsck 首先检查超级块是否合理，主要是进行健全性检查，例如确保文件系统大小大于分配的块数。通常，这些健全性检查的目的是找到一个可疑的（冲突的）超级块。在这种情况下，系统（或管理员）可以决定使用超级块的备用副本。
- **空闲块**：接下来，fsck 扫描 inode、间接块、双重间接块等，以了解当前在文件系统中分配的块。它利用这些知识生成正确版本的分配位图。因此，如果位图和 inode之间存在任何不一致，则通过信任 inode 内的信息来解决它。对所有 inode 执行相同类型的检查，确保所有看起来像在用的 inode，都在 inode 位图中有标记。
- **inode 状态**：检查每个 inode 是否存在损坏或其他问题。例如，fsck 确保每个分配的 inode 具有有效的类型字段（即常规文件、目录、符号链接等）。如果 inode 字段存在问题，不易修复，则 inode 被认为是可疑的，并被 fsck 清除，inode 位图相应地更新。
- **inode 链接**：fsck 还会验证每个已分配的 inode 的链接数。你可能还记得，链接计数表示包含此特定文件的引用（即链接）的不同目录的数量。为了验证链接计数，fsck 从根目录开始扫描整个目录树，并为文件系统中的每个文件和目录构建自己的链接计数。如果新计算的计数与 inode 中找到的计数不匹配，则必须采取纠正措施，通常是修复 inode 中的计数。如果发现已分配的 inode 但没有目录引用它，则会将其移动到 lost + found 目录。
- **重复**：fsck 还检查重复指针，即两个不同的 inode 引用同一个块的情况。如果一个inode 明显不好，可能会被清除。或者，可以复制指向的块，从而根据需要为每个inode 提供其自己的副本。
- **坏块**：在扫描所有指针列表时，还会检查坏块指针。如果指针显然指向超出其有效范围的某个指针，则该指针被认为是“坏的”，例如，它的地址指向大于分区大小的块。在这种情况下，fsck 不能做任何太聪明的事情。它只是从 inode 或间接块中删除（清除）该指针。
- **目录检查**：fsck 不了解用户文件的内容。但是，目录包含由文件系统本身创建的特定格式的信息。因此，fsck 对每个目录的内容执行额外的完整性检查，确保“.”和“..”是前面的条目，目录条目中引用的每个 inode 都已分配，并确保整个层次结构中没有目录的引用超过一次。

## 解决方案 2：日志（或预写日志）

对于一致更新问题，最流行的解决方案可能是从`数据库`管理系统的世界中借鉴的一个想法(应该就是数据库中的`事务`)。这种名为`预写日志`（write-ahead logging）的想法，是为了解决这类问题而发明的。

我们通常将预写日志称为日志（`journaling`）。

基本思路如下。更新磁盘时，在`覆写结构`之前，首先写下一点`小注记`（在磁盘上的`其他地方`，在一个众所周知的位置），描述你将要做的事情。写下这个注记就是“预写”部分， 我们把它写入一个结构，并组织成“日志”。因此，就有了预写日志。

通过将注释写入磁盘，可以保证在`更新（覆写）`正在更新的结构期间`发生崩溃`时，能够返回并`查看`你所做的`注记`，然后`重试`。因此，你会在崩溃后准确知道`要修复的内容`（以及如何修复它），而不必扫描整个磁盘。

ext2 文件系统（没有日志）:

![F1](/assets/img/2022-06-17-operating-systems-34/F1.jpg)

ext3 文件系统:

![F2](/assets/img/2022-06-17-operating-systems-34/F2.jpg)

1. `日志写入`：将事务（包括事务开始块，所有即将写入的数据和元数据更新以及事务 结束块）写入日志，等待这些写入完成。
2. `加检查点`：将待处理的元数据和数据更新写入文件系统中的最终位置

### 写入日志期间发生崩溃

在写入日志期间发生崩溃时，事情变得有点棘手。在这里，我们试图将事务中的这些块（即 TxB、I[v2]、B[v2]、Db、TxE）写入磁盘。

一种简单的方法是`一次`发出 `1 个块`写入，等待每个完成，然后发出下一个。但是，这很慢。

我们希望`一次`发出所有 `5 个块`写入，因为这会将 5 个写入转换为单个顺序写入(`连续写入`)，因此更快。然而，由于以下原因，这是`不安全`的：给定如此大的写入，`磁盘内部`可以执行`调度`并以`任何顺序`完成大批写入的小块(无法预知写入顺序)。

比如，事务`开始结束块TxB/TxE`都已经写入，但`中间的TxB`却没写入：

![F3](/assets/img/2022-06-17-operating-systems-34/F3.jpg)

为避免该问题，文件系统分两步发出事务写入。首先，它将`除 TxE 块之外`的所有块写入日志，`同时`发出这些`写入`。当这些写入完成时，日志将看起来像这样（假设又是文件追加的工作负载）：

![F4](/assets/img/2022-06-17-operating-systems-34/F4.jpg)

当这些写入完成时，文件系统会发出 `TxE` 块的写入，从而使日志处于最终的`安全状态`：

![F5](/assets/img/2022-06-17-operating-systems-34/F5.jpg)

此过程的一个重要方面是`磁盘`提供的`原子性保证`。事实证明，磁盘保证`任何 512 字节写入`都会发生或不发生（`永远不会半写`）。因此，为了确保 `TxE 的写入是原子的`，应该使它成为`一个 512 字节的块`。因此，我们当前更新文件系统的协议如下，3 个阶段中的每一个都标上了名称。

### 优化后的写入步骤

1. `日志写入`：将事务的内容（包括`TxB、元数据和数据`）写入日志，等待这些写入完成。
2. `日志提交`：将事务`提交块`（包括 `TxE`）写入日志，等待写完成，事务被认为已提交（committed）。
3. `加检查点`：将更新内容（元数据和数据）写入其最终的磁盘位置。

### 恢复

利用日志内容从崩溃中恢复（recover）

如果崩溃发生在事务被`安全地写入日志之前`（在上面的`步骤 2` 完成之前），那么我们的工作很简单：简单地`跳过`待执行的`更新`。

如果在事务`已提交到日志`之后但在加检查点完成之前发生崩溃，则文件系统可以按如下方式恢复（recover）更新: 系统引导时，文件系统恢复过程将`扫描日志`，并`查找`已提交到磁盘的`事务`。然后，这些事务被`重放`（replayed，按顺序），文件系统再次尝试将事务中的块写入它们最终的磁盘位置。称为`重做日志`（redo logging）

### 批处理日志更新

基本协议可能会增加大量额外的`磁盘流量`。

例如，假设我们在同一目录中`连续创建两个文件`，称为 file1 和 file2。要创建一个文件，必须更新许多磁盘上的结构，至少包括：inode 位图（分配新的 inode），新创建的文件 inode，包含新文件目录条目的父目录的数据块，以及父目录的 inode（现在有一个新的修改时间）。通过日志，我们将所有这些信息逻辑地提交给我们的两个文件创建的日志。因为文件在同一个目录中，我们假设在同一个 inode 块中都有 inode，这意味着如果不小心，我们最终会反复`写入`这些`相同的块`。(多个事务要写入相同的块，就会重复)

为了解决这个问题，一些文件系统不会一次一个地向磁盘提交每个更新（例如，Linuxext3）。与此不同，可以将`所有更新缓冲到全局事务`中。在上面的示例中，当创建两个文件时，文件系统只将内存中的 inode 位图、文件的 inode、目录数据和目录 inode 标记为`脏`，并将它们添加到块列表中，形成当前的事务。当最后应该将这些块写入磁盘时（例如，在`超时 5s` 之后），会提交包含上述所有更新的`单个全局事务`。因此，通过缓冲更新，文件系统在许多情况下可以避免对磁盘的`过多`的写入流量。

### 使日志有限

日志的大小有限。如果不断向它添加事务（如下所示），它将很快填满。

![F6](/assets/img/2022-06-17-operating-systems-34/F6.jpg)

第一个问题比较简单：日志`越大`，`恢复时间越长`，因为恢复过程必须重放日志中的所有事务（按顺序）才能恢复。

第二个问题更重要：当日志`已满`（或接近满）时，`不能`向磁盘`提交`进一步的事务，从而使文件系统“不太有用” （即无用）。

日志文件系统将日志视为循环数据结构，一遍又一遍地重复使用。 这就是为什么日志有时被称为`循环日志`（circular log）。一旦事务被加检查点，文件系统应`释放`它在日志中`占用的空间`，允许重用日志空间。

在`日志超级块`（journal superblock）中标记日志中`最旧`和`最新`的事务:

![F7](/assets/img/2022-06-17-operating-systems-34/F7.jpg)

在日志超级块中（不要与主文件系统的超级块混淆），日志系统记录了足够的信息，以了解哪些事务尚未加检查点，从而减少了恢复时间，并允许以`循环的方式`重新使用日志。 因此，我们在基本协议中添加了另一个步骤:

1. `日志写入`：将事务的内容（包括 TxB 和更新内容）写入日志，等待这些写入完成。
2. `日志提交`：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交（committed）。
3. `加检查点`：将更新内容写入其最终的磁盘位置。
4. `释放`：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。

### 元数据日志

对于每次写入磁盘，我们现在也要`先写入日志`，从而使写入`流量加倍`。

在写入日志和写入主文件系统之间，存在代价高昂的`寻道`，这为某些工作负载增加了显著的开销。

我们上面描述的日志模式通常称为`数据日志`（data journaling，如在 Linux ext3 中），因为它记录了所有用户数据（除了文件系统的元数据之外）。一种更简单（也更常见）的日志形式有时称为`有序日志`（ordered journaling，或称为`元数据日志`，metadata journaling）:

![F8](/assets/img/2022-06-17-operating-systems-34/F8.jpg)

先前写入日志的`数据块 Db` 将改为`直接写入`文件系统，避免额外写入。

修改确实提出了一个有趣的问题：我们`何时`应该将数据块`写入`磁盘？

在将相关元数据写入磁盘之前，一些文件系统（例如，Linux
ext3）`先将数据块`（常规文件）`写入磁盘`。(先写磁盘再写日志，防止元数据指向空数据)

1. `数据写入`：将数据写入最终位置，等待完成（等待是可选的，详见下文）。
2. `日志元数据写入`：将开始块和元数据写入日志，等待写入完成。
3. `日志提交`：将事务提交块（包括 TxE）写入日志，等待写完成，现在认为事务（包括数据）已提交（committed）。
4. `加检查点元数据`：将元数据更新的内容写入文件系统中的最终位置。
5. `释放`：稍后，在日志超级块中将事务标记为空闲。

### 棘手的情况：块复用

块被`删除`然后`重新分配`会有问题

假设你有一个名为 `foo 的目录`。用户向 foo `添加一个条目`（一个条目，不是添加一个文件，类似一个文件名的字符串加上 inode 号），因此 foo 的内容（因为目录被认为是元数据，所以 D[foo]这个数据也写入日志区的元数据了）被写入日志。假设 foo 目录数据的位置是块 1000。因此日志包含如下内容

![F9](/assets/img/2022-06-17-operating-systems-34/F9.jpg)

此时，用户`删除目录`中的`所有内容以及目录本身`，从而`释放块 1000` 以供复用。最后，用户`创建`了一个`新文件`（比如 `foobar`），结果`复用`了过去属于 `foo` 的`相同块（1000）`。foobar 的 inode 提交给磁盘，其数据也是如此。但是，请注意，因为正在使用元数据日志，所以只有 `foobar 的 inode` 被提交给日志，文件 foobar 中块 1000 中新写入的数据没有写入日志:

![F10](/assets/img/2022-06-17-operating-systems-34/F10.jpg)

现在假设发生了崩溃，所有这些信息仍然在日志中。在重放期间，恢复过程简单地`重放`日志中的所有内容，包括在块 1000 中写入目录数据。因此，重放会用旧目录内容`覆盖`当前文件 foobar 的用户数据

这个问题有一些`解决方案`。例如，可以永远不再`重复使用块`，直到所述块的删除加上检查点，从日志中清除。Linux ext3 的做法是将新类型的记录添加到日志中，称为`撤销`（revoke） 记录。在上面的情况中，`删除目录`将导致`撤销记录`被写入日志。在重放日志时，系统首先扫描这样的重新记录。任何此类被`撤销的数据`都`不会被重放`，从而避免了上述问题。

### 总结日志：时间线

![T42.1](/assets/img/2022-06-17-operating-systems-34/T42.1.jpg)

数据日志，就是先写`日志区`的`元数据和数据`，写完写 TxE 表示日志写完，再写入`文件系统区的元数据和数据`

![T42.2](/assets/img/2022-06-17-operating-systems-34/T42.2.jpg)

元数据日志就是同步写`日志区的元数据`和`文件系统区的数据`，都完成后写 TxE 表示日志写入结束，再写`文件系统元数据`，`不用`再写`数据`了

## 解决方案 3：其他方法

### 软更新

仔细地对文件系统的所有写入`排序`，以确保磁盘上的结构永远不会处于不一致的状态。例如，通过先写入指向的数据块，再写入指向它的 inode，可以确保 inode 永远不会指向垃圾。

### 写时复制（Copy-On-Write，COW）

这种技术永远`不会覆写`文件或目录。相反，它会对磁盘上以前未使用的位置进行新的更新。在完成许多更新后，COW 文件系统会翻转文件系统的根结构，以包含指向刚`更新`结构的`指针`。

### 这种技术名为基于反向指针的一致性（Backpointer-Based Consistency，BBC）

为了实现一致性，系统中的每个块都会添加一个额外的`反向指针`。例如，每个数据块都引用它所属的 inode。访问文件时，文件系统可以检查正向指针（inode 或直接块中的地址）是否指向引用它的块，从而确定文件是否一致。

两个指针`双向校验`

### 乐观崩溃一致性（optimistic crash consistency）

`尽可能多`地向磁盘发出`写入`，并利用`事务校验和`（transaction checksum）的一般形式，以及其他一些技术来检测不一致。

对于某些工作负载，这些乐观技术可以将性能提高一个数量级。

## 小结

我们介绍了崩溃一致性的问题，并讨论了处理这个问题的各种方法。

## 参考

- [Operating Systems: Three Easy Pieces 中文版](https://pages.cs.wisc.edu/~remzi/OSTEP/Chinese/43.pdf)
