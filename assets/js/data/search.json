[ { "title": "C语言中的const", "url": "/posts/const-c/", "categories": "学习笔记", "tags": "C语言", "date": "2022-09-21 09:00:00 +0800", "snippet": "定义const 将修饰离它最近的对象（优先左边）解释Bjarne 在他的《The C++ Programming Language》里面给出过一个助记的方法“以 * 分界，把一个声明从右向左读”。注意语法，* 读作 pointer to (指向…的指针)，const (常量) 是形容词，char (变量类型) 和 p (变量名) 当然都是名词。 const char * p 读作：p is a pointer to a const char，译：p 是一个指针(变量)，它指向一个常量字符(const char)。就是 p 能修改，p 指向内容不能修改 char * const p 读作：p is a const pointer to a char，译：p 是一个常量指针(const p)，它指向一个字符(变量)。就是 p 不能修改，p 指向内容能修改 其他情况另外请再注意下面的情况: 先看 const int a 和 int const a，这里没有分界符 *，虽然 const 的位置不同，但意思不变，它 const 修饰的是 int，常量整数。 再看 const char * p 和 char const * p，首先以 * 分界，虽然 const 的位置改变了，但它都是在修饰 char，常量字符。 const char * const p 就表示常量指针指向的常量字符 扩展const char a[] 和 const char *a 和 const char *a[3] const char a[]中的 a 表示 a 一个字符数组，是个数组类型的变量，大小和数组占用空间相同。a 不可修改，也就是内容不可修改 const char *a中的 a 表示指向字符的指针（对于字符数组就是指向数组第一个字符的指针），大小就是一个指针。指针可以修改，指针指向的内容不可修改 const char *a[3]中的 a 表示一个指针数组，数组包含 3 个指针，这些指针都指向字符，大小是 3 个指针大小。对于每个指针，该指针为非const，可修改，但其指向的内容为const，不可修改（相当于const char *a）#include &amp;lt;stdio.h&amp;gt;int main(){ const char a[] = &quot;abcdefghijkl&quot;; const char *b = &quot;ijklmnopqrst&quot;; const char *c[3]; printf(&quot;sizeof(a) = %d\\n&quot;,(int)sizeof(a)); // sizeof(a) = 13 printf(&quot;sizeof(b) = %d\\n&quot;,(int)sizeof(b)); // sizeof(b) = 8 printf(&quot;sizeof(c) = %d\\n&quot;,(int)sizeof(c)); // sizeof(c) = 24 printf(&quot;c[0]:%p,c[1]:%p,c[2]:%p\\n&quot;,c[0],c[1],c[2]); // c[0]:(nil),c[1]:(nil),c[2]:(nil) return 0;}参考 记住 const 的位置与区别" }, { "title": "面向对象编程(OOP)的C语言实现", "url": "/posts/c-oop/", "categories": "学习笔记", "tags": "面向对象, OOP", "date": "2022-09-05 09:00:00 +0800", "snippet": "前言阅读本文章前首先要具备一定的面向对象编程基础面向对象特性面向对象编程 （Object-oriented programming，OOP） 是一种基于以下三个基本概念的设计方式： 封装(Encapsulation) 将数据和函数打包到类中的能力 继承(Inheritance) 基于现有类定义新类的能力，以获得重用和代码组织 多态(Polymorphism) 在运行时将匹配接口的对象相互替换的能力封装即对调用者隐藏实现和非必要的内部属性要点： 头文件(.h)与实现文件(.c)分离，调用者只需引入头文件 用函数封装对对象内部变量的修改和获取，调用者只需关注函数参数和返回值shape.h:#ifndef SHAPE_H#define SHAPE_H/* Shape&#39;s attributes... */typedef struct { int16_t x; /* x-coordinate of Shape&#39;s position */ int16_t y; /* y-coordinate of Shape&#39;s position */} Shape;/* Shape&#39;s operations (Shape&#39;s interface)... */void Shape_ctor(Shape * const me, int16_t x, int16_t y);void Shape_moveBy(Shape * const me, int16_t dx, int16_t dy);int16_t Shape_getX(Shape * const me);int16_t Shape_getY(Shape * const me);#endif /* SHAPE_H */调用者只要引用头文件，而无需关心函数的实现以及Shape内的变量shape.c:#include &quot;shape.h&quot; /* Shape class interface */// 构造函数/* constructor implementation */void Shape_ctor(Shape * const me, int16_t x, int16_t y) { me-&amp;gt;x = x; me-&amp;gt;y = y;}// 修改内部变量/* move-by operation implementation */void Shape_moveBy(Shape * const me, int16_t dx, int16_t dy) { me-&amp;gt;x += dx; me-&amp;gt;y += dy;}//用get函数封装了对x和y变量的值的获取//（当然这样做不到C++语言级别的private关键字，// 使用者还是能通过Shape对象直接访问这两个变量）/* &quot;getter&quot; operations implementation */int16_t Shape_getX(Shape * const me) { return me-&amp;gt;x;}int16_t Shape_getY(Shape * const me) { return me-&amp;gt;y;} me指针在C++中就是this隐式指针main.c:#include &quot;shape.h&quot; /* Shape class interface */#include /* for printf() */int main() { Shape s1, s2; /* multiple instances of Shape */ Shape_ctor(&amp;amp;s1, 0, 1); Shape_ctor(&amp;amp;s2, -1, 2); printf(&quot;Shape s1(x=%d,y=%d)\\n&quot;, Shape_getX(&amp;amp;s1), Shape_getY(&amp;amp;s1)); printf(&quot;Shape s2(x=%d,y=%d)\\n&quot;, Shape_getX(&amp;amp;s2), Shape_getY(&amp;amp;s2)); Shape_moveBy(&amp;amp;s1, 2, -4); Shape_moveBy(&amp;amp;s2, 1, -2); printf(&quot;Shape s1(x=%d,y=%d)\\n&quot;, Shape_getX(&amp;amp;s1), Shape_getY(&amp;amp;s1)); printf(&quot;Shape s2(x=%d,y=%d)\\n&quot;, Shape_getX(&amp;amp;s2), Shape_getY(&amp;amp;s2)); return 0;}继承继承是基于现有类定义新类以重用和组织代码的能力通过将基类属性结构嵌入为派生类属性结构，可以轻松地在 C 中实现单继承。这样派生类也包含了基类的所有特性，但较难实现C++语言层级的选择性继承和多继承等特性。如果只需实现继承，则 super 对象可以放在派生类中的任何位置，使用时调用-&amp;gt;super即可访问基类部分。如图所示，super 对象被指定为派生类对象中第一个成员，其起始地址与派生类对象地址相同，可以通过调用-&amp;gt;super方式访问继承部分，也可以通过基类Shape指针即可访问Rectangle对象中的继承部分(super)，这一点是为了后面实现多态特性rect.h:#ifndef RECT_H#define RECT_H#include &quot;shape.h&quot; /* the base class interface *//* Rectangle&#39;s attributes... */typedef struct { Shape super; /* &amp;lt;== inherits Shape */ /* attributes added by this subclass... */ uint16_t width; uint16_t height;} Rectangle;/* constructor prototype */void Rectangle_ctor(Rectangle * const me, int16_t x, int16_t y, uint16_t width, uint16_t height);#endif /* RECT_H */rect.c:#include &quot;rect.h&quot;/* constructor implementation */void Rectangle_ctor(Rectangle * const me, int16_t x, int16_t y, uint16_t width, uint16_t height){ // 首先调用基类的构造函数 /* first call superclass’ ctor */ Shape_ctor(&amp;amp;me-&amp;gt;super, x, y); /* next, you initialize the attributes added by this subclass... */ me-&amp;gt;width = width; me-&amp;gt;height = height;}main.c:#include &quot;rect.h&quot; /* Rectangle class interface */#include /* for printf() */int main() { Rectangle r1, r2; /* multiple instances of Rect */ /* instantiate rectangles... */ Rectangle_ctor(&amp;amp;r1, 0, 2, 10, 15); Rectangle_ctor(&amp;amp;r2, -1, 3, 5, 8); printf(&quot;Rect r1(x=%d,y=%d,width=%d,height=%d)\\n&quot;, r1.super.x, r1.super.y, r1.width, r1.height); printf(&quot;Rect r2(x=%d,y=%d,width=%d,height=%d)\\n&quot;, r2.super.x, r2.super.y, r2.width, r2.height); /* re-use inherited function from the superclass Shape... */ Shape_moveBy((Shape *)&amp;amp;r1, -2, 3); Shape_moveBy(&amp;amp;r2.super, 2, -1); printf(&quot;Rect r1(x=%d,y=%d,width=%d,height=%d)\\n&quot;, r1.super.x, r1.super.y, r1.width, r1.height); printf(&quot;Rect r2(x=%d,y=%d,width=%d,height=%d)\\n&quot;, r2.super.x, r2.super.y, r2.width, r2.height); return 0;}对于基类函数的’this’参数可以使用(Shape *)&amp;amp;r或&amp;amp;r.super多态多态性是在运行时将匹配接口的对象相互替换的能力C++使用虚函数实现多态性。在C语言中也可以为Shape类添加几个“虚函数”，并由派生类实现核心是让派生类对象能通过统一的接口函数调用已被自己继承并实现的基类的函数。通过上一节继承中提到的利用基类指针指向基类部分的特点，可以让不同的派生类的对象都通过统一的强制转换指针操作实现对基类中函数指针的访问，利用不同的构造函数让不同的派生类的对象的该指针指向的函数不同，从而实现多态。虚拟表 （vtbl） 和虚拟指针 （vptr）虚拟表和多态关系不大，主要是为减少为了实现OOP引入的函数指针带来的空间代价shape.h:#ifndef SHAPE_H#define SHAPE_H#include/* Shape&#39;s attributes... */struct ShapeVtbl; /* forward declaration */typedef struct{ struct ShapeVtbl const *vptr; /* &amp;lt;== Shape&#39;s Virtual Pointer */ int16_t x; /* x-coordinate of Shape&#39;s position */ int16_t y; /* y-coordinate of Shape&#39;s position */} Shape;/* Shape&#39;s virtual table */struct ShapeVtbl{ uint32_t (*area)(Shape const *const me); void (*draw)(Shape const *const me);};/* Shape&#39;s operations (Shape&#39;s interface)... */void Shape_ctor(Shape *const me, int16_t x, int16_t y);void Shape_moveBy(Shape *const me, int16_t dx, int16_t dy);static inline uint32_t Shape_area(Shape const *const me){ return (*me-&amp;gt;vptr-&amp;gt;area)(me);}static inline void Shape_draw(Shape const *const me){ (*me-&amp;gt;vptr-&amp;gt;draw)(me);}/* generic operations on collections of Shapes */Shape const *largestShape(Shape const *shapes[], uint32_t nShapes);void drawAllShapes(Shape const *shapes[], uint32_t nShapes);#endif /* SHAPE_H */虚函数可以直接定义为函数指针，这里是使用了虚函数表(ShapeVtbl)，把多个函数指针压缩成一个虚表指针，防止每个派生类的对象都包含多个函数指针，其实对于同一个派生类，每个对象的函数指针都指向同一个地方（指针的值相同），这样会浪费空间所有C++编译器都通过每个类一个虚拟表 （vtbl） 和每个对象一个虚拟指针 （vptr） 来实现后绑定在构造函数中设置 vptr让不同的派生类的继承函数指向差异化的实现，这是实现多态的重要一步基类Shape实现：#include &quot;shape.h&quot;#include/* Shape&#39;s prototypes of its virtual functions */static uint32_t Shape_area_(Shape const *const me);static void Shape_draw_(Shape const *const me);/* constructor */void Shape_ctor(Shape *const me, int16_t x, int16_t y){ static struct ShapeVtbl const vtbl = {/* vtbl of the Shape class */ &amp;amp;Shape_area_, &amp;amp;Shape_draw_}; me-&amp;gt;vptr = &amp;amp;vtbl; /* &quot;hook&quot; the vptr to the vtbl */ me-&amp;gt;x = x; me-&amp;gt;y = y;}/* move-by operation */void Shape_moveBy(Shape *const me, int16_t dx, int16_t dy){ me-&amp;gt;x += dx; me-&amp;gt;y += dy;}/* Shape class implementations of its virtual functions... */static uint32_t Shape_area_(Shape const *const me){ assert(0); /* purely-virtual function should never be called */ return 0U; /* to avoid compiler warnings */}static void Shape_draw_(Shape const *const me){ assert(0); /* purely-virtual function should never be called */}/* the following code finds the largest-area shape in the collection */Shape const *largestShape(Shape const *shapes[], uint32_t nShapes){ Shape const *s = (Shape *)0; uint32_t max = 0U; uint32_t i; for (i = 0U; i &amp;lt; nShapes; ++i) { uint32_t area = Shape_area(shapes[i]); /* virtual call */ if (area &amp;gt; max) { max = area; s = shapes[i]; } } return s; /* the largest shape in the array shapes[] */}/* The following code will draw all Shapes on the screen */void drawAllShapes(Shape const *shapes[], uint32_t nShapes){ uint32_t i; for (i = 0U; i &amp;lt; nShapes; ++i) { Shape_draw(shapes[i]); /* virtual call */ }}Shape类有自己的虚表vtbl，构造对象时需要将虚指针vptr指向该虚表虚函数内使用断言的目的就是表示该函数不应该被调用，是一个纯虚函数继承 vtbl 并覆盖子类中的 vptr用自己的实现覆盖基类的实现（空间覆盖）派生类Rectangle实现：#include &quot;rect.h&quot; /* Rectangle class interface */#include /* for printf() *//* Rectangle&#39;s prototypes of its virtual functions *//* NOTE: the &quot;me&quot; pointer has the type of the superclass to fit the vtable */static uint32_t Rectangle_area_(Shape const *const me);static void Rectangle_draw_(Shape const *const me);/* constructor */void Rectangle_ctor(Rectangle *const me, int16_t x, int16_t y, uint16_t width, uint16_t height){ static struct ShapeVtbl const vtbl = {/* vtbl of the Rectangle class */ &amp;amp;Rectangle_area_, &amp;amp;Rectangle_draw_}; Shape_ctor(&amp;amp;me-&amp;gt;super, x, y); /* call the superclass&#39; ctor */ me-&amp;gt;super.vptr = &amp;amp;vtbl; /* override the vptr */ me-&amp;gt;width = width; me-&amp;gt;height = height;}/* Rectangle&#39;s class implementations of its virtual functions... */static uint32_t Rectangle_area_(Shape const *const me){ Rectangle const *const me_ = (Rectangle const *)me; /* explicit downcast */ return (uint32_t)me_-&amp;gt;width * (uint32_t)me_-&amp;gt;height;}static void Rectangle_draw_(Shape const *const me){ Rectangle const *const me_ = (Rectangle const *)me; /* explicit downcast */ printf(&quot;Rectangle_draw_(x=%d,y=%d,width=%d,height=%d)\\n&quot;, me_-&amp;gt;super.x, me_-&amp;gt;super.y, me_-&amp;gt;width, me_-&amp;gt;height);}派生类构造函数中应该覆盖基类中的虚指针vptr，指向自己的虚表(ShapeVtbl)对象vtbl虚函数调用（后绑定）通过统一接口实现不同派生类的虚函数实现的调用/* C99 */// 通过内联函数减少调用性能开销static inline uint32_t Shape_area(Shape const * const me) { return (*me-&amp;gt;vptr-&amp;gt;area)(me);}/* C89 */#define Shape_area(me_) ((*(me_)-&amp;gt;vptr-&amp;gt;area)((me_)))虚函数示例#include &quot;rect.h&quot; /* Rectangle class interface */#include &quot;circle.h&quot; /* Circle class interface */#include /* for printf() */int main(){ Rectangle r1, r2; /* multiple instances of Rectangle */ Circle c1, c2; /* multiple instances of Circle */ Shape const *shapes[] = {/* collection of shapes */ &amp;amp;c1.super, &amp;amp;r2.super, &amp;amp;c2.super, &amp;amp;r1.super}; Shape const *s; /* instantiate rectangles... */ Rectangle_ctor(&amp;amp;r1, 0, 2, 10, 15); Rectangle_ctor(&amp;amp;r2, -1, 3, 5, 8); /* instantiate circles... */ Circle_ctor(&amp;amp;c1, 1, -2, 12); Circle_ctor(&amp;amp;c2, 1, -3, 6); s = largestShape(shapes, sizeof(shapes) / sizeof(shapes[0])); printf(&quot;largetsShape s(x=%d,y=%d)\\n&quot;, Shape_getX(&amp;amp;s), Shape_getY(&amp;amp;s)); drawAllShapes(shapes, sizeof(shapes) / sizeof(shapes[0])); return 0;}将不同的派生类对象视为相同的类型，从而使用数组保存，并用相同的接口进行操作总结用C实现的多态较为复杂，最好还是使用语言层级支持OOP的C++参考 Key Concept:Object-Oriented Programming" }, { "title": "为ipv4 only设备添加ipv6支持", "url": "/posts/ipv6-over-ipv4/", "categories": "学习笔记", "tags": "ipv6-over-ipv4, tunnel", "date": "2022-08-08 09:00:00 +0800", "snippet": "HE-tunnel使用HE的IPv6隧道解决访问谷歌Google时提示异常流量CloudFlare-WARPWARP一键安装脚本安装sock代理或ipv6隧道WARP最强的地方在于网络环境非常好，远比HE-tunnel和Tor稳定Torapt install tor默认开启sock代理，端口9050，可通过修改/etc/tor/torrc文件修改端口如果无法连接tor服务器，需要修改/etc/tor/torrc文件添加代理参考 使用HE的IPv6隧道解决访问谷歌Google时提示异常流量 WARP一键安装脚本" }, { "title": "《UML 状态图的实用 C/C++设计》(QP状态机)学习笔记", "url": "/posts/quantum-platform-1/", "categories": "学习笔记", "tags": "quantum platform, QP状态机", "date": "2022-07-27 09:00:00 +0800", "snippet": " 架构 控制的倒置 (Inversion of Control) UML 状态机速成 基本的状态机概念 状态 状态图 事件 (Event) 动作和转换 (Action and Transition) 运行-到-完成执行模型 (Run-to-Completion Execution Model, RTC) UML 对传统 FSM 方法的扩展 状态机分类 行为继承 (Behavioral Inheritance) 状态的 LISKOV 替换原则 (LSP) 正交区域 进入和退出动作 (Entry and Exit Actions) 内部转换 (Internal Transistions) 转换的执行次序 本地转换和外部转换的对比 UML 里的事件类型 事件的延迟 (Event Deferral) 伪状态 (Pseudostates) UML 实例 设计一个 UML 状态机 高层设计 寻找重用 (Reuse) operandX 状态设计 处理负号的两种情况 最终状态图 标准状态机的实现方法 嵌套的 switch 语句 状态表 (State Table) 面向对象的状态设计模式 增加进入退出状态操作 封装事件处理 QEP FSM 实现方法 状态机实现技术的一般性讨论 层次式事件处理器的实现 层次式状态处理函数 层次式状态机的类 顶状态和初始伪状态 进入 / 退出动作和嵌套的初始转换 最顶层初始转换 (QHsm_init()) 分派事件（ QHsm_dispatch(), 通用结构） 在状态机里实施一个转换（ QHsm_dispatch(), 转换） 使用 QEP 实现 HSM 步骤的概要 常见问题 状态模式 终极钩子 提示器 延迟的事件 正交构件 转换到历史状态 实时框架的概念 CPU 管理 活动对象计算模式 系统结构 异步通讯 运行 - 到 - 完成 RTC 封装 事件派发机制 直接事件发送 订阅派发机制 事件内存管理 零复制的事件派发 静态和动态的事件 多路传输事件和引用计数器算法 事件的所有权 内存池 时间管理 系统时钟节拍 错误和例外的处理 C 和 C++ 里可定制的断言 基于框架的软件追踪 实时框架的实现 QF 实时框架的关键特征 QF 的结构 QF 源代码的组织 QF 里的临界区 保存和恢复中断状态 无条件上锁和解锁中断 中断上锁/解锁的内部 QF 宏 主动对象 活动对象的内部状态机 活动对象的事件队列 执行线程和活动对象优先级 QF 的事件管理 事件的结构 动态事件分配 自动垃圾收集 延迟和恢复事件 QF 的事件派发机制 直接事件发送 发行-订阅事件发送 时间管理 时间事件结构和接口 系统时钟节拍和 QF_tick() 函数 arming 和 disarm 一个时间事件 原生 QF 事件队列 QEQueue 结构 QEQueue 的初始化 原生 QF 活动对象队列 “ 原始的”线程安全的队列 原生 QF 内存池 原生 QF 内存池的初始化 从池里获得一个内存块 把一个内存块回收到池内 原生 QF 优先级集合 原生合作式 vanilla 内核 qvanilla.c 源文件 qvanilla.h 头文件 可抢占式“运行-到-完成”内核 选择一个可抢占式内核的理由 RTC 内核简介 使用单堆栈的可抢占式多任务处理 非阻塞型内核 同步抢占和异步抢占 堆栈的利用 和传统可抢占式内核的比较 QK 的实现 QK 源代码的组织 头文件 qk.h 中断的处理 源文件 qk_sched.c （ QK 调度器） 源文件 qk.c （ QK 的启动和空闲循环） 高级的 QK 特征 优先级天花板互斥体 本地线程存储 扩展的上下文切换（对协处理器的支持） 移植 QK 移植和配置 QF QP 平台抽象层 生成 QP 应用程序 创建 QP 库 目录和文件 头文件 qep_port.h 头文件 qf_port.h 源代码 qf_port.c 和平台相关的 QF 回调函数 系统时钟节拍（调用 QF_tick() ） 创建 QF 库 移植合作式 Vanilla 内核 头文件 qep_port.h 头文件 qf_port.h 系统时钟节拍（QF_tick()） 空闲处理（QF_onIdel()） QF 移植到 uc/os-II (常规 RTOS) QF 移植到 Linux （常规 POSIX 兼容的操作系统） 头文件 qep_port.h 头文件 qf_port.h qf_port.c 源代码 开发 QP 应用程序 开发 QP 应用程序的准则 准则 启发式 哲学家就餐问题 第一步：需求 第二步：顺序图 第三步：信号，事件和活动对象 第四步：状态机 第五步：初始化并启动应用程序 第六步：优雅的结束应用程序 在不同的平台运行 DPP 在 DOS 上的 Vanilla 内核 在 Cortex-M3 上的 Vanilla 内核 uC/OS-II Linux 调整事件队列和事件池的大小 调整事件队列的大小 调整事件池的大小 系统集成 事件驱动型系统的软件追踪 QS 目标系统驻留构件 QS 源代码的组织 QS 的平台无关头文件 qs.h 和 qs_dummy.h QS 的临界区 QS 记录的一般结构 QS 的过滤器 全局开/关过滤器 本地过滤器 QS 数据协议 透明 大小端 QS 追踪缓存区 初始化 QS 追踪缓存区 QS_initBuf() 面向字节的接口： QS_getByte() 面向块的接口： QS_getBlock() 字典追踪记录 应用程序相关的 QS 追踪记录 移植和配置 QS QSPY 主机应用程序 向 MATLAB 输出追踪数据 向 QP 应用程序添加 QS 软件追踪 定义平台相关的 QS 回调函数 使用回调函数 QS_onGetTime() 产生 QS 时间戳 从主动对象产生 QS 字典 添加应用程序相关的追踪记录 问题 参考架构QF 是一个轻量级实时框架，是 QP事件驱动平台的核心构件， QP 也包括了 QEP层次式事件处理器（在本书第一部分描叙），可抢占的RTC内核(QK)，和软件追踪装置(QS)。控制的倒置 (Inversion of Control)它和传统的顺序式编程方法例如“超级循环”，或传统的 RTOS 的任务不同。绝大多数的现代事件驱动型系统根据好莱坞原则被构造，“不要呼叫（调用）我们，我们会呼叫（调用）您”(Don’t call us, we will call you.)。因此，当它等待一个事件时，这个事件驱动型系统没有控制权。仅当一个事件到达了，程序才被调用去处理这个事件，然后它又很快的放弃控制权。这种安排允许这个事件驱动型系统同时等待许多事件，结果系统对所有需要处理的事件都能保持反应。 第一，它意味着一个事件驱动型系统被自然的分解到应用程序里面，由应用程序处理事件，而监督者是事件驱动的平台，由它等待事件并把它们分发给应用程序。 第二，控制存在于事件驱动平台的基础设施 (infrastructure) 中，因此从应用程序的角度看，和传统的顺序式程序相比，控制被倒置了。 第三，事件驱动型应用程序必须在处理完每个事件后交出控制权，因此和顺序式程序不同的是，运行时上下文和程序计数器不能被保留在基于堆栈的变量中。相反，事件驱动应用程序变成了一个状态机，或者实际上一组合作的状态机，并在静态变量里保留从一个事件到另一个事件的上下文。UML 状态机速成基本的状态机概念状态你不用许多变量、标志和复杂逻辑来记录事件历史，而主要依靠一个状态变量，它能被假定为一些有限的已经被确定的值，比如手机的勿扰模式包括了不播放声音、不震动、不自动亮屏等一些设置项，此时对于通知或者来电的处理和正常模式不一样，原来要判断很多设置项，现在只要判断是否是勿扰模式这一个状态就行。状态图 状态：圆角矩形 状态名：圆角矩形里的标签 状态转换：箭头 事件：箭头上的标签的/的前半部分，一般大写 动作：箭头上的标签的/的后半部分 初始转换：实心圆点加箭头事件 (Event)一个事件是对系统有重大意义的一个在时间和空间上所发生的事情。UML图中事件表示事件类型而不是实例，实际程序中判断的是事件类型实例化后的事件实例。动作和转换 (Action and Transition)从一个状态切换到另一个状态被称为状态转换，引发它的事件被称为触发事件 (triggering event) ，或简单的被称为触发 (trigger) 。运行-到-完成执行模型 (Run-to-Completion Execution Model, RTC)在 RTC 模型里，系统在分散的不可分割的 RTC 步骤里处理事件。新到的事件不能中断当前事件的处理，而且必须被存储（通常是存储在一个事件队列里），直到状态机又变成空闲。这些语义完全避免了在一个单一的状态机里的任何内部并发问题。实际上 RTC 步骤可以被抢占，只要抢占它的进程不会共享和该状态机相关的资源，抢占结束能恢复原始上下文就行。UML 对传统 FSM 方法的扩展状态机分类 有限状态机 (FSM) 行为的改变（例如，响应任何事件的改变）对应着状态改变，被称为状态转换。 扩展状态机(ESM) 事件的发生并不意味着状态改变，通过定量的方式，让事件发生达到监护条件（如次数）才改变状态。 监护条件 (Guard Condition)：为状态转换添加定量条件，如事件发送达到 1000 次条件才为真，才发生状态转换 层次式状态机(HSM) 子状态没有对应事件处理方法时，寻找父状态处理方法。不同的子状态复用了父状态的处理方法，类似于继承(抽象)包含其他状态的状态被称为复合状态 (composite state) ，相对的，没有内部结构的状态被称为简单状态 (simple state)。一个嵌套的状态当它没有被其他状态包含时被称为直接子状态 (direct substate)，否则，它被归类于过渡性嵌套子状态 (transitively nested substate) 。行为继承 (Behavioral Inheritance)复用父类处理方法，相当于 OOP 中继承父类函数状态的 LISKOV 替换原则 (LSP)一个子状态的行为应该和超状态一致。如果在状态 heating 意味着开启加热器，没有一个子状态（在不从状态 heating 转换出去的情况下）将会关闭加热器。关闭加热器并停留在 toasting 或 baking 状态就和在 heating 状态不一致，这说明它是一个（违反了 LSP ）的不良设计。正交区域计算机键盘的两个正交区域（主键区和数字键区）。当一个系统的行为被分解为独立的并发性的主动部分时，状态数目组合性增加，正交区域解决了这个常常碰到的问题。例如，除主键区外，一个计算机键盘有一个独立的数字键区。尽管正交区域意味着执行时的独立性（也就是说有一些并发性）， UML 规范没有要求为每一个正交区域分配一个独立的执行线程（尽管可以这样做）。事实上最普通的情况是，这些正交区域在同一个线程里执行。 UML 规范仅要求设计者在一个事件被派发到一些相关的正交区域时，不要依赖于任何特定的次序。进入和退出动作 (Entry and Exit Actions)UML 的状态图里的每个状态机都可以有可选的进入动作，它在进入一个状态时被执行；同时也可以有可选的退出动作，在退出一个状态时被执行。无论一个状态被以什么方法进入或退出，所有它的进入和退出动作将被执行。(自动强制执行)进入和退出动作的价值是它们提供了可担保的初始化和清理方法，非常像 OOP 里类的构造函数和析构函数如图，当炉门在打开时总是关闭加热器(heating状态退出动作)。另外当炉门被打开，应该点亮内部照明灯(door_open状态进入动作)。进入动作的执行必须总是按从最外层状态到最里层状态的次序被处理，如 DOOR_CLOSE 事件让状态变为 heating ，此时先执行 heater_on() ，再因初始转换自动进入子状态 toasting ，并执行 arm_time_event(me-&amp;gt;toast_color) 。类比于构造函数的调用顺序内部转换 (Internal Transistions)一个事件造成一些内部动作被执行但是又不导致一个状态的改变（状态转换），也不执行任何进入退出动作当你在键盘上打字时，它通过产生不同的字符码来响应。然而，除非你敲击CapsLock键，键盘的状态不会改变（没有状态转换发生）。 ANY_KEY 事件触发内部转换和自转换相反，在执行内部转换时不会执行进入和退出动作，即使内部转换是从一个超过当前活动状态较高层的层次继承的。从超状态继承的内部转换在任何的嵌套层都如同它们被直接在当前活动状态被定义一样执行。转换的执行次序如果状态机在一个复合状态（它也可以被包含在一个更高层的复合状态， 并递归嵌套）里面的叶状态，所有的直接或间接包含这个叶状态 (leaf state)的复合状态都是活动的。而且， 因为在这个层次里的一些复合状态也许有正交区域，当前活动状态事件代表了一个树，从在根部的单一顶状态开始往下直到在这个叶的单一简单状态。 UML 规范把这样一个状态树叫做状态配置 (state configuration)在 UML ，一个状态转换能直接连接任何两个状态。这两个状态也许是复合的状态，它们被定名一个转换的主源 (main source) 和主目标 (main target)。图 2.9 展示了一个简单的转换实例，并解释了在这个转换里的状态的角色。 UML 规范描叙了执行一个状态转换需要牵涉到以下的动作: 评估和转换联合的监护条件，如果监护条件为真则执行以下的步骤。 退出源状态配置。 执行和转换联合的动作。 进入到目的状态配置。在这个简单的实例里，主源和主目标在相同的层嵌套，因此这个转换序列很容易解释。例如，图 2.9 所示的转换 T1 引起监护条件 g() 的评估，假设监护条件 g() 被评估为真，后面是动作的执行序列： a() ； b() ； t() ； c() ； d() ； e() 。本书改动：本书描叙的 HSM实现（见第四章）通过进入到目标状态配置来维持必要的退出源结构的次序，但是完全在源状态的上下文里去执行和转换联合的动作。也就是说，在退出源状态配置之前执行。所实现的具体的转换序列如下： 评估和转换联合的监护条件，仅当监护条件为真，执行以下的步骤。 执行和转换联合的动作。 退出源状态配置并进入到目标状态配置。例如，图 2.9 所示的转换 T1 会引发对监护条件 g() 的评估；然后当对监护条件 g() 为真时是动作序列： t() ；a() ； b() ； c() ； d() ； e() 。就是先进行转换和对应动作，再退出源状态，因为退出源状态意味着清空了上下文，不退出就可以利用源状态的上下文信息做些事情本地转换和外部转换的对比 图中(a)上半：本地转换在主目标状态是主源状态的一个子状态时，并不会导致从主源状态的退出。 图中(a)下半：本地转换在主目标状态是主源状态的一个超状态时，不会导致退出和重新进入目标状态。 图中(b)上半：外部转换在主目标状态是主源状态的一个子状态时，导致退出和重新进入主源状态。 图中(b)下半：本地转换在主目标状态是主源状态的一个超状态时，导致退出和重新进入目标状态。 在本书第四章描叙的 HSM实现（以及本书第一版描叙的HSM实现）仅支持本地转换语义。UML 里的事件类型UML 规范定义了四种事件，通过具体的符号区分它们： signalEvent 代表一个特定的（异步）信号。它的格式是：信号名 ’(’ 逗号分开的变量表 ’)’ 。 TimeEvnt 对一个特定的最后期限建模。它用关键词 after 标识，后面是一个具体指明时间量的表达式。时间从进入到以 TimeEvnt为一个触发的状态开始计时。 callEvent 代表了同步地调用一个特定操作的请求。它的格式是：操作名 ’(’ 逗号分开的变量表 ’)’ 。 changeEvent 对一个明确的布尔表达式为真时出现的一个事件建模。它用关键词 when 标识，后面是一个布尔表达式。 本书描叙的 HSM 实现（见第四章）仅支持 SignalEvent 类型。第 2 部分描叙的实时框架增加了对 TimeEvent 类型的支持，但是 QF 里的 TimeEvent 需要明确的启动和解除，这和 UML 的 after 符号不兼容。因为 SignalEvent 多态性事件触发的固有的复杂性和非常高的性能开销，它也不被支持。事件的延迟 (Event Deferral)有时候，一个事件，在一个状态机正在某个状态中从而不能处理这个事件这种特别不方便的时刻到达。在很多情况下，事件的本性是它可以被（有限度的）推迟，直到系统进入到另一个状态，在那里它被更好的准备去处理这个原来的事件。UML 状态机提供了一个特定的机制，用来在状态里延迟事件。在每一个状态，你能包含一个 deferred / [event list]。如果在当前状态的延迟事件列表中的一个事件出现，这个事件会被保留（延迟）给将来处理，直到进入到一个没有把它放在自己的延迟事件列表中的状态。在进入这种状态时， UML 状态机将自动的恢复任何被保留的事件，不再延迟它们，而像它们刚刚到达一样处理它们。关联章节延迟的事件伪状态 (Pseudostates) 初始伪状态 (initial pseudostate)(显示为一个黑点)表示了一个初始转换的源。在一个复合状态里，可以有最多一个初始伪装态。从初始伪装态出发的转换可能有动作，但是没有触发或者监护条件。 选择伪状态 (choice pseudostate)(显示为一个菱形或空心圈)被用来进行动态条件分支。它允许转换的分裂到多个外向路径，因此决定使用哪一个路径取决于在相同的 RTC 步骤先前被执行的动作。 浅历史伪状态 (shallow-history pseudostate) 深历史伪状态 (deep-history pseudostate) 连接点伪状态 (junction pseudostate) 结合伪状态 (join pseudostate) 分支伪状态 (fork pseudostate) 只介绍两个常用的，其他的不做介绍UML 实例假想的 4 层嵌套状态机，包含了所有可能的状态转换拓扑，初始 me-&amp;gt;foo 为 0：状态切换，QHSMTST.EXE 实例程序运行在命令窗口。 在括号里的是供参照的行序号：(5) 当前状态为 s11，首先使用 s11 自带的 D 事件处理方法处理 D 事件，发现 D 的监护条件不满足，则转而执行 s11 父状态 s1 的 D 事件处理函数，发现监护条件满足。然后先退出 s11 到 s1，因为本次转换的源状态需要为 s1，然后切换到目标状态 s。因为 s 状态包含初始伪状态，需要执行初始伪状态对应的转换（见 伪状态 (Pseudostates)），所以会进入 s1 再进入 s11（虽然箭头直接指向 s11，但不能越过 s11 的进入动作）。 事件的表示 事件名称(类型) (可选)菱形分割 监护条件(判断条件，[]包裹) 分割号/ 动作 源状态(超状态有个黑点表示本状态，表示进入此状态时无条件自动进入目标状态，状态机不能处于超状态下) 目标状态 示例 1：I[me-&amp;gt;foo]/me-&amp;gt;foo=0，I为事件名称，[me-&amp;gt;foo]为监护条件，分割号/分割了事件信息和动作，me-&amp;gt;foo=0为动作。 示例 2：entry/，entry表示 entry 事件，没有对应的动作和监护条件；exit/，exit表示 exit 事件，没有对应的动作和监护条件 满足监护条件才会执行对应的状态转换和动作。子状态之间的状态转换需要源状态依次退出到双方的最小共同父状态(如 s11 和 s211 的最小共同父状态为 s，书中叫最少共同祖先 least common ancestor(LCA)，我觉得不太好理解)，再依次进入到目的标态设计一个 UML 状态机计算器（见图 2.13）总的来说操作如下：用户输入一个操作数 (operand) ，然后一个操作符 (operator)，然后另一个操作数，最后点击等号按钮得到一个结果。从编程的角度看，意味着这个计算器需要对由下面 BNF 语法定义的数字表达式进行语法分析expression ::= operand1 operator operand2 &#39;=&#39;operand1 ::= expression | [&#39;+&#39; | &#39;-&#39;] numberoperand2 ::= [&#39;+&#39; | &#39;-&#39;] numbernumber ::= {&#39;0&#39; | &#39;1&#39; | ... &#39;9&#39;}* [&#39;.&#39; {&#39;0&#39; | &#39;1&#39; | ... &#39;9&#39;}*]operator ::= &#39;+&#39; | &#39;-&#39; | &#39;*&#39; | &#39;/&#39;高层设计(A)的问题是没有结果显示状态(result)，完善后得到(B)，可以在开始下一次输入 operand1 前清空屏幕，还可以将结果作为下一次的 operand1 把信号 PLUS ，MINUS， MULTIPLY 和 DIVIDE 合并成一个高级的信号 OPER （操作数）。这个变换避免了在两个转换（从 operand1 到 opEntered，和从 result 到 opEntered）上重复相同的触发（这里的意思应该就是简化设计，不然要画4条箭头）。寻找重用 (Reuse)为了保证能在任意状态执行 Clear 初始化和关机，需要很多状态转换。此时可以提取一个超状态，初始化操作和关机操作放到超状态（图中(B)），让子状态重用该操作，这里就利用了层次式状态机operandX 状态设计三个入口： 输入 0 事件 – zeroX 状态 输入 1-9 事件 – intX 状态 输入小数点事件 – fracX 状态三个状态： zeroX 忽略输入 0 事件 其他事件产生状态切换 intX 处理输入 0-9 事件 输入小数点事件产生状态切换 fracX 处理输入 0-9 事件 忽略输入小数点事件 处理负号的两种情况如表达式 -2 * -2 =添加两个和 operandX 同级的状态 negated1 和 negated2 用于处理数字前的负号，和 zeroX 状态类似(A) 为第二个操作数添加负号，opEntered状态下收到 OPER 事件，判断监护条件按键是否是’-‘，是的话进入negated2状态，该状态仅处理数字和小数点。(B) 为第一个操作数添加负号，opEntered状态下收到 OPER 事件，判断监护条件按键是否是’-‘，是的话进入negated1状态，该状态仅处理数字和小数点。最终状态图标准状态机的实现方法定时炸弹有一个带有LCD的控制面板显示当前的超时值，还有三个按钮： UP ，DOWN 和 ARM 。用户开始时要设定时炸弹，使用 UP 和 DOWN 按钮以一秒的步长调节超时值。一旦所需要的超时值被选中，用户能通过按 ARM 按钮来启动这个炸弹。当启动后，炸弹开始每秒递减这个超时值， 并在超时值到达零时爆炸。附加的安全特征是通过输入一个密码来拆除一个已启动的定时炸弹雷管的选项。拆雷管的密码是 UP 和 DOWN 按钮的某个组合，并以 ARM 按钮被按下结束。当然，拆雷管的密码必须在炸弹超时前被正确的输入。定时炸弹状态机的 UML 状态图:嵌套的 switch 语句void Bomb1_dispatch(Bomb1 *me, Event const *e) { /* dispatching */ switch (me-&amp;gt;state) { case SETTING_STATE: { switch (e-&amp;gt;sig) { case UP_SIG: { /* internal transition with a guard */ ...} } ... } case TIMING_STATE: { switch (e-&amp;gt;sig) { case UP_SIG: { me-&amp;gt;code &amp;lt;&amp;lt;= 1; me-&amp;gt;code |= 1; break; } ... } ... } ... }}状态表 (State Table) 当前状态 事件 ( 参数 ) [ 监护条件 ] 下一状态 动作 setting UP [me-&amp;gt;timeout &amp;lt; 60] setting ++me-&amp;gt;timeout;BSP_display(me-&amp;gt;timeout);   DOWN [me-&amp;gt;timeout &amp;gt; 1] setting –me-&amp;gt;timeout;BSP_display(me-&amp;gt;timeout);   ARM   timing me-&amp;gt;code = 0;   TICK   setting   timing UP   timing me-&amp;gt;code «=1;me-&amp;gt;code = 1;   DOWN   timing me-&amp;gt;code «= 1;   ARM [me-&amp;gt;code == me-&amp;gt;defuse] setting     TICK(fine_time) [e-&amp;gt;fine_time == 0] choice –me-&amp;gt;timeout;BSP_display(me-&amp;gt;timeout);     [me-&amp;gt;timeout == 0] final BSP_boom();     [else] timing   面向对象的状态设计模式用到了多态，使用 C++实现更为简单正常来说 BombState 被定义为抽象类，应该包含至少一个纯虚函数，不过此处没有，应该是为了让子类继承父类中虚函数的空实现。增加进入退出状态操作Bomb 类的 onTick()操作不仅调用了 BombState 状态或是子状态的 onTick 事件处理，还检测了状态是否切换，并执行对应的退出和进入动作封装事件处理封装了状态中的事件处理函数，这就导致需要在封装函数内使用switch区分事件并执行操作。坏处是失去了 C++提供的多态性好处是在添加新事件时只需修改函数内内容，无需增加函数定义QEP FSM 实现方法在前面的几节里，提供了实现 FSM 的三种最流行的技术。可是从我的经验来说，单独使用它们时没有一个是最优的本章只介绍 FSM 的实现，HSM 层次式状态机的在下一章通用的 QEP 事件处理器：QEP（事件处理器）设计的创新性来自于把状态直接映射成状态处理函数，处理在状态里它们表示的全部事件/* qevent.h ----------------------------------------------------------------*/typedef struct QEventTag{ /* the event structure */ // 一个整数，相当于事件唯一标识，方便switch...case...区分事件 QSignal sig; /* signal of the event */ uint8_t dynamic_; /* dynamic attribute of the event (0 for static) */} QEvent; // 事件，可派生添加参数/* qep.h -------------------------------------------------------------------*/// 事件处理对事件处理的状态typedef uint8_t QState; /* status returned from a state-handler function */// 状态处理函数指针，本设计中状态处理函数就表示状态，有typedef表示指定它的类型为QState，// 相当于一种声明，而非定义产生实例typedef /* pointer to function type definition */ QState /* return type */ (*QStateHandler) /* name of the pointer-to-function type */ (void *me, QEvent const *e); /* argument list */ // 一个通用状态机的指针和一个 QEvent指针typedef struct QFsmTag{ /* Finite State Machine */ // 当前处于的状态，指向状态处理函数 QStateHandler state; /* current active state */} QFsm; // 派生各个状态机结构的基本类#define QFsm_ctor(me_, initial_) ((me_)-&amp;gt;state = (initial_))// 触发状态机的初始转换void QFsm_init(QFsm *me, QEvent const *e);// 派发一个事件给状态机void QFsm_dispatch(QFsm *me, QEvent const *e);// 从状态处理函数到事件处理器的返回状态#define Q_RET_HANDLED ((QState)0)#define Q_RET_IGNORED ((QState)1)#define Q_RET_TRAN ((QState)2)// 一个状态处理函数，每当它处理了当前的事件时，返回宏 Q_HANDLED( ) 。#define Q_HANDLED() (Q_RET_HANDLED)// 一个状态处理函数，每当它忽略（不处理）当前的事件时，返回宏 Q_IGNORED( )#define Q_IGNORED() (Q_RET_IGNORED)// 逗号表达式表示执行逗号前语句，但整个表达式的值为逗号后变量，优先级比&#39;=&#39;更低，// 先执行((QFsm *)me)-&amp;gt;state = (QStateHandler)(target_)，但Q_TRAN(target_)值为Q_RET_TRAN// 这里可以用(QFsm *)强制转换me是因为派生类me的第一个成员变量就是它的父类QFsm实例，内存起始位置和me一样#define Q_TRAN(target_) \\ (((QFsm *)me)-&amp;gt;state = (QStateHandler)(target_), Q_RET_TRAN)// 内部使用的信号// QEP内部维护一个不变的保留事件数组 QEP_reservedEvt_[ ]。用于保存信号对应的事件enum QReservedSignals{ Q_ENTRY_SIG = 1, /* signal for coding entry actions */ Q_EXIT_SIG, /* signal for coding exit actions */ Q_INIT_SIG, /* signal for coding initial transitions */ Q_USER_SIG /* first signal that can be used in user applications */};QEP FSM 事件处理器的实现:/* file qfsm_ini.c ---------------------------------------------------------*/#include &quot;qep_port.h&quot; /* the port of the QEP event processor */#include &quot;qassert.h&quot; /* embedded systems-friendly assertions */void QFsm_init(QFsm *me, QEvent const *e){ // 执行QFsm超状态的状态处理函数，就是init (*me-&amp;gt;state)(me, e); /* execute the top-most initial transition */ // 进入目的状态，手动指定状态切换事件(用信号Q_ENTRY_SIG指定)，并处理状态切换事件 // QEP内部维护一个不变的保留事件数组 QEP_reservedEvt_[ ]。用于保存信号对应的事件 (void)(*me-&amp;gt;state)(me, &amp;amp;QEP_reservedEvt_[Q_ENTRY_SIG]);/* enter the target */}/* file qfsm_dis.c ---------------------------------------------------------*/// 事件生成函数void QFsm_dispatch(QFsm *me, QEvent const *e){ // 在栈空间中临时保存，防止执行事件处理函数切换状态后丢失源状态 QStateHandler s = me-&amp;gt;state; /* save the current state */ // 调用当前状态中对应的事件处理函数 QState r = (*s)(me, e); /* call the event handler */ if (r == Q_RET_TRAN) // 执行事件处理函数后发生了状态转换 { /* transition taken? */ // 退出源状态，调用源状态的事件处理函数（发送信号Q_EXIT_SIG） (void)(*s)(me, &amp;amp;QEP_reservedEvt_[Q_EXIT_SIG]); /* exit the source */ // 进入目的状态，调用目的状态的事件处理函数（发送信号Q_ENTRY_SIG） (void)(*me-&amp;gt;state)(me, &amp;amp;QEP_reservedEvt_[Q_ENTRY_SIG]); /*enter target*/ }}应用程序相关的代码(定时炸弹实例):#include &quot;qep_port.h&quot; /* the port of the QEP event processor */#include &quot;bsp.h&quot; /* board support package */// 内部使用的信号enum BombSignals{ /* all signals for the Bomb FSM */ UP_SIG = Q_USER_SIG, DOWN_SIG, ARM_SIG, TICK_SIG};// 继承自QEvent的Tick事件typedef struct TickEvtTag{ QEvent super; /* derive from the QEvent structure */ uint8_t fine_time; /* the fine 1/10 s counter */} TickEvt;// 继承自QFsm的状态机，增加了自定义的一些参数typedef struct Bomb4Tag{ QFsm super; /* derive from QFsm */ uint8_t timeout; /* number of seconds till explosion */ //倒计时 uint8_t code; /* currently entered code to disarm the bomb */ //密码输入值 uint8_t defuse; /* secret defuse code to disarm the bomb */ //密码} Bomb4;// 后面是不是就是检测到事件时调用me-&amp;gt;state(me,e)就行void Bomb4_ctor(Bomb4 *me, uint8_t defuse); // 初始化（类似C++的构造函数）QState Bomb4_initial(Bomb4 *me, QEvent const *e); // 入口QState Bomb4_setting(Bomb4 *me, QEvent const *e); // setting状态事件处理函数QState Bomb4_timing(Bomb4 *me, QEvent const *e); // timing状态事件处理函数/*--------------------------------------------------------------------------*//* the initial value of the timeout */#define INIT_TIMEOUT 10/*..........................................................................*/void Bomb4_ctor(Bomb4 *me, uint8_t defuse){ QFsm_ctor_(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;Bomb4_initial); me-&amp;gt;defuse = defuse; /* the defuse code is assigned at instantiation */}/*..........................................................................*/QState Bomb4_initial(Bomb4 *me, QEvent const *e){ (void)e; me-&amp;gt;timeout = INIT_TIMEOUT; return Q_TRAN(&amp;amp;Bomb4_setting); //切换到setting}/*..........................................................................*/QState Bomb4_setting(Bomb4 *me, QEvent const *e){ // 使用switch区分事件，这里是用了QEvent中的一个整数变量sig，相当于事件唯一标识， // 因为switch只支持int整数，不支持结构体 switch (e-&amp;gt;sig) { case UP_SIG: { if (me-&amp;gt;timeout &amp;lt; 60) { ++me-&amp;gt;timeout; BSP_display(me-&amp;gt;timeout); } return Q_HANDLED();// 不切换状态就返回Q_HANDLED() } case DOWN_SIG: { if (me-&amp;gt;timeout &amp;gt; 1) { --me-&amp;gt;timeout; BSP_display(me-&amp;gt;timeout); } return Q_HANDLED(); } case ARM_SIG: { // 需要切换状态就使用Q_TRAN return Q_TRAN(&amp;amp;Bomb4_timing); /* transition to &quot;timing&quot; */ } } return Q_IGNORED();// 没有对应事件就返回Q_IGNORED()}/*..........................................................................*/void Bomb4_timing(Bomb4 *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { me-&amp;gt;code = 0; /* clear the defuse code */ return Q_HANDLED(); } case UP_SIG: { me-&amp;gt;code &amp;lt;&amp;lt;= 1; me-&amp;gt;code |= 1; return Q_HANDLED(); } case DOWN_SIG: { me-&amp;gt;code &amp;lt;&amp;lt;= 1; return Q_HANDLED(); } case ARM_SIG: { if (me-&amp;gt;code == me-&amp;gt;defuse) { return Q_TRAN(&amp;amp;Bomb4_setting); } return Q_HANDLED(); } case TICK_SIG: { // 拿派生事件的自定义参数也没问题 if (((TickEvt const *)e)-&amp;gt;fine_time == 0) { --me-&amp;gt;timeout; BSP_display(me-&amp;gt;timeout); if (me-&amp;gt;timeout == 0) { BSP_boom(); /* destroy the bomb */ } } return Q_HANDLED(); } } return Q_IGNORED();}状态机实现技术的一般性讨论 函数指针是使用 C/C++ 实现状态机时最快的途径。状态函数可以放在 ROM 里，RAM 里只需存指针。 C++语言里，异常抛出和捕捉例外和状态机的运行到完成 (RTC) 语义基本上不相容。因为破坏了事件处理的原子性 监护条件和选择伪状态的实现就是把return Q_TRAN()改为条件判断函数，将切换状态的任务交给该函数 QFsm_dispatch实现状态切换的方式是发送EXIT和ENTER事件(信号)给对应状态，这样状态可以在进入和退出时做一些事情，如初始化某些值，相关状态只需要在事件处理函数中实现对这类事件的处理。层次式事件处理器的实现下面只介绍和 FSM 实现不同的地方层次式状态处理函数一个层次式状态处理函数QStateHandler必须特别通知事件处理器有关状态嵌套层次的信息。当一个层次式状态处理函数不处理当前的事件，它返回一个宏 Q_SUPER()给事件处理器，定义如下:#define Q_RET_SUPER ((QState)3)#define Q_SUPER(super_) \\ (((QHsm *)me)-&amp;gt;state = (QStateHandler)(super_), Q_RET_SUPER)FSM 里不处理是返回Q_RET_IGNORED，因为没有超状态去处理它，HSM 里就需要返回Q_RET_SUPERQState Calc_int1(Calc *me, QEvent const *e){ switch (e-&amp;gt;sig) { case DIGIT_0_SIG: /* intentionally fall through */ case DIGIT_1_9_SIG: { BSP_insert(((CalcEvt const *)e)-&amp;gt;key_code); return Q_HANDLED(); } case POINT_SIG: { BSP_insert(((CalcEvt const *)e)-&amp;gt;key_code); return Q_TRAN(&amp;amp;Calc_frac1); } } return Q_SUPER(&amp;amp;Calc_operand1);}层次式状态机的类QHsm 类C 语言版本：typedef struct QHsmTag{ QStateHandler state; /* current active state (state-variable) */} QHsm; // 这里和FSM一样，事件处理函数的指针#define QHsm_ctor(me_, initial_) ((me_)-&amp;gt;state = (initial_))void QHsm_init(QHsm *me, QEvent const *e);// 分派事件void QHsm_dispatch(QHsm *me, QEvent const *e);// 测试HSM是否“在”一个给定的状态内，超状态包括子状态uint8_t QHsm_isIn(QHsm *me, QHsmState state);/** * 函数QHsm_top( )是顶状态的层次式状态处理函数。 * 顶状态是 UML 的概念，表示状态层次的最终根。 * 顶状态处理函数对每一个事件的处理方法是静静的忽略它， * 这是 UML 的默认方法 */QState QHsm_top(QHsm *me, QEvent const *e);c 语言版本的不太直观，没有反应出继承关系，建议看 C++版本的C++版本：class QHsm{protected: QStateHandler m_state; // current active state (state-variable)public: void init(QEvent const *e = (QEvent const *)0); void dispatch(QEvent const *e); uint8_t isIn(QHsmState state);protected: QHsm(QStateHandler initial) : m_state(initial) {} // protected ctor static QState top(QHsm *me, QEvent const *e);};其中top函数就是 C 版本中的QHsm_top，这里用了静态类型，这样子类继承后所有对象共享相同的 top 函数，也可以防止被重载。且 static 成员变量或函数在基类和派生类中是共用空间的，可以节省空间除此之外的其他成员函数都是需要重载的顶状态和初始伪状态每一个 HSM 都有（典型的是隐含）顶状态 top，它围绕着整个状态机的全部其他元素QHsm 类通过提供 QHsm_top() 层次式状态处理函数，然后由子类来继承它，从而确保顶状态对每一个派生的状态机都是可用的。 QHsm_top() 层次式状态处理函数定义如下：// protected型的静态成员函数，子类都可调用，一般在子类处理事件时如果没有找到对应处理方式时调用QState QHsm_top(QHsm *me, QEvent const *e){ // 避免编译器报未使用参数的警告，空引用一下 (void)me; /* avoid the compiler warning about unused parameter */ (void)e; /* avoid the compiler warning about unused parameter */ // 顶状态可以理解为一个虚状态，不做任何事，所以忽略掉事件 return Q_IGNORED(); /* the top state ignores all events */}状态机的初始化被特意分为 2 步。 QHsm 构造函数仅仅把状态变量初始化成初始伪状态。然后，应用程序代码必须通过调用QHsm_init()明确的触发初始转换。这个设计分割了状态机的实例化和初始化，让用户程序对系统的初始化顺序有完全的控制。下一节有详细描述以下代码展示了计算器状态机的一个初始伪状态处理函数的例子：QState Calc_initial(Calc *me, QEvent const *e){ (void)e; /* avoid the compiler warning about unused parameter */ BSP_clear(); /* clear the calculator display */ // 初始化后必须转换到默认子状态的操作 return Q_TRAN(&amp;amp;Calc_on); /* designate the default state */}非叶子状态才有初始伪状态，离开状态再次进入会触发初始化进入 / 退出动作和嵌套的初始转换enum QReservedSignals { Q_ENTRY_SIG = 1, /* signal for coding entry actions */ Q_EXIT_SIG, /* signal for coding exit actions */ Q_INIT_SIG, /* signal for coding initial transitions */ Q_USER_SIG /* first signal that can be used in user code */};状态处理函数能够通过把它们放在在 switch 语句的 case 后作为标签来处理它们。状态处理函数可以任意执行任何动作去响应这些信号限制条件： 进入动作Q_ENTRY_SIG和退出动作Q_EXIT_SIG中不能做任何状态转换 初始化动作Q_INIT_SIG必须包括 Q_TRAN() 宏来转换到当前状态的默认子状态。嵌套的初始转换必须“钻进”状态层次(直接或间接的子状态)，但是不能“上升” 到目标超状态，或“绕道”到同级状态。QState Calc_on(Calc *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { /* entry action */ BSP_message(&quot;on-ENTRY;&quot;); return Q_HANDLED(); } case Q_EXIT_SIG: { /* exit action */ BSP_message(&quot;on-EXIT;&quot;); return Q_HANDLED(); } case Q_INIT_SIG: { /* nested initial transition */ BSP_message(&quot;on-INIT;&quot;); // 初始化后必须转换到子状态 return Q_TRAN(&amp;amp;Calc_ready); } case C_SIG: { BSP_clear(); return Q_TRAN(&amp;amp;Calc_on); } case OFF_SIG: { return Q_TRAN(&amp;amp;Calc_final); } } // 无法处理时使用超状态处理 return Q_SUPER(&amp;amp;QHsm_top);}保留的信号占用最低的信号值（ 0…3,进入退出和初始化），它们不能被应用程序使用。为了方便，公开的 HSM 接口包含了信号 Q_USER_SIG ，这是用户可以使用的第一个信号值。一个典型的定义应用程序级信号的方法是使用一个新的枚举值。这样 Q_USER_SIG 能被用于偏移全部新的枚举量最顶层初始转换 (QHsm_init()) 执行和最顶层转换关联的动作 执行进入动作到达默认子状态 on 执行由状态 on 定义的和初始转换关联的动作 执行进入动作到达默认子状态 ready 执行由状态 ready 定义的和初始转换关联的动作，进入 begin 执行和状态 begin 关联的进入动作。在这一刻，转换已经完成，因为 begin 是没有嵌套的初始转换的叶状态。树状继承结构的优势是从叶节点返回到上层节点(如 top)很容易，但从上层节点进入到指定的目的节点却很复杂，因为要遍历寻找叶节点的父节点QEP 里的解决方法是使用一个临时的数组 path[] 记录从初始状态的目标状态开始的退出路径而不执行任何动作（见图 4.4 ）。通过使用保留的 QEP_EMPTY_SIG_ 信号来调用状态处理函数，令每一个状态处理函数不执行任何动作就立刻返回超状态。返回的路径被保存在 path[] 数组。在到达当前的状态后， path[] 数组被回访，精确的沿着它被退出的相反次序进入目标状态使用 path[] 数组沿着正确的次序进入目标状态配置:#define QEP_TRIG_(state_, sig_) \\ ((*(state_))(me, &amp;amp;QEP_reservedEvt_[sig_]))#define QEP_EXIT_(state_) \\ if (QEP_TRIG_(state_, Q_EXIT_SIG) == Q_RET_HANDLED) { \\ /* QS software tracing instrumentation for state entry */\\ }#define QEP_ENTER_(state_) \\ if (QEP_TRIG_(state_, Q_ENTRY_SIG) == Q_RET_HANDLED) { \\ /* QS software tracing instrumentation for state exit */\\ }void QHsm_init(QHsm *me, QEvent const *e){ QStateHandler t; /* the top-most initial transition must be taken */ // 初始伪状态产生的初始转换（只改了state没有执行对应进入动作） Q_ALLEGE((*me-&amp;gt;state)(me, e) == Q_RET_TRAN); // 临时保存源状态t（第一次为top） t = (QStateHandler)&amp;amp;QHsm_top; /* HSM starts in the top state */ do { /* drill into the target... */ QStateHandler path[QEP_MAX_NEST_DEPTH_]; int8_t ip = (int8_t)0; /* transition entry path index */ // 临时存下目的状态，同时作为路径起点，前面做过状态转换，me-&amp;gt;state已经是目的状态了 path[0] = me-&amp;gt;state; /* save the target of the initial transition */ // 返回到超状态，利用QEP_EMPTY_SIG_信号 (void)QEP_TRIG_(me-&amp;gt;state, QEP_EMPTY_SIG_); // 直到回退到源状态t，这里都只是修改state没有触发进入退出动作 while (me-&amp;gt;state != t) { // 保存路径 path[++ip] = me-&amp;gt;state; // 不断返回超状态，直到到达源状态 (void)QEP_TRIG_(me-&amp;gt;state, QEP_EMPTY_SIG_); } // 路径记录完把状态恢复为目的状态(只改了state没有执行对应进入动作) me-&amp;gt;state = path[0]; /* restore the target of the initial tran. */ /* entry path must not overflow */ Q_ASSERT(ip &amp;lt; (int8_t)QEP_MAX_NEST_DEPTH_); do {/* retrace the entry path in reverse (desired) order... */ // 反向遍历路径，从源状态一层层进入目的状态（处理ENTER信号） QEP_ENTER_(path[ip]); /* enter path[ip] */ } while ((--ip) &amp;gt;= (int8_t)0); // 临时保存源状态t（就是本循环一开始的目的状态，在下个循环里就是源状态了） // 现在来看是等于me-&amp;gt;state的，因为上面也给me-&amp;gt;state赋值了 t = path[0]; /* current state becomes the new source */ // 如果本次循环抵达的目的状态不是叶状态，还要继续深入 } while (QEP_TRIG_(t, Q_INIT_SIG) == Q_RET_TRAN); // 直到当前状态为叶状态 me-&amp;gt;state = t;} QEP 内定义的断言宏： Q_REQUIRE()，断言一个前置条件 Q_ENSURE() ，断言一个后置条件 Q_INVARIANT() ，断言一个不变量 Q_ASSERT() ，断言一个其他类型的一般性契约 Q_ALLEGE，断言一个一般性的契约，而且即使在编译时间断言被禁止了也评估当前的情况。 分派事件（ QHsm_dispatch(), 通用结构）void QHsm_dispatch(QHsm *me, QEvent const *e){ QStateHandler path[QEP_MAX_NEST_DEPTH_]; QStateHandler s;// source源状态 QStateHandler t;// target目的状态 QState r; // 临时保存当前状态，后面作为源状态 t = me-&amp;gt;state; /* save the current state */ // 执行对应状态事件处理函数，如果返回Q_RET_SUPER说明交给了超状态处理， // 此时继续执行，直到某个超状态处理了该事件 do { /* process the event hierarchically... */ s = me-&amp;gt;state; r = (*s)(me, e); /* invoke state handler s */ } while (r == Q_RET_SUPER); // 当需要转换状态时，源状态必须为处理该事件的状态， // 所以如果处理事件的状态为超状态而非当前状态， // 当前状态必须切换为该超状态，也就是返回到该超状态 if (r == Q_RET_TRAN) { /* transition taken? */ int8_t ip = (int8_t)(-1); /* transition entry path index */ int8_t iq; /* helper transition entry path index */ // 路径0赋值为目的状态 path[0] = me-&amp;gt;state; /* save the target of the transition */ // 路径1赋值为源状态 path[1] = t; // s状态就是实际处理了该事件的状态 // s状态可能是源状态，也可能是源状态的某个超状态 // 如果当前状态不为s状态时，当前状态退出直到s状态 while (t != s) { /* exit current state to transition source s... */ // 退出源状态 if (QEP_TRIG_(t, Q_EXIT_SIG) == Q_RET_HANDLED) { /*exit handled? */ // 退出成功时返回到超状态 (void)QEP_TRIG_(t, QEP_EMPTY_SIG_); /* find superstate of t */ } // t赋值为该超状态 t = me-&amp;gt;state; /* me-&amp;gt;state holds the superstate */ } // 最后t==s，执行状态切换动作（下一节讲） ... } me-&amp;gt;state = t; /* set new state or restore the current state */}对if (r == Q_RET_TRAN)的解释：当需要转换状态时，源状态必须为处理该事件的状态，所以如果处理事件的状态为超状态而非当前状态，当前状态必须切换为该超状态，也就是返回到该超状态本图中 result 收到的 OPER 事件被交给 ready 处理，ready 对事件的处理需要转换状态到 opEntered，所以必须将当前状态转变为 ready，也就是退出 result(此时不触发 ready 的 init，可以不把这个操作理解成标准的状态切换，因为本身 ready 也是临时状态，马上要切换成其他状态了)，然后触发状态切换从 ready 到 opEntered在状态机里实施一个转换（ QHsm_dispatch(), 转换）上一节是找路径，这一节是沿着路径做转换在 HSM 里执行一个通用的状态转换，到目前为止是 QEP 实现的最复杂的部分。挑战是最快的找到源状态和目标状态的最少共同祖先 (LCA) 状态。 (LCA 是同时源状态和目标状态的超状态里的最低层次的状态 ) 。然后转换序列牵涉到所有状态的退出动作，向上到达LCA（但是不退出 LCA本身），然后是递归的进入到目标状态，然后使用初始转换“钻入”到目标状态配置，直到到达一个叶状态为止。 h: 子状态到超状态的超状态/* NOTE: 上一节代码省略部分 */// 路径0保存了目的状态，给t赋值，t等于me-&amp;gt;statet = path[0]; /* target of the transition */// 如果源状态等于目的状态，相当于自转换，情况(a)适用if (s == t){ /* (a) check source==target (transition to self) */ QEP_EXIT_(s) /* exit the source */ ip = (int8_t)0; /* enter the target */}else{ // t(等于当前状态me-&amp;gt;state)退出到超状态 // 使用t作为参数，会忽略me-&amp;gt;state原有值，执行后强制赋值， // 如此处给空信号返回超状态，me-&amp;gt;state强制赋值为t的超状态 (void)QEP_TRIG_(t, QEP_EMPTY_SIG_); /* superstate of target */ // 为t赋值当前状态（目的状态的超状态） t = me-&amp;gt;state; // 情况(b)，目的状态的超状态为源状态，超状态进入子状态（源状态不用退出） if (s == t) { /* (b) check source==target-&amp;gt;super */ ip = (int8_t)0; /* enter the target */ } else { // 退出到s的超状态，为me-&amp;gt;state强制赋值 (void)QEP_TRIG_(s, QEP_EMPTY_SIG_); /* superstate of src */ /* (c) check source-&amp;gt;super==target-&amp;gt;super */ // 情况(c)，源状态的超状态等于目的状态的超状态 if (me-&amp;gt;state == t) { QEP_EXIT_(s) /* exit the source */ ip = (int8_t)0; /* enter the target */ } else { /* (d) check source-&amp;gt;super==target */ // 情况(d)，源超状态等于目的状态 if (me-&amp;gt;state == path[0]) { QEP_EXIT_(s) /* exit the source */ } else { /* (e) check rest of source==target-&amp;gt;super-&amp;gt;super.. * and store the entry path along the way */ iq = (int8_t)0; /* indicate that LCA not found */ ip = (int8_t)1; /* enter target and its superstate */ path[1] = t; /* save the superstate of target */ t = me-&amp;gt;state; /* save source-&amp;gt;super */ /* find target-&amp;gt;super-&amp;gt;super */ r = QEP_TRIG_(path[1], QEP_EMPTY_SIG_); while (r == Q_RET_SUPER) { path[++ip] = me-&amp;gt;state; /* store the entry path */ if (me-&amp;gt;state == s) { /* is it the source? */ iq = (int8_t)1; /* indicate that LCA found */ /* entry path must not overflow */ Q_ASSERT(ip &amp;lt; (int8_t)QEP_MAX_NEST_DEPTH_); --ip; /* do not enter the source */ r = Q_RET_HANDLED; /* terminate the loop */ } else { /* it is not the source, keep going up */ r = QEP_TRIG_(me-&amp;gt;state, QEP_EMPTY_SIG_); } } if (iq == (int8_t)0) { /* the LCA not found yet? */ /* entry path must not overflow */ Q_ASSERT(ip &amp;lt; (int8_t)QEP_MAX_NEST_DEPTH_); QEP_EXIT_(s) /* exit the source */ /* (f) check the rest of source-&amp;gt;super * == target-&amp;gt;super-&amp;gt;super... */ iq = ip; r = Q_RET_IGNORED; /* indicate LCA NOT found */ do { if (t == path[iq]) { /* is this the LCA? */ r = Q_RET_HANDLED; /* indicate LCA found */ ip = (int8_t)(iq - 1); /*do not enter LCA*/ iq = (int8_t)(-1); /* terminate the loop */ } else { --iq; /* try lower superstate of target */ } } while (iq &amp;gt;= (int8_t)0); if (r != Q_RET_HANDLED) { /* LCA not found yet? */ /* (g) check each source-&amp;gt;super-&amp;gt;... * for each target-&amp;gt;super... */ r = Q_RET_IGNORED; /* keep looping */ do { /* exit t unhandled? */ if (QEP_TRIG_(t, Q_EXIT_SIG) == Q_RET_HANDLED) { (void)QEP_TRIG_(t, QEP_EMPTY_SIG_); } t = me-&amp;gt;state; /* set to super of t */ iq = ip; do { if (t == path[iq]) { /* is this LCA? */ /* do not enter LCA */ ip = (int8_t)(iq - 1); iq = (int8_t)(-1); /*break inner */ r = Q_RET_HANDLED; /*break outer */ } else { --iq; } } while (iq &amp;gt;= (int8_t)0); } while (r != Q_RET_HANDLED); } } } } }}/* retrace the entry path in reverse (desired) order... */for (; ip &amp;gt;= (int8_t)0; --ip){ QEP_ENTER_(path[ip]) /* enter path[ip] */}t = path[0]; /* stick the target into register */me-&amp;gt;state = t; /* update the current state */ /* drill into the target hierarchy... */while (QEP_TRIG_(t, Q_INIT_SIG) == Q_RET_TRAN){ ip = (int8_t)0; path[0] = me-&amp;gt;state; (void)QEP_TRIG_(me-&amp;gt;state, QEP_EMPTY_SIG_); /* find superstate */ while (me-&amp;gt;state != t) { path[++ip] = me-&amp;gt;state; (void)QEP_TRIG_(me-&amp;gt;state, QEP_EMPTY_SIG_); /*find superstate*/ } me-&amp;gt;state = path[0]; /* entry path must not overflow */ Q_ASSERT(ip &amp;lt; (int8_t)QEP_MAX_NEST_DEPTH_); do { /* retrace the entry path in reverse (correct) order... */ QEP_ENTER_(path[ip]) /* enter path[ip] */ } while ((--ip) &amp;gt;= (int8_t)0); t = path[0];}使用 QEP 实现 HSM 步骤的概要计算器认识的按键是： 0 ， 1-9 ， . ， + ， - ， * ， / ， = ， C 和 E(cancel entry CE) 。ESC 按键终止程序。其他别的按键会被忽略。 枚举信号，如 C， CE ， DIGIT_0 ， DIGIT_1_9 等待 定义事件，如OPER_SIG信号对应按下+ ， - ， * ， / 的四个事件，事件参数在 key_code 变量中 struct CalcEvt : public QEvent { uint8_t key_code;}; 派生特定的状态机 class Calc : public QHsm{private: double m_operand1; // the value of operand 1 (extended state variable) uint8_t m_operator; // operator key entered (extended state variable)public: Calc() : QHsm((QStateHandler)&amp;amp;Calc::initial) { // ctor }protected: // 声明为静态,如果有扩展派生类也能共享 static QState initial(Calc *me, QEvent const *e); // initial pseudostate static QState on(Calc *me, QEvent const *e); // state handler static QState error(Calc *me, QEvent const *e); // state handler static QState ready(Calc *me, QEvent const *e); // state handler static QState result(Calc *me, QEvent const *e); // state handler static QState begin(Calc *me, QEvent const *e); // state handler static QState negated1(Calc *me, QEvent const *e); // state handler static QState operand1(Calc *me, QEvent const *e); // state handler static QState zero1(Calc *me, QEvent const *e); // state handler static QState int1(Calc *me, QEvent const *e); // state handler static QState frac1(Calc *me, QEvent const *e); // state handler static QState opEntered(Calc *me, QEvent const *e); // state handler static QState negated2(Calc *me, QEvent const *e); // state handler static QState operand2(Calc *me, QEvent const *e); // state handler static QState zero2(Calc *me, QEvent const *e); // state handler static QState int2(Calc *me, QEvent const *e); // state handler static QState frac2(Calc *me, QEvent const *e); // state handler static QState final(Calc *me, QEvent const *e); // state handler}; 定义初始伪状态，作用是执行一些初始化操作，还有转换到默认状态 on QState Calc::initial(Calc *me, QEvent const * /* e */){ BSP_clear(); return Q_TRAN(&amp;amp;Calc::on);} 定义状态处理函数 用 switch 处理信号，避免switch外的处理代码 Q_ENTRY_SIG 和 Q_EXIT_SIG：进入动作和退出动作，总是返回 Q_HANDLED()，不允许状态切换 Q_INIT_SIG：每个组合状态（带有子状态的状态）能有它自己的初始转换，初始转换不能有监护条件，初始转换只能以自己的子状态作为目的状态 内部转换：内部转换是对事件的简单反应，并从不导致状态的转换，因此也从不导致进入动作，退出动作或初始转换的执行，总是返回 Q_HANDLED() 常规转换：执行动作，返回 Q_TRAN() 监护条件：根据事件参数的值和 / 或和状态机联合的变量（扩展状态变量）来动态的评估。条件为 false 相当于没处理，需要抛给超状态处理 常见问题 不完整的状态处理函数 QState Calc_on(Calc *me, QEvent const *e){ switch (e-&amp;gt;sig) { ...case C_SIG: { // case里应该return一个预定义的QState值，如Q_HANDLED()， // 这里却是一个自定义函数，虽然结果相同，但代码不直观，违反了设计规范 return Calc_onClear(me); /* handle the Clear event */ } ... } return Q_SUPER(&amp;amp;QHsm_top);}...QState Calc_onClear(Calc *me){ BSP_clear(); return Q_TRAN(&amp;amp;Calc_on); /* transition to &quot;on&quot; */} 在进入 / 退出动作或初始转换内访问事件参数 处理 Q_ENTRY_SIG 信号时不应该访问 QEvent 参数，需要在切换时传递的参数可以定义为该状态机的全局变量（如上面的m_operand1），这样状态机里所有状态都能共享 不够优化的信号粒度 计算器状态图把数字 1 到 9 的群表示为一个 信号 IDC_1_9_SIG，而不是每个数字一个信号，这样增加了一步读取事件参数获得实际值的操作，但减少了信号数量，总体上增大了信号粒度，避免过细的信号粒度带来的复杂性 过大的信号粒度会导致一个 case 里写的条件判断过多（switch 套 switch），让代码变成意大利面条 状态模式状态机面向对象的设计模式，设计模式就是用于解决实际问题的最佳实践终极钩子 目的提供共同的设施和方式来处理事件但是让客户重载 (override)并定制系统行为的每一个方面。 问题许多事件驱动型系统需要一致性方式来处理事件。在一个 GUI 设计里，一致性是用户接口的典型性观感的一部分。挑战是在系统层软件要提供这样一种共同的观感，客户程序可以容易的默认方式使用它们。 同时，客户必须能够容易的重载默认行为的每一个方面，如果他们想这么做的话 解决方案使用一个子状态，能够继承父状态的默认方法（忽略事件并让父状态处理），也能重载产生自定义的方法（编写事件的处理方法）specific 重载了 A 事件和进入退出动作的处理，B、C、D 则继承父状态的处理其中 C 事件表示复位，D 事件表示终止 代码样本// QEP应用需要qep_port.h#include &quot;qep_port.h&quot;typedef struct UltimateHookTag{ /* UltimateHook state machine */ QHsm super; /* derive from QHsm */} UltimateHook;void UltimateHook_ctor(UltimateHook *me); /* ctor */QState UltimateHook_initial(UltimateHook *me, QEvent const *e);QState UltimateHook_generic(UltimateHook *me, QEvent const *e);QState UltimateHook_specific(UltimateHook *me, QEvent const *e);QState UltimateHook_final(UltimateHook *me, QEvent const *e);enum UltimateHookSignals{ /* enumeration of signals */ A_SIG = Q_USER_SIG, B_SIG, C_SIG, D_SIG};/*.............................................................*/void UltimateHook_ctor(UltimateHook *me){ QHsm_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;UltimateHook_initial);}/*.............................................................*/QState UltimateHook_initial(UltimateHook *me, QEvent const *e){ printf(&quot;top-INIT;&quot;); return Q_TRAN(&amp;amp;UltimateHook_generic);}/*.............................................................*/QState UltimateHook_final(UltimateHook *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;final-ENTRY(terminate);\\nBye!Bye!\\n&quot;); exit(0); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}/*............................................................*/QState UltimateHook_generic(UltimateHook *me, QEvent const *e){ switch (e-&amp;gt;sig) { ... case Q_INIT_SIG: { printf(&quot;generic-INIT;&quot;); return Q_TRAN(&amp;amp;UltimateHook_specific); } case A_SIG: { printf(&quot;generic-A;&quot;); return Q_HANDLED(); } case B_SIG: { printf(&quot;generic-B;&quot;); return Q_HANDLED(); } case C_SIG: { printf(&quot;generic-C(reset);&quot;); return Q_TRAN(&amp;amp;UltimateHook_generic); } case D_SIG: { return Q_TRAN(&amp;amp;UltimateHook_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*............................................................*/QState UltimateHook_specific(UltimateHook *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;specific-ENTRY;&quot;); return Q_HANDLED(); } case Q_EXIT_SIG: { printf(&quot;specific-EXIT;&quot;); return Q_HANDLED(); } case A_SIG: { printf(&quot;specific-A;&quot;); return Q_HANDLED(); } } // 默认使用超状态处理，类似于继承 return Q_SUPER(&amp;amp;UltimateHook_generic); /* the superstate */} 结论 specific 子状态只需要知道它将重载的事件。 可以容易的加入新事件到高层 generic 超状态而不会影响 specific 子状态。 难以去掉或者改变客户已经在使用的事件的语义。（见设计模式中的开闭原则，对扩展开放，对修改关闭，本来就应该这么做，其实这个不算问题） 在许多嵌套层次间（如果 specific 子状态有嵌套的子状态）传递每一个事件的成本很高。 提示器 目的通过创造并发送给本身一个事件而使状态图拓扑更加灵活。 问题在状态建模时，一个公共事件常常把系统的一些松散的功能很强的耦合起来。考虑这个例子，在周期性数据采集时需要在一个预定的速率查询一个传感器产生的数据。假设一个周期性 TIMEOUT 事件以一个需要的速率被派发给系统用来提供查询传感器的触发。因为系统仅有一个外部事件 (TIMEOUT 事件) ， 看来好像这个事件需要同时触发查询传感器功能和处理数据功能。一个直接的但是不够优化的解决方法是把状态机组织成 2 个不同的正交区域（用来查询和处理）。然而，正交区域增加了派发事件的成本（参考“正交组件”模式）并且需要在区域间复杂的同步，因为查询和处理并不是完全独立的。 解决方法使用一个 DATA_READY 事件用于传给自己，表示数据就绪。将“处理数据功能”（processing）作为“查询传感器功能”（polling）的子状态，继承 TIMEOUT 事件的处理方法 pollSensor()，busy作为 polling 子状态可以重载 TIMEOUT，以便实现自定义功能。例如，为了提供性能， polling 状态可以缓存原始传感器数据并仅在缓存区填满后在生成 DATA_READY 事件，图中展示了使用 if(…) 条件的这个选项，它在 polling 状态的 postFIFO(me, DATA_REDY) 的前面。本例有个特征，就是周期性查询和周期性处理虽然都需要共用定时事件，但实时性不同，周期性查询比较频繁需要实时，周期性处理甚至不需要实时处理，所以可以仅让周期性查询处理定时事件，使用另一个 DATA_READY 事件让周期性查询通知周期性处理何时能进行处理也就是仅让 polling 处理 TIMEOUT 事件，因为 processing 状态不需要频繁处理数据，可以在 idle 状态等待，直到 DATA_READY 事件发生变为 busy 开始处理数据 代码样本原生 QEP 事件处理器并不支持事件排队，这里用到了 QP 实时框架 QF，还利用了 QF 的定时组件#include &quot;qp_port.h&quot; /* QP interface */#include &quot;bsp.h&quot; /* board support package */enum SensorSignals{ TIMEOUT_SIG = Q_USER_SIG, /* the periodic timeout signal */ DATA_READY_SIG, /* the invented reminder signal */ TERMINATE_SIG /* terminate the application */};/*............................................................*/// 使用了QF中的QActive活动对象和QTimeEvt定时组件typedef struct SensorTag{ /* the Sensor active object */ QActive super; /* derive from QActive */ QTimeEvt timeEvt; /* private time event generator */ uint16_t pollCtr; uint16_t procCtr;} Sensor;void Sensor_ctor(Sensor *me);/* hierarchical state machine ... */QState Sensor_initial(Sensor *me, QEvent const *e);QState Sensor_polling(Sensor *me, QEvent const *e);QState Sensor_processing(Sensor *me, QEvent const *e);QState Sensor_idle(Sensor *me, QEvent const *e);QState Sensor_busy(Sensor *me, QEvent const *e);QState Sensor_final(Sensor *me, QEvent const *e);/*............................................................*/void Sensor_ctor(Sensor *me){ QActive_ctor_(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;Sensor_initial); QTimeEvt_ctor(&amp;amp;me-&amp;gt;timeEvt, TIMEOUT_SIG); /* time event ctor */}/* HSM definition----------------------------------------------*/QState Sensor_initial(Sensor *me, QEvent const *e){ me-&amp;gt;pollCtr = 0; me-&amp;gt;procCtr = 0; return Q_TRAN(&amp;amp;Sensor_polling);}/*............................................................*/QState Sensor_final(Sensor *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;final-ENTRY;\\nBye!Bye!\\n&quot;); BSP_exit(); /* terminate the application */ return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}/*............................................................*/QState Sensor_polling(Sensor *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { // 注册定时事件，每半秒一次 /* periodic timeout every 1/2 second */ QTimeEvt_postEvery(&amp;amp;me-&amp;gt;timeEvt, (QActive *)me, BSP_TICKS_PER_SEC / 2); return Q_HANDLED(); } case Q_EXIT_SIG: { QTimeEvt_disarm(&amp;amp;me-&amp;gt;timeEvt); return Q_HANDLED(); } case Q_INIT_SIG: { // 初始进入processing状态 return Q_TRAN(&amp;amp;Sensor_processing); } // processing和idle都交给本状态处理，busy重载了这个处理 case TIMEOUT_SIG: { static const QEvent reminderEvt = {DATA_READY_SIG, 0}; ++me-&amp;gt;pollCtr; printf(&quot;polling %3d\\n&quot;, me-&amp;gt;pollCtr); // 每4次发送一个DATA_READY事件 if ((me-&amp;gt;pollCtr &amp;amp; 0x3) == 0) { /* modulo 4 */ QActive_postFIFO((QActive *)me, &amp;amp;reminderEvt); } return Q_HANDLED(); } case TERMINATE_SIG: { return Q_TRAN(&amp;amp;Sensor_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*............................................................*/QState Sensor_processing(Sensor *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_INIT_SIG: { // 初始进入idle状态 return Q_TRAN(&amp;amp;Sensor_idle); } } return Q_SUPER(&amp;amp;Sensor_polling);}/*..............................................................*/QState Sensor_idle(Sensor *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;idle-ENTRY;\\n&quot;); return Q_HANDLED(); } case DATA_READY_SIG: { return Q_TRAN(&amp;amp;Sensor_busy); } } return Q_SUPER(&amp;amp;Sensor_processing);}/*..............................................................*/QState Sensor_busy(Sensor *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;busy-ENTRY;\\n&quot;); return Q_HANDLED(); } // busy重载了定时处理 case TIMEOUT_SIG: { ++me-&amp;gt;procCtr; printf(&quot;processing %3d\\n&quot;, me-&amp;gt;procCtr); // 处理完返回idle,TODO：这里不处理采集的话不就丢了一次采集吗 if ((me-&amp;gt;procCtr &amp;amp; 0x1) == 0) { /* modulo 2 */ return Q_TRAN(&amp;amp;Sensor_idle); } return Q_HANDLED(); } } return Q_SUPER(&amp;amp;Sensor_processing);} 结论很像监护条件，但是监护条件是明确的，对应的事件就是用于转换状态的，但这里转换状态是隐含的，称为补充性转换。通过创造一个自定义的内部事件，在满足某种条件并产生隐式转换时发送该事件给自己，即可实现明确的转换。提醒器模式的另一个重要的应用是把较长的 RTC 步骤分解为较短的几个步骤。通过在内部事件中携带上下文可以让下一个短步骤获取上个短步骤留下的上下文，从而让这些短步骤能衔接起来，看上去像是一个连续执行的长步骤。通过分解和 FIFO 事件排队，能让其他任务也能及时运行而不受长步骤影响。延迟的事件 目的通过改变事件的顺序来简化状态机。 问题有时候一个事件在某个不方便的时刻到达，这时刻系统正在某个复杂的事件队列的中间。 复杂的事件队列指一系列不应该被打断的事件，如发送请求、等待收到回复事件后处理回复，两个事件不是同时发生，但中间也不希望被插入新事件打断实例：服务器程序处理业务（如从 ATM 终端）的案例。一旦业务开始了，它典型地要走完一个处理序列，从一个远距离终端接受数据开始，然后是业务的授权。这几个事件被视为连续事件，虽然事件产生有一定时间间隔，但希望它们能连续执行而不应该被新到达的业务打断。（可以理解为中断，中断的话需要保存上下文，退出中断后恢复，同理状态机处理“中断”也要保存当前状态和上下文，等新事件处理完恢复，太麻烦了。这个正好和上面一节的拆分长步骤的例子相反，一个是希望拆分长步骤为短步骤，让其他任务也能及时运行，这里是希望各个短步骤看上去像长步骤一样中间不要被打断。） 解决添加一个等待队列，当新业务事件到达时加入这个队列而不是事件队列，在 idle 时再去读取等待队列，把等待队列里的事件加入事件队列处于 busy 状态的子状态(receiving 和 authorizing)时，收到新的请求事件，处理方法为不执行并加入等待队列，然后该事件会被移除出事件队列，原业务得以继续正常执行。idle 状态通过进入动作执行 recall() 从等待队列召回被等待的第一个事件，并发送给自己。 实例代码延迟事件状态模式严重依赖事件队列，所以用了QF框架#include &quot;qp_port.h&quot;#include &quot;bsp.h&quot;/*.......................................................................*/enum TServerSignals{ NEW_REQUEST_SIG = Q_USER_SIG, /* the new request signal */ RECEIVED_SIG, /* the request has been received */ AUTHORIZED_SIG, /* the request has been authorized */ TERMINATE_SIG /* terminate the application */};/*......................................................................*/typedef struct RequestEvtTag{ QEvent super; /* derive from QEvent */ uint8_t ref_num; /* reference number of the request */} RequestEvt;/*......................................................................*/typedef struct TServerTag{ /* Transaction Server active object */ QActive super; /* derive from QActive */ // 私用事件队列，用于等待队列 QEQueue requestQueue; /* native QF queue for deferred request events */ // 指针数组，存放了3个指针，用于QEQueue事件队列，只要指针就行，指针指向的空间由QF管理是运行时绑定的 QEvent const *requestQSto[3]; /* storage for the deferred queue buffer */ // 使用定时任务模拟延迟 QTimeEvt receivedEvt; /* private time event generator */ QTimeEvt authorizedEvt; /* private time event generator */} TServer;void TServer_ctor(TServer *me); /* the default ctor *//* hierarchical state machine ... */QState TServer_initial(TServer *me, QEvent const *e);QState TServer_idle(TServer *me, QEvent const *e);QState TServer_busy(TServer *me, QEvent const *e);QState TServer_receiving(TServer *me, QEvent const *e);QState TServer_authorizing(TServer *me, QEvent const *e);QState TServer_final(TServer *me, QEvent const *e);/*......................................................................*/void TServer_ctor(TServer *me){ /* the default ctor */ QActive_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;TServer_initial); // 私有等待队列初始化 QEQueue_init(&amp;amp;me-&amp;gt;requestQueue, me-&amp;gt;requestQSto, Q_DIM(me-&amp;gt;requestQSto)); QTimeEvt_ctor(&amp;amp;me-&amp;gt;receivedEvt, RECEIVED_SIG); QTimeEvt_ctor(&amp;amp;me-&amp;gt;authorizedEvt, AUTHORIZED_SIG);}/* HSM definition -------------------------------------------------------*/QState TServer_initial(TServer *me, QEvent const *e){ (void)e; /* avoid the compiler warning about unused parameter */ return Q_TRAN(&amp;amp;TServer_idle);}/*......................................................................*/QState TServer_final(TServer *me, QEvent const *e){ (void)me; /* avoid the compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;final-ENTRY;\\nBye!Bye!\\n&quot;); BSP_exit(); /* terminate the application */ return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}/*............................................................................*/QState TServer_idle(TServer *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { // 在idle的进入动作中尝试召回事件 RequestEvt const *rq; printf(&quot;idle-ENTRY;\\n&quot;); /* recall the request from the private requestQueue */ // 使用QF框架提供的recall()功能召回，recall()内部通过LIFO将等待队列里的事件发给 // 自己的事件队列，用LIFO是为了保证优先处理 rq = (RequestEvt const *)QActive_recall((QActive *)me, &amp;amp;me-&amp;gt;requestQueue); if (rq != (RequestEvt *)0) { /* recall posted an event? */ printf(&quot;Request #%d recalled\\n&quot;, (int)rq-&amp;gt;refNum); } else { printf(&quot;No deferred requests\\n&quot;); } return Q_HANDLED(); } case NEW_REQUEST_SIG: { printf(&quot;Processing request #%d\\n&quot;, (int)((RequestEvt const *)e)-&amp;gt;refNum); return Q_TRAN(&amp;amp;TServer_receiving); } case TERMINATE_SIG: { return Q_TRAN(&amp;amp;TServer_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*......................................................................*/QState TServer_busy(TServer *me, QEvent const *e){ switch (e-&amp;gt;sig) { case NEW_REQUEST_SIG: { // busy状态下收到新的REQUEST事件，先检查等待队列是否空闲， if (QEQueue_getNFree(&amp;amp;me-&amp;gt;requestQueue) &amp;gt; 0) { /* can defer? */ /* defer the request */ // 为空就加入等待队列，用QF框架自带的QActive_defer QActive_defer((QActive *)me, &amp;amp;me-&amp;gt;requestQueue, e); printf(&quot;Request #%d deferred;\\n&quot;, (int)((RequestEvt const *)e)-&amp;gt;ref_num); } else { /* notify the request sender that the request was ignored.. */ // 满了就提醒用户，对QF框架来说等待队列和事件队列都是不允许满了丢弃的，会断言退出 // 这里修改了QF框架，允许满了后丢弃 printf(&quot;Request #%d IGNORED;\\n&quot;, (int)((RequestEvt const *)e)-&amp;gt;ref_num); } return Q_HANDLED(); } case TERMINATE_SIG: { return Q_TRAN(&amp;amp;TServer_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*.....................................................................*/QState TServer_receiving(TServer *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;receiving-ENTRY;\\n&quot;); /* one-shot timeout in 1 second */ QTimeEvt_fireIn(&amp;amp;me-&amp;gt;receivedEvt, (QActive *)me, BSP_TICKS_PER_SEC); return Q_HANDLED(); } case Q_EXIT_SIG: { QTimeEvt_disarm(&amp;amp;me-&amp;gt;receivedEvt); return Q_HANDLED(); } case RECEIVED_SIG: { return Q_TRAN(&amp;amp;TServer_authorizing); } } return Q_SUPER(&amp;amp;TServer_busy);}/*.....................................................................*/QState TServer_authorizing(TServer *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;authorizing-ENTRY;\\n&quot;); /* one-shot timeout in 2 seconds */ QTimeEvt_fireIn(&amp;amp;me-&amp;gt;authorizedEvt, (QActive *)me, 2 * BSP_TICKS_PER_SEC); return Q_HANDLED(); } case Q_EXIT_SIG: { QTimeEvt_disarm(&amp;amp;me-&amp;gt;authorizedEvt); return Q_HANDLED(); } case AUTHORIZED_SIG: { return Q_TRAN(&amp;amp;TServer_idle); } } return Q_SUPER(&amp;amp;TServer_busy);}等待队列和事件队列的管理都由 QF 实现，使用了“零复制”方式。 一种变体： busy 状态变成了其他状态包括 idle 的超状态。 idle 子状态重载了 NEW_REQUEST 事件。 其他全部 busy 的子状态依赖在 busy 超状态的默认事件处理方法，这个方法会延迟 NEW_REQUEST 事件。相当于就是把 idle 放进了 busy，其他都一样，TODO:这样有什么好处，busy 和 idle 从意义上讲应该是互斥的，这样做是否违反了逻辑按键触发新事件的代码：void BSP_onConsoleInput(uint8_t key){ switch (key) { case &#39;n&#39;: { /* new request */ static uint8_t reqCtr = 0; /* count the requests */ RequestEvt *e = Q_NEW(RequestEvt, NEW_REQUEST_SIG); e-&amp;gt;ref_num = (++reqCtr); /* set the reference number */ /* post directly to TServer active object */ QActive_postFIFO((QActive *)&amp;amp;l_tserver, (QEvent *)e); break; } case 0x1B: { /* ESC key */ static QEvent const terminateEvt = {TERMINATE_SIG, 0}; QActive_postFIFO((QActive *)&amp;amp;l_tserver, &amp;amp;terminateEvt); break; } }} 结论 事件延迟是个简化状态模型的有价值的技术。你不用建立一个过份复杂的状态机去处理在任何时候的每个事件，而是可以延迟一个在不合适或者棘手的时刻到达的事件。当状态机可以处理它时这个事件被召回。 它需要明确的延迟和召回被延迟的事件。 QF 实时框架提供了类属 defer() 和 recall() 操作。 如果一个状态机延迟了一个以上的事件，它可以使用同样的事件队列 (QEQueue) 或为不同的事件使用不同的事件队列。类属 QF 操作 defer() 和 recall() 支持这 2 个选项。 如果事件在一个高层状态被延迟，这通常发生在这个状态的某个内部转换中。 在这个状态的进入动作是这个事件被召回，可以方便的处理这个被延迟事件类型。 事件不应该在它被明确的召回时处理（要先加入事件队列，QF 会处理）。因为， recall() 操作使用 LIFO 策略发送这个事件， 这样状态机在处理这事件前不能够改变状态。 召回一个事件牵涉到把它发送给自己，然而，和提醒器模式不一样，延迟的事件是外部的而不是被创造出来的。 正交构件 目的作为组件使用状态机。 问题许多对象包含相对独立的具有状态行为的部分。例如，考虑一个简单的数字闹钟。这个设备执行 2 个大的独立的功能：基本的计时功能和闹钟功能。每个功能都有自己的操作模式。例如，计时可以使用 2 个模式： 12小时制或 24小时制。类似的，闹钟功能也可以启动或停止。在 UML 状态图里建模这样行为的标准方法是吧每个这种松散关联的功能放到一个独立的正交区域。相当于两个线程，重用少，资源消耗大，且 QEP 不支持 解决方法并发性实际上总是在聚合对象的内部出现，也就是说，组件的多个状态对这个合成对象的单一状态有贡献 图中菱形加箭头就是 UML 中的聚合的表示将两个功能拆成两个状态机，通过聚合方式进行关联，将闹钟功能状态机（组件）放在计时功能状态机（容器）内作为组件 代码样本共有信号和事件 clock.h:#ifndef clock_h#define clock_henum AlarmClockSignals{ TICK_SIG = Q_USER_SIG, /* time tick event */ ALARM_SET_SIG, /* set the alarm */ ALARM_ON_SIG, /* turn the alarm on */ ALARM_OFF_SIG, /* turn the alarm off */ ALARM_SIG, /* alarm event from Alarm component to AlarmClock container */ CLOCK_12H_SIG, /* set the clock in 12H mode */ CLOCK_24H_SIG, /* set the clock in 24H mode */ TERMINATE_SIG /* terminate the application */};/*.................................................................*/typedef struct SetEvtTag{ QEvent super; /* derive from QEvent */ uint8_t digit;} SetEvt;// 用于通知当前时间的事件typedef struct TimeEvtTag{ QEvent super; /* derive from QEvent */ uint32_t current_time;} TimeEvt;// 只使用基类QActive指针，组件类不需要知道容器类的具体结构，该技术叫不透明指针(opaque pointer)extern QActive *APP_alarmClock; /* AlarmClock container active object */#endif /* clock_h */Alarm 组件(闹钟功能)声明 alarm.h:#ifndef alarm_h#define alarm_htypedef struct AlarmTag{ /* the HSM version of the Alarm component */ // 闹钟功能比较简单，只要ON和OFF两种状态，不需要层次式状态机 // 用FSM有限状态机就行了 QFsm super; /* derive from QFsm */ uint32_t alarm_time;} Alarm;void Alarm_ctor(Alarm *me);#define Alarm_init(me_) QFsm_init((QFsm *)(me_), (QEvent *)0)#define Alarm_dispatch(me_, e_) QFsm_dispatch((QFsm *)(me_), e_)#endif /* alarm_h */Alarm 组件(闹钟功能)的定义 alarm.c:#include &quot;alarm.h&quot;#include &quot;clock.h&quot;/* FSM state-handler functions */QState Alarm_initial(Alarm *me, QEvent const *e);QState Alarm_off(Alarm *me, QEvent const *e);QState Alarm_on(Alarm *me, QEvent const *e);/*......................................................................*/void Alarm_ctor(Alarm *me){ // 调用基类构造函数 QFsm_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;Alarm_initial);}/* HSM definition -------------------------------------------------------*/QState Alarm_initial(Alarm *me, QEvent const *e){ (void)e; /* avoid compiler warning about unused parameter */ me-&amp;gt;alarm_time = 12 * 60; return Q_TRAN(&amp;amp;Alarm_off);}/*......................................................................*/// 闹钟关状态QState Alarm_off(Alarm *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { /* while in the off state, the alarm is kept in decimal format */ // 将时间内部二进制表示形式转为人类可读小时和分钟分离的十进制格式，如725转为1205，表示12:05 // 用于设置时间时为人类用户提供方便 me-&amp;gt;alarm_time = (me-&amp;gt;alarm_time / 60) * 100 + me-&amp;gt;alarm_time % 60; printf(&quot;*** Alarm OFF %02ld:%02ld\\n&quot;, me-&amp;gt;alarm_time / 100, me-&amp;gt;alarm_time % 100); return Q_HANDLED(); } case Q_EXIT_SIG: { /* upon exit, the alarm is converted to binary format */ // 退出前转换回去 me-&amp;gt;alarm_time = (me-&amp;gt;alarm_time / 100) * 60 + me-&amp;gt;alarm_time % 100; return Q_HANDLED(); } case ALARM_ON_SIG: { return Q_TRAN(&amp;amp;Alarm_on); } // OFF状态允许设置闹钟 case ALARM_SET_SIG: { /* while setting, the alarm is kept in decimal format */ // 设置的的闹钟是人类可读的十进制格式 uint32_t alarm = (10 * me-&amp;gt;alarm_time + ((SetEvt const *)e)-&amp;gt;digit) % 10000; // 合法性判断 if ((alarm / 100 &amp;lt; 24) &amp;amp;&amp;amp; (alarm % 100 &amp;lt; 60)) { /*alarm in range?*/ me-&amp;gt;alarm_time = alarm; } else { /* alarm out of range -- start over */ me-&amp;gt;alarm_time = 0; } printf(&quot;*** Alarm SET %02ld:%02ld\\n&quot;, me-&amp;gt;alarm_time / 100, me-&amp;gt;alarm_time % 100); return Q_HANDLED(); } } return Q_IGNORED();}/*......................................................................*/QState Alarm_on(Alarm *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;*** Alarm ON %02ld:%02ld\\n&quot;, me-&amp;gt;alarm_time / 60, me-&amp;gt;alarm_time % 60); return Q_HANDLED(); } // ON状态禁止设置闹钟 case ALARM_SET_SIG: { printf(&quot;*** Cannot set Alarm when it is ON\\n&quot;); return Q_HANDLED(); } case ALARM_OFF_SIG: { return Q_TRAN(&amp;amp;Alarm_off); } // ON状态下处理由 AlarmClock 容器发送的TIME事件，获取当前时间进行比较 case TIME_SIG: { if (((TimeEvt *)e)-&amp;gt;current_time == me-&amp;gt;alarm_time) { printf(&quot;ALARM!!!\\n&quot;); /* asynchronously post the event to the container AO */ // 时间到达时发送事件给容器 QActive_postFIFO(APP_alarmClock, Q_NEW(QEvent, ALARM_SIG)); } return Q_HANDLED(); } } return Q_IGNORED();}AlarmClock 容器（计时功能）定义 clock.c:#include &quot;qp_port.h&quot;#include &quot;bsp.h&quot;#include &quot;alarm.h&quot;#include &quot;clock.h&quot;/*.....................................................................*/typedef struct AlarmClockTag{ /* the AlarmClock active object */ QActive super; /* derive from QActive */ // 当前时间 uint32_t current_time; /* the current time in seconds */ // 定时事件 QTimeEvt timeEvt; /* time event generator (generates time ticks) */ // 包含了Alarm组件（闹钟功能） Alarm alarm; /* Alarm orthogonal component */} AlarmClock;void AlarmClock_ctor(AlarmClock *me); /* default ctor *//* hierarchical state machine ... */QState AlarmClock_initial(AlarmClock *me, QEvent const *e);QState AlarmClock_timekeeping(AlarmClock *me, QEvent const *e);QState AlarmClock_mode12hr(AlarmClock *me, QEvent const *e);QState AlarmClock_mode24hr(AlarmClock *me, QEvent const *e);QState AlarmClock_final(AlarmClock *me, QEvent const *e);/*.....................................................................*/void AlarmClock_ctor(AlarmClock *me){ /* default ctor */ QActive_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;AlarmClock_initial); Alarm_ctor(&amp;amp;me-&amp;gt;alarm); /* orthogonal component ctor */ QTimeEvt_ctor(&amp;amp;me-&amp;gt;timeEvt, TICK_SIG); /* private time event ctor */}/* HSM definition -------------------------------------------------------*/QState AlarmClock_initial(AlarmClock *me, QEvent const *e){ (void)e; /* avoid compiler warning about unused parameter */ me-&amp;gt;current_time = 0; Alarm_init(&amp;amp;me-&amp;gt;alarm); /* the initial transition in the component */ return Q_TRAN(&amp;amp;AlarmClock_timekeeping);}/*.....................................................................*/QState AlarmClock_final(AlarmClock *me, QEvent const *e){ (void)me; /* avoid the compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;-&amp;gt; final\\nBye!Bye!\\n&quot;); BSP_exit(); /* terminate the application */ return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}/*.....................................................................*/QState AlarmClock_timekeeping(AlarmClock *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { /* periodic timeout every second */ QTimeEvt_fireEvery(&amp;amp;me-&amp;gt;timeEvt, (QActive *)me, BSP_TICKS_PER_SEC); return Q_HANDLED(); } case Q_EXIT_SIG: { QTimeEvt_disarm(&amp;amp;me-&amp;gt;timeEvt); return Q_HANDLED(); } case Q_INIT_SIG: { return Q_TRAN(&amp;amp;AlarmClock_mode24hr); } case CLOCK_12H_SIG: { return Q_TRAN(&amp;amp;AlarmClock_mode12hr); } case CLOCK_24H_SIG: { return Q_TRAN(&amp;amp;AlarmClock_mode24hr); } case ALARM_SIG: { printf(&quot;Wake up!!!\\n&quot;); return Q_HANDLED(); } case ALARM_SET_SIG: case ALARM_ON_SIG: case ALARM_OFF_SIG: { /* synchronously dispatch to the orthogonal component */ // 对于和组件相关的事件，通过组件提供的dispatch()函数转发给它 Alarm_dispatch(&amp;amp;me-&amp;gt;alarm, e); return Q_HANDLED(); } case TERMINATE_SIG: { return Q_TRAN(&amp;amp;AlarmClock_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*.....................................................................*/QState AlarmClock_mode24hr(AlarmClock *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;*** 24-hour mode\\n&quot;); return Q_HANDLED(); } case TICK_SIG: { TimeEvt pe; /* temporary synchronous event for the component */ if (++me-&amp;gt;current_time == 24 * 60) { /* roll over in 24-hr mode? */ me-&amp;gt;current_time = 0; } printf(&quot;%02ld:%02ld\\n&quot;, me-&amp;gt;current_time / 60, me-&amp;gt;current_time % 60); ((QEvent *)&amp;amp;pe)-&amp;gt;sig = TICK_SIG; pe.current_time = me-&amp;gt;current_time; /* synchronously dispatch to the orthogonal component */ // 每个tick都发送当前时间给组件 Alarm_dispatch(&amp;amp;me-&amp;gt;alarm, (QEvent *)&amp;amp;pe); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;AlarmClock_timekeeping);}/*.....................................................................*/QState AlarmClock_mode12hr(AlarmClock *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;*** 12-hour mode\\n&quot;); return Q_HANDLED(); } case TICK_SIG: { TimeEvt pe; /* temporary synchronous event for the component */ uint32_t h; /* temporary variable to hold hour */ if (++me-&amp;gt;current_time == 12 * 60) { /* roll over in 12-hr mode? */ me-&amp;gt;current_time = 0; } h = me-&amp;gt;current_time / 60; printf(&quot;%02ld:%02ld %s\\n&quot;, (h % 12) ? (h % 12) : 12, me-&amp;gt;current_time % 60, (h / 12) ? &quot;PM&quot; : &quot;AM&quot;); ((QEvent *)&amp;amp;pe)-&amp;gt;sig = TICK_SIG; pe.current_time = me-&amp;gt;current_time; /* synchronously dispatch to the orthogonal component */ Alarm_dispatch(&amp;amp;me-&amp;gt;alarm, (QEvent *)&amp;amp;pe); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;AlarmClock_timekeeping);} 结论 它把行为的独立部分分区为不同的状态机对象。这个分割比正交区域更深入，因为对象同时有明确的行为和明确的数据。 进行分区引进了容器-组件（也叫父-子，或主-仆）关系。容器实现主要的功能并把其他 （次要的）特征授权给组件。容器和组件都是状态机。 组件常在不同的容器或相同的容器内被重用（容器可以实例化某个给定类型组件的多个组件）。 容器同组件共享它的执行线程。 容器通过直接派送事件给组件来进行通讯。组件通过发送事件给容器来通知它，而不是通过直接地事件派送方法。 组件使用提醒器模式去通知容器（例如，通知事件特别为内部而不是外部通讯被创造出来）。如果有某个给定类型的多个组件，这个通知事件必须确定起源的组件（组件把它的 ID 号作为通知事件的一个参数传递）。 容器和组件可以共享数据。典型的，数据是容器（允许不同容器的多个实例）的一个数据成员。 典型的，容器担保对它所选择的组件是友元关系。 容器完全对它的组件负责。特别的，它必须明确的触发在全部组件的初始转换。同时明确的派发事件给组件。如果容器“忘记”在它的某些状态派发事件给某些组件，就会产生错误。 容器可以动态的开始和停止组件（例如，在容器状态机的的某些特定状态）。 状态机的结合并没有局限于只有一层。组件可以有状态机子组件，也就是说，组件可以是较低层子组件的容器。这样一种组件的递归结构可以到达任意深的层次。 转换到历史状态 目的从某个组合状态转换出来，但是记住最近的活动子状态，这样在后面你可以返回这个子状态。 问题如让烤面包炉的门在工作中被打开后，再次关闭，能够恢复开门前的执行的动作。UML 状态图使用 2 类历史伪状态处理这种情况：浅历史和深历史 解决方法它把 doorClosed 状态最近的活动叶子状态存储在一个专用的数据成员 doorClosed_history 里。doorOpen 状态的转换到历史（带圆圈的 H* ）时使用这个属性作为这个转换的目标。 实例代码#include &quot;qep_port.h&quot;/*.....................................................................*/enum ToasterOvenSignals{ OPEN_SIG = Q_USER_SIG, CLOSE_SIG, TOAST_SIG, BAKE_SIG, OFF_SIG, TERMINATE_SIG /* terminate the application */};/*.....................................................................*/typedef struct ToasterOvenTag{ QHsm super; /* derive from QHsm */ // 继承自QHsm，扩展了用于存放历史状态的doorClosed_history QStateHandler doorClosed_history; /* history of the doorClosed state */} ToasterOven;void ToasterOven_ctor(ToasterOven *me); /* default ctor */QState ToasterOven_initial(ToasterOven *me, QEvent const *e);QState ToasterOven_doorOpen(ToasterOven *me, QEvent const *e);QState ToasterOven_off(ToasterOven *me, QEvent const *e);QState ToasterOven_heating(ToasterOven *me, QEvent const *e);QState ToasterOven_toasting(ToasterOven *me, QEvent const *e);QState ToasterOven_baking(ToasterOven *me, QEvent const *e);QState ToasterOven_doorClosed(ToasterOven *me, QEvent const *e);QState ToasterOven_final(ToasterOven *me, QEvent const *e);/*.....................................................................*/void ToasterOven_ctor(ToasterOven *me){ /* default ctor */ QHsm_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;ToasterOven_initial);}/* HSM definitio -------------------------------------------------------*/QState ToasterOven_initial(ToasterOven *me, QEvent const *e){ (void)e; /* avoid compiler warning about unused parameter */ me-&amp;gt;doorClosed_history = (QStateHandler)&amp;amp;ToasterOven_off; return Q_TRAN(&amp;amp;ToasterOven_doorClosed);}/*.....................................................................*/QState ToasterOven_final(ToasterOven *me, QEvent const *e){ (void)me; /* avoid compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;-&amp;gt; final\\nBye!Bye!\\n&quot;); _exit(0); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}/*.....................................................................*/QState ToasterOven_doorClosed(ToasterOven *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;door-Closed;&quot;); return Q_HANDLED(); } case Q_INIT_SIG: { return Q_TRAN(&amp;amp;ToasterOven_off); } case OPEN_SIG: { return Q_TRAN(&amp;amp;ToasterOven_doorOpen); } case TOAST_SIG: { return Q_TRAN(&amp;amp;ToasterOven_toasting); } case BAKE_SIG: { return Q_TRAN(&amp;amp;ToasterOven_baking); } case OFF_SIG: { return Q_TRAN(&amp;amp;ToasterOven_off); } case TERMINATE_SIG: { return Q_TRAN(&amp;amp;ToasterOven_final); } } return Q_SUPER(&amp;amp;QHsm_top);}/*.....................................................................*/QState ToasterOven_off(ToasterOven *me, QEvent const *e){ (void)me; /* avoid compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;toaster-Off;&quot;); // 所有叶状态进入时都要更新一次doorClosed_history me-&amp;gt;doorClosed_history = (QStateHandler)&amp;amp;ToasterOven_off; return Q_HANDLED(); } } return Q_SUPER(&amp;amp;ToasterOven_doorClosed);}/*.....................................................................*/QState ToasterOven_heating(ToasterOven *me, QEvent const *e){ (void)me; /* avoid compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;heater-On;&quot;); return Q_HANDLED(); } case Q_EXIT_SIG: { printf(&quot;heater-Off;&quot;); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;ToasterOven_doorClosed);}/*.....................................................................*/QState ToasterOven_toasting(ToasterOven *me, QEvent const *e){ (void)me; /* avoid compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;toasting;&quot;); // 所有叶状态进入时都要更新一次doorClosed_history me-&amp;gt;doorClosed_history = (QStateHandler)&amp;amp;ToasterOven_toasting; return Q_HANDLED(); } } return Q_SUPER(&amp;amp;ToasterOven_heating);}/*.....................................................................*/QState ToasterOven_baking(ToasterOven *me, QEvent const *e){ (void)me; /* avoid compiler warning about unused parameter */ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;baking;&quot;); // 所有叶状态进入时都要更新一次doorClosed_history me-&amp;gt;doorClosed_history = (QStateHandler)&amp;amp;ToasterOven_baking; return Q_HANDLED(); } } return Q_SUPER(&amp;amp;ToasterOven_heating);}/*.......................................................................*/QState ToasterOven_doorOpen(ToasterOven *me, QEvent const *e){ switch (e-&amp;gt;sig) { case Q_ENTRY_SIG: { printf(&quot;door-Open,lamp-On;&quot;); return Q_HANDLED(); } case Q_EXIT_SIG: { printf(&quot;lamp-Off;&quot;); return Q_HANDLED(); } case CLOSE_SIG: { // 恢复历史状态 return Q_TRAN(me-&amp;gt;doorClosed_history); /* transition to HISTORY */ } } return Q_SUPER(&amp;amp;QHsm_top);} 结论 需要一个用于存储历史状态的变量，这个变量是个指针，指向了状态处理函数 转换到历史伪状态（深历史和浅历史）使用标准的 Q_TRAN() 宏编码，这里目标被特定为历史变量。 为了实现深历史伪状态，需要在相应组合状态的每个叶子状态的进入动作上明确的设置历史变量。 为了实现浅历史伪状态，需要在每一个从所需层次的退出动作上明确的设置历史变量。例如，图5.12中的 doorClosed 浅历史需要在从 toasting 的退出动作把 doorClosed_history 设置为 &amp;amp;ToasterOven_toasting，在从 baking 的退出动作把它设置为 &amp;amp;ToasterOven_baking ，以及 doorClosed 全部直接子状态。 你可以通过复位相应的历史变量明确的清理任何组合状态的历史。实时框架的概念CPU 管理传统的事件驱动型架构对实时框架不是非常适合。最起码在三个方面存在问题： 响应性：单一事件队列不允许对工作的任何合理的优先次序。每个事件，无论优先级，必须等待直到它前面的全部事件被处理完后才能被处理。 不支持对应用程序上下文的管理：流行的事件 - 动作范型在响应事件时忽略应用程序的上下文，这样应用程序员就即兴发挥，到最后搞出“面条”代码。不幸的是，事件 - 动作范型和状态机不兼容。 全局数据：在传统的事件架构里，全部的事件处理函数存取一样的全局数据。这阻碍了对问题的分区，并为任何形式的多任务带来了并发性危机。活动对象计算模式活动对象 = （控制的线程 + 事件队列 + 状态机）应用程序包含了多个活动对象，每个都封装了一个控制线程（事件循环），一个私有的事件队列和一个状态机。 控制线程（事件循环）: 图(a)中为一个环形标记（方框右下角），具体见图(b)，事件循环调用和这个活动对象联合的 dispatch()函数。 dispatch()函数执行调度和处理事件的工作， 类似于在传统事件驱动型架构的事件处理函数。 事件队列：(a)中的 event queue 状态机：(a)中的 internal state machine系统结构RTOS 层在底部提供多任务和基本服务，比如消息队列，为存储事件确定内存分区等等。基于这些服务， QF 实时框架提供 QActive 类用于活动对象的派生。 QActive 类是从 QHsm 基础类派生而来，这意味着活动对象是状态机，并且继承了在 QHsm 基础类（见第四章）定义的dispatch()操作。另外， QActive 包含了一个执行线程和一个事件队列，它基于底层 RTOS 上的消息队列。应用程序通过从 QActive 基础类派生活动对象以及从 QEvent 类派生带有参数的事件，从而扩展了实时框架。异步通讯活动对象专门的通过它们的事件队列接收事件。所以事件都被异步投递，意味着一个事件生产者仅发送一个事件给接收者活动对象的事件队列，但是不会原地等待这个事件的实际处理过程。活动对象之间也可以通过这种方式传递事件，而不只局限于内部。运行 - 到 - 完成 RTC每一个活动对象用运行到完成（ run-to-completion）方式来处理事件，它是通过活动对象的事件循环的结构来保证的。封装封装意味着活动对象不共享数据和任何其他资源。数据通过消息机制传递事件派发机制两类事件派发机制: 简单的事件直接发送机制：一个事件的生产者直接发送这个事件到消费者活动对象的事件队列。 订阅派发机制，这里一个生产者“发行”一个事件给框架，框架然后把这个事件派发给所有已经“订阅”了这个事件的活动对象。发行-订阅机制提供了在事件产生者和消费者之间较低的耦合。直接事件发送例如，QF 实时框架提供了操作 QActive_postFIFO()这个事件传递的方式需要事件产生者密切的“知道”接收者。这种知识，散布在参与应用程序的组件中，使组件之间的耦合非常强烈和在运行时不灵活。订阅派发机制 事件的产生者和消费者不需要互相了解对方（松耦合）。 通过这个机制的事件交换必须被公开的了解，全部参与者必须有相同的语义。 需要一个介质去接收所发行的事件，再把它们派发给感兴趣的订阅者。 多对多交互作用（对象-到-对象）被一对多交互作用（对象-到-介质）所取代事件内存管理事件频繁产生消耗，内存重用很重要零复制的事件派发复制整个事件到消息队列的蛮力方法是一个传统的 RTOS 能做的最好方法，因为一个 RTOS 在事件离开队列后不能够控制它们。另一方面，一个实时框架可以更加有效，因为由于控制的倒置，框架实际在管理一个事件的全部生命周期。一个事件的生命周期开始于框架分配事件内存并返回一个指向这个内存的指针给事件生产者，如图(1)，生产者然后填充事件参数，执行写入所提供的事件指针。然后，事件生产者发送这个事件指针给接收者活动对象的队列，如图(2)稍后，活动对象开始处理事件。活动对象读取通过指针从队列里提取的事件数据。最后，框架在垃圾收集步骤自动的回收事件。请注意事件从来没有被复制。同时框架确信事件没有被过早回收。当然，框架必须也保证用一个线程安全的方式执行全部操作。静态和动态的事件 静态事件：没有参数或参数不会变的事件，可以静态分配，永远不变，如上图(3) 动态事件：参数会变的事件，需要事件池动态分配多路传输事件和引用计数器算法使用订阅分发机制时也可以使用零复制派发事件指针。但该指针被多个活动对象使用，问题是如何知道最后一个活动对象完成了对这个给定事件的处理，这样它占用的空间可以被回收。一个简便的方法是使用标准的引用计数器算法，每个动态事件有个计数器，开始为 0，每次发生事件加 1，每次被回收时减 1，到 0 删除事件内存事件的所有权生产者仅能通过调用 new_() 操作来获得一个新事件的所有权。但是最后生产者必须把所有权转让给框架，如生产者发送或发行事件，主动要求删除不完整事件消费者活动对象在框架调用 dispatch(e) 操作时获得当前事件 e 的所有权(只读)。当 dispatch()操作返回到框架时，所有权被终止。内存池堆一般有碎片化、泄露、悬空指针、难以预测、无法重入、空间浪费（管理信息）等问题内存池会有一定优势，QF 实时框架，可以管理多达 3 个拥有不同块尺寸（小，中，大）的事件池。时间管理当活动对象需要安排一个超时服务，它准备它的某个时间事件以便在未来的某时刻发送给自己。时间事件为这个目的提供的公共操作：为一次性超时提供postIn()，为周期性超时提供 postEvery() 。应用程序可以明确的使用 disarm() 操作在任何时刻解除 (disarm) 任何（周期性的或一次性的）时间事件，之后该事件空间可以重用。可以通过 rearm() 操作重新设定 (rearmed)，如刷新看门狗系统时钟节拍系统时钟节拍典型地是一个以预先确定的速率发生的周期性中断，典型的速率在 10 和 100Hz 之间。下图用某种夸张的方式展示了在一个节拍间隔内一个周期性时间事件的不同的延迟：高优先级的任务能更及时获得节拍，且跳动(jitter)较少。一个仅为了一个节拍而准备的时间事件会立刻过期，比如上图第 3 个节拍处理时已经在第 4 个节拍之后了，因为还在处理第 3 个节拍对应的的事件动作，可能会导致第 4 个节拍事件没有产生(类似中断丢失)，导致第 4 个节拍对应的动作无法执行。解决方法是事件要对应两个节拍，也就是原来指定第 4 个节拍发生的动作应该指定为 4 和 5 都能发生。错误和例外的处理 契约式设计 Design by Contract, DbC 方法 通过断言assertion来保证程序正常，它们既不预防错误也实际上不处理错误 更适合小型系统，正常状态不应该有错误，有错误就复位，不允许跑飞的程序继续运行 防御式编程 通过接收更宽范围的输入或允许操作的次序不必定符合对象的状态，让操作对错误更加强壮。 适合大型系统，尽可能规避错误，即使有错误也要尝试处理和恢复，不能退出进程或重启。因为大型系统运行有很高的不确定性，比如用户的输入无法预测。QF 框架规定了一些断言宏来处理错误C 和 C++ 里可定制的断言#ifdef Q_NASSERT /* Q_NASSERT defined–assertion checking disabled */// 如果Q_NASSERT被定义，取消所有的断言，宏全定义成空语句#define Q_DEFINE_THIS_FILE#define Q_DEFINE_THIS_MODULE(name_)#define Q_ASSERT(test_) ((void)0)#define Q_ALLEGE(test_) ((void)(test_))#define Q_ERROR() ((void)0)#else /* Q_NASSERT not defined–assertion checking enabled *//* callback invoked in case the condition passed to assertion fails */#ifdef __cplusplusextern &quot;C&quot;#endif// 断言失败时Q_onAssert被调用，一般就是关中断做些保存然后复位void Q_onAssert(char const Q_ROM *const Q_ROM_VAR file, int line);// 本文件的文件名，别的文件include这个头文件后，会变成那个文件的名字，作为日志打印时的标识符// 这里使用了static变量l_this_file作为宏定义而不是__FILE__，防止每次使用Q_DEFINE_THIS_FILE宏时__FILE__被多次复制#define Q_DEFINE_THIS_FILE \\ static char const Q_ROM Q_ROM_VAR l_this_file[] = __FILE__;// Q_DEFINE_THIS_FILE替代品,需要自定义#define Q_DEFINE_THIS_MODULE(name_) \\ static char const Q_ROM Q_ROM_VAR l_this_file[] = #name_;/* general purpose assertion */// 避免悬吊if(dangling-if)，详见上文// test是一个条件，为true或是false#define Q_ASSERT(test_) \\ if (test_) \\ { \\ } \\ else \\ (Q_onAssert(l_this_file, __LINE__))/* general purpose assertion that ALWAYS evaluates the test_ argument */#define Q_ALLEGE(test_) Q_ASSERT(test_)/* Assertion that always fails */#define Q_ERROR() \\ (Q_onAssert(l_this_file, __LINE__))#endif /* Q_NASSERT *//* assertion that checks for a precondition */#define Q_REQUIRE(test_) Q_ASSERT(test_)/* assertion that checks for a postcondition */#define Q_ENSURE(test_) Q_ASSERT(test_)/* assertion that checks for an invariant */#define Q_INVARIANT(test_) Q_ASSERT(test_)/* compile-time assertion */// 用于编译时的测试，利用C语言特性数组维数不能为0，如果test_为0，编译就会失败// Q_ASSERT用于运行时测试断言，Q_ASSERT_COMPILE用于编译时测试断言，各有各的用途。比如运行时动态变化的变量要用Q_ASSERT，对于编译时确定的固定的量要用Q_ASSERT_COMPILE#define Q_ASSERT_COMPILE(test_) \\ extern char Q_assert_compile[(test_)]#endif /* qassert_h */基于框架的软件追踪简单的讲，软件追踪类似于在代码里安排一些 printf()语句，它被称为检测代码，记录并分析以后从目标系统取回来的所感兴趣的分立事件。当然，一个好的软件追踪检测设备可以做到比简单的 printf()更少的侵入并更有效。从框架自身得到的软件追踪数据，允许你为全部系统里的活动对象生成完整的，带有时间戳的顺序图和详细的状态机活动图。使用 QS 构件(Q-Spy)实现实时框架的实现QF 框架的代码实现详解，对上一章的补充QF 实时框架的关键特征 可移植性 所以 QF 源代码使用可移植的 ANSI-C ，或者嵌入式 C++子集（wiki 上说这个项目从 2002 年开始就停止了，而且 C++之父也不看好）编写，所有处理器相关的，编译器相关的，或操作系统相关的代码被抽象成一个清楚定义的平台抽象层 PAL（ platform abstraction layer）。 可伸缩性 QF 被设计用于一个细粒度的对象库的部署，你可以静态的把它链接到你的应用程序。这个策略把责任交给链接器，让它在链接时自动排除任何没用到的代码，应用程序员不需为每个应用程序在编译时刻去配置 QF 代码。 对现代状态机的支持 QF 实时框架被设计为和 QEP 层次式事件处理紧密的工作，QEP 提供了 UML 兼容的直接实现，而 QF 提了并发执行这类状态机的基础设施。 直接事件发送和发布 - 订阅式事件派发 QF 实时框架支持使用 FIFO 和 LIFO 策略对特点活动对象进行直接事件发送。QF 也支持更加先进的发行 - 订阅事件派发机制。 零复制的事件内存管理 QF 支持 事件的基于引用计数算法的多路发送，对事件的自动垃圾收集，高效的静态事件，“零复制”事件延迟， 和可多多达 3 个为了最佳内存使用而拥有不同块尺寸的事件池。 开放式序号的时间事件 每个时间事件可以被作为一个一次性或周期性超时发生器而被激活。只有被激活（ active ） 的时间事件才消耗 CPU 周期。 原生的事件队列 QF 提供原生事件队列的 2 个版本。 第一个版本是为活动对象优化的，包含一个可移植的可以为阻塞型内核、简单的合作式 vanilla 内核或 QK 可抢占型内核而做修改的层。 第二个版本是一个简单的“线程安全的”队列，它不能阻塞，被设计为给中断发送事件和存储延迟的事件。 原生的内存池 QF 提供了一个快的，可确定的，和线程安全的内场池。 QF 在内部把内存池作为管理动态事件的事件池，但是你也可以为了在你系统中分配任何其他对象而使用内存池。 内置 Vanilla 调度器 QF 实时框架包含了一个可移植的，合作式 vanilla 内核 和 QK 可抢占式内核的紧密集成 QF 实时框架也可以和可确定的，可抢占的，非阻塞 QK 内核工作。 低功耗构架 绝大多数嵌入式微处理器 MCU 提供了一个低功耗睡眠模式的选择，用来通过调节给 CPU 和其他外设的时钟来节省能量。睡眠模式通过软件控制进入，在某个外部中断时退出。 基于断言的错误处理 契约式设计（ DbC）哲学 内置软件追踪测试设备 一个实时框架可以使用软件追踪技术提供比任何传统的 RTOS 更广泛和更详细的，关于运行中应用系统的信息。关闭 Q_SPY 宏时不产生空间和性能开销 QF 的结构QF 提供了核心基本类 QActive ，用于活动对象类的派生。 QActive 类是抽象的，意味着它不是打算用于被直接实例化，而是为了派生具体的活动对象类，比如图内的Ship，Missile和 Tunnel 。QActive 类默认是从在 QEP事件处理器的 QHsm 层次式状态机类派生。这意味着，凭借着继承，活动对象是 HSM，并继承了 init() 和 dispatch() 状态机接口。 QActive 也包含了一个执行线程和一个事件队列，它可以是原生的 QF 类，或者由底层 RTOS 提供。和QEP事件处理器一样， QF 使用同样的 QEvent 类来表示事件。另外，框架提供了时间事件类 QTimeEvt，应用程序使用它来产生超时请求。QF 也提供了几个服务给应用程序，它们没有在图的类图展示出来。这些额外的 QF 服务包括生成新的动态事件 (Q_NEW()) ，发行事件（ QF_publish()），原生 QF 事件队列类 (QEQueue) ，原生 QF 内存池类（ QMPool ），和内建的合作式 vanilla 内核QF 源代码的组织QF 源代码文件典型地每个文件只包含一个函数或一个数据结构的定义。这个设计是为了把 QF 当作一个细粒度的库来部署，你可以静态的把它和你的应用程序链接。这个策略把负担交给链接器，让它去在链接时排除任何没用的代码，而不是让程序员为每个应用程序在编译时配置 QF 代码。TODO:新版本还是这样的吗，感觉整合了不少QF 里的临界区QF 和其他任何系统层软件一样，必须保护某些指令的顺序不被破坏从而担保线程安全的操作。这个必须被不可分割地执行的代码区被称为临界区。嵌入式系统可以在进入临界区时关中断，在从临界区退出时解锁中断。在不允许锁中断的系统里， QF 可以采用其他的由底层操作系统支持的机制，比如互斥体（ mutex ）QF 平台抽象层包含 了 2 个宏 QF_INT_LOCK()和 QF_INT_UNLOCK() ，分别用来进入临界区和退出临界区。保存和恢复中断状态一种临界区实现方式：{ unsigned int lock_key; . . . // 关中断前保存当前中断状态，用于后面恢复 lock_key = get_int_status(); // 关闭中断，功能由编译器提供 int_lock(); . . . /* critical section of code */ . . . // 恢复中断状态，相当于开中断 set_int_status(lock_key); . . .}用于实现这个功能的宏定义：// 这个宏用于在预编译时告诉QF框架是否使用“保存和恢复中断状态”策略(该宏定义)，// 还是下一节的“无条件锁住和解锁中断”策略(该宏不定义)#define QF_INT_KEY_TYPE unsigned int#define QF_INT_LOCK(key_) \\ do \\ { \\ (key_) = get_int_status(); \\ int_lock(); \\ } while (0)#define QF_INT_UNLOCK(key_) set_int_status(key_) QF_INT_LOCK()宏的 do {…} while (0) 循环是语法正确的用来组合指令的标准做法。这个宏可以被安全的用于 if-else 语句（在宏后加分号），而不会造成“悬吊 if”（ dangling-if ）问题。“保存和恢复中断状态”政策的主要优点是可以嵌套临界区的能力。当 QF 函数从一个已经建立的临界段比如 ISR 里调用时，且部分处理器在进入 ISR 后自动关中断(进临界区)，需要在 ISR 内部先解锁中断才能使用 QF 函数(详见下节例子)，如果做不到就需要使用上述的办法嵌套临界区。 为什么要解锁中断才能调用 QF 函数，见下一节无条件上锁和解锁中断/* QF_INT_LOCK_KEY not defined */#define QF_INT_LOCK(key_) int_lock()#define QF_INT_UNLOCK(key_) int_unlock()“无条件上锁和解锁”策略是简单和快捷的，但是不允许临界区的嵌套且需要基于优先级的中断控制器，理由见上节使用一个基于优先级的中断控制器时一个 ISR 的常规结构：// 这是个ISR中断处理程序// 绝大多数控制器在进入 ISR 时，中断被硬件上锁。中断控制器被关闭，所有中断被关闭，不论优先级// 不能嵌套临界区并不意味着你不能嵌套中断。许多处理器拥有基于优先级的中断控制器void interrupt ISR(void) { /* entered with interrupts locked in hardware */ // 中断控制器必须被通知要进入这个中断。这个通知常在定向（跳转）到 ISR 之前自动在硬件层发生。 Acknowledge the interrupt to the interrupt controller (optional) // 如果中断源是电平触发的，你需要明确的清除它，以便触发下一次该中断。 // 因为这里同优先级的中断也被关闭了，本来就不能触发，所以之后清除也没关系 Clear the interrupt source, if level triggered // 如果之前被关中断了就执行开中断，使能中断控制器，由于基于优先级的中断控制器存在， // 这样高优先级的中断可以执行，更低或相同优先级的中断依旧不能执行。此时ISR内临界区结束 QF_INT_UNLOCK(dummy); /* unlock the interrupts at the processor level */ // 主 ISR 代码在临界区外执行，因此 QF 可以被安全的调用而不需嵌套临界区。 Handle the interrupt, use QF calls, e.g., QF_tick(), Q_NEW or QF_publish() // 中断被锁住，为中断的离开建立临界区。 QF_INT_LOCK(dummy); /* lock the interrupts at the processor level */ // EOI (end of interrupt) 指令被发往中断控制器，停止这个中断的优先权 Write End-Of-Interrupt (EOI) instruction to the Interrupt Controller // 由编译器提供的中断退出步骤，从堆栈恢复 CPU寄存器，包括 CPU状态寄存器。典型地这个步骤会解锁中断。} 基于优先级的中断控制器记忆当前所服务的中断的优先级，并仅允许比当前优先级高的中断抢占这个 ISR 。较低的或相同优先级的中断在中断控制器层次被锁住，即使这些中断在处理器层次被解锁。中断优先排序发生在中断控制器硬件层，直到中断控制器接受到中断结束 EOI 指令为止。所以说这个“无条件上锁和解锁中断”策略需要基于优先级的中断控制器的支持，这样即使在ISR内部开中断，也不会导致低优先级中断插进来影响ISR主体的执行 TODO: 开中断是为了什么？是不是为了防止执行主 ISR 代码(QF 函数)的过程太长导致临界区时间太长。还是为了主 ISR 代码执行时需要用到某些中断 解答：QF 函数执行部分内部有些也使用的关开中断创建临界区的部分，为了防止中断嵌套，也就是外面关了中断，进了函数内部又关一次就会造成阻塞，也就是死锁。中断上锁/解锁的内部 QF 宏QF 平台抽象层 (platform abstraction layer)PAL 使用中断上锁/解锁宏QF_INT_LOCK()， QF_INT_UNLOCK() ，和 QF_INT_KEY_TYPE 。中断上锁 / 解锁的内部宏:#ifndef QF_INT_KEY_TYPE /* simple unconditional interrupt locking/unlocking */ #define QF_INT_LOCK_KEY_ #define QF_INT_LOCK_() QF_INT_LOCK(ignore) #define QF_INT_UNLOCK_() QF_INT_UNLOCK(ignore)#else /* policy of saving and restoring interrupt status */ #define QF_INT_LOCK_KEY_ QF_INT_KEY_TYPE intLockKey_; #define QF_INT_LOCK_() QF_INT_LOCK(intLockKey_) #define QF_INT_UNLOCK_() QF_INT_UNLOCK(intLockKey_)#endif末尾带下划线的宏保持使用两种不同策略时的一致性（自动选择）示例：void QF_service_xyz(arguments){ QF_INT_LOCK_KEY_ ... QF_INT_LOCK_(); ... /* critical section of code */ ... QF_INT_UNLOCK_();}主动对象QF 实时框架提供了基础结构 QActive 用于派生应用程序的特定好的对象。 QActive 结合了后面三个基本要素： 它是一个状态机（从 QHsm 或其他拥有兼容接口的类派生） 它是一个事件队列 它有一个带有唯一优先级的执行线程// 可以自定义基础类，只要实现了状态机接口，也就是可以不用QEP框架里的QHsm#ifndef QF_ACTIVE_SUPER_ // 基础类默认为QEP提供的QHsm类 #define QF_ACTIVE_SUPER_ QHsm // 基础类构造函数名字 #define QF_ACTIVE_CTOR_(me_, initial_) QHsm_ctor((me_), (initial_)) // 基础类init初始化函数的名字 #define QF_ACTIVE_INIT_(me_, e_) QHsm_init((me_), (e_)) // 基础类dispatch()函数的名字 #define QF_ACTIVE_DISPATCH_(me_, e_) QHsm_dispatch((me_), (e_)) // 基础类构造函数的参数的类型 #define QF_ACTIVE_STATE_ QState#endiftypedef struct QActiveTag{ /// QActive 的基础类(继承) QF_ACTIVE_SUPER_ super; /* derives from QF_ACTIVE_SUPER_ */ // 事件队列，可自定义 QF_EQUEUE_TYPE eQueue; /* event queue of active object */ // TODO:这个osObject在 #[POSIX的 QF 移植] 中会提到#ifdef QF_OS_OBJECT_TYPE QF_OS_OBJECT_TYPE osObject; /* OS-object for blocking the queue */#endif // 线程处理#ifdef QF_THREAD_TYPE QF_THREAD_TYPE thread; /* execution thread of the active object */#endif // 每个主动对象有唯一的优先级，最大为63，0是特殊的休眠优先级，也就是最大支持63个主动对象 uint8_t prio; /* QF priority of the active object */ // 用于一些移植，写入0会终止活动对象 uint8_t running; /* flag indicating if the AO is running */} QActive;// 开始执行void QActive_start(QActive *me, uint8_t prio, QEvent const *qSto[], uint32_t qLen, void *stkSto, uint32_t stkSize, QEvent const *ie);// FIFO方式发送到活动对象的事件队列void QActive_postFIFO(QActive *me, QEvent const *e);// LIFO方式发送到活动对象的事件队列void QActive_postLIFO(QActive *me, QEvent const *e);// 构造函数void QActive_ctor(QActive *me, QState initial);// 停止活动对象执行线程void QActive_stop(QActive *me);// 和事件订阅相关void QActive_subscribe(QActive const *me, QSignal sig);void QActive_unsubscribe(QActive const *me, QSignal sig);void QActive_unsubscribeAll(QActive const *me);// 用于高效的（“零复制”）事件延迟和事件恢复void QActive_defer(QActive *me, QEQueue *eq, QEvent const *e);QEvent const *QActive_recall(QActive *me, QEQueue *eq);// 从活动对象的事件队列每次移除一个事件,这个函数仅被用在 QF 内部，并且从不用于应用程序层QEvent const *QActive_get_(QActive *me);通过把宏 QF_ACTIVE_XXX_ 定义到你自己的类，你可以排除在 QF 框架和 QEP 事件处理器之间的依赖性。自定义示例：#define QF_ACTIVE_SUPER_ MyClass#define QF_ACTIVE_CTOR_(me_, ini_) MyClass_ctor((me_), (ini_))#define QF_ACTIVE_INIT_(me_, e_) MyClass_init((me_), (e_))#define QF_ACTIVE_DISPATCH_(me_, e_) MyClass_dispatch((me_), (e_))#define QF_ACTIVE_STATE_ void*活动对象的内部状态机每个活动对象都是一个状态机，如飞行和射击”游戏例子里的 Ship，Missile，或 Tunnel活动对象由 QHsm 派生，利用多态特性可以使用QHsm指针使用派生活动对象的状态机函数(QEP 层)，所以无论活动对象添加了多少自定义的变量，都可以当作状态机使用。活动对象的事件队列QF 的事件队列需要“多写单读”的存取权限，可以从其他地方(不同线程)发送事件到活动对象，活动对象线程每次取一个使用。所以需要读写互斥锁和写者互斥锁“零复制“事件队列不存储实际事件，仅存储执行事件实例的指针。可以使用操作系统提供的消息队列，尽管有点大材小用执行线程和活动对象优先级活动对象线程的步骤：// 从事件队列获取事件，没事件时可以阻塞让线程休眠。QEvent const *e = QActive_get_(a); /* get the next event for AO &#39;a&#39; */// 利用多态使用基类函数和基类指针作为参数执行派生后的函数实现QF_ACTIVE_DISPATCH_(&amp;amp;a-&amp;gt;super, e) /* dispatch to the AO &#39;a&#39; */// QF垃圾回收器回收无用的事件QF_gc(e); /* determine if event &#39;e&#39; is garbage and collect it if so */QF 应用程序需要代表系统里的每个活动对象调用QActive_start()函数(启动活动对象)void QActive_start(QActive *me, uint8_t prio, /* 唯一优先级，the unique priority */ QEvent const *qSto[], uint32_t qLen, /* 事件队列空间，event queue */ void *stkSto, uint32_t stkSize, /* 栈空间，per-task stack */ QEvent const *ie) /* 初始事件，the initialization event */{ me-&amp;gt;prio = prio; /* set the QF priority */ // 注册到QF QF_add(me); /* make QF aware of this active object */ // 执行在活动对象里的状态机的最顶初始转换,参数 ie是一个指针，指向在活动对象状态机里用于最顶初始转换的初始事件。 QF_ACTIVE_INIT_(me, ie); /* execute the initial transition */ // 初始化事件队列 Initialize the event queue object &#39;me-&amp;gt;eQueue&#39; using qSto and qLen // 创建活动对象线程 Create and start the thread &#39;me-&amp;gt;thread&#39; of the underlying kernel} “初始事件” ie 让你有机会提供一些信息给活动对象，这个活动对象(这里原文用的which，是指代上一句的一些信息还是活动对象？)在后面的初始化过程才被知道（比如，在 GUI 系统里的一个窗口处理句柄）。请注意，（在 C++里）活动对象的构造函数在 main() 之前运行，这时你没有所有的信息来初始化一个活动对象的全部方面。QF 的事件管理“零复制”事件派发方案 被框架管理的动态事件 其他不被 QF 管理的（静态分配的）事件事件的结构typedef struct QEventTag { /* QEvent base structure */ QSignal sig; /* public signal of the event instance */ // 动态还是静态事件 uint8_t dynamic_; /* attributes of a dynamic event (0 for static event) */} QEvent;7,6 表示事件池 id(大、中、小、静态 0)，5-0 表示事件引用计数器，引用计数器归 0 才回收动态事件分配大中小三个事件池，事件用完空间可回收/* Package-scope objects ---------------------------------------------------*/// 事件池管理信息，不包含实际空间QF_EPOOL_TYPE_ QF_pool_[3]; /* allocate 3 event pools */// 实际使用的池的数量uint8_t QF_maxPool_; /* number of initialized event pools *//*..........................................................................*/// poolSto参数才是分配的实际事件空间void QF_poolInit(void *poolSto, uint32_t poolSize, QEventSize evtSize){ /* cannot exceed the number of available memory pools */ // 合法性检查 Q_REQUIRE(QF_maxPool_ &amp;lt; (uint8_t)Q_DIM(QF_pool_)); /* please initialize event pools in ascending order of evtSize: */ Q_REQUIRE((QF_maxPool_ == (uint8_t)0) || (QF_EPOOL_EVENT_SIZE_(QF_pool_[QF_maxPool_ - 1]) &amp;lt; evtSize)); /* perfom the platform-dependent initialization of the pool */ // 所有框架操作需要的内存由应用程序提供给框架。这里实际分配空间为poolSto指向的内存 // 这个宏默认提供QMPool_init（就是QF原生内存池）的分配功能 QF_EPOOL_INIT_(QF_pool_[QF_maxPool_], poolSto, poolSize, evtSize); // 变量 QF_maxPool_ 被增加，表示多个池已被初始化 ++QF_maxPool_; /* one more pool */} 所有 QP 构件，包括 QF 框架，一致地假设，在系统开始时，没有明确初始值的变量被初始化为 0 ，这是 ANSI-C 标准的要求。在嵌入式系统，这个初始化步骤对应于清除.BSS段(用来放全局变量)。你应该确信在你的系统里，在 main() 被调用前 .BSS 段确实被清除了。从最小事件尺寸池分配一个事件的简单策略:QEvent *QF_new_(QEventSize evtSize, QSignal sig){ QEvent *e; /* find the pool id that fits the requested event size ... */ uint8_t idx = (uint8_t)0; // 从小到大找到合适的池 while (evtSize &amp;gt; QF_EPOOL_EVENT_SIZE_(QF_pool_[idx])) { ++idx; Q_ASSERT(idx &amp;lt; QF_maxPool_); /* cannot run out of registered pools */ } // 从池中获取e（分配空间） QF_EPOOL_GET_(QF_pool_[idx], e); /* get e -- platform-dependent */ // 断言池未枯竭 Q_ASSERT(e != (QEvent *)0); /* pool must not run out of events */ // 设置信号 e-&amp;gt;sig = sig; /* set signal for this event */ /* store the dynamic attributes of the event: * the pool ID and the reference counter == 0 */ // 设置池标记(高两位) e-&amp;gt;dynamic_ = (uint8_t)((idx + 1) &amp;lt;&amp;lt; 6); return e;}自动垃圾收集动态事件的引用计数器被存储在事件属性 dynamic_的低 6 位 LSB 里，发送事件时递增，归 0 由 QF 自动检测回收void QF_gc(QEvent const *e){ // 判断是否动态事件 if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ QF_INT_LOCK_KEY_ // 中断上锁,操作引用计数器需要临界区 QF_INT_LOCK_(); if ((e-&amp;gt;dynamic_ &amp;amp; 0x3F) &amp;gt; 1) { /* isn&#39;t this the last reference? */ // 大于1，递减 --((QEvent *)e)-&amp;gt;dynamic_; /* decrement the reference counter */ QF_INT_UNLOCK_(); } else { /* this is the last reference to this event, recycle it */ // 小于1，回收，先从高2位获取index索引，找到对应池，然后归还空间 uint8_t idx = (uint8_t)((e-&amp;gt;dynamic_ &amp;gt;&amp;gt; 6) - 1); QF_INT_UNLOCK_(); Q_ASSERT(idx &amp;lt; QF_maxPool_); /* index must be in range */ QF_EPOOL_PUT_(QF_pool_[idx], (QEvent *)e); } }}延迟和恢复事件QF 分别通过 QActive 的类函数 QActive_defer() 和 QActive_recall() 实现明确的事件延迟和恢复。见延迟的事件当事件在某个特别不方便的时刻到达时，可以被延迟一些时间直到系统有一个比较好的状态去处理这个事件，事件的延迟是很方便的void QActive_defer(QActive *me, QEQueue *eq, QEvent const *e){ (void)me; /* avoid compiler warning about &#39;me&#39; not used */ // 发送给等待队列，这里计数器会被加1，防止被回收 // 因为事件被处理后即使不执行操作放入等待队列，计数器也会被减1 QEQueue_postFIFO(eq, e); /* increments ref-count of a dynamic event */}/*..........................................................................*/QEvent const *QActive_recall(QActive *me, QEQueue *eq){ // 从等待队列取一个事件 QEvent const *e = QEQueue_get(eq); /* get an event from deferred queue */ if (e != (QEvent *)0) { /* event available? */ QF_INT_LOCK_KEY_ // 发送到事件队列，用LIFO插队到第一个，引用计数器会被加1 QActive_postLIFO(me, e); /* post it to the front of the AO&#39;s queue */ QF_INT_LOCK_(); if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ Q_ASSERT((e-&amp;gt;dynamic_ &amp;amp; 0x3F) &amp;gt; 1); // 从等待队列里拿出来了，引用计数器要减1(事件队列里的处理后会自动减) --((QEvent *)e)-&amp;gt;dynamic_; /* decrement the reference counter */ } QF_INT_UNLOCK_(); } return e; /*pass the recalled event to the caller (NULL if not recalled) */}QF 的事件派发机制QF 仅支持异步事件交换，发送者不等待事件处理派发机制： 直接事件发送的简单机制 – 一个事件的生产者直接发送这个事件给消费者活动对象的事件队列。 订阅事件发送机制 – 事件的生产者把事件发行给框架，框架然后把事件发行给所有订阅了这个事件的活动对象。直接事件发送QF 通过 QActive_postFIFO() 和 QActive_postLIFO() 函数支持直接事件发送QActive_postFIFO(AO_ship, (QEvent *)e); /* post event &#39;e&#39; to the Ship AO */这里参数 AO_ship 是 QActive 基类类型，利用了多态extern QActive * const AO_Ship; /* opaque pointer to the Ship AO */发行-订阅事件发送 初始化发行-订阅机制: QF_psInit() 订阅：QActive_subscribe(), QActive_unsubscribe(), QActive_unsubscribeAll() 发行：QF_publish()管理订阅信息的数据结构：typedef struct QSubscrListTag { // QF_MAX_ACTIVE - 1表示需要的位数 // 除以8向上取整，表示需要的字节数 uint8_t bits[((QF_MAX_ACTIVE - 1) / 8) + 1];} QSubscrList;每类信号为一行，每行中的每一位对应一个主动对象，因为优先级和主动对象一一对应，所以通过优先级(1-63)对应位唯一标识，置位表示该事件被对应的主动对象订阅。如图中 bit15 对应优先级 16 的主动对象。上图例子中每行 bit 为 64 个(目前 QF_MAX_ACTIVE 的范围是 1 到 63)，这也是主动对象提到的优先级上限为 63 的原因 初始化 QSubscrList *QF_subscrList_; /* initialized to zero per C-standard */QSignal QF_maxSignal_;/* initialized to zero per C-standard */void QF_psInit(QSubscrList *subscrSto, QSignal maxSignal){ QF_subscrList_ = subscrSto; QF_maxSignal_ = maxSignal;} 订阅 // me: 本对象，sig：要订阅的信号void QActive_subscribe(QActive const *me, QSignal sig){ uint8_t p = me-&amp;gt;prio; // 字节索引，QF_div8Lkup[p] = (p – 1)/8， // 可以每次算也可以用预生成在ROM的查找表 uint8_t i = Q_ROM_BYTE(QF_div8Lkup[p]); QF_INT_LOCK_KEY_ Q_REQUIRE(((QSignal)Q_USER_SIG &amp;lt;= sig) &amp;amp;&amp;amp; (sig &amp;lt; QF_maxSignal_) &amp;amp;&amp;amp; ((uint8_t)0 &amp;lt; p) &amp;amp;&amp;amp; (p &amp;lt;= (uint8_t)QF_MAX_ACTIVE) &amp;amp;&amp;amp; (QF_active_[p] == me)); QF_INT_LOCK_(); // 找到字节内偏移，QF_pwr2Lkup[p] = 1 &amp;lt;&amp;lt; ((p – 1) % 8)， // 可以每次算也可以用预生成在ROM的查找表 QF_subscrList_[sig].bits[i] |= Q_ROM_BYTE(QF_pwr2Lkup[p]); QF_INT_UNLOCK_();} 发行 // 给所有订阅者发行一个给定事件 evoid QF_publish(QEvent const *e){ QF_INT_LOCK_KEY_ /* make sure that the published signal is within the configured range */ Q_REQUIRE(e-&amp;gt;sig &amp;lt; QF_maxSignal_); // 读取加修改，典型的临界区 QF_INT_LOCK_(); if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ // e-&amp;gt;dynamic_为0说明是高2位也是0，就是静态事件 /*lint -e1773 Attempt to cast away const */ // 增加一次引用计数器，防止刚发送给一个活动对象事件立刻被处理了的情况下， // 引用计数器直接归0，事件被回收，无法给其他活动对象发事件 // QF_publish执行到最后给所有订阅的活动对象发完，应该要减1 ++((QEvent *)e)-&amp;gt;dynamic_; /* increment reference counter, NOTE01 */ } QF_INT_UNLOCK_();#if (QF_MAX_ACTIVE &amp;lt;= 8) { // 只有一个字节 // 赋给临时变量，后面能随便修改 uint8_t tmp = QF_subscrList_[e-&amp;gt;sig].bits[0]; while (tmp != (uint8_t)0) { // 不为0表示有订阅 // 找最高优先级的活动对象，也就是从高到低第一个为1的位， // 以 2 为底的对数查找快捷的确定在bitmask的MSB位 uint8_t p = Q_ROM_BYTE(QF_log2Lkup[tmp]); // 清掉该位 tmp &amp;amp;= Q_ROM_BYTE(QF_invPwr2Lkup[p]); /* clear subscriber bit */ Q_ASSERT(QF_active_[p] != (QActive *)0); /* must be registered */ /* internally asserts if the queue overflows */ // 向对应活动对象发送 QActive_postFIFO(QF_active_[p], e); } }#else { // Q_DIM获取字节数sizeof(array_) / sizeof((array_)[0U] uint8_t i = Q_DIM(QF_subscrList_[0].bits); do { /* go through all bytes in the subscription list */ // 遍历该事件信号对应的订阅清单里的所有字节 uint8_t tmp; // 从高到低遍历 --i; // 这里开始和上面单字节的一样了 tmp = QF_subscrList_[e-&amp;gt;sig].bits[i]; while (tmp != (uint8_t)0) { uint8_t p = Q_ROM_BYTE(QF_log2Lkup[tmp]); tmp &amp;amp;= Q_ROM_BYTE(QF_invPwr2Lkup[p]); /*clear subscriber bit */ // 这里和上面不一样，要移位一下 p = (uint8_t)(p + (i &amp;lt;&amp;lt; 3)); /* adjust the priority */ Q_ASSERT(QF_active_[p] != (QActive *)0); /*must be registered*/ /* internally asserts if the queue overflows */ QActive_postFIFO(QF_active_[p], e); } } while (i != (uint8_t)0); }#endif // 执行一次垃圾回收，将引用计数器减1，这里就是对应开头那里的增加1 QF_gc(e); /* run the garbage collector, see NOTE01 */} 为什么加锁，见比较并交换 二进制算法查找表 QF_log2Lkup[] 映射字节值到 MSB 的 bit数字 (找一个字节里的最高有效位所在的位置 1-8，可以通过表一一对应)： 注意：横坐标有部分缩放，是不等距的 如果不用这个表，运行时用$log_2(x)$算也可以，这会造成重复计算开销，嵌入式系统可以使用这种预配置的表，缺点是占用空间，比如这个表是 256 个单字节数组，占用 256 Bytes 时间管理时间事件只能是静态的一个时间事件在实例化时（在构造函数里）必须被分配一个信号，这个信号在后面不能被改变。后一个约束防止了时间事件在还被某个事件队列持有时，被意外的改变。时间事件结构和接口typedef struct QTimeEvtTag{ // 从QEvent派生 QEvent super; /* derives from QEvent */ // 双向链表前后指针 struct QTimeEvtTag *prev; /* link to the previous time event in the list */ struct QTimeEvtTag *next; /* link to the next time event in the list */ // 存储了时间事件的接收者(其他类型的事件好像没有派生这个变量) QActive *act; /* the active object that receives the time event */ // 每个tick（调用QF_tick()）递减，直到0发送事件 QTimeEvtCtr ctr; /* the internal down-counter of the time event */ // 周期性时间事件的间隔，单次为0 QTimeEvtCtr interval; /* the interval for the periodic time event */} QTimeEvt;// 构造函数，里面会给事件一个信号，该事件可重用但不应修改它的信号// 因为改了以后会导致原来接收这个事件的活动对象无法使用该事件void QTimeEvt_ctor(QTimeEvt *me, QSignal sig);// 为什么用do{...}while (0)之前提到过了，为了在宏里安全包裹多步操作// 设置定时器，用于一次性时间事件#define QTimeEvt_postIn(me_, act_, nTicks_) \\ do \\ { \\ (me_)-&amp;gt;interval = (QTimeEvtCtr)0; \\ QTimeEvt_arm_((me_), (act_), (nTicks_)); \\ } while (0)// 设置定时器，周期性时间事件#define QTimeEvt_postEvery(me_, act_, nTicks_) \\ do \\ { \\ (me_)-&amp;gt;interval = (nTicks_); \\ QTimeEvt_arm_((me_), (act_), (nTicks_)); \\ } while (0)// 解除定时器uint8_t QTimeEvt_disarm(QTimeEvt *me);// 重设定时器uint8_t QTimeEvt_rearm(QTimeEvt *me, QTimeEvtCtr nTicks);/* private helper function */// 把时间事件插入已设定的定时器的链接表内void QTimeEvt_arm_(QTimeEvt *me, QActive *act, QTimeEvtCtr nTicks);已被设定的时间事件放于链表中，已解除的不在链表中系统时钟节拍和 QF_tick() 函数QF 需要获取节拍管理时间事件，一般就是在 ISR 中调用自己的 QF_tick()void QF_tick(void){ /* see NOTE01 */ QTimeEvt *t; QF_INT_LOCK_KEY_ QF_INT_LOCK_(); // 从链表头开始 t = QF_timeEvtListHead_; /* start scanning the list from the head */ while (t != (QTimeEvt *)0) {//t = t-&amp;gt;next;遍历 // 每次调用减1 if (--t-&amp;gt;ctr == (QTimeEvtCtr)0) { /* is time evt about to expire? */ // 到达倒计时 // 判断是否是周期性事件 if (t-&amp;gt;interval != (QTimeEvtCtr)0) { /* is it periodic timeout? */ t-&amp;gt;ctr = t-&amp;gt;interval; /* rearm the time event */ } else // 不是周期性事件 { /* one-shot timeout, disarm by removing it from the list */ if (t == QF_timeEvtListHead_) { // 当前指针是头指针时，头指针直接指向next，即使next是空也没关系 QF_timeEvtListHead_ = t-&amp;gt;next; } else { // 把定时器对象节点从链表中删除 if (t-&amp;gt;next != (QTimeEvt *)0) { /* not the last event? */ t-&amp;gt;next-&amp;gt;prev = t-&amp;gt;prev; } t-&amp;gt;prev-&amp;gt;next = t-&amp;gt;next; } // 标记该节点为未使用状态 t-&amp;gt;prev = (QTimeEvt *)0; /* mark the event disarmed */ } QF_INT_UNLOCK_(); /* unlock interrupts before calling QF service */ /* postFIFO() asserts internally that the event was accepted */ // 发送事件 QActive_postFIFO(t-&amp;gt;act, (QEvent *)t); } else { static uint8_t volatile dummy; QF_INT_UNLOCK_(); // 在许多 CPU 里，中断解锁仅在下个机器指令后才生效, // 对 dummy 变量的赋值需要几个机器指令，这是编译器没办法优化掉的。这确保中断被实际解锁 // 防止QF_INT_UNLOCK_和下一个QF_INT_LOCK_挨在一起，CPU要等一段时间才能重新上锁 dummy = (uint8_t)0; /* execute a few instructions, see NOTE02 */ } // 为了下一次循环上锁 QF_INT_LOCK_(); /* lock interrupts again to advance the link */ t = t-&amp;gt;next; } QF_INT_UNLOCK_();}arming 和 disarm 一个时间事件QTimeEvt_arm_()用于把时间事件插入已设定的定时器的链接表内void QTimeEvt_arm_(QTimeEvt *me, QActive *act, QTimeEvtCtr nTicks){ QF_INT_LOCK_KEY_ Q_REQUIRE((nTicks &amp;gt; (QTimeEvtCtr)0) /* cannot arm a timer with 0 ticks */ &amp;amp;&amp;amp; (((QEvent *)me)-&amp;gt;sig &amp;gt;= (QSignal)Q_USER_SIG) /*valid signal */ &amp;amp;&amp;amp; (me-&amp;gt;prev == (QTimeEvt *)0) /* time evt must NOT be used */ &amp;amp;&amp;amp; (act != (QActive *)0)); /* active object must be provided */ me-&amp;gt;ctr = nTicks; // Q_REQUIRE判断了me-&amp;gt;prev == (QTimeEvt *)0，表示该节点未使用， // 所以这里赋值一下（不是0就行，这里指向了自己），表示该节点对应的计时器已启用 // 后面会利用这个值判断该节点是否 me-&amp;gt;prev = me; /* mark the timer in use */ me-&amp;gt;act = act; // 对链表的操作要加锁 QF_INT_LOCK_(); // 放到链表头部 me-&amp;gt;next = QF_timeEvtListHead_; if (QF_timeEvtListHead_ != (QTimeEvt *)0) { QF_timeEvtListHead_-&amp;gt;prev = me; } QF_timeEvtListHead_ = me; QF_INT_UNLOCK_();}QTimeEvt_disarm()用于关闭已经设定的定时器：uint8_t QTimeEvt_disarm(QTimeEvt *me){ uint8_t wasArmed; QF_INT_LOCK_KEY_ QF_INT_LOCK_(); if (me-&amp;gt;prev != (QTimeEvt *)0) { /* is the time event actually armed? */ // prev指针不为0表示已经被插入定时器链表了，但事件还没被发出去 // 返回1向调用者保证， 这个时间事件还没有被发送也不会被发送，仅对单次定时器有效， // 因为多次的话即使事件发出去了，节点也还在链表内 wasArmed = (uint8_t)1; // 从链表里删除 if (me == QF_timeEvtListHead_) { QF_timeEvtListHead_ = me-&amp;gt;next; } else { if (me-&amp;gt;next != (QTimeEvt *)0) { /* not the last in the list? */ me-&amp;gt;next-&amp;gt;prev = me-&amp;gt;prev; } me-&amp;gt;prev-&amp;gt;next = me-&amp;gt;next; } // 设定为未使用 me-&amp;gt;prev = (QTimeEvt *)0; /* mark the time event as disarmed */ } else { /* the time event was not armed */ // 定时器未启用，可能是从未启用，也有可能是事件已经发出去后被关闭了 wasArmed = (uint8_t)0; } QF_INT_UNLOCK_(); return wasArmed;}当状态机处于 A 状态时设置了一个定时事件，但在定时器生效前发生了状态切换到 B（图中触发的 BUTTON_PRESS 事件），此时 A 设定的定时事件还存在，QF 框架还会给当前状态机发事件，当 B 收到该事件后用自己的处理方式处理，就会有问题，因为这个是状态 A 设定的，B 没设定过，不同状态的对同一信号的处理是不同的。这时需要 A 在退出前关闭定时器（利用在 exit()中执行 QTimeEvt_disarm()），且用一个全局变量通知其他状态不要用已经在事件队列里的属于状态 A 的定时事件原生 QF 事件队列使用 QEQueue 数据结构管理，有两种类型： 第一个变体是特别为活动对象设计和优化的事件队列 原生 QF 事件队列放弃的功能： 比如可变尺寸的消息（原生 QF 事件队列是固定等长的，仅存储指向事件的指针） 阻塞在一个满队列（原生 QF 事件队列在插入时不能被阻塞，即使队列已满，不能处理满的情况） 定时阻塞在空队列（原生 QF 事件队列永远阻塞在空队列，意味着该线程不会在超时后去做其他事情） 另一个更简单的 QF 事件队列的变体，是一个通用的“原始的”线程安全的不能阻塞的队列 QEQueue 结构 这个图片好像画错了QEQueue 环形队列里存放的是事件指针(QEvent*)，在 32 位机里就是等长的 4 个字节，指向事件实例#ifndef QF_EQUEUE_CTR_SIZE #define QF_EQUEUE_CTR_SIZE 1#endif#if (QF_EQUEUE_CTR_SIZE == 1) typedef uint8_t QEQueueCtr;#elif (QF_EQUEUE_CTR_SIZE == 2) typedef uint16_t QEQueueCtr;#elif (QF_EQUEUE_CTR_SIZE == 4) typedef uint32_t QEQueueCtr;#else #error &quot;QF_EQUEUE_CTR_SIZE defined incorrectly, expected 1, 2, or 4&quot;#endiftypedef struct QEQueueTag{ // 该值和tail位置的值相同，指向下一个要被使用的事件，frontEvt为空表示队列为空队列 QEvent const *frontEvt; /* pointer to event at the front of the queue */ // 环形队列起始位置指针 QEvent const **ring; /* pointer to the start of the ring buffer */ // 环形队列结束偏移 QEQueueCtr end; /* offset of the end of the ring buffer from the start */ // 事件队列头(入队位置，FIFO) QEQueueCtr head; /* offset to where next event will be inserted */ // 事件队列尾(出队位置；入队位置，LIFO) QEQueueCtr tail; /* offset of where next event will be extracted */ // 环形队列空闲数量 QEQueueCtr nFree; /* number of free events in the ring buffer */ // 最小空闲事件数，跟踪队列使用的最差情况，用于微调环形缓存的尺寸 QEQueueCtr nMin; /* minimum number of free events ever in the buffer */} QEQueue;QEQueue 的初始化// 参数qSto为预分配空间void QEQueue_init(QEQueue *me, QEvent const *qSto[], QEQueueCtr qLen){ me-&amp;gt;frontEvt = (QEvent *)0; /* no events in the queue */ // 取指针数组的地址 me-&amp;gt;ring = &amp;amp;qSto[0]; me-&amp;gt;end = qLen; me-&amp;gt;head = (QEQueueCtr)0; me-&amp;gt;tail = (QEQueueCtr)0; me-&amp;gt;nFree = qLen; /* all events are free */ me-&amp;gt;nMin = qLen; /* the minimum so far */}qSto==NULL 和 qLen=0 将队列设置为仅 1 个容量，因为 fromtEvt 也算一个原生 QF 活动对象队列活动对象事件队列的接口包含 3 个函数： QActive_postFIFO()，QActive_postLIFO()和 QActive_get_()// 返回一个指向静态QEvent的指针QEvent const *QActive_get_(QActive *me){ QEvent const *e; QF_INT_LOCK_KEY_ QF_INT_LOCK_(); // 阻塞直到队列不为空（视实现而定，非抢占式的可能不阻塞） QACTIVE_EQUEUE_WAIT_(me); /* wait for event queue to get an event */ // 取frontEvt的值，而不是找ring内的tail e = me-&amp;gt;eQueue.frontEvt; // end初始化赋值为qLen，可以表示ring总长，这里判断是否全空 if (me-&amp;gt;eQueue.nFree != me-&amp;gt;eQueue.end) { /* any events in the buffer? */ /* remove event from the tail */ // 从tail取到frontEvt me-&amp;gt;eQueue.frontEvt = me-&amp;gt;eQueue.ring[me-&amp;gt;eQueue.tail]; // index为0表示绕尾 if (me-&amp;gt;eQueue.tail == (QEQueueCtr)0) { /* need to wrap the tail? */ // 绕尾就要把值从0直接变成尾部的qLen，然后减1就是绕尾后的index me-&amp;gt;eQueue.tail = me-&amp;gt;eQueue.end; /* wrap around */ } // 从tail取出，tail递减 --me-&amp;gt;eQueue.tail; // 空闲数增加 ++me-&amp;gt;eQueue.nFree; /* one more free event in the ring buffer */ } else // 如果全空 { me-&amp;gt;eQueue.frontEvt = (QEvent *)0; /* queue becomes empty */ // 队列为空信号 QACTIVE_EQUEUE_ONEMPTY_(me); } QF_INT_UNLOCK_(); return e;}void QActive_postFIFO(QActive *me, QEvent const *e){ QF_INT_LOCK_KEY_ QF_INT_LOCK_(); if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ ++((QEvent *)e)-&amp;gt;dynamic_; /* increment the reference counter */ } if (me-&amp;gt;eQueue.frontEvt == (QEvent *)0) // 为空 { /* empty queue? */ // 如果为空就直接赋值给frontEvt，不需要插入head再赋值给frontEvt me-&amp;gt;eQueue.frontEvt = e; /* deliver event directly */ // 队列非空信号，给QActive_get_()的QACTIVE_EQUEUE_WAIT_() QACTIVE_EQUEUE_SIGNAL_(me); /* signal the event queue */ } else // 不为空 { /* queue is not empty, insert event into the ring-buffer */ /* the queue must be able to accept the event (cannot overflow) */ // 事件队列不能满，满的情况不能处理，用断言退出 Q_ASSERT(me-&amp;gt;eQueue.nFree != (QEQueueCtr)0); /* insert event into the ring buffer (FIFO) */ // head位置插入 me-&amp;gt;eQueue.ring[me-&amp;gt;eQueue.head] = e; // 绕尾 if (me-&amp;gt;eQueue.head == (QEQueueCtr)0) { /* need to wrap the head? */ // 绕尾就要把值从0直接变成尾部的qLen，然后减1就是绕尾后的index me-&amp;gt;eQueue.head = me-&amp;gt;eQueue.end; /* wrap around */ } // 递减head --me-&amp;gt;eQueue.head; // 递减free --me-&amp;gt;eQueue.nFree; /* update number of free events */ if (me-&amp;gt;eQueue.nMin &amp;gt; me-&amp;gt;eQueue.nFree) { // nFree更小时，更新nMin me-&amp;gt;eQueue.nMin = me-&amp;gt;eQueue.nFree; /* update min so far */ } } QF_INT_UNLOCK_();}“ 原始的”线程安全的队列/* Application header file -----------------------------------------------*/#include &quot;qequeue.h&quot;extern QEQueue APP_isrQueue; /* global “raw” queue */typedef struct IsrEvtTag{ /* event with parameters to be passed to the ISR */ QEvent super; ...} IsrEvt;/* ISR module ------------------------------------------------------------*/QEQueue APP_isrQueue; /* definition of the “raw” queue */// 自定义ISR中断处理程序void interrupt myISR(){ QEvent const *e; // 取一个事件，这里的QEQueue_get()即使队列为空也不阻塞 ... e = QEQueue_get(&amp;amp;APP_isrQueue); /* get an event from the “raw” queue */ /* event available? */ if (e != (QEvent *)0) {// 执行事件 Process the event e(could be dispatching to a state machine) ... // 因为是ISR管理事件，不是QF框架，要记得回收空间 QF_gc(e); /* explicitly recycle the event */ } ...}/* Active object module --------------------------------------------------*/QState MyAO_stateB(MyAO *me, QEvent const *e){ switch (e-&amp;gt;sig) { ... case SOMETHING_INTERESTING_SIG: { IsrEvt *pe = Q_NEW(IsrEvt, ISR_SIG); pe-&amp;gt;... = ... /* set the event attributes */ // 发送事件 QEQueue_postFIFO(&amp;amp;APP_isrQueue, (QEvent *)pe); return (QSTATE)0; } ... } return (QState)&amp;amp;MyAO_stateA;}/* main module -----------------------------------------------------------*/static QEvent *l_isrQueueSto[10]; /* allocate a buffer for the “raw” queue */main(){ ... /* initialize the “raw” queue */ // 初始化事件队列 QEQueue_init(&amp;amp;APP_isrQueue, l_isrQueueSto, Q_DIM(l_isrQueueSto)); ...}QEQueue 函数 QEQueue_postFIFO() ， QEQueue_postLIFO() 和 QEQueue_get()的实现是非常直接的，因为不需要平台相关的宏。所有这些函数都是可重入的(多线程安全)，因为它们使用临界区代码维护队列的完整性。原生 QF 内存池图中粗黑线框起来的是一个块，细黑线分割了一个块，左边为下一空闲块指针。通过这种方法重用了空闲块的空间，不需要单独找地方存一张空闲表了typedef struct QMPoolTag{ // 空闲表表头，即首个空闲块的地址 void *free; /* the head of the linked list of free blocks */ // 池开始块地址 void *start; /* the start of the original pool buffer */ // 池结束块地址 void *end; /* the last block in this pool */ // 块大小 QMPoolSize blockSize; /* maximum block size (in bytes) */ // 块数量 QMPoolCtr nTot; /* total number of blocks */ // 空闲块数量 QMPoolCtr nFree; /* number of free blocks remaining */ // 空闲块曾经出现过的最小数量，用于分析使用情况 QMPoolCtr nMin; /* minimum number of free blocks ever in this pool */} QMPool原生 QF 内存池的初始化QFreeBlock 结构用于对不同架构 CPU 实现内存对齐：// 空闲链表节点，里面就一个指针typedef struct QFreeBlockTag { struct QFreeBlockTag *next;} QFreeBlock;void QMPool_init(QMPool *me, void *poolSto, uint32_t poolSize, QMPoolSize blockSize){ // 空闲链表 QFreeBlock *fb; uint32_t corr; uint32_t nblocks; /* The memory block must be valid * and the poolSize must fit at least one free block * and the blockSize must not be too close to the top of the dynamic range */ Q_REQUIRE((poolSto != (void *)0) // 预分配空间不能为空 &amp;amp;&amp;amp; (poolSize &amp;gt;= (uint32_t)sizeof(QFreeBlock)) // 池大小必须能够至少放入一个空闲块，后面有断言poolSize &amp;gt;= (uint32_t)blockSize，这里只是一种判断条件 &amp;amp;&amp;amp; ((QMPoolSize)(blockSize + (QMPoolSize)sizeof(QFreeBlock)) &amp;gt; blockSize)); // blockSize值不应该接近QMPoolSize类型值上限，比如QMPoolSize是uint16， // blockSize不应该接近65535，如果blockSize为65532， // 这里加上QFreeBlock指针的4，就会溢出回绕，最终比blockSize小。 /*lint -e923 ignore MISRA Rule 45 in this expression */ // (uint32_t)sizeof(QFreeBlock) - (uint32_t)1得到非对齐mask，如4-1=3=0x0011，如果是对齐地址，&amp;amp;操作后应该为0(相当于除以4的余数)，非对齐则不为0 corr = ((uint32_t)poolSto &amp;amp; ((uint32_t)sizeof(QFreeBlock) - (uint32_t)1)); if (corr != (uint32_t)0) // 未对齐 { /* alignment needed? */ // 算对齐误差 corr = (uint32_t)sizeof(QFreeBlock) - corr; /*amount to align poolSto*/ // poolSize相应缩小，放弃未对齐部分 poolSize -= corr; /* reduce the available pool size */ } /*lint -e826 align the head of free list at the free block-size boundary*/ // 开始给QPool赋值，强制对齐下，会丢弃未对齐部分，从对齐地址开始使用 me-&amp;gt;free = (void *)((uint8_t *)poolSto + corr); /* round up the blockSize to fit an integer # free blocks, no division */ // me-&amp;gt;blockSize通过运算变为blockSize me-&amp;gt;blockSize = (QMPoolSize)sizeof(QFreeBlock); /* start with just one */ // nblocks的计算避免用到除法，而是用while做加法计算 // nBlocks = (blockSize + sizeof(QFreeBlock) – 1)/sizeof(QFreeBlock + 1) nblocks = (uint32_t)1; /* # free blocks that fit in one memory block */ // 加法增加，也能保证me-&amp;gt;blockSize是sizeof(QFreeBlock)的整数倍，保证了每个块的地址也是对齐的 while (me-&amp;gt;blockSize &amp;lt; blockSize) { me-&amp;gt;blockSize += (QMPoolSize)sizeof(QFreeBlock); ++nblocks; } blockSize = me-&amp;gt;blockSize; /* use the rounded-up value from now on */ /* the pool buffer must fit at least one rounded-up block */ Q_ASSERT(poolSize &amp;gt;= (uint32_t)blockSize); /* chain all blocks together in a free-list... */ // 第一个直接减掉，因为已经加进链表了，见下面的while循环 poolSize -= (uint32_t)blockSize; /*don’t link the last block to the next */ // 不是从0开始，因为第一个就是me-&amp;gt;free，已经在了，见下面while循环 me-&amp;gt;nTot = (QMPoolCtr)1; /* the last block already in the pool */ // 空闲队列指针赋值 fb = (QFreeBlock *)me-&amp;gt;free; /*start at the head of the free list */ while (poolSize &amp;gt;= (uint32_t)blockSize) { /* can fit another block? */ // TODO:这里的nblocks应该是me-&amp;gt;nTot吧 fb-&amp;gt;next = &amp;amp;fb[nblocks]; /* point the next link to the next block */ // 链表生成 fb = fb-&amp;gt;next; /* advance to the next block */ poolSize -= (uint32_t)blockSize; /* reduce the available pool size */ ++me-&amp;gt;nTot; /* increment the number of blocks so far */ } fb-&amp;gt;next = (QFreeBlock *)0; /* the last link points to NULL */ me-&amp;gt;nFree = me-&amp;gt;nTot; /* all blocks are free */ me-&amp;gt;nMin = me-&amp;gt;nTot; /* the minimum number of free blocks */ me-&amp;gt;start = poolSto; /* the original start this pool buffer */ me-&amp;gt;end = fb; /* the last block in this pool */} 许多 CPU 架构对指针的正确对齐有特别的要求。例如， ARM 处理器需要一个指针被分配在一个可以被 4 整除的地址。其他的 CPU，比如 Pentium ，可以接受分配在奇数地址的指针，但是当指针在可被 4 整除的地址对齐时，执行性能会更加好。从池里获得一个内存块使用 QMPool_get() 从内存池获取一个块，支持耗尽，耗尽返回 NULL。 之前在动态事件分配中提到如果是内存池用于动态事件队列，由于 QF 不支持满队列（耗尽），所以用完无法插入队列时会直接断言报错。void *QMPool_get(QMPool *me){ QFreeBlock *fb; QF_INT_LOCK_KEY_ QF_INT_LOCK_(); fb = (QFreeBlock *)me-&amp;gt;free; /* get a free block or NULL */ if (fb != (QFreeBlock *)0) { /* free block available? */ me-&amp;gt;free = fb-&amp;gt;next; /* adjust list head to the next free block */ --me-&amp;gt;nFree; /* one less free block */ if (me-&amp;gt;nMin &amp;gt; me-&amp;gt;nFree) { me-&amp;gt;nMin = me-&amp;gt;nFree; /* remember the minimum so far */ } } QF_INT_UNLOCK_(); return fb; /* return the block or NULL pointer to the caller */}把一个内存块回收到池内QMPool_put() 用来把块回收到池内// b是要回收的块的地址void QMPool_put(QMPool *me, void *b){ QF_INT_LOCK_KEY_ Q_REQUIRE((me-&amp;gt;start &amp;lt;= b) &amp;amp;&amp;amp; (b &amp;lt;= me-&amp;gt;end) /* must be in range */ // TODO: 这里应该是小于不是小于等于，等于说明全空闲，就不能再释放了 &amp;amp;&amp;amp; (me-&amp;gt;nFree &amp;lt;= me-&amp;gt;nTot)); /* # free blocks must be &amp;lt; total */ QF_INT_LOCK_(); ((QFreeBlock *)b)-&amp;gt;next = (QFreeBlock *)me-&amp;gt;free; /* link into free list */ me-&amp;gt;free = b; /* set as new head of the free list */ ++me-&amp;gt;nFree; /* one more free block in this pool */ QF_INT_UNLOCK_();}原生 QF 优先级集合可以用来表示活动对象优先级，此时每一位对应一个活动对象typedef struct QPSet64Tag{ uint8_t bytes; /* condensed representation of the priority set */ uint8_t bits[8]; /* bitmasks representing elements in the set */} QPSet64;uint8_t bits[8]一共是 8 个 1 字节共 64 位，对应图上的 8x8 矩阵(bitmask)，bits[0]表示第 1 行,bits[7]表示第 8 行uint8_t bytes用于加快 bitmask 查找，用来指示对应行的位中是否有至少一个 1(字节值大于等于 1)。相当于是把 1 个字节压缩成 1 位，将 8 个字节看成 1 个字节处理。如bytes的第0位指示bits[0]是否大于等于 1，如大于等于 1 则为 1。bytes 为0x10010001表示bytes[0]、bytes[4]、bytes[7]大于等于 1。判断集合是否为空:#define QPSet64_notEmpty(me_) ((me_)-&amp;gt;bytes != (uint8_t)0)找出集合里最大的元素:// 先找bytes最高位，在找最高位对应的bits的最高位，bytes移位算偏移后相加#define QPSet64_findMax(me_, n_) \\ do \\ { \\ (n_) = (uint8_t)(QF_log2Lkup[(me_)-&amp;gt;bytes] - 1); \\ (n_) = (uint8_t)(((n_) &amp;lt;&amp;lt; 3) + QF_log2Lkup[(me_)-&amp;gt;bits[n_]]); \\ } while (0) 二进制对数查找表 QF_log2Lkup 见发行-订阅事件发送的发行一节插入一个值:#define QPSet64_insert(me_, n_) \\ do \\ { \\ (me_)-&amp;gt;bits[QF_div8Lkup[n_]] |= QF_pwr2Lkup[n_]; \\ (me_)-&amp;gt;bytes |= QF_pwr2Lkup[QF_div8Lkup[n_] + 1]; \\ } while (0) 字节索引 QF_div8Lkup[p] = (p – 1)/8（把值转为 bits 的索引），找字节内偏移 QF_pwr2Lkup[p] = 1 &amp;lt;&amp;lt; ((p – 1) % 8)（p-1 是因为偏移和索引都是从 0 开始，参数 p 是从 1 开始）先给 bits 赋值，再给 bytes 赋值移除一个值:#define QPSet64_remove(me_, n_) \\ do \\ { \\ (me_)-&amp;gt;bits[QF_div8Lkup[n_]] &amp;amp;= QF_invPwr2Lkup[n_]; \\ if ((me_)-&amp;gt;bits[QF_div8Lkup[n_]] == (uint8_t)0) \\ { \\ (me_)-&amp;gt;bytes &amp;amp;= QF_invPwr2Lkup[QF_div8Lkup[n_] + 1]; \\ } \\} while(0) QF_invPwr2Lkup[p] 清除对应位原生合作式 vanilla 内核QF 包含了一个简单的合作式 vanilla 内核 在计算机科学领域，香草vanilla是一个用于表示“一个事物没有经过自定义的改动而仍然保留着它们默认的形式”的术语。这个术语已经广为流传并成为事实标准。香草一词来自于传统冰淇淋的标准口味，香草味。根据 Eric S. Raymond 的《The New Hacker’s Dictionary》一书记载，香草一词在感觉上比普通一词更能表达“默认”的含义。维基百科:香草软件vanilla 内核通过在一个无限循环内不断查询所有活动对象的事件队列来工作。内核总是挑选最高优先级的预备运行(非空事件队列)的活动对象图中所示 QPSet64 类型的 QF_readySet_ 优先级集合用于表示系统内所有非空事件队列的“预备集合”，每一位对应一个活动对象。活动对象的事件队列为非空时对应位置 1 ，为空时置 0qvanilla.c 源文件#include &quot;qf_pkg.h&quot;#include &quot;qassert.h&quot;/* Package-scope objects -----------------------------------------------*/// 禁止优化，因为可能在中断中改变QPSet64 volatile QF_readySet_; /* QF-ready set of active objects *//*.....................................................................*/void QF_init(void){ /* nothing to do for the “vanilla” kernel */}/*.....................................................................*/void QF_stop(void){ /* nothing to cleanup for the “vanilla” kernel */ QF_onCleanup(); /* cleanup callback */}/*.....................................................................*/// main()中调用QF_run()，把控制权转让给QF框架，也就是运行 vanilla 内核void QF_run(void){ /* see NOTE01 */ uint8_t p; QActive *a; QEvent const *e; QF_INT_LOCK_KEY_ // 配置回调函数并启动中断 QF_onStartup(); /* invoke the QF startup callback */ for (;;) { /* the background loop */ QF_INT_LOCK_();// 处理QF_readySet_上锁 // 是否有事件要处理 if (QPSet64_notEmpty(&amp;amp;QF_readySet_)) { // 获取有事件的最高优先级的活动对象 QPSet64_findMax(&amp;amp;QF_readySet_, p); a = QF_active_[p]; QF_INT_UNLOCK_(); // 中断上锁是为了处理QF_readySet_，现在可以解锁了 // 找这个活动对象的第一个待处理事件 e = QActive_get_(a); /* get the next event for this AO */ // 执行状态函数 QF_ACTIVE_DISPATCH_(&amp;amp;a-&amp;gt;super, e); /* dispatch to the AO */ QF_gc(e); /* determine if event is garbage and collect it if so */ } else // 没有事件的话不阻塞，要做其他事情，比如进入低功耗模式 // 进入Idle函数前必须上锁，这是为了防止这时候其他任务通过中断产生了事件，因为vanilla 内核的非抢占性，导致依然按照原流程进入idle状态，这个事件就不能被及时处理了（像QK内核就可以在事件发生的时候在中断里就产生一次调度，把进入idle的动作抢占了） // 进入后在开启低功耗模式前必须解锁中断，防止死锁，因为需要中断来唤醒，不解锁中断就唤醒不了 { /* all active object queues are empty */#ifndef QF_INT_KEY_TYPE // QF_onIdle是否有参数取决于临界区机制 QF_onIdle(); /* see NOTE02 */#else QF_onIdle(intLockKey_); /* see NOTE02 */#endif /* QF_INT_KEY_TYPE */ } }}/*.....................................................................*/// 启动活动对象线程void QActive_start(QActive *me, uint8_t prio, QEvent const *qSto[], uint32_t qLen, void *stkSto, uint32_t stkSize, QEvent const *ie){ Q_REQUIRE(((uint8_t)0 &amp;lt; prio) &amp;amp;&amp;amp; (prio &amp;lt;= (uint8_t)QF_MAX_ACTIVE) &amp;amp;&amp;amp; (stkSto == (void *)0)); /* does not need per-actor stack */ (void)stkSize; /* avoid the “unused parameter” compiler warning */ QEQueue_init(&amp;amp;me-&amp;gt;eQueue, qSto, (QEQueueCtr)qLen); /* initialize QEQueue */ me-&amp;gt;prio = prio; /* set the QF priority of this active object */ QF_add_(me); /* make QF aware of this active object */ QF_ACTIVE_INIT_(&amp;amp;me-&amp;gt;super, ie); /* execute initial transition */}/*.....................................................................*/void QActive_stop(QActive *me){ QF_remove_(me);}QF_onIdle()是否有参数取决于QF 里的临界区类型，当使用简单的“无条件中断解锁”策略时，这个函数没有参数，但是在使用“保存和恢复中断状态” 策略时，它需要中断状态参数。如图，如果进入 Idle 函数前不关中断，就会产生竞争，可能就有新事件插入了。然后 Idle 处理进入低功耗模式就不能及时响应这个事件了。解决办法就是进 Idle 前关中断，然后在进 Idle 后且进入低功耗模式的同时开中断，注意这个“同时”，需要实现原子操作，也就是 MCU 的支持。qvanilla.h 头文件这个头文件最重要的功能是在事件被发送到和从活动对象事件队列移除时更新预备集合 (QF_readySet_)#ifndef qvanilla_h#define qvanilla_h#include &quot;qequeue.h&quot; /* “Vanilla” kernel uses the native QF event queue */#include &quot;qmpool.h&quot; /* “Vanilla” kernel uses the native QF memory pool */#include &quot;qpset.h&quot; /* “Vanilla” kernel uses the native QF priority set */ /* the event queue and thread types for the “Vanilla” kernel */#define QF_EQUEUE_TYPE QEQueue // 使用QEQueue作为事件队列/* native QF event queue operations */#define QACTIVE_EQUEUE_WAIT_(me_) \\ // 不阻塞，仅当它确信事件队列拥有最少一个事件时，它才调用 QActive_get_() Q_ASSERT((me_)-&amp;gt;eQueue.frontEvt != (QEvent *)0)#define QACTIVE_EQUEUE_SIGNAL_(me_) \\ // 发给空队列时修改优先集合 QPSet64_insert(&amp;amp;QF_readySet_, (me_)-&amp;gt;prio)#define QACTIVE_EQUEUE_ONEMPTY_(me_) \\ // 删除后成空队列时修改优先集合 QPSet64_remove(&amp;amp;QF_readySet_, (me_)-&amp;gt;prio)/* native QF event pool operations */#define QF_EPOOL_TYPE_ QMPool // 使用QMPool作为事件池#define QF_EPOOL_INIT_(p_, poolSto_, poolSize_, evtSize_) \\ QMPool_init(&amp;amp;(p_), poolSto_, poolSize_, evtSize_)#define QF_EPOOL_EVENT_SIZE_(p_) ((p_).blockSize)#define QF_EPOOL_GET_(p_, e_) ((e_) = (QEvent *)QMPool_get(&amp;amp;(p_)))#define QF_EPOOL_PUT_(p_, e_) (QMPool_put(&amp;amp;(p_), e_))// 共享变量声明为volatile不允许优化extern QPSet64 volatile QF_readySet_; /** QF-ready set of active objects */#endif /* qvanilla_h */可抢占式“运行-到-完成”内核选择一个可抢占式内核的理由正常情况并不需要可抢占式内核： 长过程被分割成了短的 RTC(run-to-completion) 步骤，不需要内核来分割（QP从设计层面就避免了长过程，如果用可抢占式内核就可以通过内核调度分割长过程） 活动对象执行线程不会阻塞（不阻塞意味着CPU控制权会在RTC步骤执行完成时被让出） RTC 步骤足够短，响应延迟较低需要可抢占式内核的情况：需要密集的、对时序有极高要求的任务，且低优先级的任务 RTC 时间较长且不容易分解。以一个 GPS 接收机系统为例。这个接收机在一个定点 CPU 上执行大量的浮点运算去计算 GPS 的位置（计算步骤不容易分解，且占用较长 RTC 时间）。同时， GPS 接收机必须跟踪 GPS 卫星的信号，这牵涉到在小于毫秒级间隔内的闭环控制回路。很明显我们不容易把位置计算分解成足够短的 RTC 步骤从而允许可靠的信号跟踪，即使把信号跟踪定义为最高优先级，低优先级的 RTC 过程过长依然会影响时序。 定点和浮点详见定点vs浮点数字信号处理RTC 内核简介使用单堆栈的可抢占式多任务处理常规实时内核需要为每个任务配置单独的堆栈，还要维护复杂的执行上下文。需要在切换时保存上下文到任务独立的栈的原因是调度的不确定性，例：A 切 B, B 切 C, C 切 D, D 切 A，此时 A 的上下文信息如果在全局栈中，必须把 B C D 的上下文全部出栈，这显然是不合理的，所以必须为每个任务单独配置堆栈，并在切换时把上下文信息保存在任务独立的栈中。对于可确定调度顺序(基于优先级)而且遵从运行到完成规范的任务，就可以把每个任务的上下文信息都保存在全局栈中，例：A 发事件给 B，因为 B 的优先级更高，所以内核立刻调度到 B，并把 A 的上下文保存到全局栈中，B 也可以发送事件给更高优先级的任务并执行，这样就形成嵌套，因为任务都是运行到完成，所以等栈顶任务执行完可以有序退出。这种调度策略和基于优先级的中断控制器逻辑非常像。而且和函数的嵌套调用过程也非常像非阻塞型内核上面说的 RTC 内核有个局限，就是不能阻塞。原因就是虽然看上去是调度，但实际上还是一个连续执行的过程，就像函数的嵌套调用一样，不允许中间有阻塞。不过活动对象的设计就是不阻塞的，这也不是问题。同步抢占和异步抢占 同步抢占 当一个较低优先级任务发送一个事件给一个较高优先级任务时，内核必须立刻暂停较低优先级任务的执行，并启动较高优先级的任务。 异步抢占 在中断 ISR 中发送一个事件给一个比被中断的任务更高优先级的任务时，当这个 ISR 完成后，内核必须启动较高优先级任务的执行，而不是恢复这个较低优先级的任务。(因为中断的优先级总是比任务高，必须运行到完成后才运行执行任务) 同步抢占： （2）时低优先级任务发送事件给高优先级任务，且调度器开始调度。 （5）时高优先级任务发送事件给低优先级任务，调度器不执行调度， （7）时高优先级任务运行完成并返回（2）时调用的调度器。 （8）调度器再一次检查是否有一个较高优先级任务准备运行，但是它没找到。 RTC调度器返回低优先级任务。异步抢占： （3）中断服务程序 (ISR) 执行 RTC 内核特定的进入动作，它在一个堆栈变量中保存被中断任务的优先级，把 RTC 内核的当前优先级提升到 ISR 层（在任何任务之上）。这一步是为了防止第（4）步产生事件导致的调度，因为此时内核优先级比那个任务优先级高，就不会在 ISR 内部触发调度动作 （4）ISR 发送了一个事件给高优先级任务，发送事件的动作会让 RTC 调度器工作，它立即返回，因为没有任务有比当前的优先级更高的优先级（ISR 优先级比任何任务高）。ISR 继续运行 （5）ISR 继续运行，最后执行 RTC 内核相关的退出动作 （6）RTC 内核相关的 ISR 退出，发送 End-Of-Interrupt(EOI) 指令给中断控制器，恢复被中断任务的被保留的优先级，并调用 RTC 调度器。 退出中断有 EOI 和 IRET 两步，EOI 表示停止对当前的中断嵌套层进行优先级排序(此时可以插入任意优先级新中断)，IRET 表示从中断返回。这一步只发 EOI 表示还不想从中断返回 （7）调度器开中断，并开始调度到高优先级任务。此时 RTC 调度器没有返回。 （9）高优先级任务执行完毕并返回到 RTC 调度器 （10）IRET 执行，IRET 恢复低优先级任务的上下文，从（2）开始的中断返回在第 (5) 步 RTC 内核相关的中断退出(执行 EOI 后)里，中断处理在概念上已经结束了，即使中断堆栈帧(interrupt stack frame) 继续保留在堆栈上并且 IRET 指令还没执行。在 EOI 指令之前，中断控制器仅允许比当前正在服务的中断更高优先级的中断。在 EOI 指令后，通过调用 RTC 调度器，中断被解锁，中断控制器允许所有的级别的中断，这正是在任务层所期望的行为。这样的话在（8）中高优先级任务执行时依旧可以触发中断和异步调度堆栈的利用同步抢占: （2）发送事件给高优先级任务，调用了 RTC 调度器，调度器堆栈帧(stack frame)入栈所以栈增长了 （3）RTC 调度器调用高优先级任务，任务堆栈帧(stack frame)入栈，栈再次增长 （5）高优先级任务发送事件给低优先级任务，调用了 RTC 调度器，调度器堆栈帧(stack frame)入栈，随后因为不满足调度条件立即返回，调度器堆栈帧(stack frame)出栈 （7）任务堆栈帧(stack frame)出栈 （8）调度器在调度完成后再次检查是否有较高优先级的任务要运行，没有就出栈异步抢占: （2）发生中断，由硬件控制将中断堆栈帧压栈，ISR 开始运行，并可能把某些别的上下文压入堆栈 （就是 ISR 程序，虚线所示） （4）TODO：应该会发送事件触发一次调度器调用，怎么栈没增加 （6）RTC 调度器被调用，堆栈帧入栈 （7）使能中断并调度到高优先级任务，堆栈帧入栈 （8）高优先级任务运行到结束，出栈 （9）调度器再次检查，没有就出栈 （10）ISR 出栈（虚线），硬件执行 IRET 指令，中断出栈和传统可抢占式内核的比较通过在一个堆栈管理所有的任务和中断的上下文， RTC 内核运行所需的 RAM 远比一个典型的阻塞式内核需要的少。C 编译器生成的 ISR 进入时仅保留可能在 C 函数被使用那些寄存器，而不是全部，比传统的少，降低了进入 ISR 时的堆栈和 CPU 消耗QK 的实现QK 源代码的组织&amp;lt;qp&amp;gt;\\qpc\\ - QP/C root directory (&amp;lt;qp&amp;gt;\\qpcpp for QP/C++)|+-include\\ - QP platform-independent header files| +-qk.h - QK platform-independent interface| +-. . .|+-qk\\ - QK preemptive kernel| +-source\\ - QK platform-independent source code (*.C files)| | +-qk_pkg.h - internal, interface for the QK implementation| | +-qk.c - definitionofQK_getVersion()andQActive_start()| | +-qk_sched.c - definition of QK_schedule_()| | +-qk_mutex.c - definition of QK_mutexLock()/QK_mutexUnlock()| | +-qk_ext.c - definition of QK_scheduleExt_()| || +-lint\\ - QK options for lint| +-opt_qk.lnt - PC-lint options for linting QK|+-ports\\ - Platform-specific QP ports| +-80x86\\ - Ports to the 80x86 processor| | +-qk\\ - Ports to the QK preemptive kernel| | | +-tcpp101\\ - Ports with the Turbo C++ 1.01 compiler| | | +-l\\ - Ports using the Large memory model| | | +-dbg\\ - Debug build| | | | +-qf.lib – QF library| | | | +-qep.lib – QEP library| | | +-rel\\ - Release build| | | +-spy\\ - Spy build (with software instrumentation)| | | +-make.bat – batch script for building the QP libraries| | | +-qep_port.h – QEP platform-dependent include file| | | +-qf_port.h – QF platform-dependent include file| | | +-qk_port.h – QK platform-dependent include file| | | +-qs_port.h – QS platform-dependent include file| | | +-qp_port.h – QP platform-dependent include file| +-cortex-m3\\ - Ports to the Cortex-M3 processor| | +-qk\\ - Ports to the QK preemptive kernel| | | +-iar\\ - Ports with the IAR compiler| |+-examples\\ - Platform-specific QP examples| +-80x88\\ - Examples for the 80x86 processor| | +-qk\\ - Examples for the QK preemptive kernel| | | +- . . .| +-cortex-m3\\ - Examples for the Cortex-M3 processor| | +-qk\\ - Examples for the QK preemptive kernel| | | +- . . .| +- . . .头文件 qk.h#ifndef qk_h#define qk_h// QK 内核使用原生 QF 事件队列#include &quot;qequeue.h&quot; /* The QK kernel uses the native QF event queue */// QK 内核使用原生 QF 内存池#include &quot;qmpool.h&quot; /* The QK kernel uses the native QF memory pool */// QK 内核使用原生 QF 优先级集合#include &quot;qpset.h&quot; /* The QK kernel uses the native QF priority set *//* public-scope objects */// 优先级集合，相当于等待队列extern QPSet64 volatile QK_readySet_; /**&amp;lt; QK ready-set */// 当前正在运行的任务或中断的全局系统范围的优先级extern uint8_t volatile QK_currPrio_; /**&amp;lt; current task/interrupt priority */// 全局系统范围的中断嵌套层extern uint8_t volatile QK_intNest_; /**&amp;lt; interrupt nesting level *//***************************************************************************************//* QF configuration for QK */#define QF_EQUEUE_TYPE QEQueue#if defined(QK_TLS) || defined(QK_EXT_SAVE)// 活动对象中的osObject变量的类型，比如Linux移植中使用pthread_cond_t用来表示条件变量控制线程休眠和唤醒，// 这里QK里用来表示位掩码#define QF_OS_OBJECT_TYPE uint8_t// 活动对象里的thread变量的类型，标识线程，如Linux移植中使用pthread_t标识活动对象的线程id。#define QF_THREAD_TYPE void *#endif /* QK_TLS || QK_EXT_SAVE *//* QK active object queue implementation...................................*/// QK内核不阻塞，这个宏由QActive_get_调用，原用于事件队列为空时阻塞get,这里加了断言表示调用get时要保证事件队列非空，从而满足不阻塞要求#define QACTIVE_EQUEUE_WAIT_(me_) \\ Q_ASSERT((me_)-&amp;gt;eQueue.frontEvt != (QEvent *)0)// 当空的事件队列插入新事件时被调用，#define QACTIVE_EQUEUE_SIGNAL_(me_) \\ // 加入预备队列 QPSet64_insert(&amp;amp;QK_readySet_, (me_)-&amp;gt;prio); \\ // 如果发生在任务层，则调用调度器，否则发生在中断层，不调用调度器，因为任务不可能抢占中断 if (QK_intNest_ == (uint8_t)0) \\ { \\ QK_SCHEDULE_(); \\ } \\ else \\ ((void)0)// 移除事件导致事件队列为空时调用#define QACTIVE_EQUEUE_ONEMPTY_(me_) \\ QPSet64_remove(&amp;amp;QK_readySet_, (me_)-&amp;gt;prio)/* QK event pool operations...............................................*/// 使用QF事件池#define QF_EPOOL_TYPE_ QMPool#define QF_EPOOL_INIT_(p_, poolSto_, poolSize_, evtSize_) \\ QMPool_init(&amp;amp;(p_), poolSto_, poolSize_, evtSize_)#define QF_EPOOL_EVENT_SIZE_(p_) ((p_).blockSize)#define QF_EPOOL_GET_(p_, e_) ((e_) = (QEvent *)QMPool_get(&amp;amp;(p_)))#define QF_EPOOL_PUT_(p_, e_) (QMPool_put(&amp;amp;(p_), (e_)))void QK_init(void); /* QK initialization */void QK_onIdle(void); /* QK idle callback */char const Q_ROM *Q_ROM_VAR QK_getVersion(void);// QK自己实现的互斥体typedef uint8_t QMutex; /* QK priority-ceiling mutex */// QK自己实现的互斥锁（用于临界区）QMutex QK_mutexLock(uint8_t prioCeiling);void QK_mutexUnlock(QMutex mutex);/* QK scheduler and extended scheduler */// 如果QF_INT_KEY_TYPE未定义#ifndef QF_INT_KEY_TYPE// 使用无条件中断上锁解锁void QK_schedule_(void);void QK_scheduleExt_(void); /* QK extended scheduler */#define QK_SCHEDULE_() QK_schedule_()#else// 使用保存和恢复中断状态，参数需要一个保存当前中断状态的变量void QK_schedule_(QF_INT_KEY_TYPE intLockKey);void QK_scheduleExt_(QF_INT_KEY_TYPE intLockKey); /* extended scheduler */#define QK_SCHEDULE_() QK_schedule_(intLockKey_)#endif /* QF_INT_KEY_TYPE */#endif /* qk_h */中断的处理可抢占型内核需要通过中断夺回控制权来执行调度，需要编写自己的ISR处理程序QK 里的 ISR:void interrupt YourISR(void){/* typically entered with interrupts locked */ // 一般进ISR中断是上锁的，但有些CPU不上锁 // 清除中断源如有必要，防止中断丢失 Clear the interrupt source, if necessary // 如果中断原来就是上锁的，不用上锁，否则要先上锁 // 修改QK_intNest_（需要临界区）让QK知道现在是在中断层，不允许任务抢占 ++QK_intNest_; /* account for one more interrupt nesting level */ // 退出临界区 Unlock interrupts(depending on the interrupt policy used) // 执行QF相关服务 Execute ISR body,including calling QF services, such as : Q_NEW(), QActive_postFIFO(), QActive_postLIF(), QF_publish(), or QF_tick() Lock interrupts, if they were unlocked in step(4) // 给中断控制器发送EOI Send the EOI instruction to the interrupt controller // 通知QK结束了中断层，可以开始调度 --QK_intNest_; /* account for one less interrupt nesting level */ if (QK_intNest_ == (uint8_t)0) { /* coming back to the task level? */ QK_schedule_(); /* handle potential asynchronous preemption */ }}源文件 qk_sched.c （ QK 调度器）qk_sched.c 源文件实现了 QK 调度器，它是 QK 内核的最重要的部分。仅在 2 个时刻调用 QK 调度器： 当一个事件被发送给一个活动对象的一个事件队列（同步抢占） 在 ISR 处理的尾部（异步抢占）。QK 调度器是一个简单的常规 C 函数 QK_schedule_() ，它的工作是有效的找出预备运行的最高优先级的活动对象。为了执行这个工作， QK 调度器依靠 2 个数据元素： 预备运行的任务的集合 QK_readySet_ QPSet64类型，是个位图，每个bit表示一个活动对象，按照位排序1-64优先级 当前被服务的优先级 QK_currPrio_ uint8_t类型，存储当前优先级 #include &quot;qk_pkg.h&quot;/* Public-scope objects -------------------------------------------------*/// 优先级位图QPSet64 volatile QK_readySet_; /* QK ready-set *//* start with the QK scheduler locked */// 当前优先级uint8_t volatile QK_currPrio_ = (uint8_t)(QF_MAX_ACTIVE + 1);// 嵌套级别，0表示任务层，大于等于1表示是非任务层uint8_t volatile QK_intNest_; /* start with nesting level of 0 *//*......................................................................*//* NOTE: the QK scheduler is entered and exited with interrupts LOCKED */#ifndef QF_INT_KEY_TYPE// 中断上锁策略选择void QK_schedule_(void){#elsevoid QK_schedule_(QF_INT_KEY_TYPE intLockKey_){#endif uint8_t p; /* the QK scheduler must be called at task level only */ // 需要当前为任务层，如果是中断层不执行调度 Q_REQUIRE(QK_intNest_ == (uint8_t)0); if (QPSet64_notEmpty(&amp;amp;QK_readySet_)) { /* determine the priority of the highest-priority task ready to run */ // 从位图找优先级最高的已就绪对象 QPSet64_findMax(&amp;amp;QK_readySet_, p); // 判断这个对象优先级是否超过当前优先级 // 注意此处如果任务执行中又发送事件给其他对象，导致再次调用本调度函数形成嵌套，通过这个判断可以终止嵌套，防止低优先级任务抢占 if (p &amp;gt; QK_currPrio_) {/* do we have a preemption? */ // 保存优先级用于恢复 uint8_t pin = QK_currPrio_; /* save the initial priority */ QActive *a;#ifdef QK_TLS /* thread-local storage used? */ uint8_t pprev = pin;#endif do { QEvent const *e; a = QF_active_[p]; /* obtain the pointer to the AO */ // 更新当前优先级 QK_currPrio_ = p; /* this becomes the current task priority */#ifdef QK_TLS /* thread-local storage used? */ if (p != pprev) { /* are we changing threads? */ QK_TLS(a); /* switch new thread-local storage */ pprev = p; }#endif // 解锁中断，运行任务 QK_INT_UNLOCK_(); /* unlock the interrupts */ e = QActive_get_(a); /* get the next event for this AO */ QF_ACTIVE_DISPATCH_(&amp;amp;a-&amp;gt;super, e); /* dispatch to the AO */ QF_gc(e); /* garbage collect the event, if necessary */ // 再次上锁 /* determine the highest-priority AO ready to run */ // 再次检测是否有高优先级任务等待执行，比如在上面的RTC步骤中发送事件给了其他任务（优先级比pin也就是调用本函数时的优先级高，在本函数返回前要把这些任务都处理完） QK_INT_LOCK_(); if (QPSet64_notEmpty(&amp;amp;QK_readySet_)) { QPSet64_findMax(&amp;amp;QK_readySet_, p); } else { p = (uint8_t)0; } } while (p &amp;gt; pin); /* is the new priority higher than initial? */ // 本次调度执行完成，假设内部有递归也递归执行完成，且所有优先级高于本函数调用时优先级的任务全部执行完成，本函数返回前恢复优先级 QK_currPrio_ = pin; /* restore the initial priority */#ifdef QK_TLS /* thread-local storage used? */ if (pin != (uint8_t)0) { /* no extended context for idle loop */ a = QF_active_[pin]; QK_TLS(a); /* restore the original TLS */ }#endif } }}源文件 qk.c （ QK 的启动和空闲循环）#include &quot;qk_pkg.h&quot;#include &quot;qassert.h&quot;Q_DEFINE_THIS_MODULE(qk)/*......................................................................*/void QF_init(void){ /* nothing to do for the QK preemptive kernel */ // 给个机会让QK初始化 QK_init(); /* might be defined in assembly */}/*......................................................................*/void QF_stop(void){ QF_onCleanup(); /* cleanup callback */ /* nothing else to do for the QK preemptive kernel */}/*......................................................................*/// 从main调用QF_run转让控制权void QF_run(void){ // 实现QK内核的启动，可以和 vanilla 内核对比下 QK_INT_LOCK_KEY_ QK_INT_LOCK_(); // 优先级QK_currPrio_从初始的QF_MAX_ACTIVE+1变为0，开始空闲循环 QK_currPrio_ = (uint8_t)0; /* set the priority for the QK idle loop */ // 执行一次调度 QK_SCHEDULE_(); /* process all events produced so far */ QK_INT_UNLOCK_(); QF_onStartup(); /* startup callback */ for (;;) {/* the QK idle loop */ // 给应用程序一个机会去把 CPU放入低功耗睡眠模式，或者执行其他任务(如软件追踪输出)，通常在应用程序层 (BSP) 实现 QK_onIdle()函数 // 区别于vanilla 内核，QK内核进入idle前不用上锁（且不能上锁），因为可以实现抢占，只要有事件发生就会触发一次调度，不会导致事件未及时处理 QK_onIdle(); /* invoke the QK on-idle callback */ }}/*......................................................................*/// 启动活动对象void QActive_start(QActive *me, uint8_t prio, QEvent const *qSto[], uint32_t qLen, void *tls, uint32_t flags, QEvent const *ie){ Q_REQUIRE(((uint8_t)0 &amp;lt; prio) &amp;amp;&amp;amp; (prio &amp;lt;= (uint8_t)QF_MAX_ACTIVE)); QEQueue_init(&amp;amp;me-&amp;gt;eQueue, qSto, (QEQueueCtr)qLen); me-&amp;gt;prio = prio; QF_add_(me); /* make QF aware of this active object */#if defined(QK_TLS) || defined(QK_EXT_SAVE) me-&amp;gt;osObject = (uint8_t)flags; /* osObject contains the thread flags */ me-&amp;gt;thread = tls; /* contains the pointer to the thread-local storage */#else Q_ASSERT((tls == (void *)0) &amp;amp;&amp;amp; (flags == (uint32_t)0));#endif QF_ACTIVE_INIT_(&amp;amp;me-&amp;gt;super, ie); /* execute initial transition */}/*......................................................................*/void QActive_stop(QActive *me){ QF_remove_(me); /* remove this active object from the QF */}高级的 QK 特征优先级天花板互斥体活动对象应该只通过事件进行通讯，并且不共享任何资源。你也许想选择共享某些选定的资源，就算要付出增加活动对象之间耦合的成本。如果你想这么做，你让自己背上了要处理存取这些资源（共享的内存或设备）的内部互锁的负担。可以用 QF 宏QF_INT_LOCK() 和 QF_INT_UNLOCK() 实现的临界区机制QK 支持优先级天花板互斥体(priority-ceiling mutex)，在存取一个共享资源时，防止任务级的抢占。void your_function(arguments) { // QMutex类型的临时变量（uint8_t） QMutex mutex; ... // 上锁 mutex = QK_mutexLock(PRIO_CEILING); // 临界区 You can safely access the shared resource here QK_mutexUnlock(mutex); ...}QK 互斥体(&amp;lt;qp&amp;gt;\\qpc\\qk\\source\\qk_mutex.c):QMutex QK_mutexLock(uint8_t prioCeiling){ uint8_t mutex; QK_INT_LOCK_KEY_ QK_INT_LOCK_(); // 临时保存当前优先级 mutex = QK_currPrio_; /* the original QK priority to return */ // 如果当前优先级小于天花板优先级（就是最高优先级，任务最大优先级加1，比所有任务都高） if (QK_currPrio_ &amp;lt; prioCeiling) { // 当前优先级设为天花板优先级 QK_currPrio_ = prioCeiling; /* raise the QK priority */ } QK_INT_UNLOCK_(); // 返回修改前的（调用本函数时）优先级，用于作为后面unlock时的参数 return mutex;}/*..............................................................*/void QK_mutexUnlock(QMutex mutex){ QK_INT_LOCK_KEY_ QK_INT_LOCK_(); if (QK_currPrio_ &amp;gt; mutex) { // 恢复优先级 QK_currPrio_ = mutex; /* restore the saved priority */ QK_SCHEDULE_(); } QK_INT_UNLOCK_();}其实类似于关中断让系统无法调度其他进程，只不过这个是应用层面的锁，不需要系统的关中断支持，这样就和操作系统和硬件解耦了。本地线程存储线程本地存储 (Thread-local storage,TLS) 是一种机制，变量通过它被分配，这样每个现存的线程有这个变量的一个实例。该功能是为了解决多线程使用共用的全局变量时的冲突问题。例如，ANSI C标准里的 errno 功能。errno 是一个 int 类型的宏，当程序出现问题时，设置该宏为一个错误码，也就是 errno 的值为上一次错误的错误码。但这个宏是所有线程共享的，也就是线程无法分清这是哪个线程设置的。解决方式是把 errno 定义为一个指针，指向了类型为 struct_reent 的结构，每个线程都包含了这个结构的对象(线程本地存储)，上下文切换时让 errno 指针指向对应线程的这个对象。不仅解决了重入的问题，还扩展了 errno 的功能，因为struct_reent结构可以包含大量自定义的错误信息。QK 通过提供一个上下文切换钩子 QK_TLS() 来支持 TLS概念，在每一次，每一个不同任务的优先级被处理时，它被调用。#define QK_TLS(act_) (_impure_ptr=(struct _reent *)(act_)-&amp;gt;thread)扩展的上下文切换（对协处理器的支持）C编译器为中断程序生成的上下文保存和恢复通常仅包含CPU核心寄存器，不包括各种协处理器的寄存器，比如围绕 CPU 核心的浮点协处理器，专门的 DSP 引擎，基带处理器，视频加速器或其他的协处理器。这些寄存器称为扩展上下文两种情况不需要保存扩展上下文： ISR 和 QK 空闲处理都不会使用协处理器。空闲循环不对应于某个活动对象，因此它不需要拥有 TLS 内存区域来保存扩展的上下文。（因此， 仅当某个任务抢占别的任务时才需要保存扩展上下文） 同步抢占时一般不需要，因为同步抢占相当于一次函数调用，发送事件时产生调度，然后等高优先级的处理完通过函数返回，不会在存取某个协处理器时发生这样就只有异步抢占时才需要保存扩展上下文，也就是在 QK_ISR_EXIT() 宏调用时。#define QK_ISR_EXIT() do { \\ Lock interrupts \\ Send the EOI instruction to the interrupt controller \\ --QK_intNest_; \\ if (QK_intNest_ == 0) { \\ QK_scheduleExt_(); \\ } \\} while (0)QK_scheduleExt_() 取代 QK_scheduler_() 用于保存扩展上下文。扩展上下文也包含在 TLS 区QK 扩展调度器的实现（ &amp;lt;qp&amp;gt;\\qpc\\qk\\source\\qk_ext.c）:#ifndef QF_INT_KEY_TYPEvoid QK_scheduleExt_(void){#elsevoid QK_scheduleExt_(QF_INT_KEY_TYPE intLockKey_){#endif uint8_t p; /* the QK scheduler must be called at task level only */ Q_REQUIRE(QK_intNest_ == (uint8_t)0); if (QPSet64_notEmpty(&amp;amp;QK_readySet_)) { /* determine the priority of the highest-priority task ready to run */ QPSet64_findMax(&amp;amp;QK_readySet_, p); if (p &amp;gt; QK_currPrio_) { /* do we have a preemption? */ uint8_t pin = QK_currPrio_; /* save the initial priority */ QActive *a;#ifdef QK_TLS /* thread-local storage used? */ uint8_t pprev = pin;#endif#ifdef QK_EXT_SAVE /* extended context-switch used? */ // 扩展上下文保存，pin为0表示空闲循环，不保存 if (pin != (uint8_t)0) { /*no extended context for the idle loop */ // 找到被抢占的活动对象的指针 a = QF_active_[pin]; /* the pointer to the preempted AO */ // 在调度前保存扩展上下文 // 即使不启用TLS也会保存 QK_EXT_SAVE(a); /* save the extended context */ }#endif do { QEvent const *e; a = QF_active_[p]; /* obtain the pointer to the AO */ QK_currPrio_ = p; /* this becomes the current task priority */#ifdef QK_TLS /* thread-local storage used? */ if (p != pprev) { /* are we changing threads? */ // 切换TLS指针 QK_TLS(a); /* switch new thread-local storage */ pprev = p; }#endif QK_INT_UNLOCK_(); /* unlock the interrupts */ e = QActive_get_(a); /* get the next event for this AO */ QF_ACTIVE_DISPATCH_(&amp;amp;a-&amp;gt;super, e); /* dispatch to the AO */ QF_gc(e); /* garbage collect the event, if necessary */ QK_INT_LOCK_(); /* determine the highest-priority AO ready to run */ if (QPSet64_notEmpty(&amp;amp;QK_readySet_)) { QPSet64_findMax(&amp;amp;QK_readySet_, p); } else { p = (uint8_t)0; } } while (p &amp;gt; pin); /* is the new priority higher than initial? */ QK_currPrio_ = pin; /* restore the initial priority */#if defined(QK_TLS) || defined(QK_EXT_RESTORE) // 只有被抢占时才需要恢复，0表示还在空闲循环，没有活动对象运行，不用恢复 if (pin != (uint8_t)0) { /*no extended context for the idle loop */ a = QF_active_[pin]; /* the pointer to the preempted AO */#ifdef QK_TLS /* thread-local storage used? */ // 切换TLS指针 QK_TLS(a); /* restore the original TLS */#endif#ifdef QK_EXT_RESTORE /* extended context-switch used? */ // 恢复扩展上下文 QK_EXT_RESTORE(a); /* restore the extended context */#endif }#endif } }}移植 QKQK 可以被移植到某个处理器和编译器，如果它们满足以下条件： 处理器支持一个硬件堆栈，它可以容纳很多数据（最少 256 字节）。 C或 C++编译器可以生成可重入代码。特别的，编译器必须可以在堆栈分配自动变量。 可以从 C/C++ 里上锁和解锁中断。 系统提供了一个时钟节拍中断（通常是 10 到 100Hz ）。后面省略，没有用移植和配置 QFQF 包含了一个被清楚定义的平台抽象层 PAL（ platform abstraction layer ），它封装了所有平台相关的代码，清晰把它和平台无关的代码区分开QP 平台抽象层QP 事件驱动式平台的所有软件构件，比如 QEP 事件处理器和 QF 实时框架，包含了一个平台抽象层 PAL。这个 PAL 是一个 indirection 层，它隐藏了 QP 运行时硬件和软件环境的差异，因此 QP 源代码不需要被修改从而在一个不同的环境运行。相反，修改 QP 的所有必需的改变被限制在 PAL 内。生成 QP 应用程序你在使用的 QP 移植由 qf_port.h 头文件和 QF 库文件所在的目录分支决定。编译+链接，QP 库允许连接器在链接时消除任何没有被引用的 QP 代码创建 QP 库QF 示例（QEP 或 QK 可以参考这个）：平台相关的 port 代码和平台无关的代码链接在一个 qf.lib 库中目录和文件PAL 使用一个一致的目录结构，允许你很容易的找到 QP 向某个给定 CPU，操作系统和编译器的移植。qpc\\ - QP/C root directory (qpcpp\\ for QP/C++),根目录可移动和改名，内部用的都是相对路径|+-ports\\ - Platform-specific QP ports| +-80x86\\ - Ports to the 80x86 processor，CPU架构作为第一层，如80x86、ARM，在嵌入式领域，CPU架构比操作系统更重要| | +-dos\\ - Ports to DOS with the &quot;vanilla&quot; cooperative kernel，操作系统放在第二层| | | +-tcpp101\\ - Ports with the Turbo C++ 1.01 compiler，编译器在第三层，Turbo C+ +1.01、GCC等| | | | +-l\\ - Ports using the Large memory model，编译器可以为不同的 CPU模式生成代码。例如在 DOS下用于 80x86 的某个编译器，可以生成 small， compact ，large或huge内存模型。| | | | | +-dbg\\ - Debug build，QP 库文件可以使用不同的编译开关和优化选项来编译，存放开启调试编译选项的二进制文件| | | | | | +-qf.lib - QF library，不同平台库文件命名规则也不同，Linux为libqf.a| | | | | | +-qep.lib - QEP library| | | | | +-rel\\ - Release build,使用发行编译选项的二进制文件| | | | | +-spy\\ - Spy build (with software instrumentation)，带qs追踪的二进制文件| | | | | +-make.bat - batch script for building the QP libraries，makefile文件| | | | | +-qep_port.h - QEP platform-dependent include file| | | | | +-qf_port.h - QFplatform-dependent include file，平台相关头文件| | | | | +-qs_port.h - QSplatform-dependent include file| | | | | +-qp_port.h - QPplatform-dependent include file| | || | +-qk\\ - Ports to the QK preemptive kernel| | | +-. . .| | || | +-ucos2\\ - Ports to the mC/OS-II RTOS| | | +-tcpp101\\ - Ports with the Turbo C++ 1.01 compiler| | | | +-l\\ - Ports using the Large memory model| | | | | +-ucos2.86\\ - mC/OS-II v2.86 object code and header files| | | | | +-src\\ - Port-specific source files| | | | | | +-qf_port.c - QF port to mC/OS-II source file| | | | | +-. . .| | || | +-linux\\ - Ports to the Linux operating system (POSIX)| | +-gnu\\ - Ports with the GNU compiler| | | | +-src\\ - Port-specific source files| | | | | +-qf_port.c - QF port to Linux source file| | +-. . .| || +-cortex-m3\\ - Ports to the Cortex-M3 processor，传统ARM和m3架构差别较大，独立设置| | +-vanilla\\ - Ports to the &quot;vanilla&quot; cooperative kernel| | | +-iar\\ - Ports with the IAR compiler| | | | +-dbg\\ - Debug build| | | | +-rel\\ - Release build| | | | +-spy\\ - Spy build (with software instrumentation)| | | | +-make.bat - batch script for building QP libraries| | | | +-qep_port.h - QEP platform-dependent include file| | | | +-qf_port.h - QF platform-dependent include file| | | | +-qs_port.h - QS platform-dependent include file| | | | +-qp_port.h - QP platform-dependent include file| | |...| | +-qk\\ - Ports to the QK preemptive kernel| | +-iar\\ - Ports with the IAR compiler| +-. . . - Ports to other CPUs|+-examples\\ - Platform-specific QP examples| +-80x86\\ - Examples for the 80x86 processor| | +-dos\\ - Examples for DOS with the &quot;vanilla&quot; cooperative kernel| | +-tcpp101\\ - Examples with the Turbo C++ 1.01 compiler| | +-l\\ - Examples using the Large memory model| | +-dpp\\ - DPP example，哲学家就餐问题，单独目录| | | +-dbg\\ - Debug build| | | | +-dpp.exe - Debug executable| | | +-rel\\ - Release build| | | | +-dpp.exe - Release executable| | | +-spy\\ - Spy build (with software instrumentation)| | | | +-dpp.exe - Spy executable| | | +-DPP-DBG.PRJ - Turbo C++ project to build the Debug version| | +-game\\ - &quot;Fly ’n’ Shoot&quot; game example| | +-. . .| +-cortex-m3\\ - Examples for the Cortex-M3 processor| | +-vanilla\\ - Examples for the &quot;vanilla&quot; cooperative kernel| | | +-iar\\ - Examples with the IAR compiler| | +-dpp\\ - DPP example| | +-game\\ - &quot;Fly ’n’ Shoot&quot; game example| | +-. . . - Other examples| +-. . . - Examples for other CPUs|+-include\\ - Platform independent QP header files，平台无关头文件| +-qep.h - QEP platform-independent interface| +-qf.h - QF platform-independent interface| +-qk.h - QK platform-independent interface| +-qs.h - QS platform-independent interface| +-. . . - Other platform-independent QP header files|+-qep\\ - QEP event processor，每个 QP 构件的平台独立的源代码在独立的目录里。| +-source\\ - QEP platform-independent source code (*.C files)| | +-. . .+-qf\\ - QF real-time framework| +-source\\ - QF platform-independent source code (*.C files)| | +-. . .+-qk\\ - QK preemptive kernel| +-source\\ - QK platform-independent source code (*.C files)| | +-. . .+-qs\\ - QS software tracing| +-source\\ - QS platform-independent source code (*.C files)| | +-. . .头文件 qep_port.hTODO:Q_ROM 和哈佛架构相关，需要了解下#ifndef qep_port_h#define qep_port_h/* special keyword used for ROM objects */#define Q_ROM ????/* specific pointer variant for accessing const objects in ROM */#define Q_ROM_VAR ????/* platform-specific access to constant data bytes in ROM */#define Q_ROM_BYTE(rom_var_) ????/* size of the QSignal data type */#define Q_SIGNAL_SIZE ?/* exact-width integer types */ // 使用编译器提供的标准stdint.h头文件或自定义编写来定义QP需要的扩展类型#include &amp;lt;stdint.h&amp;gt; /* WG14/N843 C99 Standard, Section 7.18.1.1 */typedef signed char int8_t; /* signed 8-bit integer */typedef signed short int16_t; /* signed 16-bit integer */typedef signed long int32_t; /* signed 32-bit integer */typedef unsigned char uint8_t; /* unsigned 8-bit integer */typedef unsigned short uint16_t; /* unsigned 16-bit integer */typedef unsigned long uint32_t; /* unsigned 32-bit integer */#include &quot;qep.h&quot; /* QEP platform-independent public interface */#endif /* qep_port_h */头文件 qf_port.h头文件 qf_port.h 包含了 PAL宏的定义， typedef，包含文件，和用于移植和配置 QF 实时框架的常数。 这是目前为止在整个 QP PAL 里最复杂和重要的文件。#ifndef qf_port_h#define qf_port_h/* Types of platform-specific QActive data members *************************/// 可以使用RTOS/OS提供的消息队列，也可以用QF自带的原生队列用于事件队列#define QF_EQUEUE_TYPE ????// 使用QF原生队列时必需，QF_OS_OBJECT_TYPE 数据成员包含一个操作系统相关的原语，在队列为空时有效的阻塞原生 QF 事件队列。#define QF_OS_OBJECT_TYPE ????// 包含和活动对象联合的线程处理#define QF_THREAD_TYPE ????/* Base class for derivation of QActive ***********************************/// 下面的宏用于自定义QActive的基类（默认时QHsm），一般不使用，命名结尾有下划线&#39;_&#39;作为标志#define QF_ACTIVE_SUPER_ ????#define QF_ACTIVE_CTOR_(me_, initial_) ????#define QF_ACTIVE_INIT_(me_, e_) ????#define QF_ACTIVE_DISPATCH_(me_, e_) ????#define QF_ACTIVE_STATE_ ????/* The maximum number of active objects in the application ******************/// 活动对象最大数量，不超过63，8或更小时性能更高#define QF_MAX_ACTIVE ????/* Various object sizes within the QF framework ***************************/// 都有默认值，空间大小和计数器大小#define QF_EVENT_SIZ_SIZE 2#define QF_EQUEUE_CTR_SIZE 1// 内存池块大小，每块2字节#define QF_MPOOL_SIZ_SIZE 2// 内存池计数器大小，为2表示最大表示0xFFFF个块#define QF_MPOOL_CTR_SIZE 2#define QF_TIMEEVT_CTR_SIZE 2/* QF critical section mechanism *****************************************/// 临界区// “保存和恢复中断状态”的策略和“无条件上锁和解锁中断”策略标志#define QF_INT_KEY_TYPE ????#define QF_INT_LOCK(key_) ????#define QF_INT_UNLOCK(key_) ????/* Include files used by this QF port *************************************/// 内核头文件#include &amp;lt;????.h&amp;gt; /* underlying OS/RTOS/Kernel interface */#include &quot;qep_port.h&quot; /* QEP port */#include &quot;qequeue.h&quot; /* native QF event-queue */#include &quot;qmpool.h&quot; /* native QF memory-pool */#include &quot;qvanilla.h&quot; /* native QF &quot;vanilla&quot; kernel */#include &quot;qf.h&quot; /* platform-independent QF interface *//********************************************************************** * Interface used only inside QF, but not in applications *//* Active object event queue operations ***********************************/// 仅用于QF和使用原生事件队列时的宏，名字结尾有下划线，避免用于用户应用。// 信号量耗尽阻塞#define QACTIVE_EQUEUE_WAIT_(me_) ????// 信号量补充解除阻塞#define QACTIVE_EQUEUE_SIGNAL_(me_) ????// 通知事件队列为空，比如vanilla需要在队列为空时将活动对象移出预备执行队列#define QACTIVE_EQUEUE_ONEMPTY_(me_) ????/* QF event pool operations **********************************************/// 事件池#define QF_EPOOL_TYPE_ ????#define QF_EPOOL_INIT_(p_, poolSto_, poolSize_, evtSize_) ????#define QF_EPOOL_EVENT_SIZE_(p_) ????#define QF_EPOOL_GET_(p_, e_) ????#define QF_EPOOL_PUT_(p_, e_) ????/* Global objects required by the QF port ***********************************/extern ???? ;...#endif /* qf_port_h */源代码 qf_port.cqf_port.c 源文件定义了 QF 移植和平台相关的代码。不是所有 QF 移植都需要这个文件。// 这个 qf_pkg.h 头文件包括 qf_port.h ，但是它还定义了一些内部宏和仅在 QF 构件内部共享的对象。#include &quot;qf_pkg.h&quot;// qf_port.h 源文件使用 QP 断言#include &quot;qassert.h&quot;// 见上面[C 和 C++ 里可定制的断言]，用于指定模块名，用于日志打印时显示的名称Q_DEFINE_THIS_MODULE(qf_port)/* Global objects -------------------------------------------------------*/.../* Local objects---------------------------------------------------------*/.../*.....................................................................*/char const Q_ROM *Q_ROM_VARQF_getPortVersion(void){ static const char Q_ROM Q_ROM_VAR version[] = &quot;4.0.00&quot;; return version;}/*.....................................................................*/void QF_init(void){ ...}/*.....................................................................*/// 系统将控制权交给QF框架void QF_run(void){ ...}/*.....................................................................*/void QF_stop(void){ ...}/*.....................................................................*/void QActive_start(QActive *me, uint8_t prio, /* the unique priority */ QEvent const *qSto[], uint32_t qLen, /* event queue */ void *stkSto, uint32_t stkSize, /* per-task stack */ QEvent const *ie) /* the initialization event */{ // 配置优先级 me-&amp;gt;prio = prio; /* set the QF priority */ // 注册到QF QF_add_(me); /* make QF aware of this active object */ // 触发最顶初始转换（相当于初始化） QF_ACTIVE_INIT_(me, ie); /* execute the initial transition */ /* Initialize the event queue object ’me-&amp;gt;eQueue’ using qSto and qLen */ // 初始化事件队列 /* Create and start the thread ’me-&amp;gt;thread’ of the underlying RTOS */ // 启动线程}/*.....................................................................*/void QActive_stop(QActive *me){ /* Cleanup me-&amp;gt;eQueue or me-&amp;gt;osObject */ // 执行清理工作，是否非栈中的内存}/*......................................................................*//* You need to define QActive_postFIFO(), QActive_postLIFO(), and * QActive_get_() only if your QF port uses the queue facility from * the underlying OS/RTOS. */// 只有用了底层OS提供的队列工具时，才需要重写这三个函数，如果用的QF自带的事件队列则不需要void QActive_postFIFO(QActive *me, QEvent const *e){ QF_INT_LOCK_KEY_ QF_INT_LOCK_(); if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ ++((QEvent *)e)-&amp;gt;dynamic_; /* increment the reference counter */ } QF_INT_UNLOCK_(); /* Post event pointer ’e’ to the message queue of the RTOS ’me-&amp;gt;eQueue’ * using the FIFO policy without blocking. Also assert that the queue * accepted the event pointer. */}/*......................................................................*/void QActive_postLIFO(QActive *me, QEvent const *e){ QF_INT_LOCK_KEY_ QF_INT_LOCK_(); if (e-&amp;gt;dynamic_ != (uint8_t)0) { /* is it a dynamic event? */ ++((QEvent *)e)-&amp;gt;dynamic_; /* increment the reference counter */ } QF_INT_UNLOCK_(); /* Post event pointer ’e’ to the message queue of the RTOS ’me-&amp;gt;eQueue’ * using the LIFO policy without blocking. Also assert that the queue * accepted the event pointer. */}/*......................................................................*/QEvent const *QActive_get_(QActive *me){ /* Get the next event from the active object queue ’me-&amp;gt;eQueue’. * Block indefinitely as long as the queue is empty. Assert no errors * in the queue operation. Return the event pointer to the caller. */}和平台相关的 QF 回调函数下面这几个函数是属于应用程序而不是QF框架的(意思就是就算这几个函数不定义，QF也能正常运行，不是必需的)。它们不在QF_port.c中定义，在 QP 应用开发中有说明void QF_onStartup(void)在 QF 取得应用程序的控制之前这个回调函数被调用。 QF_onStartup()回调函数的主要意图是初始化并启动中断(TICK时钟中断)void QF_onCleanup(void)在 QF 返回底层操作系统或 RTOS 前，调用 QF_onCleanup(void)。void QF_onIdle(void) 或 void QF_onIdle(QF_INT_KEY_TYPE lockKey)内建在 QF 里的合作式 vanilla 内核调用 QF_onIdle() 。这个回调函数的声明取决于在 QF 移植里采用的中断上锁策略。void Q_onAssert(char const Q_ROM * const Q_ROM_VAR file, int line)断言失败时的处理系统时钟节拍（调用 QF_tick() ）需要定时调用 QF_tick() 来让 QF 正常工作。一般是在系统节拍 ISR 中调用。如果是 Linux 这种不允许修改 ISR 的，就要开个节拍器线程再加上睡眠和定时唤醒来模拟。创建 QF 库不是所有 QF 源文件都要包含。qa_fifo.c,qa_lifo.c,qa_get_.c，如果自己定义了QActive_postFIFO()，QActive_postLIFO()，和 QActive_get_()可以不包含，也就是仅在使用 QF 原生的队列时才包含qvanilla.c，仅当你使用vanilla合作式内核时才需包含这个文件。移植合作式 Vanilla 内核把 vanilla 内核本身移植到目标 CPU 和编译器上头文件 qep_port.h展示了用于 80x86/DOS/Turbo C++ 1.01/Large内存模型的 qep_port.h头文件用于 80x86/DOS/Turbo C++ 1.01/Large 内存模型的 qep_port.h 头文件:#ifndef qep_port_h#define qep_port_h/* Exact-width integer types for DOS/Turbo C++ 1.01/Large memory model */// 因为Turbo C++不是标准编译器，所以不带stdint.h，要自己指定扩展类型typedef signed char int8_t;typedef signed int int16_t;typedef signed long int32_t;typedef unsigned char uint8_t;typedef unsigned int uint16_t;typedef unsigned long uint32_t;#include &quot;qep.h&quot; /* QEP platform-independent public interface */#endif /* qep_port_h */用于 Cortex-M3/IAR 的 qep_port.h头文件:#ifndef qep_port_h#define qep_port_h// IAR是标准的编译器，所以携带stdint.h#include &amp;lt;stdint.h&amp;gt; /* C99-standard exact-width integer types */#include &quot;qep.h&quot; /* QEP platform-independent public interface */#endif /* qep_port_h */头文件 qf_port.h最重要的移植决定是选择上锁和解锁中断的策略。见保存和恢复中断状态通常，你的第一安全选择应该是更先进的保存和恢复中断状态策略。然而，如果你发现在 ISR 内解锁中断是安全的，因为你的目标处理器可以在硬件对中断优先级排序，你可以使用简单和快捷的无条件中断解锁策略用于 80x86/DOS/Turbo C++ 1.01/Large 内存模型的 qf_port.h 头文件：#ifndef qf_port_h#define qf_port_h/* DOS critical section entry/exit *//* QF_INT_KEY_TYPE not defined: &quot;unconditional interrupt unlocking&quot; policy */// 80x86/DOS/Turbo C++ 1.01/Large内存模型内有基于优先级的中断控制器8259A，所以用无条件中断解锁策略#define QF_INT_LOCK(dummy) disable()#define QF_INT_UNLOCK(dummy) enable()#include &amp;lt;dos.h&amp;gt; /* DOS API, including disable()/enable() prototypes */#undef outportb /*don’t use the macro because it has a bug in Turbo C++ 1.01*/#include &quot;qep_port.h&quot; /* QEP port */#include &quot;qvanilla.h&quot; /* The &quot;Vanilla&quot; cooperative kernel */#include &quot;qf.h&quot; /* QF platform-independent public interface */#endif /* qf_port_h */Cortex-M3/IAR的 qf_port.h 头文件:#ifndef qf_port_h#define qf_port_h/* QF critical section entry/exit *//* QF_INT_KEY_TYPE not defined: &quot;unconditional interrupt unlocking&quot; policy */// Cortex-M3 有一个标准的嵌套向量中断控制器 NVIC, 所以用无条件中断解锁策略#define QF_INT_LOCK(dummy) __disable_interrupt()#define QF_INT_UNLOCK(dummy) __enable_interrupt()#include &amp;lt;intrinsics.h&amp;gt; /* IAR intrinsic functions */#include &quot;qep_port.h&quot; /* QEP port */#include &quot;qvanilla.h&quot; /* The &quot;Vanilla&quot; cooperative kernel */#include &quot;qf.h&quot; /* QF platform-independent public interface */#endif /* qf_port_h */系统时钟节拍（QF_tick()）DOS的系统时钟节拍 ISR ，它由连接到 IRQ0 的 8253/8254 时间计数器芯片的通道 0 触发80x86/DOS/Turbo C++ 1.01/Large 内存模式下的系统时钟节拍 ISR:void interrupt ISR_tmr0(void){ /* entered with interrupts LOCKED */ QF_INT_UNLOCK(dummy); /* unlock interrupts */ // 执行QF框架内的tick处理函数 QF_tick(); /* do some application-specific work ... */ QF_INT_LOCK(dummy); /* lock interrupts again */ outportb(0x20, 0x20); /* write EOI to the master 8259A PIC */}用于 Cortex-M3 的系统时钟节拍 ISR ，它由特别为这个目的而设计的，被称为 SysTick 的周期性定时器触发。进 ISR 是中断是解锁的，无需手动解锁。NVIC 中断控制器自动完成发送 EOI，不需要手动发送 EOI 指令Cortex-M3/IAR的 SysTick ISR:void ISR_SysTick(void){ /* entered with interrupts UNLOCKED */ QF_tick(); /* do some application-specific work ... */}空闲处理（QF_onIdel()）只要 vanilla 内核探测到系统里所有活动对象时间队列为空，它就调用 QF_onIdle() 回调函数。一般用于开启低功耗模式80x86 没有低功耗模式，所以只解锁中断用于 80x86/DOS 的 QF_onIdle() 回调函数:void QF_onIdle(void){ /* entered with interrupts LOCKED */ QF_INT_UNLOCK(dummy); /* always unlock interrupts */ /* do some more application-specific work ... */}用于 Cortex-M3/IAR 的 QF_onIdle() 回调函数:void QF_onIdle(void){ /* entered with interrupts LOCKED */#ifdef NDEBUG /* Put the CPU and peripherals to the low-power mode. * NOTE: You might need to customize the clock management for your * application, by gating the clock to the selected peripherals. * See the datasheet for your particular Cortex-M3 MCU. */ // 用 WFI 指令暂停 CPU（低功耗模式），需要通过中断唤醒 __asm(&quot;WFI&quot;); /* Wait-For-Interrupt */#endif // 必须通过中断唤醒，所以这里一定要开中断 QF_INT_UNLOCK(dummy); /* always unlock interrupts */ /* optionally do some application-specific work ... */}QF 移植到 uc/os-II (常规 RTOS)TODO:uc/os-II不太了解，以后用到再说QF 移植到 Linux （常规 POSIX 兼容的操作系统）大型操作系统和RTOS/裸机的区别是不允许关开中断，只能使用系统提供的 API（POSIX API、Win32 API）做有限的操作头文件 qep_port.h#ifndef qep_port_h#define qep_port_h/* 2-byte (64K) signal space */// 增加信号数量，64K个#define Q_SIGNAL_SIZE 2#include &amp;lt;stdint.h&amp;gt; /* C99-standard exact-width integers */#include &quot;qep.h&quot; /* QEP platform-independent public interface */#endif /* qep_port_h */头文件 qf_port.h#ifndef qf_port_h#define qf_port_h/* Linux event queue and thread types */// 使用QF原生QEQueue作为事件队列#define QF_EQUEUE_TYPE QEQueue// 使用POSIX中的条件变量作为事件队列为空时的阻塞标志#define QF_OS_OBJECT_TYPE pthread_cond_t// 每个活动对象一个线程#define QF_THREAD_TYPE pthread_t/* The maximum number of active objects in the application */// 最大活动对象(线程)数#define QF_MAX_ACTIVE 63/* various QF object sizes configuration for this port */// Linux一般需要32位的CPU，所以块大小和数量都定义成4字节#define QF_EVENT_SIZ_SIZE 4#define QF_EQUEUE_CTR_SIZE 4#define QF_MPOOL_SIZ_SIZE 4#define QF_MPOOL_CTR_SIZE 4#define QF_TIMEEVT_CTR_SIZE 4/* QF critical section entry/exit for Linux, see NOTE01 *//* QF_INT_KEY_TYPE not defined, &quot;unconditional interrupt locking&quot; policy */// 不定义QF_INT_KEY_TYPE，“无条件中断上锁和解锁”策略// 使用pthread_mutex_lock创建临界区#define QF_INT_LOCK(dummy) pthread_mutex_lock(&amp;amp;QF_pThreadMutex_)#define QF_INT_UNLOCK(dummy) pthread_mutex_unlock(&amp;amp;QF_pThreadMutex_)#include &amp;lt;pthread.h&amp;gt; /* POSIX-thread API */#include &quot;qep_port.h&quot; /* QEP port */#include &quot;qequeue.h&quot; /* Linux needs event-queue */#include &quot;qmpool.h&quot; /* Linux needs memory-pool */#include &quot;qf.h&quot; /* QF platform-independent public interface *//************************************************************************ * interface used only inside QF, but not in applications *//* OS-object implementation for Linux */// 利用条件变量实现的阻塞和运行信号，总是用while包裹pthread_cond_wait，见另一篇文章#define QACTIVE_EQUEUE_WAIT_(me_) \\ while ((me_)-&amp;gt;eQueue.frontEvt == (QEvent *)0) \\ pthread_cond_wait(&amp;amp;(me_)-&amp;gt;osObject, &amp;amp;QF_pThreadMutex_)#define QACTIVE_EQUEUE_SIGNAL_(me_) \\ pthread_cond_signal(&amp;amp;(me_)-&amp;gt;osObject)#define QACTIVE_EQUEUE_ONEMPTY_(me_) ((void)0)/* native QF event pool operations */#define QF_EPOOL_TYPE_ QMPool#define QF_EPOOL_INIT_(p_, poolSto_, poolSize_, evtSize_) \\ QMPool_init(&amp;amp;(p_), poolSto_, poolSize_, evtSize_)#define QF_EPOOL_EVENT_SIZE_(p_) ((p_).blockSize)#define QF_EPOOL_GET_(p_, e_) ((e_) = (QEvent *)QMPool_get(&amp;amp;(p_)))#define QF_EPOOL_PUT_(p_, e_) (QMPool_put(&amp;amp;(p_), e_))// 定义信号量extern pthread_mutex_t QF_pThreadMutex_; /* mutex for QF critical section */ 条件变量的定义见条件变量qf_port.c 源代码qf_port.c 源文件提供了在 QF 和 POSIX API 之间的“胶合代码”#include &quot;qf_pkg.h&quot;#include &quot;qassert.h&quot;#include &amp;lt;sys/mman.h&amp;gt; /* for mlockall() */#include &amp;lt;sys/select.h&amp;gt; /* for select() */Q_DEFINE_THIS_MODULE(qf_port)/* Global objects ------------------------------------------------------*/// 全局互斥体pthread_mutex_t QF_pThreadMutex_ = PTHREAD_MUTEX_INITIALIZER;/* Local objects -------------------------------------------------------*/static uint8_t l_running;/*.....................................................................*/void QF_init(void){ // 页上锁，防止交换到硬盘，桌面Linux不支持 /* lock memory so we’re never swapped out to disk */ /*mlockall(MCL_CURRENT | MCL_FUTURE); uncomment when supported */}/*.....................................................................*/void QF_run(void){ struct sched_param sparam; struct timeval timeout = {0}; /* timeout for select() */ // 应用程序初始化回调函数 QF_onStartup(); /* invoke startup callback */ /* try to maximize the priority of the ticker thread, see NOTE01 */ // 将当前线程设置成 SCHED_FIFO 调度策略和在这个策略里的最高优先级，需要root权限 // 高优先级是为了实时性，因为这个线程包含了tick处理操作 sparam.sched_priority = sched_get_priority_max(SCHED_FIFO); if (pthread_setschedparam(pthread_self(), SCHED_FIFO, &amp;amp;sparam) == 0) { /* success, this application has sufficient privileges */ } else { /* setting priority failed, probably due to insufficient privieges */ } l_running = (uint8_t)1; while (l_running) { // 在run线程里定期调用tick处理，而不是在tick ISR中，因为在Linux里没有权限访问中断 QF_tick(); /* process the time tick */ // select会修改timeout的值，需要每次重新赋值变量 timeout.tv_usec = 8000; // 向上取整至一个tick，如果tick是10ms,这里的8ms会自动变10ms // select使用空的I/O作为参数表示总是休眠（因为空的I/O不会触发唤醒信号），直到timeout到达 select(0, 0, 0, 0, &amp;amp;timeout); /* sleep for the full tick, NOTE05 */ } // 应用程序清理回调函数 QF_onCleanup(); /* invoke cleanup callback */ pthread_mutex_destroy(&amp;amp;QF_pThreadMutex_);}/*......................................................................*/void QF_stop(void){ // 可以在QF_run的循环过程中停止 l_running = (uint8_t)0; /* stop the loop in QF_run() */}/*......................................................................*/// 线程函数，参数是活动对象static void *thread_routine(void *arg){ /* the expected POSIX signature */ ((QActive *)arg)-&amp;gt;running = (uint8_t)1; /* allow the thread loop to run */ while (((QActive *)arg)-&amp;gt;running) { /* QActive_stop() stopps the loop */ // 活动对象三个步骤，等待事件、执行事件处理、清理 QEvent const *e = QActive_get_((QActive *)arg); /*wait for the event */ QF_ACTIVE_DISPATCH_(&amp;amp;((QActive *)arg)-&amp;gt;super, e); /* dispatch to SM */ QF_gc(e); /* check if the event is garbage, and collect it if so */ } // 线程退出前从QF框架中取消注册该活动对象 QF_remove_((QActive *)arg); /* remove this object from any subscriptions */ return (void *)0; /* return success */}/*.....................................................................*/void QActive_start(QActive *me, uint8_t prio, QEvent const *qSto[], uint32_t qLen, void *stkSto, uint32_t stkSize, QEvent const *ie){ pthread_attr_t attr; struct sched_param param; // 在Linux中，活动对象线程的堆栈由系统分配（pthread_create()函数），无需外部提供 Q_REQUIRE(stkSto == (void *)0); /* p-threads allocate stack internally */ // 原生QF队列 QEQueue_init(&amp;amp;me-&amp;gt;eQueue, qSto, (QEQueueCtr)qLen); // 条件变量初始化,事件队列控制信号 pthread_cond_init(&amp;amp;me-&amp;gt;osObject, 0); // 设置优先级 me-&amp;gt;prio = prio; // 注册至QF QF_add_(me); /* make QF aware of this active object */ // 初始化活动对象的状态机（就是状态机里的最顶初始转换），参数 ie 是一个指针，指向在活动对象状态机里用于最顶初始转换的初始事件。 QF_ACTIVE_INIT_(&amp;amp;me-&amp;gt;super, ie); /* execute the initial transition */ /* SCHED_FIFO corresponds to real-time preemptive priority-based scheduler * NOTE: This scheduling policy requires the superuser privileges */ pthread_attr_init(&amp;amp;attr); // 配置线程调度策略，需要root权限 pthread_attr_setschedpolicy(&amp;amp;attr, SCHED_FIFO); /* see NOTE04 */ // 配置线程优先级，把系统中最大的n个优先级给这n个活动对象 param.sched_priority = prio + (sched_get_priority_max(SCHED_FIFO) - QF_MAX_ACTIVE - 3); pthread_attr_setschedparam(&amp;amp;attr, &amp;amp;param); pthread_attr_setdetachstate(&amp;amp;attr, PTHREAD_CREATE_DETACHED); // 开始创建线程 if (pthread_create(&amp;amp;me-&amp;gt;thread, &amp;amp;attr, &amp;amp;thread_routine, me) != 0) { /* Creating the p-thread with the SCHED_FIFO policy failed. * Most probably this application has no superuser privileges, * so we just fall back to the default SCHED_OTHER policy * and priority 0. */ // 如果权限不够，失败了，就要修改参数 pthread_attr_setschedpolicy(&amp;amp;attr, SCHED_OTHER); param.sched_priority = 0; pthread_attr_setschedparam(&amp;amp;attr, &amp;amp;param); Q_ALLEGE(pthread_create(&amp;amp;me-&amp;gt;thread, &amp;amp;attr, &amp;amp;thread_routine, me) == 0); } pthread_attr_destroy(&amp;amp;attr);}/*......................................................................*/void QActive_stop(QActive *me){ // 用于中途停止活动对象 me-&amp;gt;running = (uint8_t)0; /* stop the event loop in QActive_run() */ pthread_cond_destroy(&amp;amp;me-&amp;gt;osObject); /* cleanup the condition variable */}开发 QP 应用程序开发 QP 应用程序的准则准则 活动对象应该仅通过某个异步事件交换来相互作用，不应该共享内存或其他资源。 活动对象不应该阻塞或者在RTC处理的中间忙等待事件。启发式 事件驱动型编程，非阻塞，快速返回 实现在活动对象之间的松散耦合，避免资源共享 把较长的处理分解成较短的步骤 画出顺序图哲学家就餐问题第一步：需求5个哲学家，5个餐叉，吃面需要2个餐叉，吃完会思考，核心是防止死锁和饿死。第二步：顺序图Table 对象管理餐叉，每个 Philo 对象管理一个哲学家触发 QF 定时事件Philo[m]终止思考，开始饥饿，向Table发送事件(HUNGRY(m))请求就餐许可(有足够的叉子)。Table 将就餐许可事件(EAT(m))发送给对应对象。Philo[m]进入就餐状态直到下一个定时事件，发送完成事件(DONE(m))归还叉子。第三步：信号，事件和活动对象#ifndef dpp_h#define dpp_h// 对哲学家就餐问题自定义的事件信号enum DPPSignals{ EAT_SIG = Q_USER_SIG, /* published by Table to let a philosopher eat */ DONE_SIG, /* published by Philosopher when done eating */ TERMINATE_SIG, /* published by BSP to terminate the application */ MAX_PUB_SIG, /* the last published signal */ // 这个信号是直接发送的 HUNGRY_SIG, /* posted directly from hungry Philosopher to Table */ MAX_SIG /* the last signal */};// 派生自QEvent的事件，增加了一个philoNum变量typedef struct TableEvtTag{ QEvent super; /* derives from QEvent */ uint8_t philoNum; /* Philosopher number */} TableEvt;enum{ N_PHILO = 5}; /* number of Philosophers */// 构造函数，再main开始时调用void Philo_ctor(void); /* ctor that instantiates all Philosophers */void Table_ctor(void);extern QActive *const AO_Philo[N_PHILO]; /* &quot;opaque&quot; pointers to Philo AOs */extern QActive *const AO_Table; /* &quot;opaque&quot; pointer to Table AO */#endif /* dpp_h */第四步：状态机这里产生HUNGRY事件和DONE事件不是由定时事件触发而是进入退出动作时触发，更精确的反应了语义，提高后续的可维护性准则：偏向使用进入动作和退出动作，而不是转换动作。哲学家和餐叉编号：#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;Q_DEFINE_THIS_FILE/* Active object class -----------------------------------------------------*/// 活动对象Table从QActive派生，增加了两个变量，管理叉子和饥饿度typedef struct TableTag{ QActive super; /* derives from QActive */ uint8_t fork[N_PHILO]; /* states of the forks */ uint8_t isHungry[N_PHILO]; /* remembers hungry philosophers */} Table;static QState Table_initial(Table *me, QEvent const *e); /* pseudostate */static QState Table_serving(Table *me, QEvent const *e); /* state handler */// 如上图，n顺时针递增，人和右叉为一组，标记为n，计算左边或右边组的序号#define RIGHT(n_) ((uint8_t)(((n_) + (N_PHILO - 1)) % N_PHILO))#define LEFT(n_) ((uint8_t)(((n_) + 1) % N_PHILO))enum ForkState{ FREE, USED};/* Local objects ----------------------------------------------------------*/// static让其他文件无法访问static Table l_table; /* the single instance of the Table active object *//* Global-scope objects ---------------------------------------------------*/// 指针设为const不能更改，可以让编译器把该指针分配在ROM里QActive *const AO_Table = (QActive *)&amp;amp;l_table; /* &quot;opaque&quot; AO pointer *//*........................................................................*/// 构造函数，C需要手动调用，C++会自动调用void Table_ctor(void){ uint8_t n; Table *me = &amp;amp;l_table; // 实例化超类，为super部分初始化 QActive_ctor(&amp;amp;me-&amp;gt;super, (QStateHandler)&amp;amp;Table_initial); for (n = 0; n &amp;lt; N_PHILO; ++n) { me-&amp;gt;fork[n] = FREE; me-&amp;gt;isHungry[n] = 0; }}/*.......................................................................*/// 最顶初始转换QState Table_initial(Table *me, QEvent const *e){ (void)e; /* avoid the compiler warning about unused parameter */ // 订阅信号 QActive_subscribe((QActive *)me, DONE_SIG); QActive_subscribe((QActive *)me, TERMINATE_SIG); /* signal HUNGRY_SIG is posted directly */ return Q_TRAN(&amp;amp;Table_serving);}/*.......................................................................*/QState Table_serving(Table *me, QEvent const *e){ uint8_t n, m; // Table相关事件，定义见上一节 TableEvt *pe; switch (e-&amp;gt;sig) { case HUNGRY_SIG: { // 人工延长单RTC处理的时间，方便进行压力测试 BSP_busyDelay(); // 提取事件参数 n = ((TableEvt const *)e)-&amp;gt;philoNum; /* phil ID must be in range and he must be not hungry */ Q_ASSERT((n &amp;lt; N_PHILO) &amp;amp;&amp;amp; (!me-&amp;gt;isHungry[n])); // 屏幕打印 BSP_displyPhilStat(n, &quot;hungry &quot;); m = LEFT(n); if ((me-&amp;gt;fork[m] == FREE) &amp;amp;&amp;amp; (me-&amp;gt;fork[n] == FREE)) {// 左右叉都空闲的情况 me-&amp;gt;fork[m] = me-&amp;gt;fork[n] = USED; // 生成eat事件 pe = Q_NEW(TableEvt, EAT_SIG); pe-&amp;gt;philoNum = n; QF_publish((QEvent *)pe); BSP_displyPhilStat(n, &quot;eating &quot;); } else { me-&amp;gt;isHungry[n] = 1; } return Q_HANDLED(); } case DONE_SIG: { BSP_busyDelay(); n = ((TableEvt const *)e)-&amp;gt;philoNum; /* phil ID must be in range and he must be not hungry */ Q_ASSERT((n &amp;lt; N_PHILO) &amp;amp;&amp;amp; (!me-&amp;gt;isHungry[n])); // 吃完开始思考 BSP_displyPhilStat(n, &quot;thinking&quot;); m = LEFT(n); /* both forks of Phil [n] must be used */ Q_ASSERT((me-&amp;gt;fork[n] == USED) &amp;amp;&amp;amp; (me-&amp;gt;fork[m] == USED)); // 归还叉子 me-&amp;gt;fork[m] = me-&amp;gt;fork[n] = FREE; // 右边的人是否饥饿 m = RIGHT(n); /* check the right neighbor */ if (me-&amp;gt;isHungry[m] &amp;amp;&amp;amp; (me-&amp;gt;fork[m] == FREE)) { me-&amp;gt;fork[n] = me-&amp;gt;fork[m] = USED; me-&amp;gt;isHungry[m] = 0; pe = Q_NEW(TableEvt, EAT_SIG); pe-&amp;gt;philoNum = m; QF_publish((QEvent *)pe); BSP_displyPhilStat(m, &quot;eating &quot;); } // 左边的左边的人是否饥饿 m = LEFT(n); /* check the left neighbor */ n = LEFT(m); /* left fork of the left neighbor */ if (me-&amp;gt;isHungry[m] &amp;amp;&amp;amp; (me-&amp;gt;fork[n] == FREE)) { me-&amp;gt;fork[m] = me-&amp;gt;fork[n] = USED; me-&amp;gt;isHungry[m] = 0; pe = Q_NEW(TableEvt, EAT_SIG); pe-&amp;gt;philoNum = m; QF_publish((QEvent *)pe); BSP_displyPhilStat(m, &quot;eating &quot;); } return Q_HANDLED(); } // 终止 case TERMINATE_SIG: { QF_stop(); return Q_HANDLED(); } } return Q_SUPER(&amp;amp;QHsm_top);}第五步：初始化并启动应用程序注意点： 活动对象的相对优先级 预先分配的事件队列的尺寸 活动对象启动顺序#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;/* Local-scope objects ---------------------------------------------------*/// 所有事件队列的内存缓存被静态分配static QEvent const *l_tableQueueSto[N_PHILO];static QEvent const *l_philoQueueSto[N_PHILO][N_PHILO];// 用于订阅者列表的内存空间也被静态分配，这是个bitmap，之前提到过static QSubscrList l_subscrSto[MAX_PUB_SIG];// 使用&quot;小尺寸&quot;事件池static union SmallEvent{ void *min_size;// min_size无意义，这句是为了让SmallEvent至少比一个指针占用空间大 TableEvt te; // 可以添加其他自定义事件 /* other event types to go into this pool */} l_smlPoolSto[2 * N_PHILO]; /* storage for the small event pool *//*.......................................................................*/int main(int argc, char *argv[]){ uint8_t n; Philo_ctor(); /* instantiate all Philosopher active objects */ Table_ctor(); /* instantiate the Table active object */ BSP_init(argc, argv); /* initialize the Board Support Package */ QF_init(); /* initialize the framework and the underlying RT kernel */ // 订阅功能初始化 QF_psInit(l_subscrSto, Q_DIM(l_subscrSto)); /* init publish-subscribe */ // 用于动态事件的池，默认使用QF原生内存池管理， // 这里用了BSS段空间(static变量)作为原始空间（有些嵌入式没有堆空间，这是标准做法） QF_poolInit(l_smlPoolSto, sizeof(l_smlPoolSto), sizeof(l_smlPoolSto[0]));/* initialize event pools... */ // 先初始化哲学家对象, for (n = 0; n &amp;lt; N_PHILO; ++n) { /* start the active objects... */ QActive_start(AO_Philo[n], (uint8_t)(n + 1), l_philoQueueSto[n], Q_DIM(l_philoQueueSto[n]), (void *)0, 0, /* no private stack */ (QEvent *)0); } // 后初始化table管理对象 QActive_start(AO_Table, (uint8_t)(N_PHILO + 1), l_tableQueueSto, Q_DIM(l_tableQueueSto), (void *)0, 0, /* no private stack */ (QEvent *)0); QF_run(); /* run the QF application */ return 0;}第六步：优雅的结束应用程序在嵌入式系统中不需要考虑，一般就是无限运行直到复位。在不同的平台运行 DPP在 DOS 上的 Vanilla 内核#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;.../* Local-scope objects---------------------------------------------------*/static void interrupt (*l_dosTmrISR)();static void interrupt (*l_dosKbdISR)();static uint32_t l_delay = 0UL; /* limit for the loop counter in busyDelay() */#define TMR_VECTOR 0x08#define KBD_VECTOR 0x09/*......................................................................*/// Turbo C++ 1.01编译器提供了一个扩展关健词 interrupt ，它允许你使用 C/C++ 编写ISRvoid interrupt ISR_tmr(void){ // 80x86处理器在进ISR时自动关中断，不过可以在ISR内手动开中断 // 由8259A可编程中断控制器管理中断优先级 QF_INT_UNLOCK(dummy); /* unlock interrupts */ // QF_tick()内部会关中断，且使用了“无条件中断上锁和解锁”策略， // 不支持中断嵌套，为了防止死锁，需要提前开中断，在临界区外调用QF_tick() QF_tick(); /* call QF_tick() outside of critical section */ QF_INT_LOCK(dummy); /* lock interrupts again */ // 中断结束 end-of-interrupt(EOI)指令被发往主 8259A ，因此它结束这个中断级别的优先级。 outportb(0x20, 0x20); /* write EOI to the master 8259A PIC */}/*......................................................................*/// 按键中断void interrupt ISR_kbd(void){ uint8_t key; uint8_t kcr; QF_INT_UNLOCK(dummy); /* unlock interrupts */ key = inport(0x60); /*key scan code from the 8042 kbd controller */ kcr = inport(0x61); /* get keyboard control register */ outportb(0x61, (uint8_t)(kcr | 0x80)); /* toggle acknowledge bit high */ outportb(0x61, kcr); /* toggle acknowledge bit low */ if (key == (uint8_t)129) { /* ESC key pressed? */ static QEvent term = {TERMINATE_SIG, 0}; /* static event */ QF_publish(&amp;amp;term); /* publish to all interested AOs */ } QF_INT_LOCK(dummy); /* lock interrupts again */ outportb(0x20, 0x20); /* write EOI to the master 8259A PIC */}/*.......................................................................*/void QF_onStartup(void){ /* save the origingal DOS vectors ... */ // 保存原始中断向量，在最后清理时恢复 l_dosTmrISR = getvect(TMR_VECTOR); l_dosKbdISR = getvect(KBD_VECTOR); QF_INT_LOCK(dummy); // 配置自定义的中断向量 setvect(TMR_VECTOR, &amp;amp;ISR_tmr); setvect(KBD_VECTOR, &amp;amp;ISR_kbd); QF_INT_UNLOCK(dummy);}/*.......................................................................*/void QF_onCleanup(void){ /* restore the original DOS vectors ... */ QF_INT_LOCK(dummy); // 恢复中断向量 setvect(TMR_VECTOR, l_dosTmrISR); setvect(KBD_VECTOR, l_dosKbdISR); QF_INT_UNLOCK(dummy); _exit(0); /* exit to DOS */}/*.......................................................................*/// 见[qvanilla.c 源文件](#qvanillac-源文件)void QF_onIdle(void){ /* called with interrupts LOCKED */ QF_INT_UNLOCK(dummy); /* always unlock interrutps */}/*.......................................................................*/void BSP_init(int argc, char *argv[]){ // 读取参数 if (argc &amp;gt; 1) { // 忙等待时长 l_delay = atol(argv[1]); /* set the delay counter for busy delay */ } printf(&quot;Dining Philosopher Problem example&quot; &quot;\\nQEP %s\\nQF %s\\n&quot; &quot;Press ESC to quit...\\n&quot;, QEP_getVersion(), QF_getVersion());}/*......................................................................*/// 用于手动调用延长RTC执行时间，方便调试void BSP_busyDelay(void){ uint32_t volatile i = l_delay; // 忙等待 while (i-- &amp;gt; 0UL) { /* busy-wait loop */ }}/*......................................................................*/// 打印执行信息，仅被活动对象 Table 调用void BSP_displyPhilStat(uint8_t n, char const *stat){ printf(&quot;Philosopher %2d is %s\\n&quot;, (int)n, stat);}/*......................................................................*/void Q_onAssert(char const Q_ROM *const Q_ROM_VAR file, int line){ // 断言失败时终止 QF_INT_LOCK(dummy); /* cut-off all interrupts */ fprintf(stderr, &quot;Assertion failed in %s, line %d&quot;, file, line); QF_stop();}在 Cortex-M3 上的 Vanilla 内核t（思考）， e（就餐）和 h（饥饿）#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;// 驱动库#include &quot;hw_ints.h&quot;.../* other Luminary Micro driver library include files *//* Local-scope objects ---------------------------------------------------*/static uint32_t l_delay = 0UL; /* limit for the loop counter in busyDelay() *//*......................................................................*/void ISR_SysTick(void){ // Cortex-M3 进入 ISR 时，中断是解锁的，这就有别于80x86 QF_tick(); /* process all armed time events */ /* add any application-specific clock-tick processing, as needed */}.../*......................................................................*/// 板的初始化voidBSP_init(int argc, char *argv[]){ (void)argc; /* unused: avoid the complier warning */ (void)argv; /* unused: avoid the compiler warning */ /* Set the clocking to run at 20MHz from the PLL. */ SysCtlClockSet(SYSCTL_SYSDIV_10 | SYSCTL_USE_PLL | SYSCTL_OSC_MAIN | SYSCTL_XTAL_6MHZ); /* Enable the peripherals used by the application. */ SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOA); SysCtlPeripheralEnable(SYSCTL_PERIPH_GPIOC); /* Configure the LED, push button, and UART GPIOs as required. */ GPIODirModeSet(GPIO_PORTA_BASE, GPIO_PIN_0 | GPIO_PIN_1, GPIO_DIR_MODE_HW); GPIODirModeSet(GPIO_PORTC_BASE, PUSH_BUTTON, GPIO_DIR_MODE_IN); GPIODirModeSet(GPIO_PORTC_BASE, USER_LED, GPIO_DIR_MODE_OUT); GPIOPinWrite(GPIO_PORTC_BASE, USER_LED, 0); /* Initialize the OSRAM OLED display. */ // 初始化显示驱动 OSRAMInit(1); OSRAMStringDraw(&quot;Dining Philos&quot;, 0, 0); OSRAMStringDraw(&quot;0 ,1 ,2 ,3 ,4&quot;, 0, 1);}/*......................................................................*/void BSP_displyPhilStat(uint8_t n, char const *stat){ char str[2]; str[0] = stat[0]; str[1] = &#39;\\0&#39;; OSRAMStringDraw(str, (3 * 6 * n + 6), 1);}/*......................................................................*/void BSP_busyDelay(void){ uint32_t volatile i = l_delay; while (i-- &amp;gt; 0UL) { /* busy-wait loop */ }}/*......................................................................*/void QF_onStartup(void){ /* Set up and enable the SysTick timer. It will be used as a reference * for delay loops in the interrupt handlers. The SysTick timer period * will be set up for BSP_TICKS_PER_SEC. */ // 设置节拍速率 SysTickPeriodSet(SysCtlClockGet() / BSP_TICKS_PER_SEC); SysTickEnable(); // 配置节拍中断优先级，0xC0为倒数第二低的优先级 IntPrioritySet(FAULT_SYSTICK, 0xC0); /* set the priority of SysTick */ SysTickIntEnable(); /* Enable the SysTick interrupts */ QF_INT_UNLOCK(dummy); /* set the interrupt flag in PRIMASK */}/*......................................................................*/// 没有操作系统，不需要清理，退出直接复位void QF_onCleanup(void){}/*......................................................................*/void QF_onIdle(void){ /* entered with interrupts LOCKED, see NOTE01 */ /* toggle the User LED on and then off, see NOTE02 */ GPIOPinWrite(GPIO_PORTC_BASE, USER_LED, USER_LED); /* User LED on */ GPIOPinWrite(GPIO_PORTC_BASE, USER_LED, 0); /* User LED off */#ifdef NDEBUG /* Put the CPU and peripherals to the low-power mode. * you might need to customize the clock management for your application, * see the datasheet for your particular Cortex-M3 MCU. */ // 低功耗模式 __asm(&quot;WFI&quot;); /* Wait-For-Interrupt */#endif QF_INT_UNLOCK(dummy); /* always unlock the interrupts */}/*......................................................................*/void Q_onAssert(char const Q_ROM *const Q_ROM_VAR file, int line){ (void)file; /* avoid compiler warning */ (void)line; /* avoid compiler warning */ QF_INT_LOCK(dummy); /* make sure that all interrupts are disabled */ // 实际使用要去掉这个循环 for (;;) { /* NOTE: replace the loop with reset for the final version */ }}/* error routine that is called if the Luminary library encounters an error */void __error__(char *pcFilename, unsigned long ulLine){ Q_onAssert(pcFilename, ulLine);}uC/OS-IImain.c：#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;/* Local-scope objects ---------------------------------------------------*/... static OS_STK l_philoStk[N_PHILO][256]; /* stacks for the Philosophers */static OS_STK l_tableStk[256]; /* stack for the Table */static OS_STK l_ucosTaskStk[256]; /* stack for the ucosTask *//*........................................................................*/int main(int argc, char *argv[]){ ... for (n = 0; n &amp;lt; N_PHILO; ++n) { // 需要为每个活动对象分配私有堆栈 QActive_start(AO_Philo[n], (uint8_t)(n + 1), l_philoQueueSto[n], Q_DIM(l_philoQueueSto[n]), l_philoStk[n], sizeof(l_philoStk[n]), (QEvent *)0); } QActive_start(AO_Table, (uint8_t)(N_PHILO + 1), l_tableQueueSto, Q_DIM(l_tableQueueSto), l_tableStk, sizeof(l_tableStk), (QEvent *)0); /* create a uC/OS-II task to start interrupts and poll the keyboard */ // 比其他系统多加了个任务，见下面的bsp.c OSTaskCreate(&amp;amp;ucosTask, (void *)0, /* pdata */ &amp;amp;l_ucosTaskStk[Q_DIM(l_ucosTaskStk) - 1], 0); /* the highest uC/OS-II priority */ QF_run(); /* run the QF application */ return 0;}bsp.c:#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;#include &quot;video.h&quot;/*.......................................................................*/void ucosTask(void *pdata){ (void)pdata; /* avoid the compiler warning about unused parameter */ QF_onStartup(); /* start interrupts including the clock tick, NOTE01 */ for (;;) { // for循环里要加阻塞转让控制权 OSTimeDly(OS_TICKS_PER_SEC / 10); /* sleep for 1/10 s */ if (kbhit()) { /* poll for a new keypress */ uint8_t key = (uint8_t)getch(); // 检测是否按了 ESC 键 if (key == 0x1B) { /* is this the ESC key? */ // 发布静态的 TERMINATE 事件 QF_publish(Q_NEW(QEvent, TERMINATE_SIG)); } else { /* other key pressed */ Video_printNumAt(30, 13 + N_PHILO, VIDEO_FGND_YELLOW, key); } } }}/*.......................................................................*/// 节拍中断，因为使用“保存和恢复中断状态”策略支持中断嵌套，进入ISR后不需要开中断void OSTimeTickHook(void){ QF_tick(); /* add any application-specific clock-tick processing, as needed */}/*.......................................................................*/// Idle进入低功耗模式void OSTaskIdleHook(void){ /* put the MCU to sleep, if desired */}...Linuxbsp.c:#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;#include &amp;lt;sys/select.h&amp;gt;... Q_DEFINE_THIS_FILE/* Local objects ---------------------------------------------------------*/// Linux控制台默认配置不允许异步接收用户按键，需要修改控制台配置，这个变量备份了修改前的配置static struct termios l_tsav; /* structure with saved terminal attributes */static uint32_t l_delay; /* limit for the loop counter in busyDelay() *//*.......................................................................*/// 异步监控控制台输入的线程，按下ESC终止应用static void *idleThread(void *me){ /* the expected P-Thread signature */ for (;;) { struct timeval timeout = {0}; /* timeout for select() */ fd_set con; /* FD set representing the console */ FD_ZERO(&amp;amp;con); FD_SET(0, &amp;amp;con); timeout.tv_usec = 8000; /* sleep for the full tick or until a console input arrives */ // 使用select()作为阻塞机制 if (0 != select(1, &amp;amp;con, 0, 0, &amp;amp;timeout)) { /* any descriptor set? */ char ch; read(0, &amp;amp;ch, 1); if (ch == &#39;\\33&#39;) { /* ESC pressed? */ // 按ESC发布退出事件 QF_publish(Q_NEW(QEvent, TERMINATE_SIG)); } } } return (void *)0; /* return success */}/*.......................................................................*/void BSP_init(int argc, char *argv[]){ printf(&quot;Dining Philosopher Problem example&quot; &quot;\\nQEP %s\\nQF %s\\n&quot; &quot;Press ESC to quit...\\n&quot;, QEP_getVersion(), QF_getVersion()); if (argc &amp;gt; 1) { l_delay = atol(argv[1]); /* set the delay from the argument */ }}/*.......................................................................*/void QF_onStartup(void){ /* startup callback */ struct termios tio; /* modified terminal attributes */ pthread_attr_t attr; struct sched_param param; pthread_t idle; // 修改前保存终端属性 tcgetattr(0, &amp;amp;l_tsav); /* save the current terminal attributes */ tcgetattr(0, &amp;amp;tio); /* obtain the current terminal attributes */ tio.c_lflag &amp;amp;= ~(ICANON | ECHO); /* disable the canonical mode &amp;amp; echo */ // 关闭终端属性中的不允许异步输入模式 tcsetattr(0, TCSANOW, &amp;amp;tio); /* set the new attributes */ /* SCHED_FIFO corresponds to real-time preemptive priority-based scheduler * NOTE: This scheduling policy requires the superuser priviledges */ pthread_attr_init(&amp;amp;attr); // 将idle线程配置为SCHED_FIFO调度策略 pthread_attr_setschedpolicy(&amp;amp;attr, SCHED_FIFO); // 将idle线程优先级配置为最低 param.sched_priority = sched_get_priority_min(SCHED_FIFO); pthread_attr_setschedparam(&amp;amp;attr, &amp;amp;param); pthread_attr_setdetachstate(&amp;amp;attr, PTHREAD_CREATE_DETACHED); // 创建idle线程 if (pthread_create(&amp;amp;idle, &amp;amp;attr, &amp;amp;idleThread, 0) != 0) { /* Creating the p-thread with the SCHED_FIFO policy failed. * Most probably this application has no superuser privileges, * so we just fall back to the default SCHED_OTHER policy * and priority 0. */ // 如果创建失败就尝试另外的配置重新创建 pthread_attr_setschedpolicy(&amp;amp;attr, SCHED_OTHER); param.sched_priority = 0; pthread_attr_setschedparam(&amp;amp;attr, &amp;amp;param); Q_ALLEGE(pthread_create(&amp;amp;idle, &amp;amp;attr, &amp;amp;idleThread, 0) == 0); } pthread_attr_destroy(&amp;amp;attr);}/*.......................................................................*/void QF_onCleanup(void){ /* cleanup callback */ printf(&quot;\\nBye! Bye!\\n&quot;); tcsetattr(0, TCSANOW, &amp;amp;l_tsav); /* restore the saved terminal attributes */ QS_EXIT(); /* perform the QS cleanup */}/*.......................................................................*/void BSP_displyPhilStat(uint8_t n, char const *stat){ printf(&quot;Philosopher %2d is %s\\n&quot;, (int)n, stat);}/*.......................................................................*/void BSP_busyDelay(void){ uint32_t volatile i = l_delay; while (i-- &amp;gt; 0UL) { }}/*.......................................................................*/void Q_onAssert(char const Q_ROM *const Q_ROM_VAR file, int line){ fprintf(stderr, &quot;Assertion failed in %s, line %d&quot;, file, line); QF_stop();} 相关文章：select()用法调整事件队列和事件池的大小开发阶段使用超大的队列、池和堆栈，仅在产品开发的末期才开始缩小它们。调整事件队列的大小事件队列的要求：平均事件产生速率 &amp;lt;P(t)&amp;gt; 不高于平均事件消耗速率 &amp;lt;C(t)&amp;gt;一旦 P(t) 过大导致事件队列满，QP 会视其为异常，而不是阻塞生产者或丢弃事件解决方法： 运行时评估： 运行程序一段时间并检查 nMin 的值，评估事件队列大小是否合理 静态分析 事件队列的大小取决于活动对象的优先级 一般的，优先级越高，必需的事件队列越短。因为一旦事件队列被填充，内核会尽快调度该活动对象线程运行处理事件 队列大小取决于最长的 RTC 步骤持续的时间 处理越快，必需的事件队列越短。理想情况是，某个给定活动对象的所有 RTC 步骤都只需要相同的 CPU 周期来完成。 任何相关的事件生产都能增加队列的大小 有时候 ISR 或活动对象在一个 RTC 步骤内生产多个事件实例。应该避免短时间内产生较多事件 调整事件池的大小取决于事件种类，和活动对象数量，事件实例的可重用性，事件池尺寸种类系统集成QF 允许你在软件的任何地方发送或发行事件，而不限于仅从活动对象。比如可以在设备驱动程序中发布事件。设备应该被视为一个共享的资源，对它的存取限制到仅一个活动对象内，避免共享资源竞争导致的各种问题。可以用一个活动对象封装多个设备。事件驱动型系统的软件追踪上图展示了软件追踪的一个典型设置嵌入式目标系统在运行被监测的代码，它在目标系统的 RAM 缓存区记录追踪数据。追踪数据通过一个数据连接被从这个缓存区送给一个主机，它存储、显示和分析这些信息。这个配置意味着软件追踪总是需要 2 个构件： 用来收集和发送追踪数据的目标系统驻留构件 用来接收，解压，可视化和分析这些数据的主机驻留构件。QS 目标系统驻留构件 侵入性小 - 数据格式化工作被从目标系统里移到主机执行 数据记录和发送数据给主机是分隔的，例如在目标 CPU 的空闲循环处传输数据。减少了发送数据的开销 支持数据压缩，如数据字典 带级别过滤器 带可配精度时间戳 探测传输错误并重传机制（高级数据连接控制协议 [High Level Data Link Control, HLDLC]） 轻量级传输 APIQS 源代码的组织&amp;lt;qp&amp;gt;\\qpc\\ - QP/C root directory (&amp;lt;qp&amp;gt;\\qpcpp for QP/C++) | +-include/ - QP platform-independent header files | +-qs.h - QS platform-independent active interface | +-qs_dummy.h - QS platform-independent inactive interface | +-qs/ - QS target component | +-source/ - QS platform-independent source code (*.C files) | | +-qs_pkg.h - internal, packet-scope interface for QS implementation | | +-qs.c - internal ring buffer and formatted output functions | | +-qs_.c - definition of basic unformatted output functions | | +-qs_blk.c - definition of block-oriented interface QS_getBlock() | | +-qs_byte.c - definition of byte-oriented interface QS_getByte() | | +-qs_f32.c - definition of 32-bit floating point output QS_f32() | | +-qs_f64.c - definition of 64-bit floating point output QS_f64() | | +-qs_mem.c - definition of memory-block output | | +-qs_str.c - definition of zero-terminated string output | +-ports\\ - Platform-specific QP ports | +- . . . +-examples\\ - Platform-specific QP examples | +- . . .&amp;lt;qp&amp;gt;\\qpc\\ - QP/C root directory (&amp;lt;qp&amp;gt;\\qpcpp for QP/C++) | +-include/ - QP platform-independent header files | +-qs.h - QS platform-independent active interface | +-qs_dummy.h - QS platform-independent inactive interface | +-qs/ - QS target component | +-source/ - QS platform-independent source code (*.C files) | | +-qs_pkg.h - internal, packet-scope interface for QS implementation | | +-qs.c - internal ring buffer and formatted output functions | | +-qs_.c - definition of basic unformatted output functions | | +-qs_blk.c - definition of block-oriented interface QS_getBlock() | | +-qs_byte.c - definition of byte-oriented interface QS_getByte() | | +-qs_f32.c - definition of 32-bit floating point output QS_f32() | | +-qs_f64.c - definition of 64-bit floating point output QS_f64() | | +-qs_mem.c - definition of memory-block output | | +-qs_str.c - definition of zero-terminated string output | +-ports\\ - Platform-specific QP ports | +- . . . +-examples\\ - Platform-specific QP examples | +- . . .QS 源文件通常在每个文件里只包含一个函数或一个数据结构。这种设计的目的在于把 QS 部署成一个精细粒度的库，你可以把它静态的和里的应用程序链接。精细粒度意味着 QS 库由许多小的松散耦合的模块（目标文件）组成，而不是由一个包含所有功能的单一模块组成。QS 的平台无关头文件 qs.h 和 qs_dummy.h qs.h - QS 功能的所有“活动”接口 qs_dummy.h - QS 功能的所有“不活动”接口qs.h:#ifndef qs_h#define qs_h#ifndef Q_SPY#error &quot;Q_SPY must be defined to include qs.h&quot;#endif /* Q_SPY */// 枚举QS记录类型，相当于日志标记enum QSpyRecords{ /* QEP records */ QS_QEP_STATE_ENTRY, /**&amp;lt; a state was entered */ QS_QEP_STATE_EXIT, /**&amp;lt; a state was exited */ ... /* QF records */ QS_QF_ACTIVE_ADD, /**&amp;lt; an AO has been added to QF (started) */ QS_QF_ACTIVE_REMOVE, /**&amp;lt; an AO has been removed from QF (stopped) */ QS_QF_ACTIVE_SUBSCRIBE, /**&amp;lt; an AO subscribed to an event */ QS_QF_ACTIVE_UNSUBSCRIBE, /**&amp;lt; an AO unsubscribed to an event */ QS_QF_ACTIVE_POST_FIFO, /**&amp;lt; an event was posted (FIFO) directly to AO */ ... /* QK records */ QS_QK_MUTEX_LOCK, /**&amp;lt; the QK mutex was locked */ QS_QK_MUTEX_UNLOCK, /**&amp;lt; the QK mutex was unlocked */ QS_QK_SCHEDULE, /**&amp;lt; the QK scheduled a new task to execute */ ... /* Miscellaneous QS records */ QS_SIG_DICTIONARY, /**&amp;lt; signal dictionary entry */ QS_OBJ_DICTIONARY, /**&amp;lt; object dictionary entry */ QS_FUN_DICTIONARY, /**&amp;lt; function dictionary entry */ QS_ASSERT, /** assertion failed */ ... /* User records */ QS_USER /**&amp;lt; the first record available for user QS records */ // 从QS_USER开始可以自定义记录类型};.../* Macros for adding QS instrumentation to the client code .................*///所有 QS 服务被定义为预处理器的宏。这样，即使软件追踪被禁止，你也可以把它们留在代码中。#define QS_INIT(arg_) QS_onStartup(arg_)#define QS_EXIT() QS_onCleanup()// 全局 QS 过滤器，它把某个给定 QS 追踪记录打开或关闭。#define QS_FILTER_ON(rec_) QS_filterOn(rec_)#define QS_FILTER_OFF(rec_) QS_filterOff(rec_)// 本地 QS 过滤器。这个过滤器允许你有选择的追踪那些特定的状态机对象。#define QS_FILTER_SM_OBJ(obj_) (QS_smObj_ = (obj_))#define QS_FILTER_AO_OBJ(obj_) (QS_aoObj_ = (obj_))#define QS_FILTER_MP_OBJ(obj_) (QS_mpObj_ = (obj_))#define QS_FILTER_EQ_OBJ(obj_) (QS_eqObj_ = (obj_))#define QS_FILTER_TE_OBJ(obj_) (QS_teObj_ = (obj_))#define QS_FILTER_AP_OBJ(obj_) (QS_apObj_ = (obj_))/* Macros to generate user QS records (formatted data output) ..............*/// 互斥锁，BEGIN上锁，END解锁，用于保护QS 追踪缓存#define QS_BEGIN(rec_, obj_) ...#define QS_END() ...// 不上锁（比如在临界区内再调用就不需要关中断了）#define QS_BEGIN_NOLOCK(rec_, obj_) ...#define QS_END_NOLOCK() ... ...#define QS_I8 (w_, d_) QS_u8((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_I8_T, (d_))#define QS_U8 (w_, d_) QS_u8((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_U8_T, (d_))#define QS_I16(w_, d_) QS_u16((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_I16_T, (d_))#define QS_U16(w_, d_) QS_u16((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_U16_T, (d_))#define QS_I32(w_, d_) QS_u32((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_I32_T, (d_))#define QS_U32(w_, d_) QS_u32((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_U32_T, (d_))#define QS_F32(w_, d_) QS_f32((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_F32_T, (d_))#define QS_F64(w_, d_) QS_f64((uint8_t)(((w_) &amp;lt;&amp;lt; 4)) | QS_F64_T, (d_))#define QS_STR(str_) QS_str(str_)#define QS_STR_ROM(str_) QS_str_ROM(str_)#define QS_MEM(mem_, size_) QS_mem((mem_), (size_))#if (QS_OBJ_PTR_SIZE == 1)#define QS_OBJ(obj_) QS_u8(QS_OBJ_T, (uint8_t)(obj_))#elif (QS_OBJ_PTR_SIZE == 2)#define QS_OBJ(obj_) QS_u16(QS_OBJ_T, (uint16_t)(obj_))#elif (QS_OBJ_PTR_SIZE == 4)#define QS_OBJ(obj_) QS_u32(QS_OBJ_T, (uint32_t)(obj_))#else#define QS_OBJ(obj_) QS_u32(QS_OBJ_T, (uint32_t)(obj_))#endif#if (QS_FUN_PTR_SIZE == 1)#define QS_FUN(fun_) QS_u8(QS_FUN_T, (uint8_t)(fun_))#elif (QS_FUN_PTR_SIZE == 2) ...#endif#if (Q_SIGNAL_SIZE == 1)#define QS_SIG(sig_, obj_) \\ QS_u8(QS_SIG_T, (sig_)); \\ QS_OBJ_(obj_)#elif (Q_SIGNAL_SIZE == 2) ...#endif/* Dictionary records ......................................................*/#define QS_OBJ_DICTIONARY(obj_) ...#define QS_FUN_DICTIONARY(fun_) ...#define QS_SIG_DICTIONARY(sig_, obj_) ... .../* Macros used only internally in the QP code ..............................*/#define QS_BEGIN_(rec_, obj_) ...#define QS_END_() ...#define QS_BEGIN_NOLOCK_(rec_, obj_) ...#define QS_END_NOLOCK_() .../* QS functions for managing the QS trace buffer ...........................*/voidQS_initBuf(uint8_t sto[], uint32_t stoSize);uint16_t QS_getByte(void); /* byte-oriented interface */uint8_t const *QS_getBlock(uint16_t *pNbytes); /* block-oriented interface *//* QS callback functions, typically implemented in the BSP .................*/uint8_t QS_onStartup(void const *arg);void QS_onCleanup(void);void QS_onFlush(void);QSTimeCtr QS_onGetTime(void);#endif /* qs_h */qs_dummy.h:#ifndef qs_dummy_h#define qs_dummy_h#ifdef Q_SPY#error &quot;Q_SPY must NOT be defined to include qs_dummy.h&quot;#endif#define QS_INIT(arg_) ((uint8_t)1)#define QS_EXIT() ((void)0)#define QS_DUMP() ((void)0)#define QS_FILTER_ON(rec_) ((void)0)#define QS_FILTER_OFF(rec_) ((void)0)#define QS_FILTER_SM_OBJ(obj_) ((void)0)...#define QS_GET_BYTE(pByte_) ((uint16_t)0xFFFF)#define QS_GET_BLOCK(pSize_) ((uint8_t *)0)#define QS_BEGIN(rec_, obj_) \\ if (0) \\ {#define QS_END() }#define QS_BEGIN_NOLOCK(rec_, obj_) QS_BEGIN(rec_, obj_)#define QS_END_NOLOCK() QS_END()#define QS_I8(width_, data_) ((void)0)#define QS_U8(width_, data_) ((void)0) ...#define QS_SIG(sig_, obj_) ((void)0)#define QS_OBJ(obj_) ((void)0)#define QS_FUN(fun_) ((void)0)#define QS_SIG_DICTIONARY(sig_, obj_) ((void)0)#define QS_OBJ_DICTIONARY(obj_) ((void)0)#define QS_FUN_DICTIONARY(fun_) ((void)0)#define QS_FLUSH() ((void)0) ...#endifQS 的临界区QS 目标构件必须保护追踪缓存的内部完整性，它在并发运行的任务和中断之间被共享，所以需要被视为临界区当 QS 探测 QF 临界区的宏 QF_INT_LOCK() ， QF_INT_UNLOCK() 被定义时， QS 使用了这个定义作为它自己的临界区。然而，当你在没有 QF 实时框架的情况下使用 QS 时，你需要在qs_port.h头文件里定义 QS 的平台相关的中断上锁 / 解锁策略 QS_BEGIN 和 QS_END()就是利用的qs_port.h里定义的锁宏自定义的锁_qs_port.h_:#define QS_INT_KEY_TYPE . . . #define QS_INT_LOCK(key_) . . . #define QS_INT_UNLOCK(key_) . . .QS 记录的一般结构QS 在分离的被称为 QS“追踪记录” 的小块里记录追踪数据。QS_BEGIN_xxx(record_type) /* trace record begin */ QS_yyy(data); /* QS data element */ QS_zzz(data); /* QS data element */ . . . /* QS data element */QS_END_xxx() /* trace record end */ QS_BEGIN/QS_END(): 在记录的开始处上锁中断，在记录的结尾解锁中断。 QS_BEGIN_NOLOCK()/QS_END_NOLOCK(): 用来创建应用程序相关的记录而不需进入临界区，它们仅能被用于某个临界区内部。 TODO:NOLOCK 有什么意义QS 的过滤器全局开/关过滤器预定义的类型就是qs.h中的QSpyRecords枚举型，通过过滤器启用/禁用对应类型的日志记录全局开 / 关过滤器使用一个位掩码数据QS_glbFilter_[]而高效的实现，这个数组的每一位代表一个追踪记录。当前 QSglbFilter[]包含 32 字节，总共 32×8 位可以代表 256 个不同的追踪记录。其中大约四分之一已经被用于预定义的 QP 追踪记录。剩下四分之三可以用于应用程序。#define QS_BEGIN(rec_, obj_) \\ if (((QS_glbFilter_[(uint8_t)(rec_) &amp;gt;&amp;gt; 3U] \\ &amp;amp; (1U &amp;lt;&amp;lt; ((uint8_t)(rec_) &amp;amp; 7U))) != 0) . . .\\rec_表示记录类型枚举 id，从 0 到 255，右移三位表示整除 8，因为最后三位被右移掉了，相当于把余数抹除了。这样QS_glbFilter_[]就能定位到该 id 对应的字节,如 255 对应第 32 个字节，46 对应第 5 个字节。然后再以上一步余数（和 7 进行与操作）为mask找到对应的位，代码中就是将 1 左移余数值生成一个字节 8 位里的某个 mask。如 46 余数是 6，1 左移 6 位，mask 就是 0x40，找到第 5 个字节中的 0x40 mask 对应的位 上述表达式中需要重复计算的部分可以作为编译时常数值。 如(QS_glbFilter_[5] &amp;amp; 0x40) != 0) 这里将 QS_glbFilter_定义为单字节数组而不是多字节数组是为了兼容性。 宏QS_FILTER_ON(rec_): 打开和记录 rec_ 对应的位 宏QS_FILTER_OFF(rec_): 关闭和记录 rec_ 相对应的位本地过滤器以对象为单位管理过滤器。如只开启对某个活动对象的打印，关闭其他的对象类型有：状态机、活动对象、内存池、事件队列、时间事件、一般的应用程序对象 本地过滤器 对象类型 例子 适用的 QS 记录 QS_FILTER_SM_OBJ() 状态机 QS_FILTER_SM_OBJ(&amp;amp;l_qhsmTst); QS_QEP_STATE_EMPTY,QS_QEP_STATE_ENTRY,QS_QEP_STATE_EXIT,QS_QEP_STATE_INIT,QS_QEP_INIT_TRAN,QS_QEP_INTERN_TRAN,QS_QEP_TRAN,QS_QEP_IGNORED QS_FILTER_AO_OBJ() 活动对象 t QS_FILTER_AO_OBJ(&amp;amp;l_philo[3]); QS_QF_ACTIVE_ADD,QS_QF_ACTIVE_REMOVE,QS_QF_ACTIVE_SUBSCRIBE,QS_QF_ACTIVE_UNSUBSCRIBE,QS_QF_ACTIVE_POST_FIFO,QS_QF_ACTIVE_POST_LIFO,QS_QF_ACTIVE_GET,QS_QF_ACTIVE_GET_LAST QS_FILTER_MP_OBJ()( 见注释 1) 内存池 QS_FILTER_MP_OBJ(l_regPoolSto); QS_QF_MPOOL_INIT,QS_QF_MPOOL_GETQS_QF_MPOOL_PUT QS_FILTER_EQ_OBJ()( 见注释 2) 事件队列 QS_FILTER_EQ_OBJ(l_philQueueSto[3]); QS_QF_EQUEUE_INIT,QS_QF_EQUEUE_POST_FIFO,QS_QF_EQUEUE_POST_LIFO,QS_QF_EQUEUE_GET,QS_QF_EQUEUE_GET_LAST QS_FILTER_TE_OBJ() 时间事件 QS_FILTER_TE_OBJ(&amp;amp;l_philo[3].timeEvt); QS_QF_TICK,QS_QF_TIMEEVT_ARM,QS_QF_TIMEEVT_AUTO_DISARM,QS_QF_TIMEEVT_DISARM_ATTEMPT,QS_QF_TIMEEVT_DISARM,QS_QF_TIMEEVT_REARM,QS_QF_TIMEEVT_POST,QS_QF_TIMEEVT_PUBLISH QS_FILTER_AP_OBJ() 一般的应用程序对象 QS_FILTER_AP_OBJ(&amp;amp;myAppObject); 以 QS_USER 开始的应用程序相关的记录 QS 数据协议类似 HDLC 协议QS 协议被特别设计用来简化在目标系统里的数据管理的开销，同时允许探测到任何由于追踪缓存不足造成的数据丢失。这个协议不但可以探测到在数据和其他错误之间的缺陷，而且允许在任何错误后立即重新同步，把数据丢失减到最小。帧序号+记录类型 ID+数据域+校验码+帧尾标记透明就是对帧内出现的帧尾标记字节(0x7E)做转义使用 0x7D 做转义前导符，对 0x7E 做转义，当然 0x7D 本身也要转义，方法为对要转义的字符和 0x20 异或一个例子也许可以更清楚的说明这点。假设以下的追踪记录需要被插入追踪缓存（透明字节用粗体字显示）：Record ID = 0x7D, Record Data = 0x7D 0x08 0x01假设当前的帧顺序号码是 0x7E，校验和通过计算下列字节而得到：Checksum == (uint8_t)(~(0x7E + 0x7D + 0x7D + 0x08 + 0x01)) == 0x7E实际被插入到 QS 追踪缓存的帧如下：0x7D 0x5E 0x7D 0x5D 0x7D 0x5D 0x08 0x01 0x7D 0x5E 0x7E大小端QS 传输协议规定了数据是小端（ little-endian ）高位高地址，低位低地址，优先传输低位QS 追踪缓存区追踪缓存区内保存的就是HDLC帧特点： 第一，在追踪缓存使用 HDLC 格式的数据，允许把向追踪缓存插入数据和从指针缓存已走数据解除耦合。可以按个数丢弃，无需考虑边界(自动检测边界) 第二，在缓存里使用格式化的数据能够使用“最后的是最好的”追踪策略。因为校验码可以检测覆盖导致的错误，自动丢弃被覆盖的数据初始化 QS 追踪缓存区 QS_initBuf()需要为 QS 追踪缓存分配静态存储，当日志数据量大时，缓存也要大，防止绕尾破坏数据（虽然该错误能被检测和处理，但数据还是丢了）#ifdef Q_SPY /* define QS callbacks */uint8_t QS_onStartup(void const *arg){ static uint8_t qsBuf[2 * 1024]; /* buffer for Quantum Spy */ QS_initBuf(qsBuf, sizeof(qsBuf)); // Initialize the QS data link ... return success; /* return 1 for success and 0 for failure */}#endif面向字节的接口： QS_getByte()可以在任何时候从缓存移走一个字节函数 QS_getByte() 不上锁中断，也不是可重入的。也就是用的时候要应用自己加锁TODO：为什么要这么设计，函数体内关中断不行吗QF_INT_LOCK(igonre);while ((fifo != 0) &amp;amp;&amp;amp; ((b = QS_getByte()) != QS_EOD)) /* get the next byte */{ QF_INT_UNLOCK(igonre); // 从缓存读取(移走)一个字节放入TX发送缓存 outportb(l_base + 0, (uint8_t)b); /* insert byte into TX FIFO */ --fifo; QF_INT_LOCK(igonre);}QF_INT_UNLOCK(igonre);面向块的接口： QS_getBlock()获取一个块，fifo 入参表示希望获取的长度，出参表示实际获得长度。函数返回块起始指针需要应用加锁返回长度小于输入长度时表示缓存读尽或还有回绕，再读一次，如果长度是 0 表示缓存读尽uint16_t fifo = UART_16550_TXFIFO_DEPTH; /* 16550 Tx FIFO depth */uint8_t const *block;QF_INT_LOCK(dummy);block = QS_getBlock(&amp;amp;fifo); /* try to get next block to transmit */QF_INT_UNLOCK(dummy);while (fifo-- != 0) { /* any bytes in the block? */ outportb(l_uart_base + 0, *block++);}字典追踪记录当你编译并把应用程序映像装入目标系统后，关于对象名，函数名和信号名的符号信息被从代码中剥离。QS 提供了专门的追踪记录，特别被设计用来在追踪记录本身包含目标代码的符号信息。用于 QSPY 主机应用程序的包含在追踪记录里的字典记录，非常类似传统的单步调试器使用的嵌入在目标文件里的符号信息。QS 支持 3 类字典追踪记录：对象字典，函数字典和信号字典。 对象字典 用宏 QS_OBJ_DICTONARY() 来生成对象字典，它把对象在内存的地址和它的符号名联合起来。 // 通过活动对象0的内存地址获取对象的名字QS_OBJ_DICTIONARY(&amp;amp;l_philo[0]); 函数字典 使用宏 QS_FUN_DICTONARY() 来生成函数字典，它把函数在内存的地址和它的符号名联系起来。 信号字典 使用宏 QS_SIG_DICTONARY() 来生成信号字典，它把事件信号的数值和状态机对象这两者和信号的符号名联系起来。 同时使用信号的数值和状态对象的理由是，仅使用信号值不能有效的把符号化信号区分出来。只有全局发行的信号在系统范围内才是唯一的。其他信号，仅在本地使用，在系统的不同状态机里有完全不同的意义。 应用程序相关的 QS 追踪记录应用程序相关的 QS 记录允许你从应用层代码生成追踪信息。你可以把应用相关的记录想像成和 printf() 等效的功能，但是它有更少的开销。QS_BEGIN(MY_QS_RECORD, myObjectPointer) /* trace record begin */ QS_STR(&quot;Hello&quot;); /* string data element */ QS_U8(3, n); /* uint8_t data, 3-decimal digits format */ . . . /* QS data */ QS_MEM(buf, sizeof(buf)); /* memory block of a given size */QS_END() /* trace record end */由 QS_BEGIN 开始，QS_BEGIN 自带上锁功能，参数为一个 QS 记录类型 MY_QS_RECORD（用于全局过滤器）和一个对象指针 myObjectPointer（用于本地过滤器）上图是上述示例代码的表示移植和配置 QS修改 qs_port.hQSPY 主机应用程序使用 C++实现，它的用途仅是提供 QS 数据语法分析，存储，并把数据输出到其他强大的工具比如 MATLAB。向 MATLAB 输出追踪数据略向 QP 应用程序添加 QS 软件追踪#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;/* Local-scope objects -----------------------------------------------------*/static QEvent const *l_tableQueueSto[N_PHILO];static QEvent const *l_philoQueueSto[N_PHILO][N_PHILO];static QSubscrList l_subscrSto[MAX_PUB_SIG];static union SmallEvent{ void *min_size; TableEvt te; /* other event types to go into this pool */} l_smlPoolSto[2 * N_PHILO]; /* storage for the small event pool *//*..........................................................................*/int main(int argc, char *argv[]){ uint8_t n; Philo_ctor(); /* instantiate all Philosopher active objects */ Table_ctor(); /* instantiate the Table active object */ BSP_init(argc, argv); /* initialize the BSP (including QS) */ QF_init(); /* initialize the framework and the underlying RT kernel */ /* setup the QS filters ... */ // 全局过滤器默认全禁止，这里全开一下 QS_FILTER_ON(QS_ALL_RECORDS); // 关闭一些打印较频繁的记录类型（全局过滤器） QS_FILTER_OFF(QS_QF_INT_LOCK); QS_FILTER_OFF(QS_QF_INT_UNLOCK); QS_FILTER_OFF(QS_QK_SCHEDULE); /* provide object dictionaries... */ // 创建对象字典 QS_OBJ_DICTIONARY(l_smlPoolSto); QS_OBJ_DICTIONARY(l_tableQueueSto); QS_OBJ_DICTIONARY(l_philoQueueSto[0]); QS_OBJ_DICTIONARY(l_philoQueueSto[1]); QS_OBJ_DICTIONARY(l_philoQueueSto[2]); QS_OBJ_DICTIONARY(l_philoQueueSto[3]); QS_OBJ_DICTIONARY(l_philoQueueSto[4]); QF_psInit(l_subscrSto, Q_DIM(l_subscrSto)); /* init publish-subscribe */ /* initialize event pools... */ QF_poolInit(l_smlPoolSto, sizeof(l_smlPoolSto), sizeof(l_smlPoolSto[0])); for (n = 0; n &amp;lt; N_PHILO; ++n) { /* start the active objects... */ QActive_start(AO_Philo[n], (uint8_t)(n + 1), l_philoQueueSto[n], Q_DIM(l_philoQueueSto[n]), (void *)0, 0, (QEvent *)0); } QActive_start(AO_Table, (uint8_t)(N_PHILO + 1), l_tableQueueSto, Q_DIM(l_tableQueueSto), (void *)0, 0, (QEvent *)0); QF_run(); /* run the QF application */ return 0;}定义平台相关的 QS 回调函数#include &quot;qp_port.h&quot;#include &quot;dpp.h&quot;#include &quot;bsp.h&quot;.../* Local-scope objects -----------------------------------------------------*/#ifdef Q_SPY static uint16_t l_uart_base; /* QS data uplink UART base address */...#define UART_16550_TXFIFO_DEPTH 16#endif.../*..........................................................................*/voidBSP_init(int argc, char *argv[]){ char const *com = &quot;COM1&quot;; uint8_t n; if (argc &amp;gt; 1) { l_delay = atol(argv[1]); /* set the delay counter for busy delay */ } if (argc &amp;gt; 2) { com = argv[2]; (void)com; /* avoid compiler warning if Q_SPY not defined */ } // QS未启用，QS_INIT()未自定义时，总是返回True if (!QS_INIT(com)) { /* initialize QS */ // 断言 Q_ERROR(); } ...}/*..........................................................................*/// 在空闲循环里， QK 可抢占式内核调用 QK_onIdle()回调函数void QK_onIdle(void){#ifdef Q_SPY if ((inportb(l_uart_base + 5) &amp;amp; (1 &amp;lt;&amp;lt; 5)) != 0) { /* Tx FIFO empty? */ uint16_t fifo = UART_16550_TXFIFO_DEPTH; /* 16550 Tx FIFO depth */ uint8_t const *block; QF_INT_LOCK(dummy); block = QS_getBlock(&amp;amp;fifo); /* try to get next block to transmit */ QF_INT_UNLOCK(dummy); while (fifo-- != 0) { /* any bytes in the block? */ outportb(l_uart_base + 0, *block++); } }#endif}.../*--------------------------------------------------------------------------*/#ifdef Q_SPY /* define QS callbacks *//*..........................................................................*/// 配置 80x86 系列 PC 的某个标准 UART （ COM1 到 COM4 ）static uint8_tUART_config(char const *comName, uint32_t baud){ switch (comName[3]) { /* Set the base address of the COMx port */ case &#39;1&#39;: l_uart_base = (uint16_t)0x03F8; break; /* COM1 */ case &#39;2&#39;: l_uart_base = (uint16_t)0x02F8; break; /* COM2 */ case &#39;3&#39;: l_uart_base = (uint16_t)0x03E8; break; /* COM3 */ case &#39;4&#39;: l_uart_base = (uint16_t)0x02E8; break; /* COM4 */ default: return (uint8_t)0; /* COM port out of range failure */ } baud = (uint16_t)(115200UL / baud); /* divisor for baud rate */ outportb(l_uart_base + 3, (1 &amp;lt;&amp;lt; 7)); /* Set divisor access bit (DLAB) */ outportb(l_uart_base + 0, (uint8_t)baud); /* Load divisor */ outportb(l_uart_base + 1, (uint8_t)(baud &amp;gt;&amp;gt; 8)); outportb(l_uart_base + 3, (1 &amp;lt;&amp;lt; 1) | (1 &amp;lt;&amp;lt; 0)); /* LCR:8-bits,no p,1stop */ outportb(l_uart_base + 4, (1 &amp;lt;&amp;lt; 3) | (1 &amp;lt;&amp;lt; 1) | (1 &amp;lt;&amp;lt; 0)); /*DTR,RTS,Out2*/ outportb(l_uart_base + 1, 0); /* Put UART into the polling FIFO mode */ outportb(l_uart_base + 2, (1 &amp;lt;&amp;lt; 2) | (1 &amp;lt;&amp;lt; 0)); /* FCR: enable, TX clear */ return (uint8_t)1; /* success */}/*..........................................................................*/// 初始化 QS 构件uint8_t QS_onStartup(void const *arg){ static uint8_t qsBuf[2 * 1024]; /* buffer for Quantum Spy */ // 初始化 QS 追踪缓存 QS_initBuf(qsBuf, sizeof(qsBuf)); return UART_config((char const *)arg, 115200UL);}/*..........................................................................*/// 执行 QS 的清理工作void QS_onCleanup(void){}/*..........................................................................*/// 回调函数 QS_onFlush() 把整个追踪缓存发送给主机。在每个字典追踪记录后调用这个函数， 用来避免在系统初始化时追踪缓存的溢出。void QS_onFlush(void){ uint16_t fifo = UART_16550_TXFIFO_DEPTH; /* 16550 Tx FIFO depth */ uint8_t const *block; QF_INT_LOCK(dummy); while ((block = QS_getBlock(&amp;amp;fifo)) != (uint8_t *)0) { QF_INT_UNLOCK(dummy); /* busy-wait until TX FIFO empty */ // 忙等待意味着阻塞，所有这个函数仅能在初始化时调用 while ((inportb(l_uart_base + 5) &amp;amp; (1 &amp;lt;&amp;lt; 5)) == 0) { } while (fifo-- != 0) { /* any bytes in the block? */ outportb(l_uart_base + 0, *block++); } fifo = UART_16550_TXFIFO_DEPTH; /* re-load 16550 Tx FIFO depth */ QF_INT_LOCK(dummy); } QF_INT_UNLOCK(dummy);}/*..........................................................................*/// 获取时间戳QSTimeCtr QS_onGetTime(void){ /* see Listing 11.18 */ ...}#endif /* Q_SPY *//*--------------------------------------------------------------------------*/使用回调函数 QS_onGetTime() 产生 QS 时间戳8254 芯片的计时器 0 是一个 16 位向下计数器，它被设置成当它从 0xFFFF 到 0 下溢，每次到 0 时产生标准的 18.2Hz 时钟节拍中断，下一次计数时计数器回绕成 0xFFFF。 计数速率是 1.193182MHz ，大约每个计数是 0.838 微秒。每次系统节拍中断就记一次 0x10000，精度就是 0x10000，还要获取更精细的值就要读上面说的计时器了，它的值会从 0xFFFF 到 0 。中断计数成上 0x10000 加上计数器的值就是完整的值了。有个问题就是如果系统节拍中断丢失，就会少加 0x10000，需要通过手段规避/* Local-scope objects -----------------------------------------------------*/#ifdef Q_SPY static QSTimeCtr l_tickTime; /* keeps timestamp at tick */ static uint32_t l_lastTime; /* last timestamp */#endif...// 系统时钟节拍中断void interrupt ISR_tmr(void){ uint8_t pin;#ifdef Q_SPY // 在中断处理程序里加0x10000 l_tickTime += 0x10000; /* add 16-bit rollover */#endif QK_ISR_ENTRY(pin, TMR_ISR_PRIO); /* inform QK about entering the ISR */ QF_tick(); /* call QF_tick() outside of critical section */ QK_ISR_EXIT(pin); /* inform QK about exiting the ISR */}/*..........................................................................*/#ifdef Q_SPY /* define QS callbacks */...// 总是在代码的某个临界区调用 QS_onGetTime() 函数。QSTimeCtr QS_onGetTime(void){ /* invoked with interrupts locked */ uint32_t now; uint16_t count16; /* 16-bit count from the 8254 */ if (l_tickTime != 0) // 系统节拍器已使能 { /* time tick has started? */ // 8254的计数器 0 被锁住。这样才能安全读取 outportb(0x43, 0); /* latch the 8254&#39;s counter-0 count */ count16 = (uint16_t)inportb(0x40); /* read the low byte of counter-0 */ count16 += ((uint16_t)inportb(0x40) &amp;lt;&amp;lt; 8); /* add on the hi byte */ now = l_tickTime + (0x10000 - count16); // 说明丢失了一次系统节拍中断（这个检查假设 QS_onGetTime() 在每个回绕周期被调用一次。） // 因为假设了每个中断周期内至少调用一次，所以now正常肯定是大于等于l_lastTime的 // 而且要假设周期内调用的时间是一样的 if (l_lastTime &amp;gt; now) { /* are we going &quot;back&quot; in time? */ // 手动加1 now += 0x10000; /* assume that there was one rollover */ } l_lastTime = now; } else // 系统节拍器还未使能 { now = 0; } return (QSTimeCtr)now;}#endif /* Q_SPY */从主动对象产生 QS 字典table.c:// 这个是哲学家就餐问题，有叉子、饥饿等名词，Table是活动对象类static Table l_table; /* the single instance of the Table active object */...// 初始伪状态比较适合做生成字典操作void Table_initial(Table *me, QEvent const *e){ (void)e; /* suppress the compiler warning about unused parameter */ // 这个宏可以获取参数的名字，所以要用l_table而不是me，即使它们的值相同 QS_OBJ_DICTIONARY(&amp;amp;l_table); // 函数字典 QS_FUN_DICTIONARY(&amp;amp;QHsm_top); QS_FUN_DICTIONARY(&amp;amp;Table_initial); QS_FUN_DICTIONARY(&amp;amp;Table_serving); // 全局发行的信号的信号字典记录必须和系统里所有的状态机相联系。 // 所以要给这种信号添加额外信息，这里是第二个参数 // 比如在另一个状态机里是1而不是0 QS_SIG_DICTIONARY(DONE_SIG, 0); /* global signals */ QS_SIG_DICTIONARY(EAT_SIG, 0); QS_SIG_DICTIONARY(TERMINATE_SIG, 0); // 可以直接用me的值(一个地址)作为额外信息，保证不会重复 QS_SIG_DICTIONARY(HUNGRY_SIG, me); /* signal just for Table */ /* signal HUNGRY_SIG is posted directly */ QActive_subscribe((QActive *)me, DONE_SIG); QActive_subscribe((QActive *)me, TERMINATE_SIG); Q_TRAN(&amp;amp;Table_serving);}按照本地过滤器中的对象说明，这个 l_table 应该是活动对象添加应用程序相关的追踪记录#ifdef Q_SPY ... enum AppRecords { /* application-specific trace records */ // 自定义的记录类型需要从QS_USER开始 PHILO_STAT = QS_USER };#endif.../*..........................................................................*/voidBSP_displyPhilStat(uint8_t n, char const *stat){ Video_printStrAt(17, 12 + n, VIDEO_FGND_YELLOW, stat); // 第一个是记录类型，用于全局过滤器，第二个是应用对象，用于本地过滤器， // 这里是活动对象类型，表示只记录这个活动对象相关记录 // QS_BEGIN和QS_END划定临界区 QS_BEGIN(PHILO_STAT, AO_Philo[n]) /* application-specific record begin */ QS_U8(1, n); /* Philosopher number */ QS_STR(stat); /* Philosopher status */ QS_END()}// 笔者注：格式是 时间 记录类型: n stat 0000525113 User000: 4 eating . . . 0000591471 User000: 3 hungry . . . 0000591596 User000: 2 hungry . . . 0000591730 User000: 0 hungry . . . 0000852276 User000: 4 thinking . . . 0000852387 User000: 3 eating . . . 0000983937 User000: 1 thinking . . . 0000984047 User000: 0 eating . . . 0001246064 User000: 3 thinking问题 单过程处理时间，是否在 DMA 时主动让出控制权（时间较短，让出利用率也低，还有一致性问题） 内存分配，由于没有栈空间，需要堆类型的空间（QP 自带的内存池） state local memory，每个 AO 自己的内部变量，即使是临时变量也会占用固定空间，为了退出后下次进入状态时使用，如果是临时变量会浪费空间参考 UML 状态图的实用 C/C++设计" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(三十七) 分布式系统、远程过程调用（RPC）", "url": "/posts/operating-systems-37/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统", "date": "2022-06-20 09:00:00 +0800", "snippet": "远程过程调用（RPC）最主要的抽象是基于远程过程调用（Remote Procedure Call），或简称 RPC远程过程调用包都有一个简单的目标：使在远程机器上执行代码的过程像调用本地函数一样简单直接RPC 系统通常有两部分：存根生成器（stub generator，有时称为协议编译器，protocol compiler）和运行时库（run-time library）。存根生成器通过自动化，消除将函数参数和结果打包成消息的一些痛苦。interface { int func1(int arg1); int func2(int arg1, int arg2);};存根生成器类似于写好接口文档，自动生成一个头文件，可以被其他函数调用。在内部，客户端存根中的每个函数都执行远程过程调用所需的所有工作。对于客户端，代码只是作为函数调用出现（例如，客户端调用 func1(x)）。在内部，func1()的客户端存根中的代码执行此操作： 创建消息缓冲区。消息缓冲区通常只是某种大小的连续字节数组。 将所需信息打包到消息缓冲区中。该信息包括要调用的函数的某种标识符，以及函数所需的所有参数（例如，在上面的示例中，func1 需要一个整数）。将所有这些信息放入单个连续缓冲区的过程，有时被称为参数的封送处理（marshaling）或消息的序列化（serialization）。 将消息发送到目标 RPC 服务器。与 RPC 服务器的通信，以及使其正常运行所需的所有细节，都由 RPC 运行时库处理，如下所述。 等待回复。由于函数调用通常是同步的（synchronous），因此调用将等待其完成。 解包返回代码和其他参数。如果函数只返回一个返回码，那么这个过程很简单。但是，较复杂的函数可能会返回更复杂的结果（例如，列表），因此存根可能也需要对它们解包。此步骤也称为解封送处理（unmarshaling）或反序列化（deserialization）。 返回调用者。最后，只需从客户端存根返回到客户端代码。对于服务器，也会生成代码。在服务器上执行的步骤如下： 解包消息。此步骤称为解封送处理（unmarshaling）或反序列化（deserialization），将信息从传入消息中取出。提取函数标识符和参数。 调用实际函数。终于，我们到了实际执行远程函数的地方。RPC 运行时调用 ID 指定的函数，并传入所需的参数。 打包结果。返回参数被封送处理，放入一个回复缓冲区。 发送回复。回复最终被发送给调用者。问题1：一个包如何发送复杂的数据结构？需要合理序列化问题2：并发性的服务器组织方式？常见的组织方式是线程池（thread pool）。在这种组织方式中，服务器启动时会创建一组有限的线程。消息到达时，它被分派给这些工作线程之一，然后执行 RPC 调用的工作，最终回复。在此期间，主线程不断接收其他请求，并可能将其发送给其他工作线程。运行时库如何找到远程服务？需要命名解析，如DNS。TCP作为可靠传输协议有性能损失许多 RPC 软件包都建立在不可靠的通信层之上，例如 UDP。这样做可以实现更高效的 RPC 层，但确实增加了为 RPC 系统提供可靠性的责任。通过使用某种形式的序列编号，通信层可以保证每个 RPC 只发生一次（在没有故障的情况下），或者最多只发生一次（在发生故障的情况下）。其他问题当远程调用需要很长时间才能完成时，一种解决方案是在没有立即生成回复时使用显式确认（从接收方到发送方）。这让客户端知道服务器收到了请求运行时还必须处理具有大参数的过程调用，发送方分组（fragmentation，较大的包分成一组较小的包）和接收方重组（reassembly，较小的部分组成一个较大的逻辑整体）。字节序（byte ordering）。有些机器存储值时采用所谓的大端序（big endian），而其他机器采用小端序（little endian）。之前提到服务端可以异步处理请求，客户端也要能异步调用接口，客户端在某些时候会希望看到异步 RPC 的结果。因此它再次调用 RPC 层，告诉它等待未完成的 RPC 完成，此时可以访问返回的结果。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(三十六) 数据完整性和保护", "url": "/posts/operating-systems-36/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-17 10:00:00 +0800", "snippet": "磁盘故障模式潜在扇区错误（Latent-Sector Errors，LSE）如果磁头由于某种 原因接触到表面（磁头碰撞，head crash，在正常操作期间不应发生的情况），则可能会讹误表面，使得数据位不可读。宇宙射线也会导致数据位翻转，使内容不正确。驱动器使用磁盘内纠错码（Error Correcting Code，ECC）来确定块中的磁盘位是否良好，并且在某些情况下，修复它们。块讹误（block corruption）磁盘块出现讹误（corrupt），但磁盘本身无法检测到。例如，有缺陷的磁盘固件可能会将块写入错误的位置。在这种情况下，磁盘 ECC 指示块内容很好，但是从客户端的角度来看，在随后访问时返回错误的块。类似地，当一个块通过有故障的总线从主机传输到磁盘时，它可能会讹误。由此产生的讹误数据会存入磁盘，但它不是客户所希望的。这些类型的故障特别隐蔽，因为它们是无声的故障（silent fault）。返回故障数据时，磁盘没有报告问题。该表显示了在研究过程中至少出现一次 LSE 或块讹误的驱动器百分比（大约 3 年，超过 150 万个磁盘驱动器）。该表进一步将结果细分为“廉价”驱动器（通常为 SATA驱动器） 和“昂贵”驱动器（通常为 SCSI 或 FibreChannel）。关于 LSE 的一些其他发现如下： 具有多个 LSE 的昂贵驱动器可能会像廉价驱动器一样产生附加错误。 对于大多数驱动器，第二年的年度错误率会增加。 LSE 随磁盘大小增加。 大多数磁盘的 LSE 少于 50 个。 具有 LSE 的磁盘更有可能发生新增的 LSE。 存在显著的空间和时间局部性。 磁盘清理很有用（大多数 LSE 都是这样找到的）。关于讹误的一些发现如下： 同一驱动器类别中不同驱动器型号的讹误机会差异很大。 老化效应因型号而异。 工作负载和磁盘大小对讹误几乎没有影响。 大多数具有讹误的磁盘只有少数讹误。 讹误不是与一个磁盘或 RAID 中的多个磁盘无关的。 存在空间局部性和一些时间局部性。 与 LSE 的相关性较弱。处理潜在的扇区错误潜在的扇区错误很容易处理，因为它们（根据定义）很容易被检测到。当存储系统尝试访问块，并且磁盘返回错误时，存储系统应该就用它具有的任何冗余机制， 来返回正确的数据。例如，在镜像 RAID 中，系统应该访问备用副本。在基于奇偶校验的 RAID-4 或 RAID-5 系统中，系统应通过奇偶校验组中的其他块重建该块。因此，利用标准冗余机制，可以容易地恢复诸如 LSE 这样的容易检测到的问题。检测讹误：校验和如何处理数据讹误导致的无声故障？ 校验和（checksum） 校验和就是一个函数的结果，该函数以一块数据（例如 4KB 块）作为输入，并计算这段数据的函数，产生数据内容的小概要（比如 4 字节或 8 字节）。此摘要称为校验和常见的校验和函数基于异或（XOR）使用基于 XOR 的校验和，只需对需要校验和的数据块的每个块进行异或运算，从而生成一个值，表示整个块的 XOR。XOR 计算规则： $p$ $q$ $p \\oplus q$ True True False True False True False True True False False False 交换律：${\\displaystyle p\\oplus q=q\\oplus p}$结合律：${\\displaystyle p\\oplus (q\\oplus r)=(p\\oplus q)\\oplus r}$恒等律：${\\displaystyle p\\oplus 0=p}$归零律：${\\displaystyle p\\oplus p=0}$自反：${\\displaystyle p\\oplus q\\oplus q=p\\oplus 0=p}$实例：// 源数据365e c4cd ba14 8a92 ecef 2c3a 40be f666// 二进制0011 0110 0101 1110 1100 0100 1100 11011011 1010 0001 0100 1000 1010 1001 00101110 1100 1110 1111 0010 1100 0011 10100100 0000 1011 1110 1111 0110 0110 0110我们以每行 4 个字节为一组排列数据，所以很容易看出生成的校验和是什么。只需对每列执行XOR以获得最终的校验和值(有 0 个或 2 个 1 就是 0，有 1 个或 3 个 1 就是 1)：0010 0000 0001 1011 1001 0100 0000 0011XOR 是一个合理的校验和，但有其局限性。例如，如果每个校验和单元内同一列的两个位发生变化，则校验和将不会检测到讹误加法这种方法具有快速的优点。计算它只需要在每个数据块上执行二进制补码加法，忽略溢出。它可以检测到数据中的许多变化，但如果数据被移位，则不好Fletcher 校验和（Fletcher checksum）它非常简单，涉及两个校验字节 s1 和 s2 的计算。假设块 D 由字节 d1,…, dn 组成。s1 简单地定义如下：s1 = s1 + di mod 255（在所有 di 上计算）。s2 依次为：s2 = s2 + s1 mod 255（同样在所有 di 上）fletcher 校验和几乎与 CRC（下面描述）一样强，可以检测所有单比特错误，所有双比特错误和大部分突发错误循环冗余校验（CRC）你所做的只是将 D 视为一个大的二进制数（毕竟它只是一串位）并将其除以约定的值（k）。该除法的其余部分是 CRC 的值。g(x)和 h(x)的除运算，可以通过 g 和 h 做xor（异或）运算。比如将 11001 与 10101 做 xor 运算：明白了 xor 运算法则后，举一个例子使用CRC-8算法求 101001110100001 的效验码。CRC-8 标准的 h(x) = x^8 + x^7 + x^6 + x^4 + x^2 + 1，既 h 是 9 位的二进制串 111010101。缺陷无论使用何种方法，很明显没有完美的校验和：两个具有不相同内容的数据块可能具有相同的校验和，这被称为碰撞（collision）校验和布局最基本的方法就是为每个磁盘扇区（或块）存储校验和。给定数据块 D，我们称该数据的校验和为 C（D）。因为校验和通常很小（例如，8 字节），并且磁盘只能以扇区大小的块（512 字节）或其倍数写入，所以出现的一个问题是如何实现上述布局。驱动器制造商采用的一种解决方案是使用 520 字节扇区格式化驱动器，每个扇区额外的 8 个字节可用于存储校验和在没有此类功能的磁盘中，文件系统必须找到一种方法来将打包的校验和存储到 512 字节的块中。一种可能性如下：多了写校验和扇区的操作，比前面的方法多了一步使用校验和读数据计算校验和，读存储的校验和，比较是否相同一个新问题：错误的写入“错误位置的写入（misdirected write）”。这出现在磁盘和RAID控制器中，它们正确地将数据写入磁盘，但位置错误。在单磁盘系统中，这意味着磁盘写入块 Dx 不是在地址 x（像期望那样），而是在地址 y（因此是“讹误的”Dy）。另外，在多磁盘系统中，控制器也可能将 Di，x 不是写入磁盘 i 的 x，而是写入另一磁盘 j。答案很简单：在每个校验和中添加更多信息。在这种情况下，添加物理标识符（Physical Identifier，物理 ID）非常有用。例如，如果存储的信息现在包含校验和 C（D） 以及块的磁盘和扇区号，则客户端很容易确定块内是否存在正确的信息。具体来说，如果客户端正在读取磁盘 10 上的块 4（D10,4），则存储的信息应包括该磁盘号和扇区偏移量，如下所示。如果信息不匹配，则发生了错误位置写入，并且现在检测到讹误。以下是在双磁盘系统上添加此信息的示例:最后一个问题：丢失的写入 丢失的写入（lost write） 当设备通知上层写入已完成，但事实上它从未持久，就会发生这种问题。因此，磁盘上留下的是该块的旧内容，而不是更新的新内容某些系统在系统的其他位置添加校验和，以检测丢失的写入。例如，Sun 的 Zettabyte 文件系统（ZFS）在文件系统的每个 inode 和间接块中，包含文件中每个块的校验和。因此，即使对数据块本身的写入丢失，inode 内的校验和也不会与旧数据匹配。只有当同时丢失对 inode 和数据的写入时，这样的方案才会失败。擦净这些校验和何时实际得到检查？当然，在应用程序访问数据时会发生一些检查，但大多数数据很少被访问，因此将保持未检查状态。许多系统利用各种形式的磁盘擦净（disk scrubbing）。通过定期读取系统的每个块，并检查校验和是否仍然有效，磁盘系统可以减少某个数据项的所有副本都被破坏的可能性。典型的系统每晚或每周安排扫描。校验和的开销空间开销典型的比率可能是每 4KB 数据块的 8 字节校验和，磁盘空间开销为 0.19%。访问数据时，内存中必须有足够的空间用于校验和以及数据本身。这种开销是 短暂的，并不是很重要。时间开销CPU 必须计算每个块的校验和，包括存储数据时（确定存储的校验和的值），以及访问时（再次计算校验和， 并将其与存储的校验和进行比较）。除了 CPU 开销之外，一些校验和方案可能会导致外部 I/O 开销，特别是当校验和与数据分开存储时（因此需要额外的 I/O 来访问它们），以及后台擦净所需的所有额外 I/O。小结我们已经讨论了现代存储系统中的数据保护，重点是校验和的实现和使用。不同的校验和可以防止不同类型的故障。随着存储设备的发展，毫无疑问会出现新的故障模式。也许这种变化将迫使研究界和行业重新审视其中的一些基本方法，或发明全新的方法。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(三十五) 崩溃一致性：FSCK和日志(未完成)", "url": "/posts/operating-systems-35/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-17 09:01:00 +0800", "snippet": "文件系统面临的一个主要挑战在于，如何在出现断电（power loss）或系统崩溃（system crash）的情况下，更新持久数据结构。称为崩溃一致性问题（crash-consistency problem）。崩溃一致性问题理想的做法是将文件系统从一个一致状态（在文件被追加之前），原子地（atomically）移动到另一个状态（在 inode、位图和新数据块被写入磁盘之后）。遗憾的是，做到这一点不容易，因为磁盘一次只提交一次写入，而这些更新之间可能会发生崩溃或断电。我们将这个一般问题称为崩溃一致性问题（crash-consistency problem，也可以称为一致性更新问题，consistent-update problem）。解决方案1：文件系统检查程序决定让不一致的事情发生，然后再修复它们（重启时）。fsck 是一个 UNIX 工具，用于查找这些不一致并修复它们以下是 fsck 的基本总结: 超级块：fsck 首先检查超级块是否合理，主要是进行健全性检查，例如确保文件系统大小大于分配的块数。通常，这些健全性检查的目的是找到一个可疑的（冲突的）超级块。在这种情况下，系统（或管理员）可以决定使用超级块的备用副本。 空闲块：接下来，fsck 扫描 inode、间接块、双重间接块等，以了解当前在文件系统中分配的块。它利用这些知识生成正确版本的分配位图。因此，如果位图和 inode之间存在任何不一致，则通过信任 inode 内的信息来解决它。对所有 inode 执行相同类型的检查，确保所有看起来像在用的 inode，都在 inode 位图中有标记。 inode 状态：检查每个 inode 是否存在损坏或其他问题。例如，fsck 确保每个分配的 inode 具有有效的类型字段（即常规文件、目录、符号链接等）。如果 inode 字段存在问题，不易修复，则 inode 被认为是可疑的，并被 fsck 清除，inode 位图相应地更新。 inode 链接：fsck 还会验证每个已分配的 inode 的链接数。你可能还记得，链接计数表示包含此特定文件的引用（即链接）的不同目录的数量。为了验证链接计数，fsck 从根目录开始扫描整个目录树，并为文件系统中的每个文件和目录构建自己的链接计数。如果新计算的计数与 inode 中找到的计数不匹配，则必须采取纠正措施，通常是修复 inode 中的计数。如果发现已分配的 inode 但没有目录引用它，则会将其移动到 lost + found 目录。 重复：fsck 还检查重复指针，即两个不同的 inode 引用同一个块的情况。如果一个inode 明显不好，可能会被清除。或者，可以复制指向的块，从而根据需要为每个inode 提供其自己的副本。 坏块：在扫描所有指针列表时，还会检查坏块指针。如果指针显然指向超出其有效范围的某个指针，则该指针被认为是“坏的”，例如，它的地址指向大于分区大小的块。在这种情况下，fsck 不能做任何太聪明的事情。它只是从 inode 或间接块中删除（清除）该指针。 目录检查：fsck 不了解用户文件的内容。但是，目录包含由文件系统本身创建的特定格式的信息。因此，fsck 对每个目录的内容执行额外的完整性检查，确保“.”和“..”是前面的条目，目录条目中引用的每个 inode 都已分配，并确保整个层次结构中没有目录的引用超过一次。解决方案 2：日志（或预写日志）对于一致更新问题，最流行的解决方案可能是从数据库管理系统的世界中借鉴的一个想法(应该就是数据库中的事务)。这种名为预写日志（write-ahead logging）的想法，是为了解决这类问题而发明的。我们通常将预写日志称为日志（journaling）。基本思路如下。更新磁盘时，在覆写结构之前，首先写下一点小注记（在磁盘上的其他地方，在一个众所周知的位置），描述你将要做的事情。写下这个注记就是“预写”部分， 我们把它写入一个结构，并组织成“日志”。因此，就有了预写日志。通过将注释写入磁盘，可以保证在更新（覆写）正在更新的结构期间发生崩溃时，能够返回并查看你所做的注记，然后重试。因此，你会在崩溃后准确知道要修复的内容（以及如何修复它），而不必扫描整个磁盘。ext2 文件系统（没有日志）:ext3 文件系统: 日志写入：将事务（包括事务开始块，所有即将写入的数据和元数据更新以及事务 结束块）写入日志，等待这些写入完成。 加检查点：将待处理的元数据和数据更新写入文件系统中的最终位置写入日志期间发生崩溃在写入日志期间发生崩溃时，事情变得有点棘手。在这里，我们试图将事务中的这些块（即 TxB、I[v2]、B[v2]、Db、TxE）写入磁盘。一种简单的方法是一次发出 1 个块写入，等待每个完成，然后发出下一个。但是，这很慢。我们希望一次发出所有 5 个块写入，因为这会将 5 个写入转换为单个顺序写入(连续写入)，因此更快。然而，由于以下原因，这是不安全的：给定如此大的写入，磁盘内部可以执行调度并以任何顺序完成大批写入的小块(无法预知写入顺序)。比如，事务开始结束块TxB/TxE都已经写入，但中间的TxB却没写入：为避免该问题，文件系统分两步发出事务写入。首先，它将除 TxE 块之外的所有块写入日志，同时发出这些写入。当这些写入完成时，日志将看起来像这样（假设又是文件追加的工作负载）：当这些写入完成时，文件系统会发出 TxE 块的写入，从而使日志处于最终的安全状态：此过程的一个重要方面是磁盘提供的原子性保证。事实证明，磁盘保证任何 512 字节写入都会发生或不发生（永远不会半写）。因此，为了确保 TxE 的写入是原子的，应该使它成为一个 512 字节的块。因此，我们当前更新文件系统的协议如下，3 个阶段中的每一个都标上了名称。优化后的写入步骤 日志写入：将事务的内容（包括TxB、元数据和数据）写入日志，等待这些写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交（committed）。 加检查点：将更新内容（元数据和数据）写入其最终的磁盘位置。恢复利用日志内容从崩溃中恢复（recover）如果崩溃发生在事务被安全地写入日志之前（在上面的步骤 2 完成之前），那么我们的工作很简单：简单地跳过待执行的更新。如果在事务已提交到日志之后但在加检查点完成之前发生崩溃，则文件系统可以按如下方式恢复（recover）更新: 系统引导时，文件系统恢复过程将扫描日志，并查找已提交到磁盘的事务。然后，这些事务被重放（replayed，按顺序），文件系统再次尝试将事务中的块写入它们最终的磁盘位置。称为重做日志（redo logging）批处理日志更新基本协议可能会增加大量额外的磁盘流量。例如，假设我们在同一目录中连续创建两个文件，称为 file1 和 file2。要创建一个文件，必须更新许多磁盘上的结构，至少包括：inode 位图（分配新的 inode），新创建的文件 inode，包含新文件目录条目的父目录的数据块，以及父目录的 inode（现在有一个新的修改时间）。通过日志，我们将所有这些信息逻辑地提交给我们的两个文件创建的日志。因为文件在同一个目录中，我们假设在同一个 inode 块中都有 inode，这意味着如果不小心，我们最终会反复写入这些相同的块。(多个事务要写入相同的块，就会重复)为了解决这个问题，一些文件系统不会一次一个地向磁盘提交每个更新（例如，Linuxext3）。与此不同，可以将所有更新缓冲到全局事务中。在上面的示例中，当创建两个文件时，文件系统只将内存中的 inode 位图、文件的 inode、目录数据和目录 inode 标记为脏，并将它们添加到块列表中，形成当前的事务。当最后应该将这些块写入磁盘时（例如，在超时 5s 之后），会提交包含上述所有更新的单个全局事务。因此，通过缓冲更新，文件系统在许多情况下可以避免对磁盘的过多的写入流量。使日志有限日志的大小有限。如果不断向它添加事务（如下所示），它将很快填满。第一个问题比较简单：日志越大，恢复时间越长，因为恢复过程必须重放日志中的所有事务（按顺序）才能恢复。第二个问题更重要：当日志已满（或接近满）时，不能向磁盘提交进一步的事务，从而使文件系统“不太有用” （即无用）。日志文件系统将日志视为循环数据结构，一遍又一遍地重复使用。 这就是为什么日志有时被称为循环日志（circular log）。一旦事务被加检查点，文件系统应释放它在日志中占用的空间，允许重用日志空间。在日志超级块（journal superblock）中标记日志中最旧和最新的事务:在日志超级块中（不要与主文件系统的超级块混淆），日志系统记录了足够的信息，以了解哪些事务尚未加检查点，从而减少了恢复时间，并允许以循环的方式重新使用日志。 因此，我们在基本协议中添加了另一个步骤: 日志写入：将事务的内容（包括 TxB 和更新内容）写入日志，等待这些写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交（committed）。 加检查点：将更新内容写入其最终的磁盘位置。 释放：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。元数据日志对于每次写入磁盘，我们现在也要先写入日志，从而使写入流量加倍。在写入日志和写入主文件系统之间，存在代价高昂的寻道，这为某些工作负载增加了显著的开销。我们上面描述的日志模式通常称为数据日志（data journaling，如在 Linux ext3 中），因为它记录了所有用户数据（除了文件系统的元数据之外）。一种更简单（也更常见）的日志形式有时称为有序日志（ordered journaling，或称为元数据日志，metadata journaling）:先前写入日志的数据块 Db 将改为直接写入文件系统，避免额外写入。修改确实提出了一个有趣的问题：我们何时应该将数据块写入磁盘？在将相关元数据写入磁盘之前，一些文件系统（例如，Linuxext3）先将数据块（常规文件）写入磁盘。(先写磁盘再写日志，防止元数据指向空数据) 数据写入：将数据写入最终位置，等待完成（等待是可选的，详见下文）。 日志元数据写入：将开始块和元数据写入日志，等待写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，现在认为事务（包括数据）已提交（committed）。 加检查点元数据：将元数据更新的内容写入文件系统中的最终位置。 释放：稍后，在日志超级块中将事务标记为空闲。棘手的情况：块复用块被删除然后重新分配会有问题假设你有一个名为 foo 的目录。用户向 foo 添加一个条目（一个条目，不是添加一个文件，类似一个文件名的字符串加上 inode 号），因此 foo 的内容（因为目录被认为是元数据，所以 D[foo]这个数据也写入日志区的元数据了）被写入日志。假设 foo 目录数据的位置是块 1000。因此日志包含如下内容此时，用户删除目录中的所有内容以及目录本身，从而释放块 1000 以供复用。最后，用户创建了一个新文件（比如 foobar），结果复用了过去属于 foo 的相同块（1000）。foobar 的 inode 提交给磁盘，其数据也是如此。但是，请注意，因为正在使用元数据日志，所以只有 foobar 的 inode 被提交给日志，文件 foobar 中块 1000 中新写入的数据没有写入日志:现在假设发生了崩溃，所有这些信息仍然在日志中。在重放期间，恢复过程简单地重放日志中的所有内容，包括在块 1000 中写入目录数据。因此，重放会用旧目录内容覆盖当前文件 foobar 的用户数据这个问题有一些解决方案。例如，可以永远不再重复使用块，直到所述块的删除加上检查点，从日志中清除。Linux ext3 的做法是将新类型的记录添加到日志中，称为撤销（revoke） 记录。在上面的情况中，删除目录将导致撤销记录被写入日志。在重放日志时，系统首先扫描这样的重新记录。任何此类被撤销的数据都不会被重放，从而避免了上述问题。总结日志：时间线数据日志，就是先写日志区的元数据和数据，写完写 TxE 表示日志写完，再写入文件系统区的元数据和数据元数据日志就是同步写日志区的元数据和文件系统区的数据，都完成后写 TxE 表示日志写入结束，再写文件系统元数据，不用再写数据了解决方案 3：其他方法软更新仔细地对文件系统的所有写入排序，以确保磁盘上的结构永远不会处于不一致的状态。例如，通过先写入指向的数据块，再写入指向它的 inode，可以确保 inode 永远不会指向垃圾。写时复制（Copy-On-Write，COW）这种技术永远不会覆写文件或目录。相反，它会对磁盘上以前未使用的位置进行新的更新。在完成许多更新后，COW 文件系统会翻转文件系统的根结构，以包含指向刚更新结构的指针。这种技术名为基于反向指针的一致性（Backpointer-Based Consistency，BBC）为了实现一致性，系统中的每个块都会添加一个额外的反向指针。例如，每个数据块都引用它所属的 inode。访问文件时，文件系统可以检查正向指针（inode 或直接块中的地址）是否指向引用它的块，从而确定文件是否一致。两个指针双向校验乐观崩溃一致性（optimistic crash consistency）尽可能多地向磁盘发出写入，并利用事务校验和（transaction checksum）的一般形式，以及其他一些技术来检测不一致。对于某些工作负载，这些乐观技术可以将性能提高一个数量级。小结我们介绍了崩溃一致性的问题，并讨论了处理这个问题的各种方法。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(三十四) 崩溃一致性：FSCK和日志(未完成)", "url": "/posts/operating-systems-34/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-17 09:00:00 +0800", "snippet": "文件系统面临的一个主要挑战在于，如何在出现断电（power loss）或系统崩溃（system crash）的情况下，更新持久数据结构。称为崩溃一致性问题（crash-consistency problem）。崩溃一致性问题理想的做法是将文件系统从一个一致状态（在文件被追加之前），原子地（atomically）移动到另一个状态（在 inode、位图和新数据块被写入磁盘之后）。遗憾的是，做到这一点不容易，因为磁盘一次只提交一次写入，而这些更新之间可能会发生崩溃或断电。我们将这个一般问题称为崩溃一致性问题（crash-consistency problem，也可以称为一致性更新问题，consistent-update problem）。解决方案1：文件系统检查程序决定让不一致的事情发生，然后再修复它们（重启时）。fsck 是一个 UNIX 工具，用于查找这些不一致并修复它们以下是 fsck 的基本总结: 超级块：fsck 首先检查超级块是否合理，主要是进行健全性检查，例如确保文件系统大小大于分配的块数。通常，这些健全性检查的目的是找到一个可疑的（冲突的）超级块。在这种情况下，系统（或管理员）可以决定使用超级块的备用副本。 空闲块：接下来，fsck 扫描 inode、间接块、双重间接块等，以了解当前在文件系统中分配的块。它利用这些知识生成正确版本的分配位图。因此，如果位图和 inode之间存在任何不一致，则通过信任 inode 内的信息来解决它。对所有 inode 执行相同类型的检查，确保所有看起来像在用的 inode，都在 inode 位图中有标记。 inode 状态：检查每个 inode 是否存在损坏或其他问题。例如，fsck 确保每个分配的 inode 具有有效的类型字段（即常规文件、目录、符号链接等）。如果 inode 字段存在问题，不易修复，则 inode 被认为是可疑的，并被 fsck 清除，inode 位图相应地更新。 inode 链接：fsck 还会验证每个已分配的 inode 的链接数。你可能还记得，链接计数表示包含此特定文件的引用（即链接）的不同目录的数量。为了验证链接计数，fsck 从根目录开始扫描整个目录树，并为文件系统中的每个文件和目录构建自己的链接计数。如果新计算的计数与 inode 中找到的计数不匹配，则必须采取纠正措施，通常是修复 inode 中的计数。如果发现已分配的 inode 但没有目录引用它，则会将其移动到 lost + found 目录。 重复：fsck 还检查重复指针，即两个不同的 inode 引用同一个块的情况。如果一个inode 明显不好，可能会被清除。或者，可以复制指向的块，从而根据需要为每个inode 提供其自己的副本。 坏块：在扫描所有指针列表时，还会检查坏块指针。如果指针显然指向超出其有效范围的某个指针，则该指针被认为是“坏的”，例如，它的地址指向大于分区大小的块。在这种情况下，fsck 不能做任何太聪明的事情。它只是从 inode 或间接块中删除（清除）该指针。 目录检查：fsck 不了解用户文件的内容。但是，目录包含由文件系统本身创建的特定格式的信息。因此，fsck 对每个目录的内容执行额外的完整性检查，确保“.”和“..”是前面的条目，目录条目中引用的每个 inode 都已分配，并确保整个层次结构中没有目录的引用超过一次。解决方案 2：日志（或预写日志）对于一致更新问题，最流行的解决方案可能是从数据库管理系统的世界中借鉴的一个想法(应该就是数据库中的事务)。这种名为预写日志（write-ahead logging）的想法，是为了解决这类问题而发明的。我们通常将预写日志称为日志（journaling）。基本思路如下。更新磁盘时，在覆写结构之前，首先写下一点小注记（在磁盘上的其他地方，在一个众所周知的位置），描述你将要做的事情。写下这个注记就是“预写”部分， 我们把它写入一个结构，并组织成“日志”。因此，就有了预写日志。通过将注释写入磁盘，可以保证在更新（覆写）正在更新的结构期间发生崩溃时，能够返回并查看你所做的注记，然后重试。因此，你会在崩溃后准确知道要修复的内容（以及如何修复它），而不必扫描整个磁盘。ext2 文件系统（没有日志）:ext3 文件系统: 日志写入：将事务（包括事务开始块，所有即将写入的数据和元数据更新以及事务 结束块）写入日志，等待这些写入完成。 加检查点：将待处理的元数据和数据更新写入文件系统中的最终位置写入日志期间发生崩溃在写入日志期间发生崩溃时，事情变得有点棘手。在这里，我们试图将事务中的这些块（即 TxB、I[v2]、B[v2]、Db、TxE）写入磁盘。一种简单的方法是一次发出 1 个块写入，等待每个完成，然后发出下一个。但是，这很慢。我们希望一次发出所有 5 个块写入，因为这会将 5 个写入转换为单个顺序写入(连续写入)，因此更快。然而，由于以下原因，这是不安全的：给定如此大的写入，磁盘内部可以执行调度并以任何顺序完成大批写入的小块(无法预知写入顺序)。比如，事务开始结束块TxB/TxE都已经写入，但中间的TxB却没写入：为避免该问题，文件系统分两步发出事务写入。首先，它将除 TxE 块之外的所有块写入日志，同时发出这些写入。当这些写入完成时，日志将看起来像这样（假设又是文件追加的工作负载）：当这些写入完成时，文件系统会发出 TxE 块的写入，从而使日志处于最终的安全状态：此过程的一个重要方面是磁盘提供的原子性保证。事实证明，磁盘保证任何 512 字节写入都会发生或不发生（永远不会半写）。因此，为了确保 TxE 的写入是原子的，应该使它成为一个 512 字节的块。因此，我们当前更新文件系统的协议如下，3 个阶段中的每一个都标上了名称。优化后的写入步骤 日志写入：将事务的内容（包括TxB、元数据和数据）写入日志，等待这些写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交（committed）。 加检查点：将更新内容（元数据和数据）写入其最终的磁盘位置。恢复利用日志内容从崩溃中恢复（recover）如果崩溃发生在事务被安全地写入日志之前（在上面的步骤 2 完成之前），那么我们的工作很简单：简单地跳过待执行的更新。如果在事务已提交到日志之后但在加检查点完成之前发生崩溃，则文件系统可以按如下方式恢复（recover）更新: 系统引导时，文件系统恢复过程将扫描日志，并查找已提交到磁盘的事务。然后，这些事务被重放（replayed，按顺序），文件系统再次尝试将事务中的块写入它们最终的磁盘位置。称为重做日志（redo logging）批处理日志更新基本协议可能会增加大量额外的磁盘流量。例如，假设我们在同一目录中连续创建两个文件，称为 file1 和 file2。要创建一个文件，必须更新许多磁盘上的结构，至少包括：inode 位图（分配新的 inode），新创建的文件 inode，包含新文件目录条目的父目录的数据块，以及父目录的 inode（现在有一个新的修改时间）。通过日志，我们将所有这些信息逻辑地提交给我们的两个文件创建的日志。因为文件在同一个目录中，我们假设在同一个 inode 块中都有 inode，这意味着如果不小心，我们最终会反复写入这些相同的块。(多个事务要写入相同的块，就会重复)为了解决这个问题，一些文件系统不会一次一个地向磁盘提交每个更新（例如，Linuxext3）。与此不同，可以将所有更新缓冲到全局事务中。在上面的示例中，当创建两个文件时，文件系统只将内存中的 inode 位图、文件的 inode、目录数据和目录 inode 标记为脏，并将它们添加到块列表中，形成当前的事务。当最后应该将这些块写入磁盘时（例如，在超时 5s 之后），会提交包含上述所有更新的单个全局事务。因此，通过缓冲更新，文件系统在许多情况下可以避免对磁盘的过多的写入流量。使日志有限日志的大小有限。如果不断向它添加事务（如下所示），它将很快填满。第一个问题比较简单：日志越大，恢复时间越长，因为恢复过程必须重放日志中的所有事务（按顺序）才能恢复。第二个问题更重要：当日志已满（或接近满）时，不能向磁盘提交进一步的事务，从而使文件系统“不太有用” （即无用）。日志文件系统将日志视为循环数据结构，一遍又一遍地重复使用。 这就是为什么日志有时被称为循环日志（circular log）。一旦事务被加检查点，文件系统应释放它在日志中占用的空间，允许重用日志空间。在日志超级块（journal superblock）中标记日志中最旧和最新的事务:在日志超级块中（不要与主文件系统的超级块混淆），日志系统记录了足够的信息，以了解哪些事务尚未加检查点，从而减少了恢复时间，并允许以循环的方式重新使用日志。 因此，我们在基本协议中添加了另一个步骤: 日志写入：将事务的内容（包括 TxB 和更新内容）写入日志，等待这些写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，事务被认为已提交（committed）。 加检查点：将更新内容写入其最终的磁盘位置。 释放：一段时间后，通过更新日志超级块，在日志中标记该事务为空闲。元数据日志对于每次写入磁盘，我们现在也要先写入日志，从而使写入流量加倍。在写入日志和写入主文件系统之间，存在代价高昂的寻道，这为某些工作负载增加了显著的开销。我们上面描述的日志模式通常称为数据日志（data journaling，如在 Linux ext3 中），因为它记录了所有用户数据（除了文件系统的元数据之外）。一种更简单（也更常见）的日志形式有时称为有序日志（ordered journaling，或称为元数据日志，metadata journaling）:先前写入日志的数据块 Db 将改为直接写入文件系统，避免额外写入。修改确实提出了一个有趣的问题：我们何时应该将数据块写入磁盘？在将相关元数据写入磁盘之前，一些文件系统（例如，Linuxext3）先将数据块（常规文件）写入磁盘。(先写磁盘再写日志，防止元数据指向空数据) 数据写入：将数据写入最终位置，等待完成（等待是可选的，详见下文）。 日志元数据写入：将开始块和元数据写入日志，等待写入完成。 日志提交：将事务提交块（包括 TxE）写入日志，等待写完成，现在认为事务（包括数据）已提交（committed）。 加检查点元数据：将元数据更新的内容写入文件系统中的最终位置。 释放：稍后，在日志超级块中将事务标记为空闲。棘手的情况：块复用块被删除然后重新分配会有问题假设你有一个名为 foo 的目录。用户向 foo 添加一个条目（一个条目，不是添加一个文件，类似一个文件名的字符串加上 inode 号），因此 foo 的内容（因为目录被认为是元数据，所以 D[foo]这个数据也写入日志区的元数据了）被写入日志。假设 foo 目录数据的位置是块 1000。因此日志包含如下内容此时，用户删除目录中的所有内容以及目录本身，从而释放块 1000 以供复用。最后，用户创建了一个新文件（比如 foobar），结果复用了过去属于 foo 的相同块（1000）。foobar 的 inode 提交给磁盘，其数据也是如此。但是，请注意，因为正在使用元数据日志，所以只有 foobar 的 inode 被提交给日志，文件 foobar 中块 1000 中新写入的数据没有写入日志:现在假设发生了崩溃，所有这些信息仍然在日志中。在重放期间，恢复过程简单地重放日志中的所有内容，包括在块 1000 中写入目录数据。因此，重放会用旧目录内容覆盖当前文件 foobar 的用户数据这个问题有一些解决方案。例如，可以永远不再重复使用块，直到所述块的删除加上检查点，从日志中清除。Linux ext3 的做法是将新类型的记录添加到日志中，称为撤销（revoke） 记录。在上面的情况中，删除目录将导致撤销记录被写入日志。在重放日志时，系统首先扫描这样的重新记录。任何此类被撤销的数据都不会被重放，从而避免了上述问题。总结日志：时间线数据日志，就是先写日志区的元数据和数据，写完写 TxE 表示日志写完，再写入文件系统区的元数据和数据元数据日志就是同步写日志区的元数据和文件系统区的数据，都完成后写 TxE 表示日志写入结束，再写文件系统元数据，不用再写数据了解决方案 3：其他方法软更新仔细地对文件系统的所有写入排序，以确保磁盘上的结构永远不会处于不一致的状态。例如，通过先写入指向的数据块，再写入指向它的 inode，可以确保 inode 永远不会指向垃圾。写时复制（Copy-On-Write，COW）这种技术永远不会覆写文件或目录。相反，它会对磁盘上以前未使用的位置进行新的更新。在完成许多更新后，COW 文件系统会翻转文件系统的根结构，以包含指向刚更新结构的指针。这种技术名为基于反向指针的一致性（Backpointer-Based Consistency，BBC）为了实现一致性，系统中的每个块都会添加一个额外的反向指针。例如，每个数据块都引用它所属的 inode。访问文件时，文件系统可以检查正向指针（inode 或直接块中的地址）是否指向引用它的块，从而确定文件是否一致。两个指针双向校验乐观崩溃一致性（optimistic crash consistency）尽可能多地向磁盘发出写入，并利用事务校验和（transaction checksum）的一般形式，以及其他一些技术来检测不一致。对于某些工作负载，这些乐观技术可以将性能提高一个数量级。小结我们介绍了崩溃一致性的问题，并讨论了处理这个问题的各种方法。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十八) I/O 设备", "url": "/posts/operating-systems-28/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 11:00:00 +0800", "snippet": "系统架构我们先看一个典型系统的架构（见图 36.1）。其中，CPU 通过某种内存总线（memory bus）或互连电缆连接到系统内存。图像或者其他高性能 I/O 设备通过常规的 I/O 总线（I/O bus）连接到系统，在许多现代系统中会是 PCI 或它的衍生形式。最后，更下面是外围总线（peripheral bus），比如 SCSI、SATA 或者 USB。它们将最慢的设备连接到系统，包括磁盘、鼠标及其他类似设备。为什么要用这样的分层架构？简单回答：因为物理布局及造价成本。越快的总线越短，因此高性能的内存总线没有足够的空间连接太多设备。另外，在工程上高性能总线的造价非常高。所以，系统的设计采用了这种分层的方式，这样可以让要求高性能的设备（比如显卡）离 CPU 更近一些，低性能的设备离 CPU 远一些。将磁盘和其他低速设备连到外围总线的好处很多，其中较为突出的好处就是你可以在外围总线上连接大量的设备。标准设备第一部分是向系统其他部分展现的硬件接口（interface）。就是操作外设硬件的各种寄存器实现和外设硬件的交互第二部分是它的内部结构（internal structure）。这部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成它们的工作。标准协议在图 36.2 中，一个（简化的）设备接口包含 3 个寄存器： 一个状态（status）寄存器， 可以读取并查看设备的当前状态； 一个命令（command）寄存器，用于通知设备执行某个具体任务 一个数据（data）寄存器，将数据传给设备或从设备接收数据。操作系统与该设备的典型交互:While (STATUS == BUSY) ; // wait until device is not busy// 数据写入DATA寄存器,如一个4KB的磁盘块Write data to DATA register// 命令写入命令寄存器，如写入磁盘命令Write command to COMMAND register (Doing so starts the device and executes the command)// 轮询是否完成，会阻塞占用系统CPUWhile (STATUS == BUSY) ; // wait until device is done with your request利用中断减少 CPU 开销进程 1 在 CPU 上运行一段时间（对应 CPU 那一行上重复的 1），然后发出一个读取数据的 I/O 请求给磁盘。如果没有中断，那么操作系统就会简单自旋，不断轮询设备状态，直到设备完成 I/O 操作（对应其中的 p）。当设备完成请求的操作后，进程 1 又可以继续运行。在磁盘处理进程 1 的请求时，操作系统在 CPU 上运行进程 2。磁盘处理完成后，触发一个中断，然后操作系统唤醒进程 1 继续运行。这样，在这段时间，无论 CPU 还是磁盘都可以有效地利用。使用中断并非总是最佳方案: 假如有一个非常高性能的设备，它处理请求很快： 通常在 CPU第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢:进程切换和处理中断的代价。可以考虑使用混合（hybrid）策略，先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。 另一个最好不要使用中断的场景是网络。网络端收到大量数据包，如果每一个包都发生一次中断，那么有可能导致操作系统发生活锁（livelock），即不断处理中断而无法处理用户层的请求(高负载场景)，此时轮询更好 另一个基于中断的优化就是合并（coalescing）。设备在抛出中断之前往往会等待一小段时间，在此期间，其他请求可能很快完成，因此多次中断可以合并为一次中断抛出，从而降低处理中断的代价利用 DMA 进行更高效的数据传送c就是写寄存器过程,将数据从内存拷贝到硬件的寄存器。这段时间也占用 CPU，浪费了。解决方案就是使用DMA（Direct Memory Access）。DMA 引擎是系统中的一个特殊设备， 它可以协调完成内存和设备间的数据传递，不需要 CPU 介入。DMA 工作过程如下。为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以处理其他请求了。当 DMA 的任务完成后，DMA 控制器会抛出一个中断来告诉操作系统自己已经完成数据传输。修改后的时间线如下：设备交互的方法 特权指令（privileged） 当需要发送数据给设备时，调用者指定一个存入数据的特定寄存器及一个代表设备的特定端口。执行这个指令就可以实现期望的行为。操作系统是唯一可以直接与设备交互的实体 内存映射 I/O（memory- mapped I/O） 硬件将设备寄存器作为内存地址提供。当需要访问设备寄存器时，操作系统装载（读取）或者存入（写入）到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存。纳入操作系统：设备驱动程序例如文件系统，我们希望开发一个文件系统可以工作在 SCSI 硬盘、IDE 硬盘、USB 钥匙串设备等设备之上，并且希望这个文件系统不那么清楚对这些不同设备发出读写请求的全部细节。 关键问题：如何实现一个设备无关的操作系统 如何保持操作系统的大部分与设备无关，从而对操作系统的主要子系统隐藏设备交互的细节？在最底层，操作系统的一部分软件清楚地知道设备如何工作，我们将这部分软件称为设备驱动程序（device driver），所有设备交互的细节都封装在其中。这种封装也有不足的地方。例如，如果有一个设备可以提供很多特殊的功能， 但为了兼容大多数操作系统它不得不提供一个通用的接口，这样就使得自身的特殊功能无法使用。案例研究：简单的 IDE 磁盘驱动程序IDE 硬盘暴露给操作系统的接口比较简单，包含 4 种类型的寄存器，即控制、命令块、状态和错误。在 x86 上，利用 I/O 指令 in 和 out 向特定的 I/O 地址（如下面的 0x3F6）读取或写入时，可以访问这些寄存器，如下所示：Control Register: Address 0x3F6 = 0x80 (0000 1RE0): R=reset, E=0 means &quot;enable interrupt&quot;Command Block Registers: Address 0x1F0 = Data Port Address 0x1F1 = Error Address 0x1F2 = Sector Count Address 0x1F3 = LBA low byte Address 0x1F4 = LBA mid byte Address 0x1F5 = LBA hi byte Address 0x1F6 = 1B1D TOP4LBA: B=LBA, D=drive Address 0x1F7 = Command/statusStatus Register (Address 0x1F7): 7 6 5 4 3 2 1 0 BUSY READY FAULT SEEK DRQ CORR IDDEX ERRORError Register (Address 0x1F1): (check when Status ERROR==1) 7 6 5 4 3 2 1 0 BBK UNC MC IDNF MCR ABRT T0NF AMNF BBK = Bad Block UNC = Uncorrectable data error MC = Media Changed IDNF = ID mark Not Found MCR = Media Change Requested ABRT = Command aborted T0NF = Track 0 Not Found AMNF = Address Mark Not Found下面是与设备交互的简单协议，假设它已经初始化了，如图 36.5 所示。 等待驱动就绪。读取状态寄存器（0x1F7）直到驱动 READY 而非忙碌。 向命令寄存器写入参数。写入扇区数，待访问扇区对应的逻辑块地址（LBA），并将驱动编号（master=0x00，slave=0x10，因为 IDE 允许接入两个硬盘）写入命令寄存器（0x1F2-0x1F6）。 开启 I/O。发送读写命令到命令寄存器。向命令寄存器（0x1F7）中写入 READ-WRITE 命令。 数据传送（针对写请求）：等待直到驱动状态为 READY 和 DRQ（驱动请求数据），向数据端口写入数据。 中断处理。在最简单的情况下，每个扇区的数据传送结束后都会触发一次中断处理程序。较复杂的方式支持批处理，全部数据传送结束后才会触发一次中断处理。 错误处理。在每次操作之后读取状态寄存器。如果 ERROR 位被置位，可以读取错误寄存器来获取详细信息。xv6 的 IDE 硬盘驱动程序（简化的）：// 在发起请求之前调用，确保驱动处于就绪状态。static int ide_wait_ready() { while (((int r = inb(0x1f7)) &amp;amp; IDE_BSY) || !(r &amp;amp; IDE_DRDY)) ; // loop until drive isn&#39;t busy}// 将请求发送到磁盘（在写请求时，可能是发送数据）。// 此时 x86 的 in 或 out 指令会被调用，// 以读取或写入设备寄存器。static void ide_start_request(struct buf *b) { ide_wait_ready(); outb(0x3f6, 0); // generate interrupt outb(0x1f2, 1); // how many sectors? outb(0x1f3, b-&amp;gt;sector &amp;amp; 0xff); // LBA goes here ... outb(0x1f4, (b-&amp;gt;sector &amp;gt;&amp;gt; 8) &amp;amp; 0xff); // ... and here outb(0x1f5, (b-&amp;gt;sector &amp;gt;&amp;gt; 16) &amp;amp; 0xff); // ... and here! outb(0x1f6, 0xe0 | ((b-&amp;gt;dev&amp;amp;1)&amp;lt;&amp;lt;4) | ((b-&amp;gt;sector&amp;gt;&amp;gt;24)&amp;amp;0x0f)); if(b-&amp;gt;flags &amp;amp; B_DIRTY){ outb(0x1f7, IDE_CMD_WRITE); // this is a WRITE outsl(0x1f0, b-&amp;gt;data, 512/4); // transfer data too! } else { outb(0x1f7, IDE_CMD_READ); // this is a READ (no data) }}// 将一个请求加入队列（如果前面还有请求未处理完成），// 或者直接将请求发送到磁盘（通过 ide_start_request()）void ide_rw(struct buf *b) { acquire(&amp;amp;ide_lock); // 找ide_queue链表第一个空元素，pp赋值为链表的头元素指针，相当于对链表的引用， // *pp表示元素，(*pp)-&amp;gt;qnext表示下一个元素，pp=&amp;amp;(*pp)-&amp;gt;qnext表示指针移向下个元素， // 循环条件是*pp，也就是元素不为空（不是元素指针pp不为空）,由此实现遍历链表中的有效项 for (struct buf **pp = &amp;amp;ide_queue; *pp; pp=&amp;amp;(*pp)-&amp;gt;qnext) ; // walk queue // 元素赋值为b(深拷贝) *pp = b; // add request to end // 当pp是当前头元素时成立 if (ide_queue == b) // if q is empty ide_start_request(b); // send req to disk // 是否不可用或是脏状态 while ((b-&amp;gt;flags &amp;amp; (B_VALID|B_DIRTY)) != B_VALID) sleep(b, &amp;amp;ide_lock); // wait for completion release(&amp;amp;ide_lock);}// 当发生中断时调用，从设备读取数据（如果是读请求）， 并且在结束后唤醒等待的进程，// 如果此时在队列中还有别的未处理的请求，则调用 ide_start_request() 接着处理下一个 I/O 请求。void ide_intr() { struct buf *b; acquire(&amp;amp;ide_lock); if (!(b-&amp;gt;flags &amp;amp; B_DIRTY) &amp;amp;&amp;amp; ide_wait_ready() &amp;gt;= 0) insl(0x1f0, b-&amp;gt;data, 512/4); // if READ: get data b-&amp;gt;flags |= B_VALID; b-&amp;gt;flags &amp;amp;= ˜B_DIRTY; wakeup(b); // wake waiting process if ((ide_queue = b-&amp;gt;qnext) != 0) // start next request ide_start_request(ide_queue); // (if one exists) release(&amp;amp;ide_lock);}小结中断和 DMA，用于提高设备效率。访问设备寄存器的两种方式，I/O 指令和 内存映射 I/O。设备驱动程序的概念，展示了操作系统本身如何封装底层细节，从而更容易以设备无关的方式构建操作系统的其余部分。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十七) 基于事件的并发（进阶）", "url": "/posts/operating-systems-27/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 10:00:00 +0800", "snippet": "基于事件的并发（event-based concurrency），在一些现代系统中较为流行，比如 node.js，但它源自于 C/UNIX 系统，我们下面将讨论。基于事件的并发针对两方面的问题。一方面是多线程应用中，正确处理并发很有难度。 正如我们讨论的，忘加锁、死锁和其他烦人的问题会发生。另一方面，开发者无法控制多线程在某一时刻的调度(由系统调度)。基本想法：事件循环我们使用的基本方法就是基于事件的并发（event-based concurrency）。该方法很简单：我们等待某事（即“事件”）发生；当它发生时，检查事件类型，然后做少量的相应工作（可能是 I/O 请求，或者调度其他事件准备后续处理）。这种应用都是基于一个简单的结构，称为事件循环（event loop）:while (1) { events = getEvents(); for (e in events) processEvent(e);}主循环等待某些事件发生（通过 getEvents()调用），然后依次处理这些发生的事件。处理事件的代码叫作事件处理程序（event handler）。重要的是，处理程序在处理一个事件时，它是系统中发生的唯一活动。因此，调度就是决定接下来处理哪个事件。这种对调度的显式控制，是基于事件方法的一个重要优点。重要 API：select()（或 poll()）如何接收事件?检查是否有任何应该关注的进入 I/O。例如，假定网络应用程序（如 Web 服务器）希望检查是否有网络数据包已到达，以便为它们提供服务。下面以 select()为例，手册页（在 macOS X 上）以这种方式描述 API：int select( int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout);select()检查 I/O 描述符集合，它们的地址通过 readfds、writefds 和 errorfds 参数传入(readfds相当于多个 readfd 组成的数组，writefds 同理)，分别查看它们中的某些描述符是否已准备好读取，是否准备好写入，或有异常情况待处理。在每个集合中检查前 nfds 个描述符，即检查描述符集合中从 0 到 nfds-1 的描述符。返回时，select()用给定请求操作准备好的描述符组成的子集替换给定的描述符集合。select()返回所有集合中就绪描述符的总数。一个 select 调用就能识别所有句柄状态关于 select()有几点要注意。首先，请注意，它可以让你检查描述符是否可以读取和写入。前者让服务器确定新数据包已到达并且需要处理，而后者则让服务知道何时可以回复 （即出站队列未满）。使用 select()#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(void) { // open and set up a bunch of sockets (not own) // main loop while (1) { // initialize the fd_set to all zero fd_set readFDs; FD_ZERO(&amp;amp;readFDs); // now set the bits for the descriptors // this server is interested in // (for simplicity, all of them from min max) int fd; // 将初始化完的句柄都加入到readFDs句柄集合中 for (fd = minFD; fd &amp;lt; maxFD; fd++) FD_SET(fd, &amp;amp;readFDs); // 调用select检测句柄是否可读，可读的句柄作为子集替换readFDs指针内容作为返回值 int rc = select(maxFD+1, &amp;amp;readFDs, NULL,LL, NULL); // check which actually have data using_ISSET() int fd; for (fd = minFD; fd &amp;lt; maxFD; fd++) // 检测在readFDs中存在句柄 if (FD_ISSET(fd, &amp;amp;readFDs)) // 处理对应的句柄 processFD(fd); }}为何更简单？无须锁因为一次只处理一个事件，所以不需要获取或释放锁。基于事件的服务器不能被另一个线程中断，因为它确实是单线程的。因此，线程化程序中常见的并发性错误并没有出现在基本的基于事件的方法中。一个问题：阻塞系统调用在多线程框架下，一个线程因 IO 阻塞，其他线程也能执行。而因为事件系统本质是单线程，会导致整个线程阻塞。我们在基于事件的系统中必须遵守一条规则：不允许阻塞调用。解决方案：异步 I/O异步 I/O（asynchronous I/O）。这些接口使应用程序能够发出 I/O 请求，并在 I/O 完成之前立即将控制权返回给调用者，另外的接口让应用程序能够确定各种 I/O 是否已完成。macOS X 上提供的接口（其他系统有类似的 API）。这些 API 围绕着一个基本的结构，即 struct aiocb 或 AIO 控制块（AIO control block）。该结构的简化版本如下:struct aiocb { int aio_fildes; /* 文件描述符File descriptor */ off_t aio_offset; /* 文件内的偏移量File offset */ volatile void *aio_buf; /* 读取结果的目标内存位置Location of buffer */ size_t aio_nbytes; /* 长度Length of transfer */};异步读取（asynchronous read）API:int aio_read(struct aiocb *aiocbp);检查 I/O 是否完成，并且缓冲区（由 aio_buf 指向）现在是否有了请求的数据，可以通过轮询调用检查:int aio_error(const struct aiocb *aiocbp);一些系统提供了基于中断（interrupt）的方法。此方法使用 UNIX信号（signal）在异步 I/O 完成时通知应用程序，从而消除了重复询问系统的需要。另一个问题：状态管理当事件处理程序发出异步 I/O 时，它必须打包一些程序状态，以便下一个事件处理程序在 I/O 最终完成时使用。这个额外的工作在基于线程的程序中是不需要的，因为程序需要的状态在线程栈中。基于事件的系统的手工栈管理（manual stack management），这是基于事件编程的基础例子：int rc = read(fd, buffer, size);rc = write(sd, buffer, size);在一个多线程程序中，做这种工作很容易。当 read()最终返回时，代码立即知道要写入哪个套接字，因为该信息位于线程堆栈中（在变量 sd 中）。在基于事件的系统中，为了执行相同的任务，我们首先使用上面描述的 AIO 调用异步地发出读取。假设我们使用 aio_error()调用定期检查读取的完成情况。当该调用告诉我们读取完成时，基于事件的服务器如何知道该怎么做？使用一种称为“延续（continuation）”的老编程语言结构。在某些数据结构中，记录完成处理该事件需要的信息。当事件发生时（即磁盘 I/O 完成时），查找所需信息并处理事件。在这个特定例子中，解决方案是将套接字描述符（sd）记录在由文件描述符（fd）索引的某种数据结构（例如，散列表）中。当磁盘 I/O 完成时，事件处理程序将使用文件描述符来查找延续，这会将套接字描述符的值返回给调用者。此时（最后），服务器可以完成最后的工作将数据写入套接字。什么事情仍然很难当系统从单个 CPU 转向多个 CPU 时，基于事件的方法的一些简单性就消失了。它不能很好地与某些类型的系统活动集成，如分页（paging）。例如，如果事件处理程序发生页错误，它将被阻塞(隐式阻塞，无法规避)，并且因此服务器在页错误完成之前不会有进展。阻塞对于基于事件的服务器而言是灾难性的，因此程序员必须始终注意每个事件使用的 API 语义的这种变化。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十六) 常见并发问题", "url": "/posts/operating-systems-26/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 09:04:00 +0800", "snippet": "有哪些类型的缺陷非死锁缺陷违反原子性缺陷违反了多次内存访问中预期的可串行性（即代码段本意是原子的，但在执行中并没有强制实现原子性）Thread 1:: // 判断和赋值应该是原子性的 if (thd-&amp;gt;proc_info) { ... fputs(thd-&amp;gt;proc_info, ...); ... }Thread 2:: thd-&amp;gt;proc_info = NULL;通过加锁解决违反顺序缺陷两个内存访问的预期顺序被打破了（即 A 应该在 B 之前执行，但是实际运行中却不是这个顺序）Thread 1:: void init() { ... mThread = PR_CreateThread(mMain, ...); ... }Thread 2:: void mMain(...) { ... mState = mThread-&amp;gt;State; ... }如果 mState = mThread-&amp;gt;State 语句先执行，则 mThread 为空。通过加条件变量(或信号量)解决死锁缺陷死锁：Thread 1:lock(L1);lock(L2);Thread 2:lock(L2);lock(L1);为什么发生死锁 复杂的依赖 以操作系统为例。虚拟内存系统依赖文件系统才能从磁盘读到内存页；文件系统依赖虚拟内存系统申请一页内存，以便存放读到的块。 封装 软件开发者一直倾向于隐藏实现细节，以模块化的方式让软件开发更容易。然而，模块化和锁不是很契合 以 Java 的 Vector 类和 AddAll()方法为例，我们这样调用这个方法： Vector v1, v2;v1.AddAll(v2); 在内部，这个方法需要多线程安全，因此针对被添加向量（v1）和参数（v2）的锁都需要获取。假设这个方法，先给 v1 加锁，然后再给 v2 加锁。如果另外某个线程几乎同时在调用 v2.AddAll(v1)，就可能遇到死锁。 产生死锁的条件 互斥：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）。 持有并等待：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）。 非抢占：线程获得的资源（例如锁），不能被抢占。 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的预防死锁循环等待最直接的方法就是获取锁时提供一个全序（total ordering）(不同线程申请锁的顺序相同)。假如系统共有两个锁（L1 和 L2），那么我们每次都先申请 L1 然后申请 L2，就可以避免死锁。这样严格的顺序避免了循环等待，也就不会产生死锁。更复杂的系统中不会只有两个锁，锁的全序可能很难做到。偏序（partial ordering）:安排锁的获取顺序并避免死锁。 提示：通过锁的地址来强制锁的顺序 当一个函数要抢多个锁时，我们需要注意死锁。比如有一个函数：do_something(mutex_t *m1, mutex_t *m2)，如果函数总是先抢 m1，然后 m2，那么当一个线程调用 do_something(L1, L2)，而另一个线程调用 do_something(L2, L1)时，就可能会产生死锁。 为了避免这种特殊问题，聪明的程序员根据锁的地址作为获取锁的顺序。按照地址从高到低，或者从低到高的顺序加锁，do_something()函数就可以保证不论传入参数是什么顺序，函数都会用固定的顺序加锁。具体的代码如下：if (m1 &amp;gt; m2) { // grab locks in high-to-low address order pthread_mutex_lock(m1); pthread_mutex_lock(m2);} else { pthread_mutex_lock(m2); pthread_mutex_lock(m1);}// Code assumes that m1 != m2 (it is not the same lock) 在获取多个锁时，通过简单的技巧，就可以确保简单有效的无死锁实现。持有并等待将多个抢锁步骤也作为原子操作lock(prevention);lock(L1);lock(L2);...unlock(prevention);将 L1 和 L2 抢锁过程使用 prevention 锁合并为一个原子操作。这样可以保证线程持有其中任意一个锁时其他锁也不会被其他线程占用(无需等待其他线程释放)。但这么做可能会影响性能。非抢占解决非抢占就是要让线程能占用其他线程没在用的锁，不能占着茅坑不拉屎。主动去占用其他线程已经占用的锁不可能实现，需要让线程能认识到自己占着锁也没用，找机会主动释放一次top: lock(L1); if (trylock(L2) == -1) { unlock(L1); goto top;}假设线程要同时拥有 L1 和 L2 才能继续，获得 L1 后尝试获取 L2，如果失败就解锁 L1，重新开始。需要加一定的随机延迟，防止活锁（livelock）（双方都不停放弃锁）。类似于数据库中的事务和回滚互斥Herlihy 提出了设计各种无等待（wait-free）数据结构的思想，通过强大的硬件指令，我们可以构造出不需要锁的数据结构。*address 的值等于 expected 值时，将其赋值为 new，这是个硬件提供的原子操作–比较并交换（compare-and-swap）指令：int CompareAndSwap(int *address, int expected, int new){ if (*address == expected) { *address = new; return 1; // success } return 0; // failure}假定我们想原子地给某个值增加特定的数量:void AtomicIncrement(int *value, int amount){ do { int old = *value; } while (CompareAndSwap(value, old, old + amount) == 0); /** 无同步操作 int old = *value; *value = old + amount; */}一个更复杂的例子：链表插入。这是在链表头部插入元素的代码：void insert(int value){ node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-&amp;gt;value = value; n-&amp;gt;next = head; head = n;}通过加锁解决同步：void insert(int value){ node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-&amp;gt;value = value; lock(listlock); // begin critical section n-&amp;gt;next = head; head = n; unlock(listlock); // end of critical section}用比较并交换指令（compare-and-swap)来实现插入操作:void insert(int value){ node_t *n = malloc(sizeof(node_t)); assert(n != NULL); n-&amp;gt;value = value; do { n-&amp;gt;next = head; } while (CompareAndSwap(&amp;amp;head, n-&amp;gt;next, n) == 0);}这段代码，首先把 next 指针指向当前的链表头（head），然后试着把新节点交换到链表头。但是，如果此时其他的线程成功地修改了 head 的值，这里的交换就会失败，导致这个线程根据新的 head 值重试。通过调度避免死锁只要 T1 和 T2 (需要同一个锁的线程)不同时运行，就不会产生死锁。但这样就失去了并发性检查和恢复最后一种常用的策略就是允许死锁偶尔发生，检查到死锁时再采取行动。 提示：不要总是完美（TOM WEST 定律） Tom West 是经典的计算机行业小说《Soul of a New Machine》的主人公，有一句很棒的工程格言：“不是所有值得做的事情都值得做好”。如果坏事很少发生，并且造成的影响很小，那么我们不应该去花费大量的精力去预防它。当然，如果你在制造航天飞机，事故会导致航天飞机爆炸，那么你应该忽略这个建议。很多数据库系统使用了死锁检测和恢复技术。死锁检测器会定期运行，通过构建资源图来检查循环。当循环（死锁）发生时，系统需要重启。如果还需要更复杂的数据结构相关的修复，那么需要人工参与。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十五) 信号量", "url": "/posts/operating-systems-25/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 09:03:00 +0800", "snippet": "可以使用信号量实现锁和条件变量的功能。信号量的定义信号量是有一个整数值的对象，可以用两个函数来操作它。在 POSIX 标准中，是sem_wait()和 sem_post()。#include &amp;lt;semaphore.h&amp;gt;sem_t s;sem_init(&amp;amp;s, 0, 1);sem_init 用于初始化信号量。int sem_wait(sem_t *s) { decrement the value of semaphore s by one wait if value of semaphore s is negative}int sem_post(sem_t *s) { increment the value of semaphore s by one if there are one or more threads waiting, wake one} sem_wait()要么立刻返回（调用 sem_wait()时，信号量的值大于等于 1），同时信号量减1，要么会让调用线程挂起，直到之后的一个 post 操作。 sem_post()并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，唤醒其中一个。 当信号量的值为负数时，这个值就是等待线程的个数二值信号量（锁）用信号量作为锁sem_t m;// 初值要为1sem_init(&amp;amp;m, 0, 1);sem_wait(&amp;amp;m);// critical section heresem_post(&amp;amp;m);信号量用作条件变量假设一个线程创建另外一线程，并且等待它结束:sem_t s;void *child(void *arg){ printf(&quot;child\\n&quot;); sem_post(&amp;amp;s); // signal here: child is done return NULL;}int main(int argc, char *argv[]){ // X初始值应是0 sem_init(&amp;amp;s, 0, X); // what should X be? printf(&quot;parent: begin\\n&quot;); pthread_t c; Pthread_create(c, NULL, child, NULL); sem_wait(&amp;amp;s); // wait here for child printf(&quot;parent: end\\n&quot;); return 0;}生产者/消费者（有界缓冲区）问题sem_t empty;sem_t full;sem_t mutex;void *producer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { // empty/full是一个条件变量，用于唤醒和等待 // 不过可以自动形成等待队列，比条件变量方便 sem_wait(&amp;amp;empty); // line p1 // mutex是一个锁，用于商品队列的操作的保护 // 锁的作用域很重要，尽可能缩小临界区来避免死锁和提高性能 sem_wait(&amp;amp;mutex); // line p1.5 (MOVED MUTEX HERE...) put(i); // line p2 sem_post(&amp;amp;mutex); // line p2.5 (... AND HERE) sem_post(&amp;amp;full); // line p3 }}void *consumer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { sem_wait(&amp;amp;full); // line c1 sem_wait(&amp;amp;mutex); // line c1.5 (MOVED MUTEX HERE...) int tmp = get(); // line c2 sem_post(&amp;amp;mutex); // line c2.5 (... AND HERE) sem_post(&amp;amp;empty); // line c3 printf(&quot;%d\\n&quot;, tmp); }}int main(int argc, char *argv[]){ // ... sem_init(&amp;amp;empty, 0, MAX); // MAX buffers are empty to begin with... sem_init(&amp;amp;full, 0, 0); // ... and 0 are full sem_init(&amp;amp;mutex, 0, 1); // mutex=1 because it is a lock // ...}读者—写者锁读者之间不互斥，写者之间互斥，读者和写者互斥：typedef struct _rwlock_t{ sem_t lock; // binary semaphore (basic lock) sem_t writelock; // used to allow ONE writer or MANY readers int readers; // count of readers reading in critical section} rwlock_t;void rwlock_init(rwlock_t *rw){ rw-&amp;gt;readers = 0; sem_init(&amp;amp;rw-&amp;gt;lock, 0, 1); sem_init(&amp;amp;rw-&amp;gt;writelock, 0, 1);}void rwlock_acquire_readlock(rwlock_t *rw){ // lock锁保护readers计数器 sem_wait(&amp;amp;rw-&amp;gt;lock); rw-&amp;gt;readers++; // 第一个读者需要获取写锁，来与写者互斥 // 不停有新读者进来会导致写者饿死 if (rw-&amp;gt;readers == 1) sem_wait(&amp;amp;rw-&amp;gt;writelock); // first reader acquires writelock sem_post(&amp;amp;rw-&amp;gt;lock);}void rwlock_release_readlock(rwlock_t *rw){ sem_wait(&amp;amp;rw-&amp;gt;lock); rw-&amp;gt;readers--; // 最后一个读者需要释放写锁 if (rw-&amp;gt;readers == 0) sem_post(&amp;amp;rw-&amp;gt;writelock); // last reader releases writelock sem_post(&amp;amp;rw-&amp;gt;lock);}void rwlock_acquire_writelock(rwlock_t *rw){ // 写者之间互斥，且与读者互斥，用写锁管理 sem_wait(&amp;amp;rw-&amp;gt;writelock);}void rwlock_release_writelock(rwlock_t *rw){ sem_post(&amp;amp;rw-&amp;gt;writelock);}哲学家就餐问题假定有 5 位“哲学家”围着一个圆桌。每两位哲学家之间有一把餐叉（一共 5 把）。哲学家有时要思考一会，不需要餐叉；有时又要就餐。而一位哲学家只有同时拿到了左手边和右手边的两把餐叉，才能吃到东西。while (1) { think(); getforks(); eat(); putforks();}关键的挑战就是如何实现 getforks()和 putforks()函数，保证没有死锁，没有哲学家饿死，并且并发度更高（尽可能让更多哲学家同时吃东西）。查找餐叉的函数：int left(int p) { return p; }int right(int p) { return (p + 1) % 5; }为每个餐叉分配信号量：sem_t forks[5]尝试加锁：void getforks() { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]);}void putforks() { sem_post(forks[left(p)]); sem_post(forks[right(p)]);}使用这个方案会形成死锁，每个人都拿着左手边的叉子就无法继续了（循环等待）优化方案：选第 4 个人改为先获取右手的叉子，打破循环等待void getforks(){ if (p == 4) { sem_wait(forks[right(p)]); sem_wait(forks[left(p)]); } else { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); }} 还有其他一些类似的“著名”问题，比如吸烟者问题（cigarette smoker’s problem），理发师问题（sleeping barber problem）。如何实现信号量typedef struct _Zem_t{ int value; pthread_cond_t cond; // 对value的修改锁 pthread_mutex_t lock;} Zem_t;// only one thread can call thisvoid Zem_init(Zem_t *s, int value){ s-&amp;gt;value = value; Cond_init(&amp;amp;s-&amp;gt;cond); Mutex_init(&amp;amp;s-&amp;gt;lock);}void Zem_wait(Zem_t *s){ Mutex_lock(&amp;amp;s-&amp;gt;lock); while (s-&amp;gt;value &amp;lt;= 0) Cond_wait(&amp;amp;s-&amp;gt;cond, &amp;amp;s-&amp;gt;lock); // 在这里递减value，value值就不会小于0了。 s-&amp;gt;value--; Mutex_unlock(&amp;amp;s-&amp;gt;lock);}void Zem_post(Zem_t *s){ Mutex_lock(&amp;amp;s-&amp;gt;lock); s-&amp;gt;value++; Cond_signal(&amp;amp;s-&amp;gt;cond); Mutex_unlock(&amp;amp;s-&amp;gt;lock);}小结信号量是编写并发程序的强大而灵活的原语。有程序员会因为简单实用，只用信号量，不用锁和条件变量信号量基于锁和条件变量，可以实现两者的功能作为锁时，可以自动管理等待队列作为条件变量时，免去了 while 判断是否需要等待的操作，因为内部包含了一个 value 值用于判断参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十四) 条件变量", "url": "/posts/operating-systems-24/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 09:02:00 +0800", "snippet": "锁并不是并发程序设计所需的唯一原语。在很多情况下，线程需要检查某一条件（condition）满足之后，才会继续运行。void *child(void *arg){ printf(&quot;child\\n&quot;); // XXX how to indicate we are done? // 自旋锁标记 done = 1; return NULL;}int main(int argc, char *argv[]){ printf(&quot;parent: begin\\n&quot;); pthread_t c; Pthread_create(&amp;amp;c, NULL, child, NULL); // create child // XXX how to wait for child? // 加个自旋锁等待done为1 while (done == 0) ; // spin printf(&quot;parent: end\\n&quot;); return 0;}要父线程等待子线程的话，需要加个自旋锁定义和程序线程可以使用条件变量（condition variable），来等待一个条件变成真。条件变量是一个显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等待（waiting）该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。声明：pthread_cond_t c相关操作：wait()和 signal()父线程等待子线程–使用条件变量:pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);pthread_cond_signal(pthread_cond_t *c);int done = 0;pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;pthread_cond_t c = PTHREAD_COND_INITIALIZER;void thr_exit(){ Pthread_mutex_lock(&amp;amp;m); done = 1; // 如果有等待的线程，就唤醒它(们) Pthread_cond_signal(&amp;amp;c); Pthread_mutex_unlock(&amp;amp;m);}void *child(void *arg){ printf(&quot;child\\n&quot;); thr_exit(); return NULL;}void thr_join(){ Pthread_mutex_lock(&amp;amp;m); // 这里先判断done防止done为1时永久休眠 while (done == 0) // 休眠，等待被唤醒 Pthread_cond_wait(&amp;amp;c, &amp;amp;m); Pthread_mutex_unlock(&amp;amp;m);}int main(int argc, char *argv[]){ printf(&quot;parent: begin\\n&quot;); pthread_t p; Pthread_create(&amp;amp;p, NULL, child, NULL); thr_join(); printf(&quot;parent: end\\n&quot;); return 0;}wait()调用有一个参数，它是互斥量。它假定在 wait()调用时，这个互斥量是已上锁状态。wait()的职责是释放锁，并让调用线程休眠（原子地）。当线程被唤醒时（在另外某个线程发信号给它后），它必须重新获取锁，再返回调用者。 提示：发信号时总是持有锁 尽管并不是所有情况下都严格需要，但有效且简单的做法，还是在使用条件变量发送信号时持有锁。虽然上面的例子是必须加锁的情况，但也有一些情况可以不加锁，而这可能是你应该避免的。因此，为了简单，请在调用 signal 时持有锁（hold the lock when calling signal）。 这个提示的反面，即调用 wait 时持有锁，不只是建议，而是 wait 的语义强制要求的。因为 wait 调用总是假设你调用它时已经持有锁、调用者睡眠之前会释放锁以及返回前重新持有锁。因此，这个提示的一般化形式是正确的：调用 signal 和 wait 时要持有锁（hold the lock when calling signal or wait），你会保持身心健康的。生产者/消费者（有界缓冲区）问题cond_t cond;mutex_t mutex;void *producer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { Pthread_mutex_lock(&amp;amp;mutex); // p1 if (count == 1) // p2 Pthread_cond_wait(&amp;amp;cond, &amp;amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;amp;cond); // p5 Pthread_mutex_unlock(&amp;amp;mutex); // p6 }}void *consumer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { Pthread_mutex_lock(&amp;amp;mutex); // c1 // 1. 此处存在问题，当有两个消费者（Cus1,Cus2）时，其中Cus1进入休眠， // Cus2正好在生产者生产后执行get把count消费掉，此时 // 生产者又调用signal唤醒Cus1休眠的，直接执行了get发现 // 没有count了,所以要把if改成while，wait出来还要再 // 判断一次count // 2. 使用while带来另一个问题，Cus1消费后本该唤醒生产者， // 但如果唤醒了Cus2线程，因为没东西消费，Cus2也会等待， // 就会导致三个线程都在等待中。解决方法是设置两个条件变量， // 保证消费者唤醒生产者，生产者唤醒消费者 if (count == 0) // c2 Pthread_cond_wait(&amp;amp;cond, &amp;amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;amp;cond); // c5 Pthread_mutex_unlock(&amp;amp;mutex); // c6 printf(&quot;%d\\n&quot;, tmp); }} 一条关于条件变量的简单规则：总是使用 while 循环（always use while loop）。最终代码：int buffer[MAX];int fill = 0;int use = 0;int count = 0;void put(int value){ buffer[fill] = value; fill = (fill + 1) % MAX; count++;}int get(){ int tmp = buffer[use]; use = (use + 1) % MAX; count--; return tmp;}cond_t empty, fill;mutex_t mutex;void *producer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { Pthread_mutex_lock(&amp;amp;mutex); // p1 while (count == MAX) // p2 Pthread_cond_wait(&amp;amp;empty, &amp;amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;amp;fill); // p5 Pthread_mutex_unlock(&amp;amp;mutex); // p6 }}void *consumer(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { Pthread_mutex_lock(&amp;amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(&amp;amp;fill, &amp;amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;amp;empty); // c5 Pthread_mutex_unlock(&amp;amp;mutex); // c6 printf(&quot;%d\\n&quot;, tmp); }}覆盖条件以下代码用于内存分配管理，free 后会唤醒 allocate 时因空间不够而等待的线程// how many bytes of the heap are free?int bytesLeft = MAX_HEAP_SIZE;// need lock and condition toocond_t c;mutex_t m;void *allocate(int size){ Pthread_mutex_lock(&amp;amp;m); while (bytesLeft &amp;lt; size) Pthread_cond_wait(&amp;amp;c, &amp;amp;m); void *ptr = ...; // get mem from heap bytesLeft -= size; Pthread_mutex_unlock(&amp;amp;m); return ptr;}void free(void *ptr, int size){ Pthread_mutex_lock(&amp;amp;m); bytesLeft += size; Pthread_cond_signal(&amp;amp;c); // whom to signal?? Pthread_mutex_unlock(&amp;amp;m);}但 pthread_cond_signal()无法得知应该唤醒哪个线程，比如 free(50)后应该唤醒 allocate(10)等待线程而不是 allocate(100)等待线程。使用 pthread_cond_broadcast()唤醒所有等待的线程。这样做，确保了所有应该唤醒的线程都被唤醒。当然，不利的一面是可能会影响性能。Lampson 和 Redell 把这种条件变量叫作覆盖条件（covering condition），因为它能覆盖所有需要唤醒线程的场景（保守策略）参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十三) 基于锁的并发数据结构", "url": "/posts/operating-systems-23/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 09:01:00 +0800", "snippet": "并发计数器// 简单的计数器，value值递增typedef struct counter_t{ int value;} counter_t;void init(counter_t *c){ c-&amp;gt;value = 0;}void increment(counter_t *c){ c-&amp;gt;value++;}void decrement(counter_t *c){ c-&amp;gt;value--;}int get(counter_t *c){ return c-&amp;gt;value;}简单但无法扩展的实现typedef struct counter_t{ int value; pthread_mutex_t lock;} counter_t;void init(counter_t *c){ c-&amp;gt;value = 0; Pthread_mutex_init(&amp;amp;c-&amp;gt;lock, NULL);}void increment(counter_t *c){ Pthread_mutex_lock(&amp;amp;c-&amp;gt;lock); c-&amp;gt;value++; Pthread_mutex_unlock(&amp;amp;c-&amp;gt;lock);}void decrement(counter_t *c){ Pthread_mutex_lock(&amp;amp;c-&amp;gt;lock); c-&amp;gt;value--; Pthread_mutex_unlock(&amp;amp;c-&amp;gt;lock);}int get(counter_t *c){ Pthread_mutex_lock(&amp;amp;c-&amp;gt;lock); int rc = c-&amp;gt;value; Pthread_mutex_unlock(&amp;amp;c-&amp;gt;lock); return rc;}这样做在多CPU环境下性能很差。因为这种锁导致了多 CPU 情况下也只允许一个线程在运行，其他都在自旋等待，没发挥出多 CPU 的优势。可扩展的计数（扩展的意思是支持多 CPU）懒惰计数器（sloppy counter）懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个 CPU 核心有一个局部计数器。具体来说，在 4 个 CPU 的机器上，有 4 个局部计数器和 1 个全局计数器。除了这些计数器，还有锁：每个局部计数器有一个锁，全局计数器有一个。懒惰计数器的基本思想是这样的。如果一个核心上的线程想增加计数器，那就增加它的局部计数器，访问这个局部计数器是通过对应的局部锁同步的。因为每个 CPU 有自己的局部计数器，不同 CPU 上的线程不会竞争，所以计数器的更新操作可扩展性好。为了保持全局计数器更新（以防某个线程要读取该值），局部值会定期转移给全局计数器，方法是获取全局锁，让全局计数器加上局部计数器的值，然后将局部计数器置零局部转全局的频度，取决于一个阈值，这里称为 S（表示 sloppiness）。S 越小，懒惰计数器则越趋近于非扩展的计数器。S 越大，扩展性越强，但是全局计数器与实际计数的偏差越大。在这个例子中，阈值 S 设置为 5，4 个 CPU 上分别有一个线程更新局部计数器 L1,…, L4。随着时间增加，全局计数器 G 的值也会记录下来。每一段时间，局部计数器可能会增加。如果局部计数值增加到阈值 S，就把局部值转移到全局计数器，局部计数器清零。 时间 L1 L2 L3 L4 G 0 0 0 0 0 0 1 0 0 1 1 0 2 1 0 2 1 0 3 2 0 3 1 0 4 3 0 3 2 0 5 4 1 3 3 0 6 5→0 1 3 4 5（来自 L1） 7 0 2 4 5→0 10（来自 L4） typedef struct counter_t{ int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // local count (per cpu) pthread_mutex_t llock[NUMCPUS]; // ... and locks int threshold; // update frequency} counter_t;// init: record threshold, init locks, init values// of all local counts and global countvoid init(counter_t *c, int threshold){ c-&amp;gt;threshold = threshold; c-&amp;gt;global = 0; pthread_mutex_init(&amp;amp;c-&amp;gt;glock, NULL); int i; for (i = 0; i &amp;lt; NUMCPUS; i++) { c-&amp;gt;local[i] = 0; pthread_mutex_init(&amp;amp;c-&amp;gt;llock[i], NULL); }}// update: usually, just grab local lock and update local amount// once local count has risen by &#39;threshold&#39;, grab global// lock and transfer local values to itvoid update(counter_t *c, int threadID, int amt){ pthread_mutex_lock(&amp;amp;c-&amp;gt;llock[threadID]); c-&amp;gt;local[threadID] += amt; // assumes amt &amp;gt; 0 if (c-&amp;gt;local[threadID] &amp;gt;= c-&amp;gt;threshold) { // transfer to global pthread_mutex_lock(&amp;amp;c-&amp;gt;glock); c-&amp;gt;global += c-&amp;gt;local[threadID]; pthread_mutex_unlock(&amp;amp;c-&amp;gt;glock); c-&amp;gt;local[threadID] = 0; } pthread_mutex_unlock(&amp;amp;c-&amp;gt;llock[threadID]);}// get: just return global amount (which may not be perfect)int get(counter_t *c){ pthread_mutex_lock(&amp;amp;c-&amp;gt;glock); int val = c-&amp;gt;global; pthread_mutex_unlock(&amp;amp;c-&amp;gt;glock); return val; // only approximate!}并发链表// basic node structuretypedef struct node_t{ int key; struct node_t *next;} node_t;// basic list structure (one used per list)typedef struct list_t{ node_t *head; pthread_mutex_t lock;} list_t;void List_Init(list_t *L){ L-&amp;gt;head = NULL; pthread_mutex_init(&amp;amp;L-&amp;gt;lock, NULL);}int List_Insert(list_t *L, int key){ pthread_mutex_lock(&amp;amp;L-&amp;gt;lock); node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(&quot;malloc&quot;); pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock); return -1; // fail } new-&amp;gt;key = key; new-&amp;gt;next = L-&amp;gt;head; L-&amp;gt;head = new; pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock); return 0; // success}int List_Lookup(list_t *L, int key){ pthread_mutex_lock(&amp;amp;L-&amp;gt;lock); node_t *curr = L-&amp;gt;head; while (curr) { if (curr-&amp;gt;key == key) { pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock); return 0; // success } curr = curr-&amp;gt;next; } pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock); return -1; // failure}从代码中可以看出，代码插入函数入口处获取锁，结束时释放锁。如果 malloc 失败（在极少的时候），会有一点小问题，在这种情况下，代码在插入失败之前，必须释放锁。我们调整代码，让获取锁和释放锁只环绕插入代码的真正临界区(缩小临界区)。前面的方法有效是因为部分工作实际上不需要锁，假定 malloc()是线程安全的，每个线程都可以调用它，不需要担心竞争条件和其他并发缺陷。只有在更新共享列表时需要持有锁。下面展示了这些修改的细节。void List_Init(list_t *L){ L-&amp;gt;head = NULL; pthread_mutex_init(&amp;amp;L-&amp;gt;lock, NULL);}void List_Insert(list_t *L, int key){ // synchronization not needed node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(&quot;malloc&quot;); return; } new-&amp;gt;key = key; // just lock critical section pthread_mutex_lock(&amp;amp;L-&amp;gt;lock); new-&amp;gt;next = L-&amp;gt;head; L-&amp;gt;head = new; pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock);}int List_Lookup(list_t *L, int key){ int rv = -1; pthread_mutex_lock(&amp;amp;L-&amp;gt;lock); node_t *curr = L-&amp;gt;head; while (curr) { if (curr-&amp;gt;key == key) { rv = 0; break; } curr = curr-&amp;gt;next; } pthread_mutex_unlock(&amp;amp;L-&amp;gt;lock); return rv; // now both success and failure}扩展链表手锁（hand-over-hand locking，也叫作锁耦合，lock coupling）每个节点都有一个锁，替代之前整个链表一个锁。遍历链表的时候，首先抢占下一个节点的锁，然后释放当前节点的锁。这样多个线程可以独立访问不同的区域，减少冲突。它增加了链表操作的并发程度。但是实际上，在遍历的时候，每个节点获取锁、释放锁的开销巨大，很难比单锁的方法快。并发队列Michael 和 Scott 的并发队列:typedef struct __node_t{ int value; struct __node_t *next;} node_t;typedef struct queue_t{ node_t *head; node_t *tail; pthread_mutex_t headLock; pthread_mutex_t tailLock;} queue_t;void Queue_Init(queue_t *q){ // tmp是假节点 node_t *tmp = malloc(sizeof(node_t)); tmp-&amp;gt;next = NULL; q-&amp;gt;head = q-&amp;gt;tail = tmp; pthread_mutex_init(&amp;amp;q-&amp;gt;headLock, NULL); pthread_mutex_init(&amp;amp;q-&amp;gt;tailLock, NULL);}void Queue_Enqueue(queue_t *q, int value){ node_t *tmp = malloc(sizeof(node_t)); assert(tmp != NULL); tmp-&amp;gt;value = value; tmp-&amp;gt;next = NULL; pthread_mutex_lock(&amp;amp;q-&amp;gt;tailLock); q-&amp;gt;tail-&amp;gt;next = tmp; q-&amp;gt;tail = tmp; pthread_mutex_unlock(&amp;amp;q-&amp;gt;tailLock);}int Queue_Dequeue(queue_t *q, int *value){ pthread_mutex_lock(&amp;amp;q-&amp;gt;headLock); node_t *tmp = q-&amp;gt;head; node_t *newHead = tmp-&amp;gt;next; // 如果是假节点，则视为空 if (newHead == NULL) { pthread_mutex_unlock(&amp;amp;q-&amp;gt;headLock); return -1; // queue was empty } *value = newHead-&amp;gt;value; q-&amp;gt;head = newHead; pthread_mutex_unlock(&amp;amp;q-&amp;gt;headLock); free(tmp); return 0;}有两个锁，一个负责队列头，另一个负责队列尾。这两个锁使得入队列操作和出队列操作可以并发执行，因为入队列只访问 tail 锁，而出队列只访问 head 锁。并发散列表#define BUCKETS (101)typedef struct hash_t{ list_t lists[BUCKETS];} hash_t;void Hash_Init(hash_t *H){ int i; for (i = 0; i &amp;lt; BUCKETS; i++) { List_Init(&amp;amp;H-&amp;gt;lists[i]); }}int Hash_Insert(hash_t *H, int key){ int bucket = key % BUCKETS; return List_Insert(&amp;amp;H-&amp;gt;lists[bucket], key);}int Hash_Lookup(hash_t *H, int key){ int bucket = key % BUCKETS; return List_Lookup(&amp;amp;H-&amp;gt;lists[bucket], key);}本例的散列表使用我们之前实现的并发链表，性能特别好。每个散列桶（每个桶都是一个链表）都有一个锁，而不是整个散列表只有一个锁，从而支持许多并发操作。这个简单的并发散列表扩展性（性能）极好，相较于单纯的链表。原因就是缩小了临界区，减少了不同线程间操作的冲突小结增加并发不一定能提高性能；有性能问题的时候再做优化。关于最后一点，避免不成熟的优化（premature optimization），对于所有关心性能的开发者都有用。我们让整个应用的某一小部分变快，却没有提高整体性能，其实没有价值参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十二) 锁", "url": "/posts/operating-systems-22/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-16 09:00:00 +0800", "snippet": "锁的基本思想lock()和 unlock()函数的语义很简单。调用 lock() 尝试获取锁，如果没有其他线程持有锁（即它是可用的），该线程会获得锁，进入临界区当持有锁的线程在临界区时，其他线程就无法进入临界区。Pthread 锁POSIX 库将锁称为互斥量（mutex），因为它被用来提供线程之间的互斥。即当一个线程在临界区，它能够阻止其他线程进入直到本线程离开临界区。pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;pthread_mutex_lock(&amp;amp;lock); // wrapper for pthread_mutex_lock()balance = balance + 1;pthread_mutex_unlock(&amp;amp;lock);评价锁 互斥（mutual exclusion） 能够阻止多个线程 进入临界区 公平性（fairness） 每一个竞争线程有公平的机会抢到锁。是否有竞争锁的线程会饿死（starve），一直无法获得锁 性能（performance） 使用锁之后增加的时间开销控制中断最早提供的互斥解决方案之一，就是在临界区关闭中断:void lock() { DisableInterrupts();}void unlock() { EnableInterrupts();}假设我们运行在这样一个单处理器系统上。通过在进入临界区之前关闭中断（使用特殊的硬件指令），可以保证临界区的代码不会被中断，从而原子地执行。缺点: 要求我们允许所有调用线程执行特权操作（打开关闭中断），即信任这种机制不会被滥用。关中断后操作系统无法获得控制权 这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上，每个线程都试图进入同一个临界区，关闭中断也没有作用。线程可以运行在其他处理器上，因此能够进入临界区 关闭中断导致中断丢失，可能会导致严重的系统问题。假如磁盘设备完成了读取请求，正常应该会给个中断，但 CPU 错失了这一中断，那么，操作系统如何知道去唤醒等待读取的进程测试并设置指令（原子交换）最简单的硬件支持是测试并设置指令（test-and-set instruction），也叫作原子交换（atomic exchange）。typedef struct lock_t { int flag; } lock_t;void init(lock_t *mutex) { // 0 -&amp;gt; lock is available, 1 -&amp;gt; held mutex-&amp;gt;flag = 0;}void lock(lock_t *mutex) { while (mutex-&amp;gt;flag == 1) // TEST the flag ; // spin-wait (do nothing) mutex-&amp;gt;flag = 1; // now SET it!}void unlock(lock_t *mutex) { mutex-&amp;gt;flag = 0;}上述代码中，每次 lock 会判断 flag 的值，也就是测试并设置指令（test-and-set instruction）中的test，然后判断成功才set但如果没有硬件辅助，也就是让测试并设置作为一个原子操作，会导致两个线程有可能同时进入临界区。自旋等待spin-wait也影响性能 自旋锁（spin lock） 一直自旋，利用 CPU 周期，直到锁可用。实现可用的自旋锁在 SPARC 上，这个指令叫 ldstub（load/store unsigned byte，加载/保存无符号字节）；在 x86 上，是 xchg（atomic exchange，原子交换）指令。但它们基本上在不同的平台上做同样的事，通常称为测试并设置指令（test-and-set）。int TestAndSet(int *old_ptr, int new) { int old = *old_ptr; // fetch old value at old_ptr *old_ptr = new; // store &#39;new&#39; into old_ptr return old; // return the old value}将测试并设置作为原子操作typedef struct lock_t { int flag;} lock_t;void init(lock_t *lock) { // 0 indicates that lock is available, 1 that it is ld lock-&amp;gt;flag = 0;}void lock(lock_t *lock) { while (TestAndSet(&amp;amp;lock-&amp;gt;flag, 1) == 1) ; // spin-wait (do nothing)}void unlock(lock_t *lock) { lock-&amp;gt;flag = 0;}评价自旋锁正确性（correctness）: 自旋锁一次只允许一个线程进入临界区。因此，这是正确的锁公平性（fairness）: 自旋锁不提供任何公平性保证性能（performance）: 在单 CPU 的情况下，性能开销相当大。其他线程都在竞争锁，都会在放弃 CPU 之前，自旋一个时间片，浪费 CPU 周期。在多 CPU 上，自旋锁性能不错（如果线程数大致等于 CPU 数）比较并交换比较并交换指令（SPARC 系统中是 compare-and-swap，x86 系统是 compare-and-exchange）int CompareAndSwap(int *ptr, int expected, int new) { int actual = *ptr; if (actual == expected) *ptr = new; return actual;}比较并交换的基本思路是检测 ptr 指向的值是否和 expected 相等；如果是，更新 ptr 所指的值为新值。否则，什么也不做。不论哪种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。在自旋锁中可以替换测试并设置指令void lock(lock_t *lock) {while (CompareAndSwap(&amp;amp;lock-&amp;gt;flag, 0, 1) == 1) ; // spin}C 中实现(x86)：char CompareAndSwap(int *ptr, int old, int new) { unsigned char ret; // Note that sete sets a &#39;byte&#39; not the word __asm__ __volatile__ ( &quot; lock\\n&quot; &quot; cmpxchgl %2,%1\\n&quot; &quot; sete %0\\n&quot; : &quot;=q&quot; (ret), &quot;=m&quot; (*ptr) : &quot;r&quot; (new), &quot;m&quot; (*ptr), &quot;a&quot; (old) : &quot;memory&quot;); return ret;}链接的加载和条件式存储指令一些平台提供了实现临界区的一对指令链接的加载（load-linked）和条件式存储（store-conditional）int LoadLinked(int *ptr) { return *ptr;}int StoreConditional(int *ptr, int value) { if (no one has updated *ptr since the LoadLinked to this address) { *ptr = value; return 1; // success! } else { return 0; // failed to update }}条件式存储（store-conditional）指令，只有上一次执行LoadLinked的地址在期间都没有更新时， 才会成功，同时更新了该地址的值先通过 LoadLinked 尝试获取锁值，如果判断到锁被释放了，就执行StoreConditional判断在执行完LoadLinked到StoreConditional执行前ptr 有没有被更新，没有:说明没有其他线程来抢，可以进临界区，有:说明已经被其他线程抢走了，继续重复本段落所述内容循环：void lock(lock_t *lock) { while (1) { while (LoadLinked(&amp;amp;lock-&amp;gt;flag) == 1) ; // spin until it&#39;s zero if (StoreConditional(&amp;amp;lock-&amp;gt;flag, 1) == 1) return; // if set-it-to-1 was a success: all done // otherwise: try it all over again }}void unlock(lock_t *lock) { lock-&amp;gt;flag = 0;}获取并增加 获取并增加（fetch-and-add）指令 它能原子地返回特定地址的旧值，并且让该值自增一。int FetchAndAdd(int *ptr) { int old = *ptr; *ptr = old + 1; return old;}typedef struct lock_t { int ticket; int turn;} lock_t;void lock_init(lock_t *lock) { lock-&amp;gt;ticket = 0; lock-&amp;gt;turn = 0;}void lock(lock_t *lock) { int myturn = FetchAndAdd(&amp;amp;lock-&amp;gt;ticket); while (lock-&amp;gt;turn != myturn) ; // spin}void unlock(lock_t *lock) { FetchAndAdd(&amp;amp;lock-&amp;gt;turn);}原理是每次进入 lock，就获取当前ticket值，相当于挂号，然后全局 ticket 本身会自增一，后续线程都会获得属于自己的唯一ticket值，lock-&amp;gt;turn表示当前叫号值，叫到号的运行，unlock 时递增lock-&amp;gt;turn更新叫号值就行。这种方法保证了公平性，FIFO自旋过多：怎么办一个线程会一直自旋检查一个不会改变的值，浪费掉整个时间片！如果有 N 个线程去竞争一个锁，情况会更糟糕。同样的场景下，会浪费 N−1 个时间片，只是自旋并等待一个线程释放该锁。如何让锁不会不必要地自旋，浪费 CPU 时间？使用队列：休眠替代自旋需要一个队列来保存等待锁的线程。Solaris 中 park()能够让调用线程休眠，unpark(threadID)则会唤醒 threadID 标识的线程。两阶段锁 两阶段锁（two-phase lock） 如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。上文的 Linux 锁就是这种锁，不过只自旋一次；更常见的方式是在循环中自旋固定的次数(希望这段时间内能获取到锁)，然后使用 futex 睡眠。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十一) 并发：介绍", "url": "/posts/operating-systems-21/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-15 12:00:00 +0800", "snippet": "pthread 库介绍线程创建#include &amp;lt;pthread.h&amp;gt;intpthread_create( pthread_t * thread, const pthread_attr_t * attr, void * (*start_routine)(void*), void * arg); thread 指向 pthread_t 结构类型的指针，我们将利用这个结构与该线程交互，因此需要将它传入 pthread_create()，以便将它初始化。相当于该线程的身份证 attr 指定该线程可能具有的任何属性。包括设置栈大小，或关于该线程调度优先级的信息等 *start_routine 一个函数指针（function pointer）,指向要运行的函数 arg 要运行的函数的参数线程完成通过pthread_join阻塞等待线程完成pthread_create(&amp;amp;p, NULL, mythread, (void *) 100); pthread_join(p, (void **) &amp;amp;m);锁int pthread_mutex_lock(pthread_mutex_t *mutex);int pthread_mutex_unlock(pthread_mutex_t *mutex);pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;// 或是int rc = pthread_mutex_init(&amp;amp;lock, NULL);pthread_mutex_lock(&amp;amp;lock);x = x + 1; // or whatever your critical section ispthread_mutex_unlock(&amp;amp;lock);创建一个临界区如果另一个线程确实持有该锁，那么尝试获取该锁的线程将不会从该调用返回(阻塞等待)，直到获得该锁int pthread_mutex_trylock(pthread_mutex_t *mutex);int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout);这两个调用用于获取锁(非阻塞获取锁)。如果锁已被占用，则 trylock 版本将失败。获取锁的 timedlock 定版本会在超时或获取锁后返回，以先发生者为准。通常应避免使用这两种版本条件变量(Condition Variables)不同于信号量(semaphore)，信号量应该是条件变量+互斥锁的组合，见此文当线程之间必须发生某种信号时，如果一个线程在等待另一个线程继续执行某些操作，条件变量就很有用。int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);int pthread_cond_signal(pthread_cond_t *cond);要使用条件变量，必须另外有一个与此条件相关的锁。在调用上述任何一个函数时，应该持有这个锁。第一个函数pthread_cond_wait()使调用线程进入休眠状态，因此等待其他线程发出信号，通常当程序中的某些内容发生变化时，现在正在休眠的线程可能会关心它。典型的用法如下所示：pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;pthread_cond_t cond = PTHREAD_COND_INITIALIZER;pthread_mutex_lock(&amp;amp;lock);while (ready == 0) pthread_cond_wait(&amp;amp;cond, &amp;amp;lock);pthread_mutex_unlock(&amp;amp;lock);唤醒线程的代码运行在另外某个线程中，调用pthread_cond_signal时也需要持有对应锁。像下面这样：pthread_mutex_lock(&amp;amp;lock);ready = 1;pthread_cond_signal(&amp;amp;cond);pthread_mutex_unlock(&amp;amp;lock);pthread_cond_wait有第二个参数，因为它会隐式地释放锁，以便在其线程休眠后唤醒线程可以获取锁，之后又会重新获得锁。本例通过 while 判断 ready 的值的变更，而不是通过条件变量唤醒判断 ready 已变更。将唤醒视为某种事物可能已经发生变化的暗示，而不是绝对的事实，这样更安全编译和运行代码需要包括头文件 pthread.h 才能编译。链接时需要 pthread库，增加 -pthread 标记。prompt&amp;gt; gcc -o main main.c -Wall -pthread小结 补充：线程 API 指导 当你使用 POSIX 线程库（或者实际上，任何线程库）来构建多线程程序时，需要记住一些小而重要的事情： 保持简洁。最重要的一点，线程之间的锁和信号的代码应该尽可能简洁。复杂的线程交互容易产生缺陷。 让线程交互减到最少。尽量减少线程之间的交互。每次交互都应该想清楚，并用验证过的、正确的方法来实现（很多方法会在后续章节中学习）。 初始化锁和条件变量。未初始化的代码有时工作正常，有时失败，会产生奇怪的结果。 检查返回值。当然，任何 C 和 UNIX 的程序，都应该检查返回值，这里也是一样。否则会导致古怪而难以理解的行为，让你尖叫，或者痛苦地揪自己的头发。 注意传给线程的参数和返回值。具体来说，如果传递在栈上分配的变量的引用，可能就是在犯错误。 每个线程都有自己的栈。类似于上一条，记住每一个线程都有自己的栈。因此，线程局部变量应该是线程私有的，其他线程不应该访问。线程之间共享数据，值要在堆（heap）或者其他全局可访问的位置。 线程之间总是通过条件变量发送信号。切记不要用标记变量来同步。 多查手册。尤其是 Linux 的 pthread 手册，有更多的细节、更丰富的内容。请仔细阅读！ 参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二十) 并发：介绍", "url": "/posts/operating-systems-20/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-15 11:00:00 +0800", "snippet": "单个线程的状态与进程状态非常类似。线程有一个程序计数器（PC），记录程序从哪里获取指令。每个线程有自己的一组用于计算的寄存器。所以，如果有两个线程运行在一个处理器上，从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切换（context switch）。线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们将状态保存到进程控制块（Process Control Block，PCB）。现在，我们需要一个或多个线程控制块（Thread Control Block，TCB），保存每个线程的状态。但是，与进程相比，线程之间的上下文切换有一点主要区别：地址空间保持不变（即不需要切换当前使用的页表）。在多线程的进程中，每个线程独立运行，当然可以调用各种例程来完成正在执行的任何工作。不是地址空间中只有一个栈，而是每个线程都有一个栈。实例：线程创建#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;assert.h&amp;gt;#include &amp;lt;pthread.h&amp;gt;void *mythread(void *arg) { printf(&quot;%s\\n&quot;, (char *) arg); return NULL;}intmain(int argc, char *argv[]) { pthread_t p1, p2; int rc; printf(&quot;main: begin\\n&quot;); rc = pthread_create(&amp;amp;p1, NULL, mythread, &quot;A&quot;); assert(rc == 0); rc = pthread_create(&amp;amp;p2, NULL, mythread, &quot;B&quot;); assert(rc == 0); // join waits for the threads to finish rc = pthread_join(p1, NULL); assert(rc == 0); rc = pthread_join(p2, NULL); assert(rc == 0); printf(&quot;main: end\\n&quot;); return 0;}为什么更糟糕：共享数据两个线程递增同一个数，每次运行最终结果都不一样原因是共享数据未保证操作原子性后面都是些概念性的东西，不做赘述参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十九) VAX/VMS虚拟内存系统", "url": "/posts/operating-systems-19/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-15 10:00:00 +0800", "snippet": "数字设备公司（DEC）在 20 世纪 70 年代末推出了 VAX-11 小型机体系结构。该系统的操作系统被称为 VAX/VMS（或者简单的 VMS），其主要架构师之一是 Dave Cutler，他后来领导开发了微软 Windows NT只讲重点，直接看原文就行分段的 FIFO防止有“自私贪婪的内存”（memory hog）—— 一些程序占用大量内存， 使其他程序难以运行。每个进程都有一个可以保存在内存中的最大页数，称为驻留集大小（Resident Set Size，RSS）。每个页都保存在 FIFO 列表中。当一个进程超过其 RSS 时，“先入”的页被驱逐。决定了进程不能占用过大内存纯粹的 FIFO 并不是特别好。为了提高 FIFO 的性能，VMS 引入了两个 二次机会列表（second-chance list），页在从内存中被踢出之前被放在其中。具体来说， 是全局的干净页空闲列表和脏页列表。当进程 P 超过其 RSS 时，将从其每个进程的 FIFO 中移除一个页。如果干净（未修改），则将其放在干净页列表的末尾。如果脏（已修改），则 将其放在脏页列表的末尾。如果另一个进程 Q 需要一个空闲页，它会从全局干净列表中取出第一个空闲页。但是， 如果原来的进程 P 在回收之前在该页上出现页错误(不在物理内存中，在磁盘中)，则 P 会从空闲（或脏）列表中回收，从而避免昂贵的磁盘访问。这些全局二次机会列表越大，分段的 FIFO 算法越接近 LRU页聚集通过聚集，VMS 将大批量的页从全局脏列表中分组到一起，并将它们一举写入磁盘（从而使它们变干净）。写时复制（copy-on-write，COW）如果操作系统需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间(相当于两个空间是共享的，还是同一个)，并在两个地址空间中将其标记为只读。如果两个地址空间都只读取页面，则不会采取进一步的操作，因此操作系统已经实现了快速复制而不实际移动任何数据。如果其中一个地址空间确实尝试写入页面，就会陷入操作系统。操作系统会注意到该页面是一个 COW 页面，因此（惰性地）分配一个新页，填充数据，并将这个新页映射到错误处理的地址空间。该进程然后继续，现在有了该页的私人副本。例子：fork()会创建调用者地址空间的精确副本,就是原来的程序要复制一份，fork 出的新程序和原来的是一样的,如果后面还有 exec 替换不同的程序，那这个复制操作实际上没有意义。对于大的地址空间，这样的复制过程很慢，并且是数据密集的。更糟糕的是，大部分地址空间会被随后的 exec()调用立即覆盖，它用即将执行的程序覆盖调用进程的地址空间。通过改为执行写时复制的 fork()，操作系统避免了大量不必要的复制，从而保留了正确的语义，同时提高了性能。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十八) 超越物理内存：策略", "url": "/posts/operating-systems-18/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-15 09:00:00 +0800", "snippet": "由于内存压力（memory pressure）迫使操作系统换出（paging out）一些页，为常用的页腾出空间。确定要踢出（evict）哪个页（或哪些页）封装在操作系统的替换策略（replacement policy）中。这章讲的是 cache，就是加速硬盘读取，以页为单位，在内存中创建硬盘页的缓存缓存管理将物理内存页作为硬盘内存页的缓存cache能直接从物理内存页中找到即为缓存命中，未找到即为缓存未命中就可以计算程序的平均内存访问时间（Average Memory Access Time，AMAT）：${AMAT} = (P_{Hit}·T_M) + (P_{Miss}·T_D)$其中 $T_M$ 表示访问内存的成本， $T_D$ 表示访问磁盘的成本， $P_{Hit}$ 表示在缓存中找到数据的概率（命中），$P_{Miss}$ 表示在缓存中找不到数据的概率（未命中）。 $P_{Hit}$ 和 $P_{Miss}$ 从 0.0 变化到 1.0，并且 $P_{Miss}$ + $P_{Hit}$ = 1.0。在现代系统中，磁盘访问的成本非常高，即使很小概率的未命中也会拉低正在运行的程序的总体 AMAT。显然，我们必须尽可能地避免缓存未命中，避免程序以磁盘的速度运行。最优替换策略 最优（optimal）策略: 替换内存中在最远将来才会被访问到的页，可以达到缓存未命中率最低。 提示：与最优策略对比非常有用 用于自己实现的算法的评估依据。虽然最优策略非常不切实际，但作为仿真或其他研究的比较者还是非常有用的。比如，单说你喜欢的新算法有 80% 的命中率是没有意义的，但加上最优算法只有 82% 的命中率（因此你的新方法非常接近最优），就会使得结果很有意义，并给出了它的上下文。因此，在你进行的任何研究中，知道最优策略可以方便进行对比，知道你的策略有多大的改进空间，也用于决定当策略已经非常接近最优策略时，停止做无谓的优化[AD03]。遗憾的是，正如我们之前在开发调度策略时所看到的那样，未来的访问是无法知道的，你无法为通用操作系统实现最优策略。在开发一个真正的、可实现的策略时，我们将聚焦于寻找其他决定把哪个页面踢出的方法。因此，最优策略只能作为比较，知道我们的策略有多接近“完美”。简单策略：FIFO页在进入系统时，简单地放入一个队列。当发生替换时，队列尾部的页（“先入”页）被踢出。先进先出（FIFO）根本无法确定页的重要性：即使页 0 已被多次访问，FIFO 仍然会将其踢出，因为它是第一个进入内存的另一简单策略：随机在内存满的时候它随机选择一个页进行替换。有些时候（仅仅 40%的概率），随机和最优策略一样好，有时候情况会更糟糕，随机策略取决于当时的运气。利用历史数据：LRU如果某个程序在过去访问过某个页，则很有可能在不久的将来会再次访问该页页替换策略可以使用的一个历史信息是频率（frequency）。如果一个页被访问了很多次，也许它不应该被替换，因为它显然更有价值。页更常用的属性是访问的近期性（recency），越近被访问过的页，也许再次访问的可能性也就越大。这一系列的策略是基于人们所说的局部性原则（principle of locality） 补充：局部性类型 程序倾向于表现出两种类型的局部。第一种是空间局部性（spatial locality），它指出如果页 P 被访问，可能围绕它的页（比如 P−1 或 P + 1）也会被访问。第二种是时间局部性（temporal locality），它指出近期访问过的页面很可能在不久的将来再次访问。假设存在这些类型的局部性，对硬件系统的缓存层次结构起着重要作用，硬件系统部署了许多级别的指令、数据和地址转换缓存，以便在存在此类局部性时，能帮助程序快速运行。 当然，通常所说的局部性原则（principle of locality）并不是硬性规定，所有的程序都必须遵守。事实上，一些程序以相当随机的方式访问内存（或磁盘），并且在其访问序列中不显示太多或完全没有局部性。因此，尽管在设计任何类型的缓存（硬件或软件）时，局部性都是一件好事，但它并不能保证成功。相反，它是一种经常证明在计算机系统设计中有用的启发式方法基于局部性原则，有两种替换策略。“最不经常使用”（Least-Frequently-Used，LFU）策略会替换最不经常使用的页。同样，“最近最少使用”（Least-Recently-Used，LRU） 策略替换最近最少使用的页面。工作负载示例当工作负载不存在局部性时，使用的策略区别不大。LRU、FIFO 和随机都执行相同的操作，命中率完全由缓存的大小决定。“80—20”负载场景，它表现出局部性：80%的引用是访问 20%的页（“热门”页）。剩下的 20%是对剩余的 80%的页（“冷门”页）访问。“循环顺序”工作负载，其中依次引用 50个页，从 0 开始，然后是 1，…，49，然后循环，重复访问。展示了 LRU 或者 FIFO 的最差情况。实现基于历史信息的算法如何找到最近最少使用的页，也就是找到更新时间最久的页硬件可以在每个页访问时更新内存中的时间字段（时间字段可以在每个进程的页表中，或者在内存的某个单独的数组中，每个物理页有一个）。因此，当页被访问时，时间字段将被硬件设置为当前时间。 然后，在需要替换页时，操作系统可以简单地扫描系统中所有页的时间字段以找到最近最少使用的页。遗憾的是，随着系统中页数量的增长，扫描所有页的时间字段只是为了找到最精确最少使用的页，这个代价太昂贵。近似 LRU需要硬件增加一个使用位（use bit，有时称为引用位，reference bit）,系统的每个页有一个使用位，然后这些使用位存储在某个地方（例如，它们可能在每个进程的页表中，或者只在某个数组中）。每当页被引用（即读或写）时，硬件将使用位设置为 1。但是，硬件不会清除该位（即将其设置为 0），这由操作系统负责。Corbato 的时钟算法：时钟指针（clock hand）开始时指向随便某个特定的页（哪个页不重要）。当必须进行页替换时，操作系统检查当前指向的页 P 的使用位是 1 还是 0。如果是 1，则意味着页面 P最近被使用，因此不适合被替换。然后，P 的使用位设置为0，时钟指针递增到下一页（P + 1）。该算法一直持续到找到一个使用位为 0 的页，使用位为 0 意味着这个页最近没有被使用过（在最坏的情况下，所有的页都已经被使用了，那么就将所有页的使用位都设置为 0）。这个算法有个问题，就是查找次数不稳定，如果是随机扫描而不是指针递增就好很多考虑脏页这章讲的其实不是 swap，而是cache，就是加速硬盘读取，以页为单位，在内存中创建硬盘页的缓存如果页已被修改（modified）并因此变脏（dirty），则踢出它就必须将它写回磁盘，这很昂贵。如果它没有被修改（因此是干净的，clean），踢出就没成本。物理帧可以简单地重用于其他目的而无须额外的 I/O。因此，一些虚拟机系统更倾向于踢出干净页，而不是脏页。为了支持这种行为，硬件应该包括一个修改位（modified bit，又名脏位，dirty bit）。每次写入页时都会设置此位，因此可以将其合并到页面替换算法中。例如，时钟算法可以被改变，以扫描既未使用又干净的页先踢出。无法找到这种页时，再查找脏的未使用页面，等等。其他虚拟内存策略操作系统还必须决定何时将页载入内存。操作系统可能会猜测一个页面即将被使用，从而提前载入。这种行为被称为预取（prefetching），只有在有合理的成功机会时才应该这样做。例如，一些系统将假设如果代码页 P 被载入内存，那么代码页 P + 1 很可能很快被访问，因此也应该被载入内存。这种行为通常称为聚集（clustering）写入，或者就是分组写入（grouping），这样做有效是因为硬盘驱动器的性质，执行单次大的写操作，比许多小的写操作更有效。抖动当内存就是被超额请求时，这组正在运行的进程的内存需求是否超出了可用物理内存？系统将不断地进行换页，这种情况有时被称为抖动（thrashing）当内存超额请求时，某些版本的 Linux 会运行“内存不足的杀手程序（out-of-memory killer）”。这个守护进程选择一个内存密集型进程并杀死它，从而以不怎么委婉的方式减少内存。小结终极解决方案：加内存参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十七) 超越物理内存：机制", "url": "/posts/operating-systems-17/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-14 09:00:00 +0800", "snippet": "交换空间在硬盘上开辟一部分空间用于物理页的移入和移出。一般这样的空间称为交换空间（swap space）。存在位当硬件在 PTE 中查找时，可能发现页不在物理内存中。硬件（或操作系统，在软件管理 TLB 时）判断是否在内存中的方法，是通过页表项中的一条新信息，即存在位（present bit）。如果存在位设置为 1，则表示该页存在于物理内存中，并且所有内容都如上所述进行。如果存在位设置为0，则页不在内存中，而在硬盘上。访问不在物理内存中的页，这种行为通常被称为页错误（page fault）。在页错误时，硬件自己无法处理，操作系统被唤起来处理页错误。一段称为“页错误处理程序（page-fault handler）”的代码会执行，来处理页错误。页错误在 TLB 未命中的情况下，我们有两种类型的系统：硬件管理的 TLB（硬件在页表中找到需要的转换映射）和软件管理的 TLB（操作系统执行查找过程）。不论在哪种系统中，如果页不存在，都由操作系统负责处理页错误。操作系统的页错误处理程序（page-fault handler）确定要做什么。 补充：为什么硬件不能处理页错误 我们从 TLB 的经验中得知，硬件设计者不愿意信任操作系统做所有事情。那么为什么他们相信操作系统来处理页错误呢？有几个主要原因。首先，页错误导致的硬盘操作很慢。即使操作系统需要很长时间来处理故障，执行大量的指令，但相比于硬盘操作，这些额外开销是很小的。其次，为了能够处理页故障，硬件必须了解交换空间，如何向硬盘发起 I/O 操作，以及很多它当前所不知道的细节。因此，由于性能和简单的原因，操作系统来处理页错误，即使硬件人员也很开心操作系统可以用 PTE 中的某些位来存储硬盘地址，这些位通常用来存储像页的 PFN 这样的数据。当操作系统接收到页错误时，它会在 PTE 中查找地址，并将请求发送到硬盘，将页读取到内存中。当硬盘 I/O 完成时，操作系统会更新页表，将此页标记为存在，更新页表项（PTE）的 PFN 字段以记录新获取页的内存位置，并重试指令。下一次重新访问 TLB 还是未命中，然而这次因为页在内存中，因此会将页表中的地址更新到 TLB 中（也可以在处理页错误时更新 TLB 以避免此步骤）。最后的重试操作会在 TLB 中找到转换映射，从已转换的内存物理地址，获取所需的数据或指令。请注意，当 I/O 在运行时，进程将处于阻塞（blocked）状态。因此，当页错误正常处理时，操作系统可以自由地运行其他可执行的进程。因为 I/O 操作是昂贵的，一个进程进行 I/O（页错误）时会执行另一个进程，这种交叠（overlap）是多道程序系统充分利用硬件的一种方式。内存满了怎么办页交换策略（page-replacement policy）：从硬盘中换入（page in），换出（page out）当然是有性能损失的页错误处理流程页错误控制流算法（硬件）:VPN = (VirtualAddress &amp;amp; VPN_MASK) &amp;gt;&amp;gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp;amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &amp;lt;&amp;lt; SHIFT) | Offset Register = AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB Miss PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) // 不合法，超界限，段错误 else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) // 无权限错误 else if (PTE.Present == True) // assuming hardware-managed TLB TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) // 在物理内存，插入TLB RetryInstruction() else if (PTE.Present == False) RaiseException(PAGE_FAULT) // 不在物理内存，页错误页错误处理算法（软件）:PFN = FindFreePhysicalPage() // 找用于换入的物理内存页if (PFN == -1) // no free page found PFN = EvictPage() // run replacement algorithmDiskRead(PTE.DiskAddr, pfn) // sleep (waiting for I/O)PTE.present = True // update page table with presentPTE.PFN = PFN // bit and translation (PFN)RetryInstruction() // retry instruction，重试后TLB还是未命中的，需要再做插入TLB操作交换何时真正发生为了保证有少量的空闲内存，大多数操作系统会设置高水位线（High Watermark，HW）和低水位线（Low Watermark，LW），来帮助决定何时从内存中清除页。当操作系统发现有少于 LW 个页可用时，后台负责释放内存的线程会开始运行，直到有 HW 个可用的物理页。这个后台线程有时称为交换守护进程（swap daemon）或页守护进程（page daemon）小结在页表结构中需要添加额外信息，比如增加一个存在位（present bit，或者其他类似机制），告诉我们页是不是在内存中。如果不存在，则操作系统页错误处理程序（page-fault handler）会运行以处理页错误（page fault），从而将需要的页从硬盘读取到内存，可能还需要先换出内存中的一些页，为即将换入的页腾出空间。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十六) 分页：较小的表", "url": "/posts/operating-systems-16/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-13 11:00:00 +0800", "snippet": "假设一个 32 位地址空间（232 字节）， 4KB（212 字节）的页和一个 4 字节的页表项。一个地址空间中大约有一百万个虚拟页面（232/212）。乘以页表项的大小，你会发现页表大小为4MB。回想一下：通常系统中的每个进程都有一个页表！有一百个活动进程（在现代系统中并不罕见），就要为页表分配数百兆的内存！简单的解决方案：更大的页再以 32 位地址空间为例，但这次假设用 16KB 的页。因此，会有 18 位的 VPN 加上 14 位的偏移量。假设每个页表项（4 字节）的大小相同，现在线性页表中有 218 个项，因此每个页表的总大小为 1MB，页表缩到四分之一。 补充：多种页大小 另外请注意，许多体系结构（例如 MIPS、SPARC、x86-64）现在都支持多种页大小。通常使用一个小的（4KB 或 8KB）页大小。但是，如果一个“聪明的”应用程序请求它，则可以为地址空间的特定部分使用一个大型页（例如，大小为 4MB），从而让这些应用程序可以将常用的（大型的）数据结构放入这样的空间，同时只占用一个 TLB 项。这种类型的大页在数据库管理系统和其他高端商业应用程序中很常见。然而，多种页面大小的主要原因并不是为了节省页表空间。这是为了减少 TLB 的压力，让程序能够访问更多的地址空间而不会遭受太多的 TLB 未命中之苦。然而，正如研究人员已经说明[N+02]一样，采用多种页大小，使操作系统虚拟内存管理程序显得更复杂，因此，有时只需向应用程序暴露一个新接口，让它们直接请求大内存页，这样最容易。这种方法的主要问题在于，大内存页会导致每页内的浪费，这被称为内部碎片（internal fragmentation）问题（因为浪费在分配单元内部）。混合方法：分页和分段一个进程只使用了部分页，大部分页表都没有使用，充满了无效的（invalid）项。浪费了页表空间分段见《Operating Systems: Three Easy Pieces》学习笔记(十二) 分段，有一个基址（base）寄存器，告诉我们每个段在物理内存中的位置，还有一个界限（bound）或限制（limit）寄存器，告诉我们该段的大小。基址不是指向段本身，而是保存该段的页表的物理地址。界限寄存器用于指示页表的结尾（即它有多少有效页）。假设 32 位虚拟地址空间包含 4KB 页面，并且地址空间分为 4 个段。在这个例子中，我们只使用 3 个段：一个用于代码，另一个用于堆，还有 一个用于栈。用地址空间的前两位确定地址引用哪个段,假设 00 是未使用的段，01 是代码段，10 是堆段，11 是栈段。因此，虚拟地址如下所示：在硬件中，假设有 3 个基本/界限对，代码、堆和栈各一个。当进程正在运行时，每个段的基址寄存器都包含该段的线性页表的物理地址。因此，系统中的每个进程现在都有 3 个与其关联的页表。在上下文切换时，必须更改这些寄存器，以反映新运行进程的页表的位置。在 TLB 未命中时（假设硬件管理的 TLB，即硬件负责处理 TLB 未命中），硬件使用分段位（SN）来确定要用哪个基址和界限对。从基址寄存器找到页表的起始物理地址，再加上 VPN*sizeof(PTE)就是页表项(PTE)的地址，判断是否超过界限寄存器规定的界限，然后从页表项找到对应页的物理地址。(页表项就是页表线性数组中的一条记录)SN = (VirtualAddress &amp;amp; SEG_MASK) &amp;gt;&amp;gt; SN_SHIFTVPN = (VirtualAddress &amp;amp; VPN_MASK) &amp;gt;&amp;gt; VPN_SHIFTAddressOfPTE = Base[SN] + (VPN * sizeof(PTE))栈和堆之间未分配的页不再占用页表中的空间（仅将其标记为无效）。(就是分段的特性)当然分段有的缺点不可避免，如果有一个大而稀疏的堆(堆的基址只有一个，堆内部空间的浪费避免不了)，仍然可能导致大量的页表浪费，同时外部碎片再次出现多级页表如何去掉页表中的所有无效区域，而不是将它们全部保留在内存中？将线性页表变成树的形式。我们将这种方法称为多级页表（multi-level page table）假设一个页能存4个页表记录（页表项PTE），通过页目录的每一项(PDE)表示 4 个页表项组成的一个页，只有启用的页才分配空间。支持稀疏空间的，不需要连续，这种间接方式，让我们能够将页表页放在物理内存的任何地方。在本例中，还有问题，如何定位PDE，需要用到虚拟地址 VPN 中的开头页目录索引PDEAddr = PageDirBase +（PDIndex×sizeof（PDE））(上述表达式也能看出稀疏也是有限制的，至少被页目录索引 PageDirBase 限制了范围)当然比二级更多层级的页表也是允许的多级页表是有成本的。在 TLB 未命中时，需要从内存加载两次，才能从页表中获取正确的地址转换信息（一次用于页目录，另一次用于 PTE 本身），而用线性页表只需要一次加载。因此，多级表是一个时间—空间折中（time-space trade-off）的小例子。另一个明显的缺点是复杂性。无论是硬件还是操作系统来处理页表查找（在 TLB 未命中时），这样做无疑都比简单的线性页表查找更复杂。反向页表 反向页表（inverted page table） 整个系统只有一个页表，其中的项代表系统的每个物理页，而不是有许多页表（系统的每个进程一个）。页表项告诉我们哪个进程正在使用此页，以及该进程的哪个虚拟页映射到此物理页。通常在此基础结构上建立散列表，以加速查找。将页表交换到磁盘一些系统将这样的页表放入内核虚拟内存（kernel virtual memory），从而允许系统在内存压力较大时，将这些页表中的一部分交换（swap）到磁盘。小结在一个内存受限的系统中（像很多旧系统一样），小结构是有意义的。在具有较多内存， 并且工作负载主动使用大量内存页的系统中，用更大的页表来加速 TLB 未命中处理，可能是正确的选择。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十五) 分页：快速地址转换（TLB）", "url": "/posts/operating-systems-15/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-13 10:00:00 +0800", "snippet": "对每次内存访问，硬件先检查 TLB，看看其中是否有期望的转换映射，如果有，就完成转换（很快），不用访问页表 （其中有全部的转换映射）。因此，更好的名称应该是地址转换缓存（address-translation cache）。TLB 的基本算法TLB 命中（TLB hit）,直接取TLB 未命中，硬件访问页表来寻找转换映射，并用该转换映射更新 TLB，当 TLB 更新成功后，系统会重新尝试该指令示例：访问数组访问 a[1]后，TLB 有了 VPN=06 的映射，下次访问 a[2]或 a[0]也能 TLB 命中. 硬件缓存背后的思想是利用指令和数据引用的局部性（locality）。通常有两种局部性：时间局部性（temporal locality）和空间局部性（spatial locality）。时间局部性是指，最近访问过的指令或数据项可能很快会再次访问。空间局部性是指，当程序访问内存地址 x 时，可能很快会访问邻近 x 的内存。谁来处理 TLB 未命中 硬件： 发生未命中时， 硬件会“遍历”页表，找到正确的页表项，取出想要的转换映射，用它更新 TLB，并重试该指令 一个例子是 x86 架构，它采用固定的多级页表（multi-level page table） 软件： 精简指令集计算机上。 发生 TLB 未命中时，硬件系统会抛出一个异常（见图 19.3 第 11 行），这会暂停当前的指令流，将特权级提升至内核模式，跳转至陷阱处理程序（trap handler）。接下来你可能已经猜到了，这个陷阱处理程序是操作系统的一段代码，用于处理 TLB 未命中。这段代码在运行时，会查找页表中的转换映射，然后用特别的“特权”指令更新 TLB，并从陷阱返回。此时，硬件会重试该指令（导致 TLB 命中）。 可能导致无限递归，比如陷阱处理程序中也有未命中的。可以把 TLB 未命中陷阱处理程序直接放到物理内存中 [它们没有映射过（unmapped），不用经过地址转换]。或者在 TLB 中保留一些项，记录永久有效的地址转换，并将其中一些永久地址转换槽块留给处理代码本身，这些被监听的（wired）地址转换总是会命中 TLB。 TLB 的内容VPN ｜ PFN ｜ 其他位VPN和PFN同时存在于TLB中，因为一条地址映射可能出现在任意位置（用硬件的术语，TLB 被称为全相联的（fully-associative）缓存）。硬件并行地查找这些项，看看是否有匹配。其他位:TLB 通常有一个有效（valid）位，用来标识该项是不是有效地转换映射。通常还有一些保护（protection）位，用来标识该页是否有访问权限。例如，代码页被标识为可读和可执行，而堆的页被标识为可读和可写。还有其他一些位，包括地址空间标识符（address-space identifier）、脏位（dirty bit）等。上下文切换时对 TLB 的处理TLB 中包含的虚拟到物理的地址映射只对当前进程有效，对其他进程是没有意义的。一些系统增加了硬件支持，实现跨上下文切换的 TLB 共享。比如有的系统在 TLB 中添加了一个地址空间标识符（Address Space Identifier，ASID）。可以把 ASID 看作是进程标识符（Process Identifier，PID），但通常比 PID 位数少（PID 一般 32 位， ASID 一般是 8 位）。ASID 标识不同进程，可以存在相同的 VPN。操作系统在上下文切换时，必须将某个特权寄存器设置为当前进程的 ASID。上图表示两个进程共享同一物理页（例如代码段的页），因为是只读和执行的，可以共享，比如代码段存放的内存。TLB 替换策略 最少使用（least-recently-used，LRU） 随机（random）策略随机（random）策略可以避免极端情况，如一个程序循环访问 n+1 个页，但 TLB 大小只能存放 n 个页，每次访问内存都会触发 TLB 未命中实际系统的 TLB 表项这个例子来自 MIPS R4000[H93]，它是一种现代的系统，采用软件管理 TLB。MIPS R4000 支持 32 位的地址空间，页大小为 4KB。所以在典型的虚拟地址中，预期会看到 20 位的 VPN和 12 位的偏移量。但是，你可以在 TLB 中看到，只有 19 位的 VPN。事实上，用户地址只占地址空间的一半（剩下的留给内核），所以只需要 19 位的 VPN。VPN 转换成最大 24 位的物理帧号（PFN），因此可以支持最多有 64GB 物理内存（224 个 4KB 内 存页）的系统。3 个一致性位（Coherence，C），决定硬件如何缓存该页（其中一位超出了本书的范围）；脏位（dirty），表示该页是否被写入新数据（后面会介绍用法）；有效位（valid），告诉硬件该项的地址映射是否有效。还有没在图 19.4 中展示的页掩码（page mask）字段，用来支持不同的页大小。MIPS 的 TLB 通常有 32 项或 64 项，大多数提供给用户进程使用，也有一小部分留给操作系统使用。操作系统可以设置一个被监听的寄存器，告诉硬件需要为自己预留多少 TLB 槽。这些保留的转换映射，被操作系统用于关键时候它要使用的代码和数据，在这些时候，TLB 未命中可能会导致问题（例如，在 TLB 未命中处理程序中）。由于 MIPS 的 TLB 是软件管理的，所以系统需要提供一些更新 TLB 的指令。MIPS 提供了 4 个这样的指令： TLBP，用来查找指定的转换映射是否在 TLB 中； TLBR，用来将 TLB 中的内容读取到指定寄存器中； TLBWI，用来替换指定的 TLB 项； TLBWR，用来随机替换一个 TLB 项。操作系统可以用这些指令管理 TLB 的内容。当然这些指令是特权指令小结如果一个程序短时间内访问的页数超过了 TLB 中的页数，就会产生大量的 TLB 未命中，运行速度就会变慢。这种现象被称为超出 TLB 覆盖范围（TLB coverage）。可以用更大的页来缩小页的数量，增加命中率访问 TLB 很容易成为 CPU 流水线的瓶颈，尤其是有所谓的物理地址索引缓存（physically-indexed cache）,这是 CPU 内部的缓存。有了这种缓存，地址转换必须发生在访问该缓存之前，这会让操作变慢。虚拟地址索引缓存（virtually-indexed cache）解决了一些性能问题，但也为硬件设计带来了新问题。物理地址索引缓存详见Physically indexed, physically tagged (PIPT) caches参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十四) 空闲空间管理", "url": "/posts/operating-systems-14/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-13 09:00:00 +0800", "snippet": "一个简单例子在这个例子中，有 8 个页帧（由 128 字节物理内存构成，也是极小的）为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。页表的主要作用是为地址空间的每个虚拟页面保存地址转换（address translation）为了转换（translate）该过程生成的虚拟地址，我们必须首先将它分成两个组件：虚拟页面号（virtual page number，VPN）和页内的偏移量（offset）。检索页表，找到虚拟页 1 所在的物理页面, 物理帧号（PFN）（有时也称为物理页号，physical page number 或 PPN）是 7（二进制 111）,最终物理地址是 1110101页表存在哪里一般放在内存中。列表中究竟有什么最简单的形式称为线性页表（linear page table），就是一个数组。操作系统通过虚拟页号（VPN）检索该数组，并在该索引处查找页表项（PTE），以便找到期望的物理帧号（PFN）。 PTE 的内容: 有效位（valid bit） 特定地址转换是否有效,例如，当一个程序开始运行时，它的代码和堆在其地址空间的一端，栈在另一端。所有未使用的中间空间都将被标记为无效（invalid），如果进程尝试访问这种内存，就会陷入操作系统，可能会导致该进程终止。因此，有效位对于支持稀疏地址空间至关重要。通过简单地将地址空间中所有未使用的页面标记为无效，我们不再需要为这些页面分配物理帧，从而节省大量内存。 保护位（protection bit） 表明页是否可以读取、写入或执行 存在位（present bit） 表示该页是在物理存储器还是在磁盘上（即它已被换出，swapped out） 脏位（dirty bit） 表明页面被带入内存后是否被修改过 图 18.5 显示了来自 x86 架构的示例页表项[I09]。它包含一个存在位（P），确定是否允许写入该页面的读/写位（R/W） 确定用户模式进程是否可以访问该页面的用户/超级用户位（U/S），有几位（PWT、PCD、PAT 和 G）确定硬件缓存如何为这些页面工作，一个访问位（A）和一个脏位（D），最后是页帧号（PFN）本身。 分页消耗假设一个页表基址寄存器（page-table base register）包含页表的起始位置的物理地址。VPN = (VirtualAddress &amp;amp; VPN_MASK) &amp;gt;&amp;gt; SHIFTPTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))VPN MASK将被设置为 0x30（十六进制 30，或二进制 110000），它从完整的虚拟地址中挑选出 VPN 位；SHIFT 设置为 4（偏移量的位数），这样我们就可以将 VPN 位向右移动以形成正确的整数虚拟页码。例如，使用虚拟地址 21（010101），掩码将此值转换为 010000，移位将它变成 01，或虚拟页 1，正是我们期望的值。然后，我们使用该值作为页表基址寄存器指向的 PTE 数组的索引。offset = VirtualAddress &amp;amp; OFFSET_MASKPhysAddr = (PFN &amp;lt;&amp;lt; SHIFT) | offset// Extract the VPN from the virtual addressVPN = (VirtualAddress &amp;amp; VPN_MASK) &amp;gt;&amp;gt; SHIFT// Form the address of the page-table entry (PTE)PTEAddr = PTBR + (VPN * sizeof(PTE))// Fetch the PTEPTE = AccessMemory(PTEAddr)// Check if process can access the pageif (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT)else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT)else // Access is OK: form physical address and fetch it offset = VirtualAddress &amp;amp; OFFSET_MASK PhysAddr = (PTE.PFN &amp;lt;&amp;lt; PFN_SHIFT) | offset Register = AccessMemory(PhysAddr)内存追踪一段循环赋值 c 代码：int array[1000];...for (i = 0; i &amp;lt; 1000; i++) array[i] = 0;编译：prompt&amp;gt; gcc -o array array.c -Wall -Oprompt&amp;gt; ./array反编译后的汇编：0x1024 movl $0x0,(%edi,%eax,4)0x1028 incl %eax0x102c cmpl $0x03e8,%eax0x1030 jne 0x1024第一条指令将零值（显示为$0x0）移动到数组位置的虚拟内存地址，这个地址是通过取%edi的内容并将其 加上%eax乘以4 来计算的。%edi 保存数组的基址，而%eax 保存数组索引（i）。(array[i]=0)第二条指令增加保存在%eax中的数组索引(i++)第三条指令将该寄存器的内容与十六进制值 0x03e8 或十进制数 1000 进行比较(i&amp;lt;1000)。如果比较结果显示两个值不相等（这就是 jne 指令测试）第四条指令跳回到循环的顶部。假设一个大小为 64KB 的虚拟地址空间。我们还假定页面大小为 1KB。 页表：物理地址 1KB(1024) 代码段：虚拟地址 1KB,大小 1KB,VPN=1,映射到物理页 4(VPN 1-&amp;gt;PFN 4) 数组：4000 字节（1000X4)，int占4字节,我们假设它驻留在虚拟地址 40000 到 44000（不包括最后一个字节）。(VPN 39 → PFN 7), (VPN 40 → PFN 8), (VPN 41 → PFN 9), (VPN 42 → PFN 10)当它运行时，每个指令将产生两个内存引用：一个访问页表以查找指令所在的物理框架，另一个访问指令本身将其提取到 CPU 进行处理另外，在 mov 指令的形式中，有一个显式的内存引用，这会首先增加另一个页表访问（将数组虚拟地址转换为正确的物理地址），然后时数组访问本身。图 18.7 展示了前 5 次循环迭代的整个过程。左边虚拟地址和右边实际物理地址。 访问页表取物理地址，1024 是指令所在内存对应的页表，1174 是数组所在内存对应的页表 访问数组内存 访问代码段内存取指令小结分页（paging）不会导致外部碎片，因为分页（按设计）将内存划分为固定大小的单元。其次，它非常灵活，支持稀疏虚拟地址空间会导致较慢的机器（有许多额外的内存访问来访问页表）和内存浪费（内存被页表塞满而不是有用的应用程序数据）。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十三) 空闲空间管理", "url": "/posts/operating-systems-13/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-09 10:00:00 +0800", "snippet": "要满足变长的分配请求，应该如何管理空闲空间？什么策略可以让碎片最小化？不同方法的时间和空间开销如何？假设通过 malloc()和 free()分配释放内存只有外部碎片分配后不能移动，大小固定底层机制 空闲链表分割：合并： 追踪已分配空间的大小为每块分配的空间添加头块，实际占用空间是头块大小加上分配大小。头块包括分配大小和幻数，幻数用于验证，是个固定常数，如 1234567释放时，头块也要释放 嵌入空闲列表head 指向空闲列表头，组成一个空闲列表。合并空闲空间需要遍历。 让堆增长类似 sbrk 可以扩展堆大小基本策略 最优匹配 遍历整个空闲列表，选择最接近用户请求大小的块，从而尽量避免空间浪费，但遍历要付出较高的性能代价。 最差匹配 最差匹配（worst fit）方法与最优匹配相反，它尝试遍历找最大的空闲块，分割并满足用户需求后，将剩余的块（很大）加入空闲列表。大多数研究表明它的表现非常差，导致过量的碎片，同时还有很高的开销 首次匹配 首次匹配（first fit）策略就是找到第一个足够大的块，将请求的空间返回给用户。无需全遍历 下次匹配 不同于首次匹配每次都从列表的开始查找，下次匹配（next fit）算法多维护一个指针， 指向上一次查找结束的位置。其想法是将对空闲空间的查找操作扩散到整个列表中去，避免对列表开头频繁的分割。这种策略的性能与首次匹配很接它，同样避免了遍历查找。无需全遍历 其他方式 分离空闲列表(segregated list)如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象。其他大小的请求都一给更通用的内存分配程序。比如 16KB 大小的块列表，好处是不会产生碎片。 伙伴系统空闲空间首先从概念上被看成大小为 2^N 的大空间。当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小（再一分为二就无法 满足）。形成一棵二叉树递归合并伙伴，如果将这个 8KB 的块归还给空闲列表，分配程 序会检查“伙伴”8KB 是否空闲。如果是，就合二为一，变成 16KB 的块。然后会检查这 个 16KB 块的伙伴是否空闲，如果是，就合并这两块。每对互为伙伴的块的内存地址只有一位不同，找到对应伙伴很容易小结讨论了最基本的内存分配程序形式。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十二) 分段", "url": "/posts/operating-systems-12/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-09 09:00:00 +0800", "snippet": "结合上一节，堆和栈之间有一大块“空闲”空间，如果没被使用，也占用了物理内存。如果虚拟内存地址空间很大，对物理内存也是极大的浪费分段：泛化的基址/界限在 MMU 中引入三对基址和界限寄存器，每个逻辑段（segment）一对：代码、栈和堆只有已用的内存才在物理内存中分配空间，因此可以容纳巨大的地址空间，其中包含大量未使用的地址空间（有时又称为稀疏地址空间，sparse address spaces）。段寄存器的值: 段 基址 大小 代码 32KB 2KB 堆 34KB 2KB 栈 28KB 2KB 比如访问 100，是在代码段中，物理地址则是 32KB+100=32868，然后判断是否在界限 32KB+2KB 内，合法时发起对物理地址的访问比如访问 4200，是在堆段中，先找到相对于堆段起始位置偏移量 4200-4096=104，物理地址是 34KB+104=34920 段错误指的是在支持分段的机器上发生了非法的内存访问。越界访问会造成段异常（segmentation violation）或段错误（segmentation fault）引用段的方式 显式（explicit）方式 就是用虚拟地址的开头几位来标识不同的段 // get top 2 bits of 14-bit VA 2Segment = (VirtualAddress &amp;amp; SEG_MASK) &amp;gt;&amp;gt; SEG_SHIFT// now get offsetOffset = VirtualAddress &amp;amp; OFFSET_MASKif (Offset &amp;gt;= Bounds[Segment]) RaiseException(PROTECTION_FAULT)else PhysAddr = Base[Segment] + Offset Register = AccessMemory(PhysAddr) 隐式（implicit）方式 硬件通过地址产生的方式来确定段。例如，如果地址由程序计数器产生（即它是指令获取），那么地址在代码段。如果基于栈或基址指针，它一定在栈段。其他地址则在堆段 栈栈的增长方向和代码及堆相反。除了基址和界限外，硬件还需要知道段的增长方向（用一位区分，比如 1 代表自小而大增长，0 反之）假设要访问虚拟地址 15KB，它应该映射到物理地址 27KB。该虚拟地址的二进制形式是：11 1100 0000 0000（十六进制 0x3C00）。硬件利用前两位（11）来指定段，但然后我们要处理偏移量 3KB。为了得到正确的反向偏移，我们必须从 3KB 中减去最大的段地址：在这个例子中，段可以是4KB(图上显示是 2KB，假设最大是能到 4KB 的)，因此正确的偏移量是 3KB 减去 4KB，即−1KB。 只要用这个反向偏移量（−1KB）加上基址（28KB），就得到了正确的物理地址 27KB。用户可以进行界限检查，确保反向偏移量的绝对值小于段的大小。支持共享要节省内存，有时候在地址空间之间共享（share）某些内存段是有用的为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。基本为每个段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。通过将代码段标记为只读，同样的代码可以被多个进程共享，而不用担心破坏隔离。虽然每个进程都认为自己独占这块内存，但操作系统秘密地共享了内存，进程不能修改这些内存，所以假象得以保持比如同一份二进制文件运行多个进程,可以共享代码段图中代码段的权限是可读和可执行，因此物理内存中的一个段可以映射到多个虚拟地址空间。有了保护位，前面描述的硬件算法也必须改变。除了检查虚拟地址是否越界，硬件还需要检查特定访问是否允许。如果用户进程试图写入只读段，或从非执行段执行指令，硬件会触发异常，让操作系统来处理出错进程。细粒度与粗粒度的分段 粗粒度的分段 比如只分成三个段，代码、栈、堆 细粒度的分段 将三个段进一步细分。操作系统可以更好地了解哪些段在使用哪些没有，从而可以更高效地利用内存。操作系统支持栈和堆之间没有使用的区域就不需要再分配物理内存细分后会产生外部碎片（external fragmentation）解决方案： 紧凑（compact）物理内存，重新安排原有的段 操作系统先终止运行的进程，将它们的数据复制到连续的内存区域中去，改变它们的段寄存器中的值，指向新的物理地址，从而得到了足够大的连续空闲空间 空闲列表管理算法 试图保留大的内存块用于分配。相关的算法可能有成百上千种，包括传统的最优匹配（best-fit，从空闲链表中找最接近需要分配空间的空闲块返回）、最坏匹配（worst-fit）、首次匹配（first-fit）以及像伙伴算法（buddy algorithm） [K68]这样更复杂的算法 参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十一) 机制：地址转换", "url": "/posts/operating-systems-11/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-08 11:00:00 +0800", "snippet": "高效、灵活地虚拟化内存。需要一种基于硬件的地址转换（hardware-based address translation），简称为地址转换（address translation）。将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。虚拟地址映射用户进程在物理内存中并不是从 0 地址开始的动态（基于硬件）重定位(dynamic relocation)进程的虚拟地址都是从 0 开始的进程中使用的内存引用都是虚拟地址（virtual address），硬件接下来将虚拟地址加上基址寄存器中的内容，得到物理地址（physical address），再发给内存系统。还有个界限寄存器，用于限制进程地址空间范围，进程不能访问为超过该值限制的虚拟地址空间，比如限制 16KB，则不能访问 17KB 的内存，硬件应该阻止转换成物理地址硬件支持：总结动态重定位：硬件要求 硬件要求 解释 特权模式 需要，以防用户模式的进程执行特权操作 基址/界限寄存器 每个 CPU 需要一对寄存器来支持地址转换和界限检查 能够转换虚拟地址并检查它是否越界 电路来完成转换和检查界限，在这种情况下，非常简单 修改基址/界限寄存器的特权指令 在让用户程序运行之前，操作系统必须能够设置这些值，需要特权模式 注册异常处理程序的特权指令 操作系统必须能告诉硬件，如果异常发生，那么执行哪些代码，需要特权模式 能够触发异常 如果进程试图使用特权指令或越界的内存 操作系统的职责 进程创建时，操作系统从空闲列表（free list）找到位置分配内存空间，并标记为已用 进程终止时，操作系统需要回收内存到空闲列表 上下文切换时，需要保存/加载基址和界限寄存器。比如放在进程结构或进程控制块 PCB 中。 当进程暂停时，操作系统可以切换其地址空间，只要分配新空间，拷贝，然后修改进程结构/PCB 里的基址寄存器就行 操作系统必须提供异常处理程序（exception handler），向硬件注册，当进程出现如越界访问等异常操作时，CPU 会执行这段异常处理程序，如终止该进程。受限直接执行协议（动态重定位）: 操作系统@启动（内核模式） 硬件   初始化陷阱表       记住以下地址：- 系统调用处理程序- 时钟处理程序- 非法内存处理程序- 非常指令处理程序   开始中断时钟       开始时钟，在 x ms 后中断   初始化进程表 初始化空闲列表     操作系统@运行（核心模式） 硬件 程序（用户模式） 为了启动进程 A：- 在进程表中分配条目- 为进程分配内存- 设置基址/界限寄存器(应该是写入进程结构)- 从陷阱返回（进入 A）       恢复 A 的寄存器转向用户模式跳到 A（最初）的程序计数器       进程 A 运行- 获取指令   转换虚拟地址并执行获取       执行指令   如果显式加载/保存- 确保地址不越界- 转换虚拟地址并执行- 加载/保存       ……   时钟中断转向内核模式跳到中断处理程序   处理陷阱调用 switch()例程- 将寄存器（A）保存到进程结构（A）（包括基址/界限）- 从进程结构（B）恢复寄存器（B）（包括基址/界限）从陷阱返回（进入 B）       恢复 B 的寄存器转向用户模式跳到 B 的程序计数器       进程 B 运行- 执行错误的加载   加载越界转向内核模式跳到陷阱处理程序   处理本期报告- 决定终止进程 B- 回收 B 的内存- 移除 B 在进程表中的条目     参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(十) 插叙：内存操作 API", "url": "/posts/operating-systems-10/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-08 10:00:00 +0800", "snippet": "在本章中，我们将介绍 UNIX 操作系统的内存分配接口内存类型 栈内存 它的申请和释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。比如，一个函数的局部变量，在进入函数时分配，退出时释放。 堆内存 申请和释放都是显式的，比如 C 语言的malloc。 malloc()调用malloc 的用法，应该都会，不介绍了free()调用释放 malloc 分配的空间calloc()调用类似 malloc()，返回前会将区域全置 0。realloc()创建一个更大的内存区域，并将旧区域拷贝到新区域常见错误 声明指针，但未分配空间 分配的空间不够，导致溢出 分配后未初始化 分配后忘记释放（带 GC 的语言可以自动回收内存） 在用完前释放了内存（悬挂指针） 重复释放内存 free()传入的指针参数错误进程结束时操作系统会回收所有内存，即使不进行 free()内存分析工具：purify和valgrind底层操作系统支持malloc 和 free 依赖于 brk 系统调用，用于改变程序分断(break)位置：堆结束位置。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(九) 抽象：地址空间", "url": "/posts/operating-systems-9/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-06-08 09:00:00 +0800", "snippet": "早期系统操作系统曾经是一组函数（实际上是一个库），在内存中（在本例中，从物理地址 0 开始），然后有一个正在运行的程序（进 程），目前在物理内存中（在本例中，从物理地址 64KB 开始）， 并使用剩余的内存。这里几乎没有抽象。多道程序和时分共享3 个进程（A、B、C），每个进程拥有从 512KB 物理内存中切出来给它们的一小部分内存。假定只有一 个 CPU，操作系统选择运行其中一个进程（比如 A），同时其 他进程（B 和 C）则在队列中等待运行。地址空间 代码 程序代码位置，静态的 栈 向上增长，不一定放在底部 堆 向下增长，不一定放在代码段下这个 0-16KB 的地址空间是虚拟的，不是实际的物理地址（0 物理地址一般是 boot 程序，不可能给一个用户程序用）内存虚拟化也保证了隔离性和安全性。目标 透明：进程不知道自己运行在虚拟内存环境下，就好像地址都是物理地址一样 效率：虚拟化时不应该拖慢调度和运行时间，不应该占用更多内存 保护：不会影响操作系统和其他进程的内存空间小结参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "Orangepi4维护指南", "url": "/posts/orangepi4-maintain/", "categories": "教程", "tags": "orangepi4, maintain, shell", "date": "2022-05-30 09:00:00 +0800", "snippet": "固件使用 Armbian focal cli 版本，基于 Ubuntu server 20.04armbian 官网存储外置 USB 硬盘自动休眠修改 etc 配置# /etc/hdparm.conf/dev/sda { write_cache = on spindown_time = 120}立刻休眠# 省电standbyhdparm -y /dev/sda# 休眠sleephdparm -Y /dev/sda测速# 非缓存hdparm -t /dev/sda# 缓存hdparm -T /dev/sda空间占用# 总使用情况df -h# 具体目录和一级子目录使用情况du -d 1 -h# 具体目录，不包含子目录使用情况du -s -hsmart 健康状态查询smartctl -a /dev/sda查看目录被进程占用# fuserfuser -aumv /mnt/disk3# 递归查找某个目录中被打开的文件信息lsof +D /var/log/nginx查看进程 IO 情况iotop 实时统计：iotop -oPpidstat 连续统计：pidstat -d 1代理启动 udp2raw_arm启动 v2ray状态查看htopvideomanage生成缩略图 进入/home/dev/videomanager/vcsithumb/ 修改 config.ini 执行 python3 vcsithumb.py(root 用户)更新数据库 进入/home/dev/videomanager/videodb/ 修改 config.ini 备份 videodb.db 执行 python3 videodb.py(dev 用户)编译 web 进入/home/dev/videomanager/videoweb/ 执行 npm run build(dev 用户)安装openjdk安装openjdk参考 linux 查看哪个进程占用磁盘 IO_带鱼兄的博客-CSDN 博客_linux 查看磁盘被哪个进程占用 Linux hdparm 命令 | 菜鸟教程 fuser 与 lsof – 查看文件被哪些进程占用 - 常四 - 博客园" }, { "title": "DLMS Green Book学习笔记", "url": "/posts/dlms-green-1/", "categories": "技术", "tags": "C++, DAO, database", "date": "2022-04-19 09:00:00 +0800", "snippet": " s1 Scope s3 Terms, definitions and abbreviations and symbols s3.1 General DLMS/COSEM definitions s4 Information exchange in DLMS/COSEM s4.1 General s4.2 Communication model s4.3 Naming and addressing s4.3.3 Addressing s4.3.4 System title s4.3.5 Logical Device Name s4.4 Connection oriented operation s4.5 Application associations s4.5.2 Application context s4.5.3 Authentication s4.5.4 xDLMS context s4.5.5 Security context s4.5.6 Access rights s4.6 Messaging patterns s4.8 Communication profiles s4.9 Model of a DLMS/COSEM system s4.10 Model of DLMS servers s4.11 Model of a DLMS client s4.12 Interoperability and interconnectivity in DLMS/COSEM s4.13 Ensuring interconnectivity: the protocol identification service s4.14 System integration and installation s5 Physical layer services and procedures for connection-oriented asynchronous data exchange s5.1 Overview s5.2 Service specification s5.2.1 List of services s5.2.2 Use of the physical layer services s5.2.3 Service definitions s5.3 Protocol specification s5.3.1 Physical layer protocol data unit s5.3.2 Transmission order and characteristics s5.3.3 Physical layer operation – description of the procedures s5.3.3.1 General s5.3.3.2 Setting up a physical connection s5.3.3.3 The Identification service s5.3.3.4 Data transfer s5.3.3.5 Disconnection of an existing physical connection s5.4 example: PhL service primitives and Hayes commands s6 Direct Local Connection s7 DLMS/COSEM transport layer for IP networks s7.2 The TCP-UDP/IP based transport layers s7.2.3 The DLMS/COSEM connection-less, UDP-based transport layer s7.2.3.3.2 The wrapper protocol data unit (WPDU) s7.2.4 The DLMS/COSEM connection-oriented, TCP-based transport layer sTCP-CONNECT sTCP-DISCONNECT sTCP-ABORT sTCP-DATA s7.2.4.3 Protocol specification for the DLMS/COSEM TCP-based transport layer s7.2.4.3.5 Definition of the procedures s7.2.5 Converting OSI-style TL services to and from RFC-style TCP function calls s7.2.5.1 Transport layer and TCP connection establishment s7.2.5.2 Closing a transport layer and a TCP connection s7.2.5.3 TCP connection abort s7.2.5.4 Data transfer using the TCP-DATA service s7.3 The DLMS/COSEM CoAP based transport layer s7.3.2 Overview s7.3.3 Structure of the DLMS/COSEM CoAP transport layer s7.3.3.2 Identification and addressing s7.3.3.2.2 DLMS/COSEM AL identification within the CoAP transport layer sDLMS/COSEM CoAP transport layer SAPs s7.3.4 Service specification for the DLMS/COSEM CoAP transport layer s7.3.4.2 The DLMS/COSEM CoAP-DATA service primitives s7.3.4.2.1 CoAP-DATA.request s7.3.4.2.2 CoAP-DATA.indication s7.3.4.2.2 CoAP-DATA.confirm s7.3.5 Protocol specification of the DLMS/COSEM CoAP transport layer s7.3.5.2 The DLMS/COSEM CoAP TL Protocol Data Unit (CoAP-PDU) s7.3.5.3 The DLMS/COSEM CoAP Wrapper Protocol Data Unit (CWPDU) s7.3.5.4 The Constrained Application Protocol (CoAP) s7.3.5.4.2 The CoAP Message s7.3.5.4.3 CoAP retransmission and response piggybacking s7.3.5.4.5 CoAP Block Transfer s7.3.5.5 Error Handling s7.3.5.5.2 CoAP protocol layers s7.3.5.5.3 CoAP wrapper layer s7.3.5.5.4 Propagation of errors through CoAP wrapper layer s7.3.5.6 DLMS/COSEM CoAP TL confirmations s7.3.5.7 CoAP wrapper state machine s7.3.5.7.2 CoAP DLMS/COSEM wrapper request/response context s7.3.5.7.4 CoAP-DATA.request invocation handling s7.3.5.7.5 Handling of incoming CWPDU or CoAP layer transmission failures s7.3.5.7.6 Garbage collection s7.3.6 DLMS/COSEM CoAP TL Data Transfers s7.3.6.2 General transfer of confirmed DLMS/COSEM AL service requests s7.3.6.3 Reliable DLMS/COSEM CoAP TL operation s7.3.6.4 Unreliable DLMS/COSEM CoAP TL operation s7.3.6.5 DLMS/COSEM CoAP Block Transfer operation s7.3.6.6 DLMS GBT operation over DLMS/COSEM CoAP TL s8 Data Link Layer using the HDLC protocol s8.1 Overview s8.1.2 Structure of the data link layer s8.1.3 Specification method s8.2 Service specification s8.2.2 Setting up the data link connection: the DL-CONNECT and MA-CONNECT services s8.2.2.2 DL-CONNECT.request and MA-CONNECT.request s8.2.2.3 DL-CONNECT.indication and MA-CONNECT.indication s8.2.2.4 DL-CONNECT.response and MA-CONNECT.response s8.2.2.5 DL-CONNECT.confirm and MA-CONNECT.confirm s8.2.3 Disconnecting the data link connection: the DL-DISCONNECT and MA-DISCONNECT services s8.2.3.2 DL-DISCONNECT.request and MA-DISCONNECT.request s8.2.3.3 DL-DISCONNECT.indication and MA-DISCONNECT.indication s8.2.3.4 DL-DISCONNECT.response and MA-DISCONNECT.response s8.2.3.5 DL-DISCONNECT.confirm and MA-DISCONNECT.confirm s8.2.4 Data transfer: the DL-DATA and MA-DATA services s8.2.4.2 DL-DATA.request and MA-DATA.request s8.2.4.3 DL-DATA.indication and MA-DATA.indication s8.2.4.4 DL-DATA.confirm and MA-DATA.confirm s8.2.5 Physical layer services used by the MAC sublayer s8.2.5.4 Data transfer s8.3 Protocol specification for the LLC sublayer s8.3.2 LLC PDU format s8.3.3 State transition tables for the LLC sublayer s8.4 Protocol specification for the MAC sublayer s8.4.1 The MAC PDU and the HDLC frame s8.4.1.1 HDLC frame format type 3 s8.4.2 MAC addressing s8.4.2.2 Address field structure s8.4.2.3 Reserved special HDLC addresses s8.4.2.4 Handling special addresses s8.4.2.5 Handling inopportune address lengths in the server s8.4.3 Command and response frames s8.4.4 Elements of the procedures s8.4.4.2 Transmission considerations s8.4.4.3 HDLC channel states s8.4.5 HDLC channel operation – Description of the procedures s8.4.5.2 Data station characteristics s8.4.5.3 Procedures for setting up and disconnecting the data link s8.4.5.4 Procedures for data exchange s8.4.5.5 Exception recovery s8.4.5.6 Time-outs and other MAC sublayer parameters s8.4.5.7 State transition diagram for the server MAC sublayer s8.5 FCS calculation s8.5.1 Test sequence for the FCS calculation s8.5.2 Fast frame check sequence (FCS) implementation s8.5.3 16-bit FCS computation method s8.6 Data link layer management services s9 DLMS/COSEM application layer s9.1 DLMS/COSEM application layer main features s9.1.2 DLMS/COSEM application layer structure s9.1.3 The Association Control Service Element, ACSE s9.1.4 The xDLMS application service element s9.1.4.2 The xDLMS initiate service s9.1.4.3 COSEM object related xDLMS services s9.1.4.3.2 xDLMS services used by the client with LN referencing s9.1.4.3.3 xDLMS services used by the client with SN referencing s9.1.4.3.4 Unsolicited services s9.1.4.3.5 Selective access s9.1.4.3.6 Multiple references s9.1.4.3.7 Attribute_0 referencing s9.1.4.4 Additional mechanisms s9.1.4.4.2 Referencing methods and service mapping s9.1.4.4.3 Identification of service invocations: the Invoke_Id parameter s9.1.4.4.4 Priority handling s9.1.4.4.5 Transferring long messages s9.1.4.4.6 Composable xDLMS messages s9.1.4.4.7 Compression and decompression s9.1.4.4.8 General protection sGeneral block transfer (GBT) s9.1.4.5 Additional data types s9.1.4.6 xDLMS version number s9.1.4.7 xDLMS conformance block s9.1.4.8 Maximum PDU size s9.1.5 Layer management services s9.1.6 Summary of DLMS/COSEM application layer services s9.1.7 DLMS/COSEM application layer protocols s9.2 Information security in DLMS/COSEM s9.2.2 The DLMS/COSEM security concept s9.2.2.2 Identification and authentication s9.2.2.2.1 Identification s9.2.2.2.2 Authentication mechanisms s9.2.2.3 Security context s9.2.2.4 Access rights s9.2.2.5 Application layer message security s9.2.2.6 COSEM data security s9.2.3 Cryptographic algorithms s9.2.3.2 Hash function s9.2.3.3 Symmetric key algorithms s9.2.3.3.2 Encryption and decryption s9.2.3.3.3 Advanced Encryption Standard s9.2.3.3.4 Encryption Modes of Operation s9.2.3.3.5 Message Authentication Code s9.2.3.3.6 Key wrapping s9.2.3.3.7 Galois/Counter Mode s9.2.3.3.8 AES key wrap s9.2.3.4 Public key algorithms s9.2.3.4.2 Elliptic curve cryptography s9.2.3.4.3 Data conversions s9.2.3.4.4 Digital signature s9.2.3.4.5 Elliptic curve digital signature (ECDSA) s9.2.3.4.6 Key agreement s9.2.3.5 Random number generation s9.2.3.6 Compression s9.2.3.7 Security suite s9.2.4 Cryptographic keys – overview s9.2.5 Key used with symmetric key algorithms s9.2.5.1 Symmetric keys types s9.2.5.2 Key information with general-ciphering APDU and data protection s9.2.5.3 Key identification s9.2.5.4 Key wrapping s9.2.5.5 Key agreement s9.2.5.6 Symmetric key cryptoperiods s9.2.6 Keys used with public key algorithms s9.2.6.2 Key pair generation s9.2.6.3 Public key certificates and infrastructure s9.2.6.3.2 Trust model s9.2.6.3.3 PKI architecture – informative s9.2.6.4 Certificate and certificate extension profile s9.2.6.4.2 The X.509 v3 Certificate s9.2.6.5 Suite B end entity certificate types to be supported by DLMS servers s9.2.6.6 Management of certificates s9.2.6.6.2 Provisioning servers with trust anchors s9.2.6.6.3 Provisioning the server with further CA certificates s9.2.6.6.4 Security personalisation of the server s9.2.6.6.5 Provisioning servers with certificates of clients and third parties s9.2.6.6.6 Provisioning clients and third parties with certificates of servers s9.2.6.6.7 Certificate removal from the server s9.2.7 Applying cryptographic protection s9.2.7.2 Protecting xDLMS APDUs s9.2.7.2.2 Security policy and access rights values s9.2.7.2.3 Ciphered xDLMS APDUs s9.2.7.2.4 Encryption, authentication and compression s9.2.7.2.5 Digital signature s9.2.7.3 Multi-layer protection by multiple parties s9.2.7.4 HLS authentication mechanisms s9.2.7.5 Protecting COSEM data s9.3 DLMS/COSEM application layer service specification s9.3.1 Service primitives and parameters s9.3.2 The COSEM-OPEN service s9.3.2.3 Use s9.3.3 The COSEM-RELEASE service s9.3.4 The COSEM-ABORT service s9.3.5 Protection and general block transfer parameters s9.3.6 The GET service s9.3.7 The SET service s9.3.8 The ACTION service s9.3.9 The ACCESS service s9.3.9.2 Service specification s9.3.10 The DataNotification service s9.3.11 The EventNotification service s9.3.12 The TriggerEventNotificationSending service s9.3.13 Variable access specification s9.3.14 The Read service s9.3.15 The Write service s9.3.16 The UnconfirmedWrite service s9.3.17 The InformationReport service s9.3.18 Client side layer management services: the SetMapperTable.request s9.4 DLMS/COSEM application layer protocol specification s9.4.1 The control function (CF) s9.4.1.1 State definitions of the client side control function s9.4.1.2 State definitions of the server side control function s9.4.2 The ACSE services and APDUs s9.4.2.1 ACSE functional units, services and service parameters s9.4.2.2 Registered COSEM names s9.4.3 APDU encoding rules s9.4.3.1 Encoding of the ACSE APDUs s9.4.3.2 Encoding of the xDLMS APDUs s9.4.3.3 XML s9.4.4 Protocol for application association establishment s9.4.4.1 Protocol for the establishment of confirmed application associations s9.4.4.2 Repeated COSEM-OPEN service invocations s9.4.4.3 Establishment of unconfirmed application associations s9.4.4.4 Pre-established application associations s9.4.5 Protocol for application association release s9.4.6 Protocol for the data transfer services s9.4.6.1 Negotiation of services and options – the conformance block s9.4.6.2 Confirmed and unconfirmed xDLMS service invocations s9.4.6.3 Protocol for the GET service s9.4.6.4 Protocol for the SET service s9.4.6.5 Protocol for the ACTION service s9.4.6.6 Protocol for the ACCESS service s9.4.6.7 Protocol of the DataNotification service s9.4.6.8 Protocol for the EventNotification service s9.4.6.9 Protocol for the Read service s9.4.6.10 Protocol for the Write service s9.4.6.11 Protocol for the UnconfirmedWrite service s9.4.6.12 Protocol for the InformationReport service s9.4.6.13 Protocol of general block transfer mechanism s9.4.6.13.2 The GBT procedure s9.4.6.13.3 GBT procedure state variables s9.4.6.13.7 GBT protocol examples s9.4.6.13.8 Aborting the GBT procedure s9.4.6.14 Protocol of exception mechanism s9.5 Abstract syntax of COSEM PDUs s9.6 COSEM PDU XML schema s10 Using the DLMS/COSEM application layer in various communications profiles s10.1 Communication profile specific elements s10.2 The 3-layer, connection-oriented, HDLC based ommunication profile s10.2.2 The structure of the profile s10.2.3 Identification and addressing scheme s10.2.4 Supporting protocol layer services and service mapping s10.2.5 Communication profile specific service parameters of the DLMS/COSEM AL services s10.2.6 Specific considerations / constraints s10.2.6.1 Confirmed and unconfirmed AAs and data transfer service invocations, frame types used s10.2.6.2 Correspondence between AAs and data link layer connections, releasing AAs s10.2.6.3 Service parameters of the COSEM-OPEN / -RELEASE / -ABORT services s10.2.6.4 EventNotification service and protocol s10.2.6.5 Transporting long messages s10.2.6.6 Supporting multi-drop configurations s10.3 The TCP-UDP/IP based communication profiles (COSEM_on_IP) s10.3.6 Specific considerations / constraints s10.3.6.6 Transporting long messages s10.3.6.7 Allowing COSEM servers to establish the TCP connection s10.4 The CoAP based communication profile (DLMS/COSEM_on_CoAP) s10.4.3 Identification and addressing s10.4.4 Supporting layer services and service mapping s10.4.6 Specific considerations / constraints s10.8 LPWAN profile s10.9 Wi-SUN profile s10.10 Gateway protocol s11 AARQ and AARE encoding examples s12 Encoding examples: AARQ and AARE APDUs using a ciphered application context s13 S-FSK PLC encoding examples s14 Data transfer service examples s14.4 Profile generic IC buffer attribute encoding examples s14.4.3 Get-response with Profile generic null-data compressed encoding example s14.4.4 Get-response with Profile generic compact-array encoding example s14.4.5 Get-response with Profile generic null-data and delta-value encoding example s1 Scope 建模: 包括设备的接口模型和数据识别规则;在 blue book 中定义 消息: 这涵盖了将接口模型映射到协议数据单元(APDU)的服务，以及这个 APDU 的编码。在本 green book 中定义 传输: 通过通信通道传输消息。在本 green book 中定义通信模型：s3 Terms, definitions and abbreviations and symbolss3.1 General DLMS/COSEM definitions ACSE APDU：Association Control Service Element (ACSE)标准 A-ASSOCIATE/A-RELEASE 实现的 APDU，AARQ/AARE/RLRQ/RLRE application association：两个应用实体 AEs 之间的合作关系 application entity,AE: 独立于系统的应用活动，这些活动作为应用服务提供给应用代理，例如，一组应用服务元素，它们共同执行应用程序的所有或部分通信方面。 xDLMS APDU：xDLMS Application Service Element (xDLMS ASE)使用的 APDUs4 Information exchange in DLMS/COSEMs4.1 GeneralThe key characteristics of data exchange using DLMS/COSEM are the following: devices can be accessed by various parties: clients and third parties; 使用 DLMS/COSEM 进行数据交换的主要特点如下:设备可以被各种各方访问:客户端和第三方; mechanisms to control access to the resources of the device are provided; 提供了控制对设备资源的访问的机制; these mechanisms are made available by the DLMS/COSEM AL and the COSEM objects ( Association SN / LN object, Security setup object); 这些机制是由 DLMS/COSEM AL 和 COSEM 对象(关联 SN / LN 对象，安全设置对象)提供的; security and privacy is ensured by applying cryptographical protection to xDLMS messages and to COSEM data; 通过对 xDLMS 消息和 COSEM 数据应用加密保护来确保安全性和私密性; low overhead and efficiency is ensured by various mechanisms including selective access, compact encoding and compression; 通过各种机制，包括选择性访问、压缩编码和压缩，确保了低开销和效率; at a site, there may be single or multiple devices. 在一个站点，可能有单个或多个设备。 In the case of multiple devices at a site, a single access point can be made available; 在一个站点有多个设备的情况下，可以提供一个单一的接入点; data exchange may take place either remotely or locally. 数据交换可以在远程或本地进行。 Depending on the capabilities of the device, local and remote data exchange may be performed simultaneously without interfering with each other; 根据设备的能力，本地和远程数据交换可以在不相互干扰的情况下同时进行; various communication media can be used on local networks (LN), neighbourhood networks (NN) and wide area networks (WAN). 各种通信媒体可用于局域网(LN)、邻网(NN)和广域网(WAN)。 s4.2 Communication modelapplication processes(APs)之间的通信通过应用程序实体(application entities,AEs)之间的通信进行建模。AE 代表 AP 的通信功能。AP 中可能有多组OSI 通信功能，因此一个AP可以用多种AEs来表示（比如一个 AP 可以使用 HDLC-based profile，也可以使用 TCP-IP based profile）。一个 AE 只对应一个 AP（可能两个 AP 都使用 HDLC-based profile，这两个 AE 也是不同的，可以理解为类和对象的关系，基于同一个类的两个对象实例化后是不同的）。一个 AE 包含一组称为 application service elements(ASEs)的通信功能 TODO:AE 的意思还不明确s4.3 Naming and addressing一个server AP对应一个logical device,client AP可以不对应 logical device。每个AP绑定一个 Service Access Point(SAP)，SAP位于 application layer(AL)层。也就是说 SAP 用于区分基于同一个 AL 的不同 AP(对服务端也可以说是 logical device).s4.3.3 AddressingSAP 用于区分基于同一个 AL 的不同 APs4.3.4 System title 按单一 DLMS/COSEM 实体唯一，和逻辑设备名不同，一个实体可以有多个逻辑设备(名)，但只能有一个systemtitle,实体中的逻辑设备共享该 systemtitle 固定8字节长，前 3 字节厂家 ID，和逻辑设备名相同，后面的 5 字节，应为 0-999,999,999,999(0x0-0xE8D4A50FFF)交换方式（见 10.4.3.3）： 通信配置注册过程 在明确建立 AA 的情况下，在 AA 建立期间使用COSEM-OPEN服务; 通过在“Security setup”对象写入 client_system_title 属性和读取的 server_system_title 属性。适用于预连接 AA 加密 APDU 交换，general-ciphering (originator and recipient system title)或 general-glo-ciphering (originator system title).s4.3.5 Logical Device Name蓝皮书 part2 4.1.8s4.4 Connection oriented operation Phase 1: AA establishment Phase 2: Message exchange Phase 3: AA Release预连接AA不需要 1 和 3s4.5 Application associationsApplication Associations (AAs)是一个客户端AE和一个服务端AE间的逻辑连接。可以使用 ACSE 服务建立，也可以是预连接的一个 COSEM 逻辑设备可以支持一个或多个 AAs，每个 AAs 有一个不同的客户端。每个 AA 决定发生信息交换的上下文。 confirmed AA: confirmed AA由客户端提出并被服务器接受，前提是： 客户端用户为服务器所知，见 4.3.6; 客户端在 4.5.2 中提出的应用上下文对于服务器来说是可接受的; 客户端(见 4.5.3)提出的认证机制对服务器来说是可接受的，认证是成功的; xDLMS 上下文的元素参见 4.5.4 可以在客户端和服务器之间成功协商。 unconfirmed AA: 客户端也会提出未经确认的AA，并假设服务器会接受它。 没有协商发生。 未确认的 AA 对于从客户端向服务器发送广播消息很有用。 s4.5.2 Application context应用程序上下文确定： AL 中存在的一组应用服务元素（Application Service Elements,ASEs） COSEM 对象属性和方法的引用方式：短名称(SN) 引用或逻辑名称(LN) 引用。 另见 9.1.4.3.1 传输语法 是否使用加密s4.5.3 AuthenticationDLMS 中的认证发生在 AA 建立阶段 在confirmed AAs中，客户端(单向认证)或客户端和服务器(双向认证)都可以对对端进行认证。 对于unconfirmed AA，只有客户端可以验证对端。 在预连接AA中，身份验证不可用。s4.5.4 xDLMS contextxDLMS 上下文确定可以在给定的 AA 中使用的 xDLMS 服务和功能集。见 9.1.4。 additional services, see 9.1.4.3; additional mechanisms, see 9.1.4.4; additional data types, see 9.1.4.5; new DLMS version number, see 9.1.4.6; new conformance block, see 9.1.4.7; clarification of the meaning of the PDU size, see 9.1.4.8.s4.5.5 Security context当应用程序上下文规定加密时，安全上下文是相关的。 它包括安全套件、安全策略、安全密钥和其他安全材料。 另见 9.2.2.3。 它由“Security setup”对象管理。s4.5.6 Access rights访问权限确定客户访问 AA 内的 COSEM 对象属性和方法的权限。 访问权限集取决于客户端的角色，并在服务器中预先配置。 另见 9.2.2.4。s4.6 Messaging patterns在confirmed AA 中： 客户端可以发送确认的服务请求，服务器响应：pull操作 客户端可以发送未经确认的服务请求。 服务器没有响应 服务器可以向客户端发送未经请求的服务请求：push操作 note:主动推送的服务可以是 InformationReport（使用 SN 引用）、EventNotification（使用 LN 引用）或 DataNotification（同时使用 SN 和 LN 引用）。在unconfirmed AA 中： 只有客户端可以发起服务请求，并且只有未确认的请求。 服务器无法响应，也无法发起服务请求。s4.8 Communication profiles通信配置文件指定了 DLMS/COSEM AL 和建模 Application Process (AP) 的 COSEM 数据模型如何由较低的通信媒体特定协议层支持。通信配置文件包括许多协议层。 每一层都有不同的任务并为其上层提供服务并使用其支持协议层的服务。 客户端和服务器 COSEM AP 使用最高协议层的服务，即 DLMS/COSEM AL 的服务。 这是唯一包含 COSEM 特定元素(xDLMS ASE)的协议层； 见 9.1.4。 任何能够提供 DLMS/COSEM AL 所需服务的层都可以支持它。 较低层的数量和类型取决于所使用的通信媒体。s4.9 Model of a DLMS/COSEM system设备被建模为一组逻辑设备，托管在单个物理设备中。 每个逻辑设备代表一个服务器 AP，并对设备功能的一个子集进行建模，这些功能子集可以通过其通信接口看到。使用 COSEM 对象对各种功能进行建模。数据采集系统被建模为一组客户端ap，可以由一个或多个物理设备托管。每个客户端 AP 可能有不同的角色和访问权限，由设备授予。公共客户端0x10和管理逻辑设备0x01APs 有一个特殊的角色，它们应该一直存在。s4.10 Model of DLMS servers IP based profiles:DLMS/COSEM AL由 DLMS/COSEM Transport layer(TL)支持，该 TL 由 internet TCP 或 UDP 层和一个包装器(wrapper)组成。包装器的主要作用是适应OSI风格的服务集，该服务集由 DLMS/COSEM TL 在 TCP 和 UDP 函数调用之间提供。它还为逻辑设备提供寻址，将它们绑定到一个称为包装器端口的SAP。管理逻辑设备总是绑定到包装器端口0x01。最后，包装器提供有关 APDU 传输长度的信息，以帮助对等端识别 APDU 的末端。由于 TCP 的流特性，这是必要的。如果没有包装器这层，APDU 直接通过 TCP 发出去，由于 TCP 是流式的，APDU 不包含头尾信息，对端不知道是否是个完整的 APDU，无法解析 3-layer,CO,HDLC based profile:DLMS/COSEM AL 由基于 HDLC 的数据链路层支持。 它的主要作用是在对等层之间提供可靠的数据传输。 它还以这样一种方式提供逻辑设备的寻址，即每个逻辑设备都绑定到单个 HDLC 地址。 管理逻辑设备始终绑定到地址 0x01。 为了允许创建一个本地网络，以便通过一个单一的接入点可以到达特定站点的几个物理设备，另一个地址，即物理设备地址也由数据链路层提供。 逻辑设备地址被称为高 HDLC 地址，而物理设备地址被称为低 HDLC 地址。 另见 8.4.2s4.11 Model of a DLMS client客户端模型 DLMS/COSEM AL 使用 HDLC 或 IP-based TLs 提供的服务，由AP决定使用哪种。 与服务器端不同，客户端的 HDLC 层提供的寻址只有一个级别，即每个应用程序流程(AP)的服务接入点(SAP)的级别。(也就是没有物理地址级别，见8.4.2，原语参数中客户端地址只有一个字节，就是 SAP 地址)客户端 AP 和服务器端 AP 由各自的SAP识别，因此，客户端和服务器端 AP 之间的AA可以由一对客户端和服务器端SAP识别。s4.12 Interoperability and interconnectivity in DLMS/COSEM互操作性和互联性 Interoperability： 双方的 COSEM 对象定义相同，都使用 DLMS/COSEM AL 层 interconnectivity： AEs 互联。如果两个 AEs 使用相同的通信配置文件，则它们是可互联的 s4.13 Ensuring interconnectivity: the protocol identification service协议识别服务在 DLMS/COSEM 中，AA 的建立总是由客户端AE发起。然而，在某些情况下，它可能不了解未知服务器设备所使用的协议栈（例如，当服务器启动物理连接建立时）。在这种情况下，客户端 AE 需要获得关于服务器中实现的协议栈的信息。为此，提供了一种特定的应用级服务：协议识别服务。它是一种可选的应用级服务，允许客户机 AE 在建立物理连接后获得关于服务器中实现的协议栈的信息。5.3.3.3 中规定的协议识别服务直接使用 PhL 的数据传输服务（PH-DATA.request /.indicat）；它绕过了其他协议层。建议在所有可以访问 PhL 的通信配置文件中支持它。s4.14 System integration and installation系统集成和安装DLMS/COSEM 以多种方式支持系统集成。这里描述了一个可能的过程。如图 7 所示，Public Client(在任何配置文件中绑定到地址0x10)在每个客户端系统中都是必需的。它的主要作用是揭示一个未知的–例如新安装的–设备的结构。这发生在公共客户端和管理逻辑设备之间的强制AA中，没有安全预防措施。一旦知道了结构，就可以使用适当的身份验证机制和 xDLMS 的密码保护来访问数据当系统中安装了新设备时，可能会向客户端生成事件报告。一旦检测到这一点，客户机就可以检索设备的内部结构，然后向设备发送必要的配置信息(例如关税时间表和特定于安装的参数)。这样，设备就可以使用了s5 Physical layer services and procedures for connection-oriented asynchronous data exchange物理层s5.1 Overview 通信是点对点或点对多点 至少可以有半双工连接 异步传输 1 位起始位，8 位数据位，无奇偶校验和 1 位停止位(8N1) 串口通信原理 9600 8N1 代表着波特为 9600，8 个数据位，无奇偶校验和 1 个停止位，这一种是较为常用的串行协议配置方法。那么，9600 8N1 的数据包是什么样的呢？举个例子吧！传输 ASCII 字符’O‘和’K‘的设备必须创建两个数据包。O 的 ASCII 值（大写）为 79，则二进制值01001111，而 K 的二进制值为01001011。剩下的就是追加同步位。假设传输数据时首先传输最低位： s5.2 Service specifications5.2.1 List of services 建立/发布相关业务 PH-CONNECT, PH-ABORT; 数据传输业务 PH-DATA; 层管理服务 层管理服务由层管理进程使用或为层管理进程提供，层管理进程是AP的一部分。下面给出一些示例: PH-INITIALIZE.request / PH-INITIALIZE.confirm; PH-GET_VALUE.request / PH-GET_VALUE.confirm PH-SET_VALUE.request / PH-SET_VALUE.confirm PH-LM_EVENT.indication s5.2.2 Use of the physical layer services物理连接建立/释放服务是由物理连接管理器AP使用并为物理连接管理器AP提供的，而不是数据链路层注意这张图很关键，表明了管理器AP用于管理物理层的关系，包括管理器AP和物理层的原语，链路层和物理层的原语s5.2.3 Service definitions PH-CONNECT.request 连接建立服务的服务请求原语 在 DLMS/COSEM 环境中，PH-CONNECT.request 原语的用户是物理连接管理器AP。它被用于建立一个物理连接。收到该基元后，PhL 实体将执行所需的动作–例如拨号（如物理层 PhL 向 modem 发送AT指令）–以与对等 PhL 实体建立物理连接。5.4 中给出了智能 Hayes 调制解调器情况下的这些动作的例子。 PH-CONNECT.indication 连接建立服务的服务指示原语 PH-CONNECT.indication 由 PhL 实体基元生成，用于向服务用户实体指示一个远程设备要求建立物理连接。 PH-CONNECT.confirm 连接建立服务的服务确认原语 PhL 实体用来传递相关联的 PH-CONNECT.request 的结果。如果由于本地错误(例如电话线不可用)而无法建立连接，则是本地生成的。 PH-DATA.request 数据传输服务的服务请求原语 求使用 PhL 传输过程向一个或多个远程 PhL 实体发送数据字节 PH-DATA.indication 数据传输服务的服务指示原语。 向服务用户实体指示有效数据字节的到达 PH-ABORT.request 连接中止服务的服务请求原语 请求原语由服务用户实体 Physical Connection Manager 调用，以请求 PhL 实体终止现有的物理连接 PH-ABORT.confirm 连接中止服务的服务确认原语 PH-ABORT.confirm 原语由 PhL 实体生成，用于向服务用户实体 Physical Connection Manager 确认物理断开尝试的结果 PH-ABORT.indication 连接中止服务的服务指示原语。 原语由 PhL 实体生成，用于通知服务用户实体物理连接已意外终止。 s5.3 Protocol specifications5.3.1 Physical layer protocol data unitPhysical layer protocol data unit,PHPDU被指定为一个字节。然而，为了传输目的，这个数据字节可能被调制解调器设备扩展(错误检测/校正)或修改(位填充)，这取决于所使用的调制方案。s5.3.2 Transmission order and characteristicsPHSDU字节——PH-DATA 服务的 Data 参数——在传输前应以一个开始位和一个停止位完成。产生的帧应该从起始位开始传输，首先是最低有效位，最低有效位标识为位 0，最高有效位标识为位 7。s5.3.3 Physical layer operation – description of the proceduress5.3.3.1 General连接的建立和释放由物理连接管理器AP管理。任何希望使用 DLMS/COSEM 协议的AP应在请求连接之前检查PhL的连接状态。如果 PhL 处于非连接状态，它将请求物理连接管理器建立连接(结合 5.3.3.3 和 5.3.3.4 就是说建立和释放还有识别服务由 AP 来做，这些做完后的数据传输阶段AP 就不管了，通过数据链路层直接调用)s5.3.3.2 Setting up a physical connection客户机和服务器设备都可以充当主叫设备，初始化到远程设备(即被叫设备)的物理连接。在这个DLMS/COSEM配置文件中，这些原语的服务用户只能是物理连接管理器进程在被叫设备端，当检测到物理连接的启动时，需要对连接进行管理：协商、接受或拒绝。这些动作–与执行 PH-CONNECT.request 原语类似–取决于物理连接类型和使用的调制解调器，并可能以自主方式或由PhL本身完成(该过程不需要 Physicalconnection manager process 参与)。当主叫和被叫设备的PhL完成建立（或不建立）所需的物理连接时，它们使用PH-CONNECT.confirm（主叫方）和PH-CONNECT.indicat（被叫方）基元将结果通知服务用户实体。s5.3.3.3 The Identification service用于客户端读取协议栈识别信息可选的识别服务是一种应用层面（特别注意，应用层面）的服务。它的目的是让客户获得关于服务器中实现的协议栈的信息。因此，它不使用整个协议栈；识别信息在客户端AP和服务器AP之间使用PhL数据data服务直接交换。如果在多播配置中使用了一个以上的服务器，客户端能够识别每个服务器中的协议栈。该服务在PH-CONNECT后CONNECTED 状态才能调用只能由客户端发起请求 IDENTIFY.request 请求识别信息 IDENTIFY.response IDENTIFY.response 消息由服务器AP调用，携带识别请求的结果： 协议标准 版本 修订信息 错误信息 在客户端，这是一个 IDENTIFY.confirm 原语。 IDENTIFY.request APDU包含一个或三个字节。为了保持一致性，它的发送应受到数据链路层的时间限制（帧间和响应超时）。当收到这第一个字符时，PhL 进入 “识别中“状态，等待更多的字节或帧间超时(意味着消息的结束)。 identify识别阶段过程： 如果在收到三个以上的字节之前检测到消息结束条件(超时也算结束标志)，PhL 将收到的 APDU 视为IDENTIFY.request APDU。它使用 PH-DATA.indicaton 原语将收到的字节发送到（物理连接管理器）AP，并返回到 “等待接收“状态，允许解决最终的错误。 跳过 identify识别阶段，直接进入数据传输阶段： 另一方面，如果在收到第四个传入字节之前没有检测到消息结束的条件（因为 IDENTIFY.request 最大就是 3 字节，收到第 4 个字节还没有结束标志，说明就不是 IDENTIFY.request 了，同时要保证正确的数据 PDU 长度是大于 3 字节的），PhL 认为识别过程已经结束，并进入 “数据传输“状态。传入的字节应使用PH-DATA.indicaton服务发送至服务用户的上层协议层。在 3 层的 CO、HDLC 的 COSEM 配置文件中，这是 MAC 子层。在这种连接中，PhL不能返回到识别阶段。 PhL 有参数 Destination_process 表示数据发到哪一层去，默认为 NULL 表示发给物理层管理 AP，进入数据传输模式后为其他值表示发给 MAC 层。s5.3.3.4 Data transfer一旦PhL退出识别阶段，它就进入了数据传输阶段，其中PH-DATA.request和PH-DATA.indicative原语完全由上层协议层即数据链路层使用。在识别阶段AP 是可以通过 PH-DATA 原语向物理层传数据的，进数据传输阶段就不行了PhL不负责任何数据流控制功能：通过 PH-DATA.request primitive 收到的数据应立即传输，或者–当实施物理数据流控制时–应覆盖之前尚未传输的字节。由于 PH-DATA 服务既不是本地确认，也不是远程确认，因此在后一种情况下，不应发出错误信号。s5.3.3.5 Disconnection of an existing physical connection客户端或服务器都可以启动现有物理连接的断开连接。这通过调用 PH-ABORT.request 原语的物理连接管理器 AP 来实现PH-ABORT.request 的调用者，会收到 PH-ABORT.confirm 作为通知(在本地处理，本地的物理层通知本地的调用 AP，不外发，断开操作无需通知对方)对方不会收到任何关于断开的消息，只能通过检测物理连接断开来发现物 Qq 理通道断开了。然后物理层生成 PH-ABORT.indication如果是信道异常导致的断开，双方应该都会收到物理层传来的 PH-ABORT.indication，双方都断开。s5.4 example: PhL service primitives and Hayes commandsPH-CONNECT:对于主叫者，physicalconnection manager AP 向物理层 PhL 发送PH-CONNECT.request，物理层 PhL 向 modem(DCE)发送AT拨号命令，并返回拨号结果，物理层将结果转换为PH-CONNECT.confirm返回给 AP对于被叫者，AP 会被物理层通知PH-CONNECT.indication表示物理层已连接PH-DATA:假设之前建立了与远程 DCE 的连接，并且 DCE 现在处于数据传输模式，那么传递到本地 DCE 的所有数据都将被传输到远程 DCE（不是透明传输，每一层都会对 data 数据做处理，比如添加开始停止位，校验位等）。PH-ABORT：在可以终止连接之前，必须首先将调制解调器切换到本地命令模式(从数据传输模式)s6 Direct Local Connection光口物理层连接s7 DLMS/COSEM transport layer for IP networks 基于 UDP 的无连接传输层; 面向连接的基于 TCP 的传输层; 一个基于无连接 CoAP 的传输层DLMS/COSEM TL由CoAP、UDP或TCP传输层和一个称为包装器wrapper的额外子层组成s7.2 The TCP-UDP/IP based transport layersDLMS/COSEM_on_IP可以把 DLMS/COSEM AL 视为和 HTTP 一样的网络应用，使用 TCP-UDP 传输层服务IANA 中注册了 4059/TCP-UDP 端口DLMS/COSEM AL只监听一个UDP或TCP端口。另一方面，如 4.9 和 DLMS UA 1000-1 所示，一个物理设备可能承载多个客户端或服务器ap。包装器子层提供的附加寻址功能允许寻址这些ap。包装wrapper子层具有以下功能: 它在 UDP/TCP 端口上提供了一个额外的寻址能力(wPort); 它提供有关数据传输长度的信息。这个特性可以帮助发送方和接收方识别一个完整的APDU的接收，它可以在多个TCP包中发送和接收TCP-CONNECT and TCP-DISCONNECT services 的用户是 TCP Connection Manager Process，就是说 TCP 连接和释放不是 AL 管理的，由专门的管理进程管的，当然 AL 也要了解 TCP 当前的连接状态。s7.2.3 The DLMS/COSEM connection-less, UDP-based transport layer无连接，可实现多播广播；开销小缺点：不可靠（可以由上层实现可靠，当然 DLMS AL 层不会这么做，但是 CoAP 协议是个例子，基于 UDP 实现了可靠传输），无重复发送保护.request 和.indication 服务原语是必需的。本地的.confirm 服务原语的实现是可选的。UDP-DATA.request( Local_wPort, Remote_wPort, Local_UDP_Port, Remote_UDP_Port, Local_IP_Address, Remote_IP_Address, Data_Length, Data)UDP-DATA.indication( Local_wPort, Remote_wPort, Local_UDP_Port, Remote_UDP_Port, Local_IP_Address, Remote_IP_Address, Data_Length, Data)UDP-DATA.confirm( Local_wPort, Remote_wPort, Local_UDP_Port, Remote_UDP_Port, Local_IP_Address, Remote_IP_Address, Result)Result参数的值表示基于 DLMS/COSEM UDP 的 TL 是否能够发送请求的 UDP 数据报:能(OK)或不能(NOK)。result 为 OK 只能表示数据已发送，不保证能送达UDP-DATA.confirm 是可选的在这个通信配置文件中，包装子层是一个无状态的实体：它的唯一作用是确保使用 wPort 号码的源和目的地 DLMS/COSEM AE 识别，并提供OSI风格的UDP-DATA.xxx服务调用与标准UDP提供的 SEND()和 RECEIVE()接口函数之间的转换。对于 UDP 这种面向数据报而非面向流的协议，包装器中的长度字段并非必要，因为每个 udp 报文就是完整单一的，不存在分好几包还要拼包拆包处理粘包等操作，但为了和 TCP兼容还是需要该字段s7.2.3.3.2 The wrapper protocol data unit (WPDU) version:始终为 0x0001 source/destination wPort:DLMS/COSEM AE 的端口 Data length:APDU 数据长度s7.2.4 The DLMS/COSEM connection-oriented, TCP-based transport layer面向流的，可靠，包括重传、全双工、流控缺点：端到端，不支持广播和多播TCP作为一种面向连接的传输协议，涉及到建立连接、交换数据和释放连接三个阶段。因此，基于 TCP 的DLMS/COSEM TL为服务用户提供三个阶段的OSIstyle服务: 在连接建立阶段，将TCP-CONNECT服务提供给服务用户TCP连接管理器进程; 在数据传输阶段，TCP-DATA服务提供给服务用户DLMS/COSEM AL; 在连接关闭阶段，TCP-DISCONNECT服务被提供给服务用户TCP连接管理进程; 此外，一个TCP-ABORT服务被提供给服务用户DLMS/COSEM AL。TCP连接管理服务的服务用户不是DLMS/COSEM AL，而是TCP连接管理进程。该工艺的规范超出了本技术报告的范围TCP-DATA可本地或远程确认，UDP-DATA只能本地确认sTCP-CONNECTTCP-CONNECT.request( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address)TCP-CONNECT.indication( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address)TCP-CONNECT.response( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Result)TCP-CONNECT.confirm( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Result, Reason_of_Failure)TCP-CONNECT 由 TCP 连接管理进程和 TCP 层进行交互TCP 连接管理进程不能拒绝 TCP 连接请求，所以 TCP-CONNECT.response 总是成功的TCP-CONNECT.confirm 一般来说需要远程确认，如果是本地确认，可能回失败sTCP-DISCONNECTTCP-DISCONNECT.request( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address)TCP-DISCONNECT.request 用于断开请求TCP-DISCONNECT.indication( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Reason)TCP-DISCONNECT.indication 中Reason参数: 对端设备请求了 TCP 断开(Reason == REMOTE_REQ) 本地检测到 TCP 连接断开(Reason == ABORT)TCP-DISCONNECT.response( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Result)TCP 连接管理进程不能拒绝TCP 断开请求，表示远程断开 Reason == REMOTE_REQTCP-DISCONNECT.confirm( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Result, Reason_of_Failure)同 TCP-CONNECT.confirmsTCP-ABORT见 7.2 图 27，TCP-ABORT 是AL层和TL层交互的原语TCP-ABORT.indication( Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Reason)由基于 DLMS/COSEM TCP 的TL生成，用于向服务用户DLMS/COSEM AL表示支持 TCP 连接的非请求中断。当收到此指示时，DLMS/COSEM AL应释放所有使用此 TCP 连接建立的AAs，并应使用 COSEM-ABORT.indivation服务原语向 COSEM AP 表明这一点。sTCP-DATATCP-DATA.request( Local_wPort, Remote_wPort, Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Data_Length, Data)Data 是 APDUTCP-DATA.indication ( Local_wPort, Remote_wPort, Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Data_Length, Data)TCP-DATA.indication 基元由 DLMS/COSEM TL生成，用于向服务用户 DLMS/COSEM AL指示已从远程设备收到 xDLMS APDU。如果携带 APDU 的 TCP 数据包中的 Local_TCP_Port 和 Local_wPort 参数都包含有效的端口号，即接收设备中存在一个与给定端口号绑定的 DLMS/COSEM AE，则在基于 DLMS/COSEM TCP 的 TL接收完整的APDU（在一个或多个TCP 数据包中）后生成。否则，收到的消息将被直接丢弃。TCP-DATA.indication 需要在接收完完整包并解包后交给 AL,Data 是 APDUTCP-DATA.confirm( Local_wPort, Remote_wPort, Local_TCP_Port, Remote_TCP_Port, Local_IP_Address, Remote_IP_Address, Confirmation_Type, Result)可选的，request 的确认s7.2.4.3 Protocol specification for the DLMS/COSEM TCP-based transport layerwrapper 层和 UDP 的不同，因为 TCP 是流式的，需要发送/接收全 APDU，还要处理粘包等s7.2.4.3.5 Definition of the procedureswrapper 层透传TCP 连接管理器 AP和TCP 层之间的调用。 TODO:该设计是否合理，wrapper 层又多做了判断操作，直接管理 TCP 层是否更合理 TCP connection为了能够响应，响应方必须在接收第一个 SYN 包之前执行一个“被动”打开。为此，它必须联系本地操作系统(OS)，以表明它已经准备好接受传入的连接请求。作为这个联系的结果，操作系统分配一个TCP端口号给连接的端点(开启 TCP端口监听)，并为将来的连接保留所需的资源——但是没有发送消息。 TCP disconnection客户端和服务端TCP连接管理器进程可以通过调用TCP-DISCONNECT.request来启动该过程。 TCP connection abort基于 DLMS/COSEM TCP 的 TL 在 TCP-ABORT.indication 原语的帮助下指示支持 TCP 连接到 DLMS/COSEM AL 的中断或断开。 请注意，这是提供给 DLMS/COSEM AL 的唯一 TCP 连接管理服务(其他服务都是提供给 TCP 连接管理进程的)。当 TCP 连接被 TCP 连接管理器进程断开时调用该服务（优雅断开的情况），或者当 TCP 断开以非请求方式发生时，例如 TCP 子层检测到不可解决的错误或 物理连接被关闭。 TODO:前文 TCP-ABORT 一节提到 TCP-ABORT 不是非请求中断才生成吗?为什么请求中断也会生成该服务的目的是通知 DLMS/COSEM AL TCP 连接中断，以便它可以释放所有现有的 AA。 Data transfer using the TCP-DATA service可选TCP-DATA.confirm原语表示 TCP-DATA结果。请求原语之前调用，这是 OK 或 NOK。然而，这个结果的含义取决于实现。当.confirm 原语被实现为本地确认时，结果 t 表示 DLMS/COSEM TL 是否能够缓冲发送APDU 或发送APDU。当它作为远程确认实现时，结果表明 APDU 是否已成功交付到目的地。WPDU 由 wrapper 层打包组包解包，TCP 是流式的，不关心字节范围，WPDU 可能被分为好几个 TCP 包发送s7.2.5 Converting OSI-style TL services to and from RFC-style TCP function callss7.2.5.1 Transport layer and TCP connection establishments7.2.5.2 Closing a transport layer and a TCP connections7.2.5.3 TCP connection abort通过 TCP Wrapper 层轮询 TCP 层状态s7.2.5.4 Data transfer using the TCP-DATA serviceAL层通过 request 原语发送一个992字节的APDU，Wrapper层加上8字节的头，第一次发送1000字节，实际一包发出去 476 字节，还剩 524 字节，以此类推直到发完，向 AL 层回复 confirm 原语。该过程由 Wrapper 层控制。Wrapper 层接收到完整的 wrapper 头+APDU 后，解开 wrapper 头，将 APDU 放在TCP-DATA.ind原语中发送给 AL 层。s7.3 The DLMS/COSEM CoAP based transport layers7.3.2 Overview受限应用协议 (Constrained Application Protocol,CoAP) 是由 IETF 核心工作组定义的专用互联网应用协议。 CoAP 专为在资源受限的设备中使用而设计，用于通过非受限或受限的互联网通信网络（例如，低功耗、有损网络）进行通信。 CoAP 旨在提供高效的数据传输能力，同时满足可靠性、多播支持、极低开销、效率和简单性等特殊要求。基于 CoAP 的DLMS/COSEM CoAP TL提供不可靠和可靠的传输服务(CoAP 原来是属于应用层的，这里 DLMS 协议里把它做成了传输层，用来给 AL 提供服务)。不可靠的 CoAP 服务支持组播和广播。DLMS/COSEM CoAP TL 为服务用户 DLMS/COSEM AL 提供OSI风格的服务。整个DLMS/COSEM CoAP TL层包括了 Wrapper 层、CoAP 层、UDP 层，和标准 OSI 模型中的不同s7.3.3 Structure of the DLMS/COSEM CoAP transport layerDLMS/COSEM CoAP TL提供不可靠和可靠的运输服务。 不可靠的 DLMS/COSEM CoAP 传输服务使用non-confirmable (NON) CoAP 消息 可靠的 DLMS/COSEM CoAP TL 服务使用confirmable (CON) CoAP 消息，并带有 CoAP 消息层提供的重试机制。CoAP wrapper层提供的服务： 通过与CoAP请求/响应层操作的交互，将OSI风格的数据服务原语(CoAP-DATA)传递给DLMS/COSEM AL，以实现CoAP POST方法的使用 DLMS/COSEM服务接入点SAP寻址功能，从而允许多个DLMS/COSEM AEs驻留在物理设备的同一个 CoAP 客户机和服务器端点上s7.3.3.2 Identification and addressing识别与寻址默认 5683 端口，同一个物理机里的客户端和服务端可以共用该端口 TODO: 结合 Bluebook 4.9 关于 CoAP 配置的对象s7.3.3.2.2 DLMS/COSEM AL identification within the CoAP transport layer一个 CoAP 端口可以为不同的应用（如除了 DLMS 的应用）提供服务，用URIPath区分(CoAP 类似于 HTTP，可以通过 URI 区分接入点)，IANA 规定的默认端口为 5683默认情况下，DLMS/COSEM AL，无论是 DLMS 客户端 AL 还是 DLMS 服务器 AL，都使用该URI-Path: “dlms”coap://127.0.0.1:5683/dlmssDLMS/COSEM CoAP transport layer SAPss7.3.4 Service specification for the DLMS/COSEM CoAP transport layer远程环回确认(积极（传输成功的情况）的 TL 确认，用于可靠传输)，表示报文被远端确认，确认发送给本地 CoAP client，再由本地wrapper层返回给 AL 层 confirm 原语本地环回确认(消极（失败的情况，比如发生了什么错误）的 TL 确认，用于可靠和不可靠传输，可靠传输中可能是对方超时没回确认，视为失败，不可靠传输中可能是 udp 层有错误导致调用发送函数失败，视为失败)，用于失败的情况，由本地CoAP client返回给 wrapper 层错误信息，本地wrapper层返回给 AL 层 confirm 原语s7.3.4.2 The DLMS/COSEM CoAP-DATA service primitivess7.3.4.2.1 CoAP-DATA.requestCoAP-DATA.request( Transport_Mode, Local_SAP, Remote_SAP, Local_IP_address [Optional Use], Local_Port [Optional Use], Remote_IP_address, Remote_Port, Remote_Path [Optional Use], Response_Mode, Request_ID [Optional Use], Data_Length, Data) Transport_Mode: CoAP 传输模式，“RELIABLE”可靠，“UNRELIABLE”不可靠（这里的可靠其实是对于整个DLMS/COSEM传输层来说的，首先由 wrapper 层负责，当然底层还是需要 CoAP 可靠或不可靠模式的支持）,见7.3.5.6。对于CoAP协议提供的不可靠传输模式主要还是在广播的时候用的 Remote_Path： CoAP Uri-Path。Response_Mode 为“RESPONSE”忽略该参数 Response_Mode：表示是否期望返回 DLMS/COSEM 响应 APDU。影响CWPDU中的WRM。它取值:”CONFIRMED“， “UNCONFIRMED“， “RESPONSE“。 Request_ID：标识了特定的数据请求操作。Request_ID 将在可能产生的CoAP-DATA.confirm原语中返回，表明 DLMS/COSEM CoAP TL传送数据参数中给出的 APDU 的成功或失败。见7.3.5.6Request_ID 被指定为支持在已发送多个携带请求的 APDU 且 DLMS/COSEM CoAP TL 确认尚未完成的情况下，以每个APDU 为基础返回 DLMS/COSEM CoAP TL确认(类似于 TCP 的滑动窗口，可以异步确认)。以下情况适用: 如果 Request_ID 未被指定，CoAP-DATA.confirm 原语中 Request_ID 也不被指定。 如果 Transport_Mode 被设置为UNRELIABLE，并且 DLMS/COSEM CoAP TL 实现不支持这种操作模式的 CoAP-DATA.confirm 原语，那么 Request_ID 可以不被指定。 如果 DLMS/COSEM CoAP TL 服务不支持CoAP-DATA.confirm原语，CoAP wrapper 将忽略指定的 Request_ID 标识。 使用场景： 发送DLMS/COSEM请求（单播或多播广播）： Remote_Path指定为对方 Uri-Path Local_Port and Local_IP_address可选 Response_Mode： 需确认的请求，使用CONFIRMED 无需确认的请求，使用UNCONFIRMED General Block Transfer(GBT)分块传输的请求,视情况，比如单播或广播，可用CONFIRMED或UNCONFIRMED 发送DLMS/COSEM响应（也为 CoAP-DATA.request，只要是发送就是request，和 AL 层的报文类型无关）： Remote_Path不指定 Local_Port and Local_IP_address需要指定，和请求匹配 Transport_mode, Local_SAP, Remote_SAP, Remote_IP_address, Remote_Port 需匹配请求 Response_Mode： 一般为RESPONSE APDU 为 GBT 时，为CONFIRMED，Remote_Path 需指定 TODO:这不是和上面说的不指定矛盾了吗 s7.3.4.2.2 CoAP-DATA.indicationCoAP-DATA.indication( Transport_Mode, Local_SAP, Remote_SAP, Local_IP_address, Local_Port, Remote_IP_address, Remote_Port, Data_Length, Data) Transport_Mode: CoAP 传输模式，“RELIABLE”可靠，“UNRELIABLE”不可靠s7.3.4.2.2 CoAP-DATA.confirmCoAP-DATA.confirm( Local_SAP, Remote_SAP, Local_IP_address [Optional Use], Local_Port [Optional Use], Remote_IP_address, Remote_Port, Request_ID [Optional Use], Result) Local_SAP：本地 DLMS/COSEM AE 的 SAP Request_ID：对应的 CoAP-DATA.request 中携带的，如果 request 没有指定就是未定义 Result：“REMOTE OK”表示远端已接收，“NOT OK”表示发送失败使用场景：CoAP-DATA.confirm 由 wrapper 层生成对于不可靠的传输模式，Result 没有“REMOTE OK”远程确认，但可以生成“NOT OK”表示本地错误，对不可靠传输模式该原语是可选的s7.3.5 Protocol specification of the DLMS/COSEM CoAP transport layers7.3.5.2 The DLMS/COSEM CoAP TL Protocol Data Unit (CoAP-PDU)CoAP-PDU = UDP header + CoAP header + CWPDU(wrapper header + APDU)DLMS/COSEM CoAP TL PDU是一个UDP数据报，携带CoAP消息作为其有效载荷。该 CoAP 消息携带CoAP头和 DLMS/COSEM CoAP Wrapper PDU（CWPDU）。CWPDU 携带 DLMS/COSEM APDU作为其有效载荷加上 DLMS/COSEM CoAP TL控制信息，。s7.3.5.3 The DLMS/COSEM CoAP Wrapper Protocol Data Unit (CWPDU)CWPDU = wrapper header + APDUDLMS/COSEM CoAP 包装协议数据单元(CWPDU)由一个可选的DLMS/COSEM CoAP wrapper头和它的有效负载APDU组成。CoAP请求中 CWPDU才包含DLMS/COSEM CoAP wrapper报头。CoAP响应中 CWPDU不包含DLMS/COSEM CoAP wrapper头， 不同于 TCP 或 UDP，CoAP 是请求响应模型的，所以请求和回应在 DLMS 的 TL 层也是一一对应的（通过 Token 匹配），客户端完全可以知道回应的 wrapper 头中的SAP应该是什么。所以响应中的 wrapper 头可以省略CoAP 不是流式传输，报文也是完整的，不需要长度信息 The DLMS/COSEM CoAP TL version：TL 版本号，0-15，目前为 0 Reserved bits：保留 The CoAP Wrapper Response Mode (WRM)：通知对方的 wrapper 层是否应该期望收到对方的 AL 层响应，(为 1 时，服务端 wrapper 层就知道不需要等待服务端 AL 层响应，客户端 AL 也不会收到传输层给它的确认，但当启用了传输层可靠传输时，传输层自己要保证发送成功，包括超时重发和失败重发)，见 7.3.5.6 Remote SAP：接收站点的 SAP Local SAP：发送站点的 SAPs7.3.5.4 The Constrained Application Protocol (CoAP)s7.3.5.4.2 The CoAP MessageCoAP 消息以简单的二进制格式编码。消息由一个固定大小的4字节头、一个可变长度的Token值(0-8 字节)、0个或多个tlv编码的选项(可选地)和负载组成。一个非空的CWPDU作为有效负载在 CoAP 消息中携带。本节其实就是介绍标准 coap 协议，可以看其他文章，见CoAP 学习笔记（1）CoAP 报文结构DLMS/COSEM CoAP TL 层只用到了其中的一部分的 code CoAP Request method codes 在DLMS/COSEM CoAP TL的CoAP消息中使用的请求方法代码如下 Request method Meaning Use 0.02 POST method 发送新的包含 CWPDU 的请求或响应 0.00 空报文 ACK message without piggybacked response 在可靠传输中用于ACKs确认，不带响应 CoAP Success Response codes Success Response code Meaning Use 2.04 Success (Changed) 对已存在的请求/响应回复包含 CWPDU 的响应 三种响应模式见上述文章客户端错误和服务器错误响应代码由CoAP协议层或CoAP包装器根据错误条件填充 Token(可选，TKL 指定是否存在) 令牌用于配置响应和请求 Token Length(TKL 指定) 建议 DLMS/COSEM CoAP TL 实施的 CoAP 请求/响应层使用的令牌长度限制为0-4字节，以平衡令牌传输成本和上下文不匹配的风险，或者当令牌在相同的 CoAP 端点之间重复使用时可能出现的重复检测失败。进一步参考 RFC 7252。 DLMS 服务器的 DLMS/COSEM CoAP TL 的 CoAP 协议层使用的 Token 长度可在CoAP设置对象中指定，见 DLMS UA 1000-1 Part 2 Ed.15:2021, 4.9.8。 Options Options 也只用到了标准中的一部分,当然没有规定只能用这些，但要保证双方能处理这些选项 Uri-Path: CoAP uri 路径，默认是 dlms Content-Format：允许的传输格式，和 HTTP 类似，可以不指定，因为默认都是application/octet-stream Block1 and Block2：在 RFC 7959 中新增的两个 option，用于表示分块传输，见 7.3.5.4.5，另见CoAP 分块传输 s7.3.5.4.3 CoAP retransmission and response piggybacking当 CWPDU 在可靠的 CoAP 消息层支持的新 CoAP 请求/响应上下文中传输时（即通过可确认的（CON）CoAP 消息），那么，正如 RFC 7252 所规定的，CoAP 消息层将继续重传CoAP 请求消息，直到它被 CoAP 服务器终端确认。这可以是单独的CoAP确认消息ACK的返回形式，也可以是附带CWPDU 或错误响应的piggybacked ACK消息 关于piggybacking 技术： 在双向通信中，每当收到帧时，接收方都会等待，并且不会立即将控制帧（确认或ACK）发送回发送方。 接收方等待，直到其网络层传入下一个数据包。然后，延迟的确认将附加到此传出数据帧。 这种暂时延迟确认以便可以与下一个传出数据帧挂钩的技术称为piggybacking。 优点：提高效率，更好地利用可用信道带宽。 缺点：如果 接收方没有要发送 的内容，则接收器可能会阻塞服务。这可以通过在接收到数据帧时启用计数器（接收器超时）来解决。如果计数结束并且没有要发送的数据帧，则接收方将发送 ACK 控制帧。发送方还会添加一个计数器（发送器超时），如果计数器在没有收到确认的情况下结束，则发送方将假定数据包丢失，然后再次发送帧。 该技术主要是为了减轻网络负担,这个附带内容可以是接收器对于上一帧的回复（如果处理快的话也可以是本次请求的回复），也可以是主动上报等CoAP 层会考虑使用piggybacking的可能性，ACK会延时发送，直到本地 wrapper 层收到 AL 层的数据并打包成 CWPDU 或超时，再发送附带或不附带数据的ACK。要是超时的话这个 CWPDU 单独发送，不附带在这个 ACK 中7.3.5.4.3.2 CoAP Retransmission ParametersDLMS/COSEM CoAP TL 中的可靠 CoAP 消息传递层使用许多参数来控制 RFC 7252 定义的 CoAP 重传算法。这些参数在 CoAP setup interface class 类中指定 ack_timeout 需确认消息的最小初始 ACK 超时 initial_ack_timeout是在ack_timeout和ack_timeout x ack_random_factor之间随机选择的值。 initial_ack_timeout是可靠的 CoAP 消息层的初始重传延迟。 ack_random_factor 用于申请初始 ACK 超时随机性的随机因子。 max_retransmit 需确认消息的最大重传次数。 delay_ack_timeout CoAP 消息传递层在返回确认之前等待应用层返回响应的时间（以毫秒为单位），piggybacking 相关的，防止太久不回 ACK 触发对方重传 7.3.5.4.3.3 CoAP Congestion Control Parameters 拥塞控制 NSTART 以下任一形式的同时未完成的 CoAP 请求消息的数量： 没收到 ACK 的 CON 消息(需确认消息) 没收到响应的 NON 消息(无需确认消息) PROBING_RATE 探测速率 定义一个端点发送到另一个没有响应的端点时不应超过的平均数据速率(字节/秒)。 s7.3.5.4.5 CoAP Block Transfer见 7.3.5.4.2第 31 篇：CoAP 分块传输在 APDU 大于 MTU，且小于 receiver_max_pdu_size 时生效（大于 receiver_max_pdu_size 本身就不合法，AL 或 TL 应该屏蔽该报文） TODO:为什么是 APDU 大于 MTU，MTU 不是链路层的限制吗，就算要分也是加上 IP 头，UDP 头和 CoAP 头，wrapper 头后的 APDU 的长度作为基准吧DLMS/COSEM CoAP TL 中的 CoAP 块传输层应按照RFC 7959的建议，在没有不当延迟的情况下完成 CoAP 块传输s7.3.5.5 Error Handlings7.3.5.5.2 CoAP protocol layersCoAP消息层或请求/响应层的错误通过重置消息(名词)或 CoAP 协议层实体根据 RFC 7252 和 RFC 7959自动生成的 CoAP 客户端和服务器错误响应传递给发送的 CoAP 实体s7.3.5.5.3 CoAP wrapper layerwrapper层的错误处理，就是从一个 wrapper 层发给另一个 wrapper 层 Unreliable CoAP transport 不可靠传输 一般是多播，在多播情况下 wrapper 将接收到的不能处理的 CWPDU丢弃 TODO:wrapper 层是不是通过 CWPDU 中的客户端 SAP 参数知道是否是多播的 更新：有可能，或者是CoAP协议会带这个原语参数通知wrapper层是否是广播多播。然后其实这个丢弃和多播无关，不是多播也会丢弃。因为是不可靠传输，所以不需要 wrapper 层回确认（空报文）或否认 Reliable CoAP transport 可靠传输 接收端 wrapper 层无法处理接收到的 CWPDU(由 CoAP request 携带)时返回错误 这种错误响应可能有助于诊断，也可能有助于主动纠正措施。通常，当传入的请求由于语法错误而无法提供服务时，将返回CoAP客户端错误(类似 HTTP 状态码里的 4xx 表示客户端错误，5xx 表示服务器错误，HTTP 状态码)，而当 CoAP 包装器无法处理明显有效的请求时，将返回CoAP服务器错误 s7.3.5.5.4 Propagation of errors through CoAP wrapper layer返回到发送端 CoAP 协议层的错误响应应该以所产生的CoAP消息层交付失败（见下）的形式传播到发送端CoAP wrapper层，或者以返回的错误本身的直接形式传播，无论它们是由接收CoAP协议层还是由接收CoAP包装器层产生的。 CoAP 消息层交付失败原因： 接收到重置消息 放弃 CoAP block transfer 操作 可靠 CoAP 消息传递层放弃可靠传输的 CoAP 消息 CoAP 层错误或 UDP 或 IP 层错误 如果是可靠传输，CWPDU 的交付失败必须从 CoAP 协议层传播到 wrapper 层，以便其酌情通知 AL 层。s7.3.5.6 DLMS/COSEM CoAP TL confirmationsCoAP包装器请求/响应上下文（见 7.3.5.7）对于在本地发起的 CoAP 请求/响应上下文中传送的任何未完成的 CWPDU（还没有收到 CoAP 响应）保持给定Request_ID的状态，以便 wrapper 层在返回负面（比如有错误发生）或正面（比如传输成功）的 DLMS/COSEM CoAP TL 确认时可以用 CoAP-DATA.confirm 原语向 AL 层返回 Request_ID。对于不可靠的 DLMS/COSEM CoAP TL，这个是可选的，也就是无需维护维护Request_ID的状态。也只能回复负面的确认（无需正面确认，因为不可靠就是无确认的） CoAP 传输层错误指示 如果CoAP 包装器从 CoAP 协议层收到在本地发起的 CoAP 请求/响应上下文中传输的 CWPDU 的交付失败指示，则CoAP包装器通过 CoAP-DATA.confirm 原语（结果为 “NOT OK“）和与 CoAP-DATA.request 原语中的 APDU 提供的 Request_ID 相匹配的Request_ID来传达相关 APDU 的交付失败。参见 7.3.5.7.5。 CoAP 传输层确认 支持 DLMS/COSEM CoAP TL 确认，如果接收端的 AL 层不会对这条报文回确认，那这个确认可以由接收端传输层自己生成并回复(AL 层面无需响应，也就不会回响应，但传输层可靠传输层面需要确认)。使用带有 push_operation_method (1) 的无需确认 DataNotification 的可靠数据推送操作需要 DLMS/COSEM CoAP TL 确认。 参见 DLMS UA 1000-1 第 2 部分 Ed.15:2021, 4.4.8.2.2.11)，就是蓝皮书中的 push_operation_method 为 1 这种情况，需要传输层确认，而无需 AL 层确认，当然确认结果也不用给 AL 层，重发也是传输层自己负责 CoAP 包装层支持 DLMS/COSEM CoAP TL 确认，用于在 CoAPDATA.request 原语中以 Response_Mode = UNCONFIRMED 和 Transport_Mode = RELIABLE 提供的 APDU。(服务端 AL 层无需响应，客户端 AL 也不会收到传输层给它的确认，但传输层自己要保证发送成功，包括超时重发和失败重发。 注意，CoAP 层只会在未收到 ACK 时重发，对于 wrapper 层 CWPDU 未收到的情况需要 wrapper 层自己重发 TODO:可靠传输不是靠 CoAP 的 ACK 吗，为什么还要单独再搞个 wrapper 层的确认 更新：DLMS/COSEM TL 层的可靠传输，属于整一层的，CoAP 的 ACK 也是 wrapper 层用于判断传输成功的一种依据。比如还有明明收到了 ACK 但没收到对方 wrapper 层的响应，就要由 wrapper 层自己重发，来保证可靠传输 过程： 在 Response_Mode = UNCONFIRMED 的 CoAP-DATA.request 原语中提供给 CoAP 包装器的 APDU 应由 CoAP 包装器在 CoAP 包装器响应模式(WRM)设置为 1 的 CWPDU 中的新本地发起 CoAP 请求/响应上下文中传输（WRM = 1)（WRM 见 7.3.5.2，关于 CWPDU 的定义）。 这指示接收 CoAP 包装器不要等待返回 DLMS AL 响应或 DLMS AP 响应； 接收 CoAP 包装器应在将接收到的嵌入的 APDU 成功交付给 DLMS AL 时，当通过可靠 CoAP 消息传递层 在 WRM = 1 的 CWPDU 中接收到 APDU 时，返回一个空的 CWPDU 作为对发送 CoAP 包装器的成功响应实体 对于 WRM = 1 接收到的 CWPDU 的错误处理遵循上面描述的一般错误处理 s7.3.5.7 CoAP wrapper state machinewrapper 层状态机 空闲Idle：关闭状态，没有关联状态，CoAP 请求/响应层中没有相应的 CoAP 请求/响应上下文 客户端等待模式Client Waiting Mode：接收到 AL 层传来的 CoAP-DATA.req，直到把该 req 处理完,包括等待结果，进入 Idle 模式。 服务器等待模式Server Waiting Mode：接收 CoAP 层传来的非空且需 AL 层回复（WRM=0）消息，发给 AL 层后，等待AL 层回复 CoAP-DATA.req 消息 服务Serving：接收到 CoAP 层传来的非空且无需 AL 层回复(WRM=1)消息，发给 AL 层后直接结束，进入 Idle s7.3.5.7.2 CoAP DLMS/COSEM wrapper request/response context在客户端等待模式状态下维护的参数取自 CoAP-DATA.request 服务原语的服务参数(AL 层发来的)在服务器等待模式和服务状态下维护的参数取自较低的 CoAP 协议层和传入 CWPDU 的 CWPDU 标头(远端客户端发来的) 空闲到客户端等待模式 收到 AL 层 CoAP-DATA.request 调用，且 Response_Mode = UNCONFIRMED（UNCONFIRMED无需回应，不可能是回应，只能是请求），CWPDU中的WRM置1 收到 AL 层 CoAP-DATA.request 调用，且 Response_Mode = CONFIRMED，且是个请求（没找到对应请求，说明不是回应） 收到 AL 层 CoAP-DATA.request 调用，且 Response_Mode = RESPONSE，且是个请求（没找到对应请求，说明不是回应），和GBT相关 空闲到服务器等待模式 收到 CoAP 层传来的非空且需AL层回复（WRM=0）消息，发给 AL 层后，等待AL 层回复 CoAP-DATA.req 消息 服务器等待模式到空闲状态： 在服务器等待模式下收到 AL 层传来的CoAP-DATA.request原语，且该原语中的 Transport_Mode, the Local SAP, the Remote SAP, the Local_IP_address, the Local_port, the Remote_IP_address and the Remote_Port参数与当前wrapper层上下文中的对应 收到 AL 层 CoAP-DATA.request 调用，且 Response_Mode = RESPONSE，且是个回应（找的到对应的请求） 收到 AL 层 CoAP-DATA.request 调用，且 Response_Mode = CONFIRMED，且是个回应（找的到对应的请求）（GBT 相关） 客户端等待模式到空闲状态 收到 CoAP 层失败信息 收空(确认)或非空(响应)CWPDU 然后根据情况处理后回给 AL 层 空闲状态到服务状态 接收到 CoAP 层传来的非空且无需 AL 层回复(WRM=1)消息，发给 AL 层后直接结束，进入 Idle（可能还要回个空 CWPDU 给对方 wrapper 层表示确认） s7.3.5.7.4 CoAP-DATA.request invocation handlings7.3.5.7.5 Handling of incoming CWPDU or CoAP layer transmission failuress7.3.5.7.6 Garbage collectionCoAP 相关的缓存清理，和实现相关。s7.3.6 DLMS/COSEM CoAP TL Data Transferss7.3.6.2 General transfer of confirmed DLMS/COSEM AL service requestss7.3.6.3 Reliable DLMS/COSEM CoAP TL operationPiggybacked 模式下，ACK 和 response 同时回复，由客户端掌握重发权，没收到 ACK 就重发separate 模式下，ACK 先发，response 后发，在响应阶段服务端掌握重发权，如果 response 没收到对方 ACK 则重发 TODO:如果是服务端发给客户端的 ACK 丢了呢 更新：客户端没收到ACK重发请求s7.3.6.4 Unreliable DLMS/COSEM CoAP TL operations7.3.6.5 DLMS/COSEM CoAP Block Transfer operationCoAP 块传输，用于 APDU 大于 MTU 但小于 receiver_max_pdu_size 的情况，主要是用于让 IP 层无需再分片，属于 CoAP 标准中的一部分。对于 UNRELIABLE 服务，图 58 中的 Transport_Mode 替换为UNRELIABLE，CoAP type 替换为NONs7.3.6.6 DLMS GBT operation over DLMS/COSEM CoAP TLDLMS GBT 分块，区别于 CoAP 块传输，属于 DLMS/COSEM AL 层实现的分块传输，在某些方面优于 CoAP 块传输。 TODO:FIRST-PART 是不是就只是用来交换 GBT 参数的，此时直接发出去应该 data 是个空的也行 更新：22年5月26日已经讨论，这确实是用来请求GBT参数的，这种情况发生在所有GBT参数由AP层管理的情况下。照理说如果AL可以管理这个参数，AL可以不向AP层申请。9.4.6.13.3中Table 96写明了AL有默认参数，而且需要AP提供一个参数用于更新该默认值，也就是官方建议使用AL向AP请求参数的方式。如果AL和AP层合并也可以避免该问题。 TODO:后面是有关GBT的部分s8 Data Link Layer using the HDLC protocols8.1 Overview本章指定数据链路层为三层，面向连接，基于HDLC，异步通信配置文件。本规范支持以下通信环境: 点对点和点对多点配置 专用和交换数据传输设施 半双工和全双工连接 异步 启动/停止 传输，1 个启动位，8 个数据位，无奇偶校验，1 个停止位s8.1.2 Structure of the data link layer为了确保面向连接和无连接两种操作模式都有一致的数据链路层服务规范，数据链路层被划分为两个子层:逻辑链路控制(LLC)子层和媒体访问控制(MAC)子层LLC 层 类型 1：无连接。该方式对信息的发送通常无法保证接收。 类型 2：面向连接。该方式提供了四种服务：连接的建立、确认和承认响应、差错恢复（通过请求重发接收到的错误数据实现）以及滑动窗口（系数：128）。通过改变滑动窗口可以提高数据传输速率。 类型 3：无连接承认响应服务。类型1的 LLC 无连接服务中规定了一种静态帧格式，并支持运行网络协议。有关传输层网络协议通常是使用服务类型 1 方式。类型2的 LLC 面向连接服务支持可靠数据传输，运用于不需要调用网络层和传输层协议的局域网环境。(相当于把 TCP 层的事情干了)MAC 子层（该数据链路层规范的主要部分）基于 ISO/IEC 13239。与原始 HDLC 标准相比，该标准的第二版包括许多增强功能，例如在寻址、错误保护和分段。 第三版采用了一种新的帧格式，可满足电表和类似行业遥测应用中的环境要求。MAC 子层的主要功能包括数据帧的封装/卸装，帧的寻址和识别，帧的接收与发送，链路的管理，帧的差错控制等。MAC 子层的存在屏蔽了不同物理链路种类的差异性;非常重要的一项功能是仲裁介质的使用权，即规定站点何时可以使用通信介质。实际上，局域网技术中是采用具有冲突检测的载波侦听多路访问（Carrier Sense Multiple Access /Collision Detection，CSMA/CD）这种介质访问方法的。为本技术报告的目的，已从 HDLC 标准中做出以下选择： TODO:后面都看不懂s8.1.3 Specification method数据链路层的子层根据服务和协议(services and protocols)进行划分层间交互原语参数类型： 传输至对端对等层的参数，包含在帧报文中，如地址、控制信息 局部使用的参数 透明传输的参数，收到后本层不处理，直接给下一层s8.2 Service specification本节规定了服务用户层使用面向连接的程序对数据链路层要求的服务。事实上，所有 DL 服务都由 MAC 子层提供：LLC 子层将 DL-CONNECT.xxx 服务原语作为适当的 MA-CONNECT.xxx 服务原语透明地传输到“真实”服务提供者 MAC 子层或从“真实”服务提供者 MAC 子层接收。由于客户端和服务器端 LLC 和 MAC 子层不同，因此为双方指定了服务原语。MAC 子层的寻址方案在 8.4.2 中规定。s8.2.2 Setting up the data link connection: the DL-CONNECT and MA-CONNECT services数据链路连接的建立只能由客户端请求。因此，DL-CONNECT / MA-CONNECT .request和.confirm原语仅在客户端(主站)提供。另一方面，MA-CONNECT / DL-CONNECT .indication和.response原语仅在服务器(辅助站点)端提供。在本地检测到错误的情况下，DL-CONNECT / MA-CONNECT .request 原语也可以在本地进行确认。(虚线部分)s8.2.2.2 DL-CONNECT.request and MA-CONNECT.requestDL-CONNECT.request( Destination_MSAP, Source_MSAP, User_Information)MA-CONNECT.request( Destination_MSAP, Source_MSAP, User_Information) Destination_MSAP 和 Source_MSAP: 标识要建立的引用数据链路层连接。 User_Information：为可选配置。其内容的规范不属于本技术报告的范围。服务用户层调用 DL-CONNECT.request 原语，LLC 层接收后调用 MA-CONNECT.request 原语发给 MAC 层，MAC 层发送格式化后的SNRM帧(Set Normal Response Mode (a HDLC frame type,HDLC 协议的一部分))s8.2.2.3 DL-CONNECT.indication and MA-CONNECT.indicationDL-CONNECT.indication( Destination_MSAP, Source_MSAP, User_Information)MA-CONNECT.indication( Destination_MSAP, Source_MSAP, User_Information)和上面的相反，接收 SRNM 转换报文s8.2.2.4 DL-CONNECT.response and MA-CONNECT.responseDL-CONNECT.response( Destination_MSAP, Source_MSAP, Result, User_Information)MA-CONNECT.response( Destination_MSAP, Source_MSAP, Result, User_Information)Result 指示提议的连接是否可以被接受，以及是否应该发送响应帧。它可以有以下值之一: Result == OK这意味着接收到的连接请求可以被服务用户层接受。MAC 层收到后发送UA帧 Result == NOK。这意味着接收到的连接请求不能被服务用户层接受;（如果链路层收到第二个连接请求，但同时只能有一个，即使服务用户层接受，连接也不能建立），MAC 层收到后发送DM帧 Result == NO-RESPONSE。这意味着不应发送对 DL-CONNECT.indication 的响应。MAC 层收到 MA-CONNECT.response 后不发送任何帧 TODO:这里的 MA-DISCONNECT.response 写错了s8.2.2.5 DL-CONNECT.confirm and MA-CONNECT.confirmDL-CONNECT.confirm( Destination_MSAP, Source_MSAP, Result, User_Information)MA-CONNECT.confirm( Destination_MSAP, Source_MSAP, Result, User_Information)Result 表示之前调用的 DL-CONNECT / MA-CONNECT.request 服务调用的结果。 它可以具有以下值之一： Result == OK。 这意味着远程站接受了连接请求； Result == NOK-REMOTE。 这意味着远程站没有接受连接请求； Result == NOK-LOCAL。 这意味着发生了本地错误，例如服务用户层试图建立一个已经存在的数据链路连接； Result == NO-RESPONSE。 这意味着远程站没有响应连接请求。s8.2.3 Disconnecting the data link connection: the DL-DISCONNECT and MA-DISCONNECT servicess8.2.3.2 DL-DISCONNECT.request and MA-DISCONNECT.request同上 8.2.2.2s8.2.3.3 DL-DISCONNECT.indication and MA-DISCONNECT.indicationDL-DISCONNECT.indication ( Destination_MSAP, Source_MSAP, Reason, Unnumbered_Send_Status, User_Information)MA-DISCONNECT.indication ( Destination_MSAP, Source_MSAP, Reason, Unnumbered_Send_Status, User_Information) Reason Reason == REMOTE：数据链路层收到来自客户端的断开连接请求。 这种情况可能只发生在服务器端； Reason == LOCAL-DL：出现致命的数据链路连接失败； Reason == LOCAL-PHY：出现致命的物理连接故障。 后两种情况可能同时发生在客户端和服务器端。 Unnumbered_Send_Status，USS，参数的值指示在 DL-DISCONNECT / MA-DISCONNECT .indication 原语调用的时刻，MAC 子层是否具有（USS == TRUE）或不具有（USS == FALSE) 待处理的 UI 消息。 User_Information 可选s8.2.3.4 DL-DISCONNECT.response and MA-DISCONNECT.responseservice user layer 不能拒绝该服务，结果仅表明指定的 DL connection 是否存在RESULT == NO-RESPONSE 表明 MAC 不应该发送任何响应s8.2.3.5 DL-DISCONNECT.confirm and MA-DISCONNECT.confirm和 response 类似s8.2.4 Data transfer: the DL-DATA and MA-DATA services使用 I 帧或 UI 帧 和 DL-DISCONNECT 及 DL-CONNECT 的区别是这个 DL-DATA 不再是透传了，LLC 层需要组 LSDU 作为 data，前面两个 LLC 就是什么也不干，直接把参数和 data 给 MAC 层。s8.2.4.2 DL-DATA.request and MA-DATA.requestFrame_type： client: I-COMPLETE and UI;(这里假设了 client 的资源足够大（比如缓冲区），所以调用原语时不需要分包，直接用完整的) server: I-COMPLETE, I-FIRST-FRAGMENT, I-FRAGMENT, ILAST-FRAGMENT, and UI收到调用后，LLC 层组装LSDU，其中包括LLC specific fields (the two LLC addresses and the LLC_Quality parameter)，不在 Frame_type == I-FRAGMENT or I-LAST-FRAGMENT 中添加，因为这个是头信息，只要在 I-FIRST-FRAGMENT 和 I-COMPLETE 中添加就行s8.2.4.3 DL-DATA.indication and MA-DATA.indicationLLC 层要解 LSDU，校验LLC specific fields (the two LLC addresses and the LLC_Quality parameter)s8.2.4.4 DL-DATA.confirm and MA-DATA.confirmMAC 层生成，MAC 层判断是否发送成功Frame_type = I-FIRST-FRAGMENT, I-FRAGMENT or I-LAST-FRAGMENTs8.2.5 Physical layer services used by the MAC sublayer物理层配置还有断开不是 MAC 层管的（见5.2.2）物理层断开会通过PH-ABORT.indication原语通知 MAC 层s8.2.5.4 Data transferPH-DATA.request and .indication 原语s8.3 Protocol specification for the LLC sublayers8.3.2 LLC PDU format Source_LSAP: 最低位表示 command(0)/response(1) Control byte: LLC_Quality，保留，固定 0x00destination LSAP 0xFF用于广播s8.3.3 State transition tables for the LLC sublayer区别是 client 端没有 I-FRAGMENT or ILAST-FRAGMENT，就不用判断类型，LSDU 里全部加上 LLC 头就行s8.4 Protocol specification for the MAC sublayers8.4.1 The MAC PDU and the HDLC frames8.4.1.1 HDLC frame format type 3 Flag field:固定0x7E，在帧头尾,连续发送时头尾可以互连 Frame format field: Format type sub-field (4 bit):3，表示type3(HDLC frame format type 3) the Segmentation bit (S, 1 bit):类型细分，对上面的 format type 的继续细分 the frame length sub-field (11 bit):除了 flag 外的长度 Destination and source address fields:见 8.4.2 Control field：控制字段，见 8.4.3 Header check sequence (HCS) field：对头部序列的校验，计算opening flag和HCS之间的部分，如 Frame format+Dest. address+Src. address+Control，不包括后面的信息域和 FCS。当信息域不存在或者为空时，则 HCS 不存在，仅有 FCS Information field：携带信息域（比如 MSDU）,I and UI 帧可用(其他类型帧可能也有，后面提到了 Disconnect (DISC) command) Frame check sequence (FCS) field：计算校验，除 flag 和 FCSs8.4.2 MAC addressings8.4.2.2 Address field structureHDLC 地址：HDLC 帧格式type 3(参见 8.4.1.1)包含两个地址字段:目的地址和源地址。根据数据传输的方向，客户端地址和服务器地址都可以是目的地址或源地址。 client address：总是 1 字节，不能扩展 server address：只允许 1，2，4 字节 upper HDLC address：Logical Device(在物理设备内的一个单独的可寻址的实体) lower HDLC address：Physical Device,可选 s8.4.2.3 Reserved special HDLC addresses 每个字节的 LSB 用于标识是否有后续字节，所以不计入实际字节的表示，也就是一个字节就7个有效位。1111 1111 表示一个字节，后续无字节，然后把 LSB 去掉就是 1111 111，前面补 0 就是 0111 1111，一个字节最大就能表示0x7F。如果要表示0xFF,就是，0000 0010 1111 1111，去掉无效位（每个字节的 LSB），0000 001 1111 111，合并填 0，就是 0000 0000 1111 1111。对于 4 个字节的情况，分高 upper 地址 2 字节和低 lower 地址 2 字节考虑。s8.4.2.4 Handling special addresses源地址不能用 All-station or the Nostation addresss8.4.2.5 Handling inopportune address lengths in the server对于服务端接收，源地址(就是客户端地址)固定 1 字节，超过 1 字节的帧丢弃（client address 仅允许 1 字节）对于目的地址长度，有如下要求：s8.4.3 Command and response framesRRR is the receive sequence number N(R)SSS is the send sequence number N(S)P/F is the poll/final bit.P 表示poll bit，表示是否交出发送权，一般需要响应的请求的最后一帧会置为TRUE I帧，Information transfer command and response 信息传递 N(S)：发送帧的序号 N(R)：期望接收到的下一帧的序号，表明N(R)-1序号的帧已被正确接收。 发送接收最大information field长度默认为128字节 Receive ready (RR) command and response 通知准备好接收 I 帧 确认之前收到的 N(R)-1 序号的 I 帧 Receive not ready (RNR) command and response 通知未准备好接收 I 帧 确认之前收到的 N(R)-1 序号的 I 帧 RNR 接收方应该要知道，N(R)-1 之后的 I 帧发送都是无效的，也不应该再发 I 帧了 Set normal response mode (SNRM) command SNRM 命令应用于将已分配地址的从站置于正常响应模式（NRM），其中所有控制字段的长度应为一个八位字节。 次站应通过在第一个响应机会时发送 UA 响应来确认 SNRM 命令的接受。 在接受该命令后，从站发送和接收状态变量应设置为零。 此命令执行后，原来由 DL 层管理的未被确认的 I 帧需要交还给更高层管理，是否重新交给 DL 层发送取决于该高层。 TODO:什么是正常响应模式。更新：见 8.4.4 Disconnect (DISC) command 终止之前配置的可操作或初始化模式，从站应进入逻辑断开模式。 TODO:逻辑断开模式和正常断开模式区别？更新：应该是同一个概念，就是 NDM 从站应发 UA 响应表示确认收到 （同 SNRM）此命令执行后，原来由 DL 层管理的未被确认的 I 帧需要交还给更高层管理，是否重新交给 DL 层发送取决于该高层。 可以理解为 SNRM 的逆操作 可能携带 information field Unnumbered acknowledge (UA) response 对 SNRM 和 DISC 的响应 可能携带 information field,用于传递 DL 层参数 Disconnected mode (DM) response 报告自身处于 Normal Disconnected Mode(NDM)状态 请求主站或其他关联站向自己发送模式设置命令，如切成 NRM 响应模式设置请求，报告自己仍处于 NDM 例如，可以通过 SNRM 命令退出 NDM，进入 NRM Frame reject (FRMR) response 从站报告接收到的帧的错误，该错误不能通过重传相同的解决，且该错误不是由于 FCS 错误引起的： Unnumbered information (UI) command and response command 发送信息给从站，不影响 V(S)和 V(R)，可以在任何模式（NRM,NDM）下使用 UI请求不指定从站响应，可能丢失或重复 V(S)：Send state Variable V(R)：Receive state Variable 不影响 I 帧或其他帧的序号 response 发送信息给主站，不影响 V(S)和 V(R)，可以在任何模式（NRM,NDM）下使用 可能丢失或重复 s8.4.4 Elements of the procedures当主备用站点之间建立了物理链路，但没有建立活动的数据链路通道时，客户端和服务器端的 MAC 子层都处于正常断开模式Normal Disconnected Mode(NDM);不传送或不接受任何信息或编号的监控帧。从站功能限制为： 接收与响应 SNRM 接收 UI 发送 UI 响应 收到 DISC 后发送 DM 响应当 MAC 连接建立后，MAC 层工作在正常响应模式(NRM)。从站(服务器)只有在从主站(客户端)获得明确的许可后才可以开始数据传输。在收到许可(POLL BIT == TRUE)后，从站发起响应传输。响应传输可以由一个或多个帧组成，同时保持活跃的数据链路通道状态(见 8.4.4.3.1)。响应传输的最后一帧应由从站明确表示(FINAL BIT == TRUE)。在最后一帧指示之后，从站应停止发送，直到再次收到主站的明确许可。s8.4.4.2 Transmission considerations TODO:透明传输需要查看文档ISO/IEC 13239:2002, 4.3按照一个字节内低位优先传输，多个字节按照最高有效字节优先，如0x1234，先传0x12s8.4.4.3 HDLC channel states Active HDLC channel state 当主站或从站处于传输帧中的一个字节状态时，就是 active 状态，保留有继续传输权 Abort sequence 不适用 Start/stop transmission inter-octet time-out 字节间超时等待状态，接收完一个字节开始等待，直到收到下个字节或超时，超时要结束接收。 Idle HDLC channel state 当连续标记保持条件持续一段系统特定的时间($T_{idle}$)时，数据链路通道进入空闲状态。 s8.4.5 HDLC channel operation – Description of the procedures选择了非平衡连接模式(unbalanced connection-mode)的数据链路操作。不平衡数据链路包括一个主站和一个或多个从站。数据链路的整体错误恢复最终由主站负责选择了NRM和NDM模式。s8.4.5.2 Data station characteristics主站负责: 设置数据链路，断开数据链路; 发送信息传递、监督和无序号命令; 检查收到的响应。从站应负责: 检查收到的命令; 根据接收到的指令，发送信息，监督和无序号命令的回复。s8.4.5.3 Procedures for setting up and disconnecting the data link Setting up the data link 主站发 SNRM，从站回 UA 表示确认并进入 NRM，回 DM 表示无法进入 NRM 主站未收到回应等待超时重发，直到 MAX_NB_OF_RETRIES 次数停止 HDLC parameter negotiation during the connection phase SNRM/UA 消息交换不仅可以建立连接，还可以协商一些数据链路参数 最大 information field 长度参数，默认 128 字节 发送 接收 Window size 窗口大小，默认 1，最大 7. 发送 接收 SNRM 中的 Window size – receive 是强制的，UA 中的‘Max_info_field_length– receive’ (0x40), and the ‘Window size – transmit’ (0x07)是强制的 Disconnecting the data link 主站发DISC，从站回UA响应，并进入 NDM。如果已经处于断开模式 NDM，将发送DM响应。 超时重发和 Setting up the data link 相同 s8.4.5.4 Procedures for data exchange收到 MA-DATA.request 调用后，发送I帧，只能在NRM下发送。若 Frame_type == UI，则发送UI帧，一般用于广播多播，且可以在NRM或NDM状态发送。 Exchange of information frames 主站请求的最后一帧poll bit置 1，表示等待响应，从站响应的最后一帧final bit置位表示发送结束。 8.4.5.4.5 Transferring long MSDUs from the server to the client 服务端资源有限，客户端资源较多，对 dl-data 进行分段，Frame_type == IFIRST-FRAGMENT、I-FRAGMENT、I-LAST-FRAGMENT 8.4.5.4.6 Multi- and broadcasting 对使用UI帧实现多播广播的情况，仅允许客户端发送，服务端不允许 只有 UI(和 DISC)消息可以作为广播或组播消息，此时 UI 帧的Poll bit必须为FALSE,表示无需响应（就是不会把发送权交给从站） DISC一般用于在通过断开低层连接方式断开AA时发送的命令。 多播广播支持对一个物理设备的多个逻辑设备，或多个物理设备，根据 HDLC 目的地址的 upper 和 lower 字节 8.4.5.4.7 Sending an UI frame from the server to the client 服务端发送 UI 帧的情况 在 HDLC 中因为是主从模型，服务器作为从站没有权利主动上报，需要等客户端作为主站发送任意请求后，因为需要回复，从站获得发送权，再趁机发送该上报 UI 帧，且应在响应的最后一帧前发送 其他情况： 客户端发送 RR 帧，P=1 客户端发送空的 UI 帧，P=1 8.4.5.4.8 Handling the CALLING device physical address CALLING Physical Device address，见 8.4.2.3 允许服务端发起物理连接请求，以便自己能上报数据（8.4.5.4.7那些数据） 客户端需要发送SNRM为服务端配置模式，其中 Lower MAC Address 的值应该为CALLING Physical Device Address (0x7E)，表示该报文是给正在寻求发起连接的服务端。 多点 multi-drop 网络中，所有服务端收到后首先判断自身的CALLING DEVICE标志，如为TRUE，表示自己正在寻求发起连接，则接收，如果为 FALSE，则丢弃。（收到 PH-ABORT.indication 物理层断开后应该置为 FALSE） 服务端接收后需要回复UA（确认）或DM（否认），此时源地址的Lower MAC Address字段应为正确的本机 MAC 物理地址，而不是 CALLING Physical Device Address s8.4.5.5 Exception recovery Response time-out 响应超时 发送完 poll bit 为 1 的帧后开始计时，收到 final bit 为 0 的帧时刷新计时，收到 final bit 为 1 的帧时结束计时 超时应该重发，当该帧时 I 帧时不应该重发，应该发 RR 帧同步 I 帧序号，确认丢失的是哪帧（TODO:是否同步完再重发 I 帧） FCS and HCS error TODO：引用了一些其他标准 有错误帧时，所有的连续帧都应被丢弃。 N(S) sequence error Command/response frame rejection FRMR 回应 Busy s8.4.5.6 Time-outs and other MAC sublayer parameters Time-out 1: Response time-out (TO_WAIT_RESP) 等待响应超时时间，所有命令和信息帧，客户端参数 TO_WAIT_RESP &amp;gt; RespTime + 2*MaxTxTime Layer Parameter 1: Maximum number of retries (MAX_NB_OF_RETRIES) 最大超时重发次数 Time-out 2: Inactivity time-out 未向 PhL 发送或接收超时，每次发送或接收时重置。调用DL-LM_EVENT.indication原语，见8.6.2.7。超时应断开 DL 层连接 Time-out 3: Inter-frame time-out 帧间超时，接收端参数，超时未收到下一帧表示已经结束 Maximum information field length 最大 information field 长度，默认 128 Window size 窗口大小，默认 1 s8.4.5.7 State transition diagram for the server MAC sublayers8.5 FCS calculations8.5.1 Test sequence for the FCS calculation TODO：计算规则不明确s8.5.2 Fast frame check sequence (FCS) implementation16 位的 FCS 计算参考 RFC 1662s8.5.3 16-bit FCS computation methods8.6 Data link layer management services DL-INITIALIZE 初始化 DL 层参数 DL-GET_VALUE 从 DL 层获取一个或多个参数 DL-SET_VALUE 设置 DL 层的一个或多个参数 DL-LM_EVENT 通知 DL 层的事件 s9 DLMS/COSEM application layers9.1 DLMS/COSEM application layer main featuress9.1.2 DLMS/COSEM application layer structureDLMS/COSEM AL 的主要组成部分是应用服务对象Application Service Object(ASO)。它向其服务用户 COSEM Application Process (APs)提供服务，并使用支持协议层提供的服务。它在客户端和服务器端都包含三个必需的组件: 关联控制服务元素，Association Control Service Element，ACSE 扩展 DLMS 应用服务元素 the extended DLMS Application Service Elemen，xDLMS ASE; 控制功能 the Control Function，CF。 Client SN_Mapper ASE 是客户端专有可选项xDLMS ASE提供在 COSEM APs之间传输数据的服务,见 9.1.4Control Function (CF)元素指定ASO服务如何调用ACSE、xDLMS ASE和支持协议层的服务的适当服务原语。见 9.4.1。客户端和服务器 DLMS/COSEM ASO都可能包含其他可选的应用程序协议组件。当服务器使用SN引用时，可选的Client SN_Mapper ASE 出现在客户端AL ASO中。它使用 LN 和 SN 引用提供服务之间的映射。见 9.1.5。DLMS/COSEM AL也执行 OSI 表示层的一些功能: 对ACSE和xDLMS APDUs进行编码和解码，参见 9.4.3; 另外，生成和使用代表ACSE和xDLMS APDUs的XML文档; 用于压缩和解压; 启用、验证和删除密码保护。s9.1.3 The Association Control Service Element, ACSE用于面向连接（connection oriented (CO)）通信提供 application association 建立与释放服务： COSEM-OPEN; COSEM-OPEN 服务用于建立AAs。它基于 ACSE A-ASSOCIATE 服务。基于 ASE 过程中的 Application_Context_Name, Security_Mechanism_Name and xDLMS context 参数 confirmed AAs使用 COSEM-OPEN 服务，可以在单个客户端和单个服务器之间建立； unconfirmed AAs使用 COSEM-OPEN 服务，可以在单个客户端和多个服务器见建立，只有客户端发送，服务端不回应。（多播，广播） pre-established AAs 可能预先存在。 不使用 COSEM-OPEN 服务。 客户端必须知道服务器支持的上下文。 预先建立的 AA 可以是确认或未确认。 COSEM-RELEASE 不丢失信息，优雅释放AAs TCP-UDP/IP based profile：基于ACSE A-RELEASE 服务 3-layer, CO, HDLC based profile：confirmed AAs直接断开对应协议层连接，Pre-established AAs 无需断开 COSEM-ABORT 异常释放，可能丢失信息，它不依赖于 ACSE A-ABORT 服务 s9.1.4 The xDLMS application service element为了访问 COSEM 对象的属性和方法，使用了xDLMS ASE的服务s9.1.4.2 The xDLMS initiate service建立xDLMS上下文s9.1.4.3 COSEM object related xDLMS services与 COSEM 对象相关的 xDLMS 服务用于访问 COSEM对象属性和方法。 Logical Name (LN) referencing Short Name (SN) referencing客户端ASO总是使用带有LN引用的 xDLMS ASE。服务器ASO可以使用带有LN引用的 xDLMS ASE，也可以使用带有SN引用的 xDLMS ASE，或者两者都使用服务可以是： requested / solicited：客户端请求 客户端请求的服务也可以(见 9.4.6.2): confirmed:在这种情况下，服务器提供对请求的响应; unconfirmed:在这种情况下，服务器不提供对请求的响应。 unsolicited: 由服务器端发起，无需请求 来自服务器的未经请求的DataNotification也可能是(见 9.3.10): confirmed:在这种情况下，客户端提供一个响应来确认收到了未经请求的 DataNotification unconfirmed:在这种情况下，客户端没有对未经请求的 DataNotification 提供响应 附加服务-不是基于 IEC 61334-4-41:1996 规定的 DLMS 服务-是: 使用 LN 引用访问 COSEM 对象属性和方法的GET、SET、ACTION和ACCESS; 服务器用于向客户端推送数据的DataNotification服务; 服务端使用EventNotification服务通知客户端服务器发生的事件。 IEC 61334-4-41:1996规定的是早期的 DLMS，后面有扩充的叫做 xDLMS,多了很多重要的东西s9.1.4.3.2 xDLMS services used by the client with LN referencingGET9.3.6、SET9.3.7、ACTION9.3.8、ACCESS9.3.9s9.1.4.3.3 xDLMS services used by the client with SN referencingRead9.3.14、Write9.3.15、UnconfirmedWrite9.3.16s9.1.4.3.4 Unsolicited services主动上报共有 DataNotification，LN 有 EventNotification，SN 有 InformationReports9.1.4.3.5 Selective access选择性访问属性内部分内容s9.1.4.3.6 Multiple references在 COSEM 对象相关的服务调用中，可以引用一个或多个命名变量、属性和/或方法，见 9.4.6.1的multiple-references参数，比如ACCESS总是支持这个特性s9.1.4.3.7 Attribute_0 referencing属性0表示引用所有公共属性（属性号为正），s9.1.4.4 Additional mechanisms与 IEC 61334-4-41:1996 中规定的 DLMS 相比，xDLMS 指定了一些新的机制来提高功能、灵活性和效率。其他机制包括: 使用逻辑名 logical names 进行引用; 识别服务调用; 优先处理; 传输较长的应用信息; 可组合的 xDLMS 消息; 压缩解压; 通用密码保护; 通用块传输 general block transfer(GBT)下面逐个介绍s9.1.4.4.2 Referencing methods and service mapping在confirmed AAs的情况下，引用方法在 AA 建立阶段通过 COSEM 应用上下文进行协商。在 AA 成立期间不得改变。在给定的 AA 中使用 LN 或 SN 服务是独占的。在unconfirmed and pre-established AAs 的情况下，客户端 AL 需要提前知道服务器支持的引用方法。s9.1.4.4.3 Identification of service invocations: the Invoke_Id parameter在 client/server 模型中，请求由客户机发送，响应由服务器发送。允许客户端在接收到对前一个请求的响应之前发送多个请求，前提是较低层允许这样做。需要用Invoke_Id来标识数据包，这样客户端才能判断响应是对应哪个请求的在ACCESS和DataNotification服务(参见 9.3.9 和 9.3.10)中，使用Long-Invoke-Id参数来代替Invoke_Id 参数。EventNotification服务不包含Invoke_Id 参数。此功能仅在LN引用时可用s9.1.4.4.4 Priority handling对于使用LN引用的数据传输服务，有两个优先级可用:normal (FALSE)和high (TRUE)。服务器不按先来先服务FIFS，而是根据优先级处理此功能仅在LN引用时可用s9.1.4.4.5 Transferring long messagesxDLMS 服务原语由xDLMS APDUs以编码形式携带。这种编码形式可能比客户端/服务器协商的最大接收PDU大小长两种方案： 通用块传输(GBT)机制 特定于服务的块传输机制如果最大接收 PDU 大小很大，超过了下一层的限制，APDUs 符合条件，不用分块，那就需要下一层进行分包操作特定于服务的块传输机制用于： 使用 LN 参引用的 confirmed services:GET、SET、ACTION; 使用 SN 参引用的 confirmed services:Read、Write特定于服务的块传输在以下情况下不可用: unconfirmed services unsolicited services (DataNotification, EventNotification and InformationReport) the ACCESS service特定于服务的块传输只能一包一包顺序传，不支持流式传输，不支持恢复丢失块。加密是加一个 block，而不是整个 APDU，服务专用数字签名不可用。TODO：服务专用数字签名是什么相反，GBT机制可以与任何 xDLMS APDU 一起使用，包括通用密码和通用签名APDU。它提供双向块传输、流和丢失块恢复。当需要加密保护时，对完整的APDU进行加密保护，然后被保护的 APDU 以块的形式传输，如图 87 所示。s9.1.4.4.6 Composable xDLMS messages可组合的 xDLMS 消息处理 xDLMS 消息的三个重要方面是编码/解码、应用、验证/删除密码保护和块传输，见9.3.5。可组合 xDLMS 消息的概念将这三个方面分开一旦 AL 构建了与 AP 调用的服务原语对应的 APDU，就可以使用通用保护机制来应用密码保护。然后产生不受保护或受保护的 APDU ，当长度超过协商的 APDU 长度时，可以采用通用块传输机制。s9.1.4.4.7 Compression and decompressionFor details, see 9.2.3.6.s9.1.4.4.8 General protection此机制可用于对任何 xDLMS APDU 应用密码保护，这允许在客户机和服务器之间或第三方和服务器之间应用多层保护。见 9.2.2.5。 the general-ded-ciphering and the general-glo-ciphering APDUs; the general-ciphering APDUs; the general-signing APDU.sGeneral block transfer (GBT)GBT 机制可用于块内传输任何长或短xDLMS APDU。在 GBT 中，块由通用块传输APDU携带，而不是由特定于服务的“with-datablock”APDUs 携带。GBT 机制支持双向块传输、流传输和丢失块恢复: 双向块传输意味着当一方发送块时，另一方不仅可以确认接收到的块，而且如果它有块可以发送，它也可以发送它们，就是全双工模式; 流式传输意味着一方可以发送多个区块，而无需另一方对每个区块进行确认,有一个发送窗口;参考 TCP 传输 丢失块恢复意味着如果发送的块的接收未被确认，它可以被再次发送。如果使用流，丢失的块恢复发生在每个流窗口的结束。通用块传输机制的协议在 9.4.6.13 中指定s9.1.4.5 Additional data typess9.1.4.6 xDLMS version number6s9.1.4.7 xDLMS conformance blockxDLMS一致性块支持具有扩展功能的优化的 DLMS 服务实现。它可以通过标记“Application 31”与 DLMS 一致性块区分开来。请参见 9.4.6.1、9.5 和 9.6。confirmed AAs可以在AA建立期间协商一致性块，unconfirmed and pre-established AAs需要客户端提前知道server 的一致性块s9.1.4.8 Maximum PDU size Client Max Receive PDU Size Unsigned16，必须能满足 AARE APDU 大小 低于 12 的值被保留，0 表示无限制 Server Max Receive PDU Size Unsigned16 低于 12 的值被保留，0 表示无限制s9.1.5 Layer management services这些服务的规范不在本技术报告的范围内。s9.1.6 Summary of DLMS/COSEM application layer services The DLMS/COSEM AL services are specified in 9.3. The DLMS/COSEM AL protocol is specified in 9.4. The abstract syntax of the ACSE and xDLMS APDUs is specified in 9.5. The XML schema is defined in 9.6.s9.1.7 DLMS/COSEM application layer protocolsDLMS/COSEM AL协议是基于ISO/IEC 15954:1999中规定的ACSE标准和IEC 61334-4-41:1996中规定的DLMS标准，并扩展了 DLMS/COSEM。s9.2 Information security in DLMS/COSEM DLMS/COSEM 安全概念 security concept，见 9.2.2; 选择的加密算法，见 9.2.3; 安全密钥，见 9.2.4、9.2.5、9.2.6; 使用加密算法进行实体认证，xDLMS APDU 保护和 COSEM 数据保护，见 9.2.7。s9.2.2 The DLMS/COSEM security concepts9.2.2.2 Identification and authentications9.2.2.2.1 Identification如 4.3.3 所述，DLMS/COSEM AEs被绑定到支持 AL 的协议层中的服务接入点(SAPs)。这些 SAPs 存在于 AA 中包含 xDLMS APDUs 的 PDUs。客户端用户识别机制使服务器能够区分客户端的不同用户(可能是运营商或第三方)，以记录他们访问设备的活动。也看到 4.3.6。s9.2.2.2.2 Authentication mechanisms身份验证机制确定通信实体在 AA 建立期间使用的协议来证明自己。 No security (Lowest Level Security) authentication 无安全性(最低级别安全性)身份验证的目的是允许客户机从服务器检索一些基本信息。这种身份验证机制不需要任何身份验证;客户端可以访问安全上下文中的 COSEM 对象属性和方法，以及给定 AA 中普遍存在的访问权限。 Low Level Security (LLS) authentication 服务器要求客户端通过提供服务器知道的密码来证明自己。该密码是由当前持有的“Association SN / LN”对象建模的 AA 来建立的。“Association SN / LN”对象提供了更改密码的方法。 High Level Security (HLS) authentication 客户端和服务器都必须成功地证明自己（双向认证），以建立一个 AA。 Pass 1:客户端发送一个“challenge”CtoS 信息，以及根据身份验证机制附加的信息给服务器; Pass 2:服务器发送一个“challenge”StoC 信息，以及根据身份验证机制附加的信息给客户端; 如果 StoC 与 CtoS相同，客户应拒绝并中止AA 建立过程。所以 StoC 与 CtoS 必须是独立生成的且不同的。 Pass 3:客户端根据对给定 AA 有效的 HLS 身份验证机制的规则处理StoC和其他信息，并将结果发送给服务器。服务器检查f(StoC)是否是正确处理的结果，如果是，则接受客户端的身份验证 Pass 4:服务器根据对给定 AA 有效的 HLS 身份验证机制的规则处理CtoS和附加信息，并将结果发送给客户端。客户端检查f(CtoS)是否是正确处理的结果，如果是，则接受服务器的身份验证。 总结，由服务端先校验客户端合法性，再由客户端校验服务端合法性pass2后，如果 application context and xDLMS context合法（这两个参数再 pass1 和 2 交换或生成，pass2 后已存在，只不过要到 pass4 全走完才激活），则授予当前”Association SN / LN”对象的reply_to_HLS_authentication方法权限pass3 和 4 依赖于 reply_to_HLS_authentications9.2.2.3 Security context 安全套件security suite，确定可用的安全算法，参见 9.2.3.7; 安全策略security policy，确定在 AA 内交换的所有 xDLMS APDUs 的保护类型。可能的安全策略在 9.2.7.2.2 中指定; 安全材料security material，与给定安全算法相关的，包括安全密钥、初始化向量、公钥证书等。由于每个安全算法的安全材料都是特定的，因此在相关条款中详细指定了元素。s9.2.2.4 Access rights属性的访问权限包括:no_access、read_only、write_only 或 read_and_write。方法的访问权限可以是 no_access 或 access。可以对访问特定的属性或方法的 APDUs 单独配置加密，.request 和.response 也可以s9.2.2.5 Application layer message security就是对称加密传输的过程，AA 已经建立的情况下为了确保端到端消息安全性，第三方必须能够与 DLMS 服务器交换受保护的 xDLMS 服务请求。在这种情况下，客户端充当代理 第三方Third party: 感知 DLMS/COSEM，即它可以生成和处理封装了携带 COSEM 对象相关的服务请求和响应的 xDLMS APDUs的消息; 它能够对携带请求的 xDLMS APDU 应用自己的保护 TODO：这个保护是不是不在 DLMS 规定的范围内，比如用 HTTP 传输，TLS 保护。但是接受服务端消息时又写到能够处理 server - client general protected APDU，AA 不是 client 和 server 建立的吗，third party 的密钥是哪里来的，对应9.2.7.3一起 它能够验证由服务器和/或客户端应用的保护响应。 The DLMS client 作为第三方和服务器之间的中间人broker; 根据TP-client消息中包含的信息，为第三方提供适当的AA; 验证 TP 有权使用该 AA;验证方法超出了本技术报告的范围。 这里提到了AA是client和server维护的，和third party无关，但third party可以利用这个AA传递消息 它可以验证第三方申请的保护; 封装第三方客户端消息到一个通用的受保护的 xDLMS APDU; 它可以验证服务器对封装 COSEM 对象相关服务响应或未经请求的服务请求的 APDU 应用的保护;(Push 操作时); 它可以对发送到 TP 的受保护的 xDLMS APDU 应用自己的保护。 The server 与第三方使用的客户端(预先)建立AA; 它可以检查使用 AA 的第三方的身份; 一旦客户端和/或第三方应用的保护被服务端成功验证，服务端将提供访问 COSEM 对象属性和方法的权限，这些属性和方法由安全策略和访问权限确定; 它应该准备响应——或者，在推送操作的情况下，一个未经请求的服务请求——并应用由传入请求的保护、访问权限和安全策略决定的保护。 s9.2.2.6 COSEM data security对具体COSEM 对象内属性、方法参数等的保护，与 AL 层整体加密整个 xDLMS APDU 有区别。s9.2.3 Cryptographic algorithms 散列函数 hash functions 对称加密 symmetric key algorithms 非对称加密 asymmetric key algorithmss9.2.3.2 Hash function一个好的哈希函数是单向函数（逆过程很难），且要找到产生相同哈希值的两个特定输入也是极其困难的。哈希函数接受任意长度的输入，输出固定长度的值。一般用于校验完整性在 DLMS/COSEM 中使用哈希算法的目的如下: 数字签名，见 9.2.3.4.4; 密钥协议，见 9.2.3.4.6; HLS 认证。具体算法与认证机制有关，请参见 9.2.7.4。s9.2.3.3 Symmetric key algorithms对称密钥算法在 DLMS/COSEM 中用于以下目的: 使用 HLS 认证机制对通信伙伴进行认证，参见 9.2.7.4; xDLMS 消息的认证和加密，参见 9.2.7.2; COSEM 数据认证和加密，参见 9.2.7.5。s9.2.3.3.2 Encryption and decryptions9.2.3.3.3 Advanced Encryption StandardAES 算法，属于分组加密算法AES 结合了安全性、性能、效率、易于实现和灵活性。具体来说，该算法在各种计算环境的硬件和软件上都有良好的性能。此外，该算法对内存的要求非常低，这使得它非常适合于空间受限的环境。 TODO:内存占用少是不是因为是分组加密，每一块加解密时占用少导致的s9.2.3.3.4 Encryption Modes of OperationAES-GCM 可规避相同明文块加密成相同密文块带来的重复特征检测，密文块批量篡改的问题。s9.2.3.3.5 Message Authentication Code消息验证码 MACMAC 作用与 HASH 函数相似，都可以验证完整性，不同的是 MAC需要密钥而 HASH 不需要密钥。MAC 还能验证真实性，即使内容被篡改因为没有密钥也无法生成 MACs9.2.3.3.6 Key wrapping可以使用对称密钥算法使用密钥封装密钥(也称为密钥加密密钥)来封装(即加密)密钥材料。master key见 9.2.3.3.8s9.2.3.3.7 Galois/Counter ModeGCM 是 AES 算法的一种运行模式。加密或认证可选，可以仅加密或仅认证 认证加密函数 输入: 密钥，EK 明文，表示为P; 附加认证数据Additional Authenticated Data(AAD)，记为A; 初始化向量initialization vector(IV)表示为IV。 明文和 AAD 是 GCM 保护的两类数据。GCM 保护了明文和 AAD 的真实性;GCM 还保护明文的机密性，而 AAD 则是透明的（明文加密认证，AAD仅认证） 长度要求（bit）： len(P) &amp;lt; 2^39-256; len(A) &amp;lt; 2^64-1; 1 &amp;lt;= len(IV) &amp;lt;= 2^64-1. P、A、IV 的位长都是8的倍数，所以这些值都是字节串。 输出： 一个与明文 P 位长度相同的密文C 一个身份验证标记或标记，简称T 认证解密函数 输入： 密钥，EK 密文 C 附加认证数据Additional Authenticated Data(AAD)，记为A; 一个身份验证标记，简称T 输出： 一个与密文 C长度相同的明文P 一个特殊的错误代码，在本技术报告中表示为 FAIL The initialization vector, IV 就是 frame counter，每加密一次加 1,DLMS 协议里是 systemtitle + IC systemtitle 又称固定字段 64位（8字节） IC 又称调用字段 32位（4字节） 任意两个物理设备的固定字段不能相同（由systemtitle保证唯一），对同一逻辑设备的任意两次请求的调用字段不能相同（每次请求递增） 固定字段的位长将可以为给定密钥实现验证加密功能的不同物理设备的数量限制为 2^64。调用字段的位长将验证加密功能的调用次数限制为 2^32 输入集而不违反唯一性要求。 每个加密密钥(EK)都有两个相关联的调用计数器(IC)，一个用于经过身份验证的加密函数，另一个用于经过身份验证的解密函数。 当密钥建立时，对应的IC复位为 0; 使用认证加密功能后，对应的 IC加1。如果 IC 已达到最大值，任何进一步调用认证加密函数将返回错误，且 IC不得增加。 使用鉴权解密功能时，验证IC的值。该值必须等于或大于最低可接受值。 如果被验证的值满足此要求，则使用认证解密功能后，最低可接受值为 已验证的IC值加1 。如果 被验证的值小于 最低可接受值，则验证失败，经过验证的解密功能也会失败。如果被验证的值等于最大值，则经过验证的解密函数将返回一个错误。 TODO:这里有个问题，如果客户端出现异常，被验证值设置得很大，那不是会很快到达最大值，导致设备不可用 The encryption key, EK GCM只使用一个密钥，即分组密码密钥。在 DLMS/COSEM 中，这被称为加密密钥，表示为EK。它的大小取决于安全套件(参见 9.2.3.7)，应该是: for security suite 0 and 1, 128 bits (16 octets): len(EK) = 128; for security suite 2, 256 bits (32 octets): len(EK) = 256; 密钥应该随机均匀生成，或者近似随机均匀生成，即每个可能的密钥生成的概率(几乎)相等。因此，该键将是新的，即，不等于任何以前的键，且概率很高。密钥应该是秘密的，应使用只适用于 GCM 和选定的分组密码 AES。密钥建立和管理的附加要求在 NIST SP 800-38D:2007, 8.1 中进行了讨论。 The authentication key, AK 作为附加认证数据(AAD)的一部分 Length of the authentication tag 身份验证标记的位长t是一个安全参数。在安全套件 0、1 和 2 中，其值应为 96 位。 s9.2.3.3.8 AES key wrap对于封装密钥数据，DLMS/COSEM 选择了RFC 3394中指定的 AES 密钥封装算法。该算法旨在包装或加密关键数据。它对64位块进行操作。在 wrap 之前，关键数据被解析为n个64位的块,n至少为2。(AES 密钥长度是 128、192、256，所以肯定满足要求)加密输入密钥加密密钥KEK和明文密钥，明文密钥为n个64bit块，输出(n+1)*64bit长度密文解密相反。AES-WRAP algorithmGB∕T 36624-2018 信息技术 安全技术 可鉴别的加密机制 概述 AES-WRAP: Advanced Encryption Standard (AES) Key Wrap Algorithm。本文的总结均来自《RFC-3394》。 Any data being wrapped will be referred to as the key data; The key used to do the wrapping will be referred to as the key-encryption key (KEK)。 The term “key data” is used broadly to mean any data being wrapped, but particularly keys, since this is primarily a key wrap algorithm。 A KEK can be a 128-bit key, a 192-bit key, or a 256-bit key。 下面的 key wrap 和 key unwrap 都是 index based 模式的。 IV分两种：Default 和 Alternative。Default 时， IV = A6A6A6A6A6A6A6A6 key wrap Inputs: Plaintext, n 64-bit values {P1, P2, …, Pn}, and Key, K (the KEK). Outputs: Ciphertext, (n+1) 64-bit values {C0, C1, …, Cn}. Steps: Initialize variables Set A = IV, an initial value (see 2.2.3) For i = 1 to n { R[i] = P[i]; } Calculate intermediate values. For j=0 to 5 For i=1 to n B = AES(K, A | R[i]) A = MSB(64, B) ^ t where t = (n*j)+i R[i] = LSB(64, B) Output the results. Set C[0] = A For i = 1 to n C[i] = R[i] key unwrap Inputs: Ciphertext, (n+1) 64-bit values {C0, C1, …, Cn}, and Key, K (the KEK). Outputs: Plaintext, n 64-bit values {P0, P1, K, Pn}. Steps: Initialize variables. Set A = C[0] For i = 1 to n R[i] = C[i] Compute intermediate values. For j = 5 to 0 For i = n to 1 B = AES-1(K, (A ^ t) | R[i]) where t = n*j+i A = MSB(64, B) R[i] = LSB(64, B) Output results. If A is an appropriate initial value (see 2.2.3) Then For i = 1 to n P[i] = R[i] Else Return an error 模块W 图中的S是明文64bit块，输入输出等长 说明 AES(K, W) Encrypt W using the AES codebook with key K AES-1(K, W) Decrypt W using the AES codebook with key K MSB(j, W) Return the most significant j bits of LSB(j, W) Return the least significant j bits of W 在 DLMS/COSEM 中，KEK 的大小取决于安全套件(参见 9.2.3.7)，并应是: 对于安全套件0和1,128 位(16 位):len(KEK) = 128; 对于安全套件2,256 位(32 位):len(KEK) = 256。s9.2.3.4 Public key algorithms公钥密码系统一般采用难以解决的问题作为算法的基础。RSA 算法是基于非常大的整数的质因数分解。椭圆曲线密码体制(ECC)是基于求解椭圆曲线离散对数问题(ECDLP)的难度。 通信双方认证 xDLMS APDUs 和 COSEM 数据的数字签名 密钥协商key agreement一些非对称密钥算法可以用于多种目的(例如，用于数字签名和密钥建立)。用于一种目的的密钥不得用于其他目的。(只对公钥有这个要求，不过公私钥一般是一一配对的)s9.2.3.4.2 Elliptic curve cryptography椭圆曲线密码学 ECC素数域上的椭圆曲线由实数(x, y)组成，满足下列方程:\\[y^2=x^3+ax+b\\]曲线的形状由 a 和 b 两个参数决定 NIST 推荐使用椭圆曲线s9.2.3.4.3 Data conversions本节描述了数据转换原语，用于在用于指定公钥算法的不同数据类型之间进行转换：八位字节串 (OS)、位串 (BS)、整数 (I)、字段元素 (FE) 和椭圆曲线点 （ECP）。 DLMS/COSEM 使用八位组字符串来表示公钥算法的元素，并使用这些数据类型与八位组字符串之间的转换原语。 长度为 d 的八位字节串 $M_{d–1}$ $M_{d–2}$ … $M_0$ 被编码为 A-XDR OCTET STRING，其中最左边的八位字节$M_{d–1}$对应于八位字节串的编码值的第一个八位位组 Conversion between Bit Strings and Octet Strings (BS2OS) 位串转换为八位串的数据转换原语称为位串到八位串转换原语，或称 BS2OS。它以位字符串作为输入，输出八位字符串。长度为 l 的字节串$b_{l-1} b_{l-2}…b_{0}$应该转换为长度为$d=⌈l/8⌉$的八位字符串$M_{d-1} M_{d-2}…M_{0}$。 位串在内存中的编码非常密集。每个位只占用一位存储空间，整个位串的开销由一个小常数限定。但是，与访问向量或字符串的元素相比，访问位串中的位要慢。如果性能是最重要的问题，最好使用字符串来存储布尔值集，即使它们占用更多空间。 位串和八位字节串的区别就是位串的位长不需要是8的倍数，而可以是任意值，转换的时候需要补足8的倍数 转换器在左边填充足够的零，使位数为8的倍数，然后将其分解为八位。 for $0 \\le i \\lt d – 1$, let the octet $M_i = b_{8i+7} b_{8i+6} … b_{8i},$; the leftmost octet $M_{d–1}$ shall have its leftmost $8d – l$ bits set to zero;最左边的 OS 字节需要包含位串最左边填 0 部分 its rightmost $8 – (8d – l)$ bits shall be $b_{l–1} b_{l–2} … b_{8d–8}$. Conversion between Octet Strings and Bit Strings (OS2BS) 和上面相反 最左一字节的最左位必须是 0 Conversion between Integers and Octet Strings (I2OS) 输入为非负整数$x$，预期长度$d$，需要满足$256^d \\gt x$ 每个整数的位用一个字节表示： $x = x_{d-1} \\cdot 256^{d-1} + x_{d-2} \\cdot 256^{d-2} + \\cdots + x_1 \\cdot 256 + x_0$; where $0 ≤ x_i &amp;lt; 256$ for $0 ≤ i ≤ d-1$; $M_i = x_i$, for $0 ≤ i ≤ d-1$. 256正好是二进制0b100000000，1在8位，这样的话0-7位就表示$x_0$，通过$x_1 \\cdot 256$让8-15位表示$x_1$ 例：十进制1234，转为OS为$0 \\cdot 256^3+0 \\cdot 256^2+4 \\cdot 256^1+210$结果为0x000004D2。其实就是把数字转换为16进制数用HEX表示 Conversion between Octet Strings and Integers (OS2I) 和上面相反 0 字节的 OS 输出整数 0 Conversion between Field Elements and Octet Strings (FE2OS) 将字段元素转换为八位字符串的数据转换原语称为字段元素到八位字符串转换原语，或FE2OS。它接受一个字段元素作为输入，并输出相应的八位字符串。应用 I2OS 转换原语，参数$l$将域元素$x \\in F_p$转换为长度为$d =⌈\\log_{256}p⌉$的八位字符串$M_{d-1} M_{d-2} … M_0$，其中 $FE2OS(x) = I2OS(x,l)$ Conversion between Octet Strings and Field Elements (OS2FE) 与上面相反 $OS2FE(x) = OS2I(x) \\mod p$ TODO:Field Elements 是什么，FE2OS 不懂 更新：域元素应该就是某个域范围内的一个值，比如域为0-9999，这个值可能就是3456。$log_{256}45768865=3.18098289749$，所以长度就至少是4，结果为0x02BA60A1，其实就是把数字转换为16进制数用HEX表示s9.2.3.4.4 Digital signature数字签名是书面签名的电子模拟，可用于向收件人或第三方证明消息是由发信人签名的(这种特性称为不可否认性)。还可以为所存储的数据和程序生成数字签名，以便可以在稍后时间验证数据和程序的完整性s9.2.3.4.5 Elliptic curve digital signature (ECDSA)对于 DLMS/COSEM，选择了 FIPS PUB 186-4:2013 中指定的椭圆曲线数字签名(ECDSA)算法。NSA1 提供了一个实现指南。 在 DLMS/COSEM 中使用的椭圆曲线和算法为: in the case of Security Suite 1, the elliptic curve P-256 with the SHA-256 hash algorithm; in the case of Security Suite 2, the elliptic curve P-384 with the SHA-384 hash algorithm. 签名 输入： 要签名的消息 M; 签名者的私钥 d 输出： ECDSA signature (r, s) over M. 验签 输入： 已签名的消息 M’ ECDSA signature (r’,s’) 签名者的公钥 Q 在 DLMS/COSEM 中，应使用纯文本格式：签名 (r, s) 被编码为八位字节串 $R || S$(表示串联，不是逻辑运算符的或)，即作为八位字节串 R = I2OS(r,l) 和 S = I2OS(s,l) 的串联, $l = [\\log_{256} n]$。 因此，签名具有 2l 个八位字节的固定长度。s9.2.3.4.6 Key agreement密钥协商允许两个实体联合计算共享密钥并从中派生密钥材料。对于 DLMS/COSEM，已从 NIST SP 80056A Rev. 2: 2013 中选择了三种椭圆曲线密钥协商方案 椭圆曲线密钥协商方案： the Ephemeral Unified Model C(2e, 0s, ECC CDH) scheme; 此方案用于 DLMS 客户机和服务器之间就主密钥、全局加密密钥和/或身份验证密钥达成一致。客户端扮演U方角色，服务器扮演V方角色。流程由“Security setup”接口类的方法支持;见 DLMS UA 1000-1 Part 2 Ed.15:2021, 4.4.7. 双方从域参数 d中生成一个临时密钥对。双方交换临时公钥，然后使用域参数、各自的临时私钥和对方的临时公钥计算共享密钥Z。密钥材料是使用 9.2.3.4.6.5 中指定的密钥派生函数从共享密钥Z和其他输入中派生出来的。() TODO:域参数是什么 TODO:密钥材料，密钥派生是什么。 the One-Pass Diffie-Hellman C(1e,1s, ECC CDH) scheme; 和上面的类似，主要是静态动态公钥的区别，就是不需要服务端把动态公钥给客户端，客户端可以通过预先导入的证书（可信 CA 签名）获得对方的静态公钥 全程只需要发送一次公钥 the Static Unified Model C(0e, 2s, ECC CDH) scheme. 和上面的类似，将动态公钥变成了静态公钥，不需要发送公钥，只需要 Nonce，Nonce 用于计算密钥材料，保证每次生成的密钥材料不同。 Key Derivation Function – The NIST Concatenation KDF 密钥派生函数 Function call: kdf(Z, OtherInput) Z共享密钥，byte string OtherInput keydatalen一个整数，表示要生成的密钥材料的长度(以位为单位):安全套件1为128位，安全套件2为256位; OtherInfo等于下列串联的位字符串 $AlgorithmID || PartyUInfo || PartyVInfo {||SuppPubInfo}{||SuppPrivInfo}$ AlgorithmIDbit string，指示如何解析派生的密钥材料,以及派生的密钥材料将用于哪种算法 GUEK and GAK：AES-GCM-128 / AES-GCM-256. KEK：AES-WRAP-128 / AES-WRAP-256 PartyUInfoU 方提供的公开信息，用于派生过程，bit string PartyVInfoV 方提供的公开信息，用于派生过程，bit string SuppPubInfo(Optional),额外的公开信息，DLMS/COSEM 不使用 SuppPrivInfo(Optional),额外的非公开信息，DLMS/COSEM 不使用 s9.2.3.5 Random number generation应提供强随机数生成器(RNG)，以生成 DLMS/COSEM 中使用的各种算法所需的随机数。s9.2.3.6 Compression和加密无关，只是放在一起s9.2.3.7 Security suite安全套件确定可用于各种密码原语的密码算法集和密钥长度。DLMS/COSEM安全套件(见表 27)基于NSA suite B，包括用于`身份验证、加密、密钥协议、数字签名和哈希的加密算法s9.2.4 Cryptographic keys – overview密钥作用： 明文到密文的转换; 密文到明文的转换; 验证码(MAC)的计算和验证; 密钥包装 wrapping; 应用和验证数字签名; 密钥协商。s9.2.5 Key used with symmetric key algorithmss9.2.5.1 Symmetric keys types对称密钥的分类： 按目的分类 key encrypting key (KEK)用于加密其他对称加密密钥，master key encryption key 用于 AES-GCM 算法的块加密 authentication key 用于 AES-GCM 算法的 AAD 按生命周期分类 打算使用较长时间的静态密钥。 在 DLMS/COSEM 中，它们可能是： 一个全局密钥，可用于在相同合作伙伴之间重复建立的多个 AA。 全局密钥可以是单播加密密钥（GUEK）、广播加密密钥（GBEK）或认证密钥（GAK）； 在两个合作伙伴之间建立的单个 AA 期间可以重复使用的专用密钥。 因此，其生命周期与 AA 的生命周期相同。 专用密钥只能是单播加密密钥。 临时密钥通常用于 一个 AA 内的单个交换。 TODO:InitiateRequest APDU 和 AARQ 是什么关系？答：见 12.3 Table 133 最后，InitiateRequest APDU 是 AARQ 中 user-information 字段的一部分，是可以加密的专用密钥由 AARQ APDU 中的InitiateRequest APDU携带，这个 InitiateRequest APDU本身要被全局单播加密密钥（GUEK）加密，AARE 中的InitiateResponse APDU也要用相同的方式加密。 AARQ 和 AARE APDUs 本身不受保护。s9.2.5.2 Key information with general-ciphering APDU and data protection当 general-ciphering APDU 用于保护 xDLMS APDU 或 COSEM 数据时，发送方不仅要发送加密后的xDLMS APDU / COSEM 数据，同时也要发送密钥的必要信息，该信息已经或将用于加密/解密 xDLMS APDU/COSEM 数据，包括EK、AK、MK等s9.2.5.3 Key identification TODO:没看懂s9.2.5.4 Key wrapping可以用 key wrapping 加密的： the master key, KEK; and/or the global unicast encryption key GUEK; and/or the global broadcast encryption key GBEK; and/or the (global) authentication key, GAK.“Security setup” 对象的 key_transfer 方法。s9.2.5.5 Key agreement可以用 The Ephemeral Unified Model C(2e,0s, ECC CDH) scheme 协商的密钥： the master key, KEK; and/or the global unicast encryption key GUEK; and/or the global broadcast encryption key GBEK; and/or the (global) authentication key, GAK.s9.2.5.6 Symmetric key cryptoperiods对称密钥的加密周期应在项目特定的配套规范中确定。s9.2.6 Keys used with public key algorithms非对称加密算法密钥分类： 按目的：数字签名、密钥协商 按生命周期：静态密钥、临时密钥 s9.2.6.2 Key pair generation由(q, FR, a, b {, domain_parameter_seed}, G, n, h)生成私钥 d 和公钥 Qs9.2.6.3 Public key certificates and infrastructurePublic Key Infrastructure (PKI)s9.2.6.3.2 Trust modelDLMS servers 设备制造过程应该预先导入trust anchors信任锚、自己的证书、CA 证书、DLMS clients and third parties 证书。 设备制造导入证书或信任锚属于Out of Band (OOB)带外过程，也就是正规操作以外的过程，正常导入证书应该是通过“Security setup”对象 信任锚见这篇文章，信任锚就是最终信任的那个实体，可以有多个，可以是 root CA，一般操作系统预装了可以信赖的 root CA 列表“Security setup”类提供： 提供关于存储在服务器上的证书的信息的属性; 用于生成服务器密钥对的方法和用于生成服务器上的证书签名请求(CSR)信息的方法,CSR 由客户端代为发送给CA; 导入、导出、移除证书的方法证书一般都有一个有效期限。但是，颁发给DLMS服务器的证书可能无限期有效。证书到期后，可能需要进行替换。在服务器使用证书之前，必须对其进行验证。验证包括: 检查证书的语法有效性; 检查证书包含的属性; 检查证书有效期是否未过期; 检查信任锚点的认证路径; 检查证书颁发者的签名s9.2.6.3.3 PKI architecture – informativePKI 是一种安全基础设施，它创建和管理公钥证书，以方便使用公钥(即，非对称密钥)加密。 在验证绑定的准确性后，生成并分发公钥证书，以将公钥绑定到其他信息上（证书包含了公钥和部分设备自定义信息，最后加上数字签名） 维护和分发未过期证书的证书状态信息。 Root-CA提供 PKI 的信任锚点。它为 Sub-CAs 颁发证书，并维护一个证书撤销列表(CRL)。Root-CA 证书策略定义了处理证书颁发的规则 Root-CA 拥有根证书“C(Root)”。Root-CA 的证书是用 Root-CA 的私钥自签名的。Sub-CAs证书也使用 Root-CA私钥签名。 Sub-CASub-CA 是为终端实体颁发证书的组织，被 Root-CA 授权 每个 Sub-CA Certificate Policy 证书策略必须遵守 Root-CA Certificate Policy 备存发给终端实体 End entity 的证书清单及证书撤销清单 Sub-CA 拥有证书C(sub-CA)。此证书由 Root-CA 颁发。Sub-CA 的私钥用于签名终端实体 End entity 证书。 End entities 数字签名密钥证书C(digitalSignature)，用于数字签名; 静态密钥协商密钥证书C(keyAgreement)，用于密钥密钥协商; （可选）TLS- certificate C(TLS)，用于在建立 TLS 安全通道之前在 DLMS 客户端和 DLMS 服务器之间进行认证。 s9.2.6.4 Certificate and certificate extension profile所有证书都应具有为X.509 V3证书指定的结构。s9.2.6.4.2 The X.509 v3 Certificate m (mandatory): 强制使用; o (optional): 可选; x (do not use): 不要使用.Certificate： tbsCertificate包含主题和颁发者的名称、与主题关联的公钥、有效期和其他相关信息 VersionV3 为 2 Serial number序列号必须为 CA 分配给每个证书的正整数。对于给定 CA 颁发的每个证书，它必须是唯一的。上限20个字节 Issuer and Subject颁发者字段标识签名和颁发证书的实体。 Common Name 需要是 DLMS/COSEM System title Validity period证书有效期 开始生效(notBefore) 无效时间(notAfter) DLMS 服务器可以获得无法指定有效过期日期的证书;这样的证书将在设备的整个生命周期内使用 为了表明证书没有明确定义的到期日期，notAfter 应该被分配 99991231235959Z 的 GeneralizedTime 值。 SubjectPublicKeyInfo标识公钥和密钥算法 SubjectPublicKeyInfo ::= SEQUENCE{ Algorithm AlgorithmIdentifier, subjectPublicKey BIT STRING}AlgorithmIdentifier ::= SEQUENCE{ algorithm OBJECT IDENTIFIER, parameters ANY DEFINED BY algorithm OPTIONAL} AlgorithmIdentifier 用于识别密钥算法 OBJECT IDENTIFIER： OID value: 1.2.840.10045.2.1; OID description: ECDSA and ECDH Public Key. parameter： 1.2.840.10045.3.1.7：NIST P-256 1.3.132.0.34：NIST P-384 Subject Unique ID主题唯一 id 可以选择性地用于终端设备证书，而不是服务器证书。 Certificate extensions Authority Key Identifier标识公钥，公钥是和用于签名证书的私钥对应的 SubjectKeyIdentifier标识包含特定公钥的证书 KeyUsage密钥用途，keyAgreement、digitalSignature 等 CertificatePolicies证书策略 SubjectAltNames主题备用名称,可以当作 subject 的扩展 IssuerAltName签发者备用名称 Basic constraints标识本证书所有者是否为 CA Extended Key Usage该证书可作为 TLS 服务器证书使用 cRLDistributionPoints标识如何获取 CRL Other extensions signatureAlgorithm包含 CA 用于签名此证书的签名算法的标识符。和signatureValue相关 AlgorithmIdentifier ::= SEQUENCE{ algorithm OBJECT IDENTIFIER parameters ANY DEFINED BY algorithm OPTIONAL} ecdsa-with-SHA256, OID 1.2.840.10045.4.3.2 in the case of security suite 1; ecdsa-with-SHA384, OID 1.2.840.10045.4.3.3 in the case of security suite 2; signatureValue由ASN.1 DER编码的tbsCertificate生成的数字签名 用于验证 tbsCertificate 的有效性 s9.2.6.5 Suite B end entity certificate types to be supported by DLMS servers终端设备包含的证书类型证书必须用 ECDSA 签名，证书中的P-256类型密钥必须用P-256或P-384类型密钥签名，证书中的P-384类型密钥必须用P-384类型密钥签名 Root-CA 自签名证书（信任锚） Sub-CA 证书 用于 ECDSA 签名生成和验签的证书 Key Establishment(Key agreement)用证书（ECDH算法，One-Pass Diffie-Hellman C(1e, 1s) scheme or with the Static Unified Model C(0e, 2s, ECC CDH) scheme） TLS 证书s9.2.6.6 Management of certificates证书管理s9.2.6.6.2 Provisioning servers with trust anchors为服务器提供信任锚，需要再设备正常运行前导入Root-CA,Sub-CA证书或直接信任的CA公钥。可以有多个信任锚信任锚的部署或替换是带外操作，out of band (OOB)信任锚证书和其他证书存储在一起 TODO:这个是否有安全问题，比如 windows 有专门的受信任根证书区域，每个分类都有专属区域。 更新:见下句可以导出，不能导入或删除，解释了上面的安全问题，是有防篡改保护的直接信任的 CA 公钥不能导出s9.2.6.6.3 Provisioning the server with further CA certificates为服务器提供进一步的CA证书（应该是 Sub-CA，非信任锚）“Security setup”对象中的import_certificate方法导入的 CA 证书需要使用信任锚校验s9.2.6.6.4 Security personalisation of the server安全个性化导入非对称密钥： 通过设备商专有方式导入私钥和公钥证书 “Security setup”相关函数产生 客户端调用generate_key_pair方法。方法调用参数指定要生成的特定用途的密钥对:数字签名、密钥协商或 TLS; 客户端调用generate_certificate_request方法。方法调用参数标识生成证书签名请求(CSR)所需的密钥对。返回参数包括 CSR，由新生成的密钥对的私钥签名; TODO:CSR 还要私钥签名吗，用哪个私钥签名 客户端向CA发送CSR，该消息封装了调用 generate_certificate_request 方法得到的返回参数。CA(如果满足必要条件)颁发证书并将其发送给客户端; 客户端调用import_certificate方法。方法调用参数包含证书。服务器验证证书，如果成功，则将证书上的信息添加到 certificates 属性。如果验证失败，证书将被丢弃。 导入新证书成功后，旧证书将被移除。 使用服务器证书的各方可以通过以下方式获得证书: 带外out of band; 使用“Security setup”对象的export_certificate方法 作为AARE的一部分(在HLS认证期间) s9.2.6.6.5 Provisioning servers with certificates of clients and third parties向服务器提供客户端和第三方证书服务器要验证数字签名，要使用使用静态密钥协商密钥的方案执行密钥协商，或要建立TLS连接，服务器需要对方的适当公钥证书。如果在制造时已经知道客户端和/或第三方，则制造商可以将其公钥证书注入服务器。否则，可以使用“Security setup”对象的import_certificate方法为服务器提供客户端和第三方的证书。s9.2.6.6.6 Provisioning clients and third parties with certificates of servers向客户端和第三方提供服务器的证书要验证数字签名，要使用使用静态密钥协商密钥的方案执行密钥协商，或要建立TLS连接，客户端或第三方需要对方的适当公钥证书。证书可以随服务器一起交付，并插入到客户端/第三方 OOB 中。或者，客户端或第三方可以使用“Security setup”对象的export_certificate方法从服务器请求证书。方法调用参数标识所请求的证书。s9.2.6.6.7 Certificate removal from the server从服务器上删除证书当属于服务器的证书被删除时，与公钥相关联的私钥也应被销毁。“Security setup“对象的remove_certificate方法用于删除证书s9.2.7 Applying cryptographic protection 保护xDLMS APDUs参见 9.2.7.2; 处理 HLS 认证期间的挑战信息challenges，见 9.2.7.4; 保护COSEM data，参见 9.2.7.5。s9.2.7.2 Protecting xDLMS APDUs本小节 9.2.7.2 指定了 9.2.3.3 和 9.2.3.4 中指定的加密算法如何用于保护 xDLMS APDUs:s9.2.7.2.2 Security policy and access rights valuesaccess rights访问权限由“Association LN”的 object_list 属性或“Association SN”对象的 access_rights_list 持有。access_rights 的access_mode元素决定了访问类型并规定了密码保护。它是一个 enum 数据类型。对 COSEM对象 属性 和/或 方法 的访问权Access rights可能要求对 xDLMS APDUs 进行 认证、加密 和/或 签名 。为此，只允许保护程度超过或等于安全策略security policy要求的 APDUs。保护程度低于安全策略和访问权限要求的 APDU 应被拒绝。在这种情况下，更多的保护是指在 xDLMS APDU 上应用比安全策略所要求的更多种类的保护：例如，安全策略 security policy 要求所有的 APDU 都经过认证，但访问权限 Access rights 要求 APDU 经过加密和认证，即更高的保护。 (access rights 是针对某个对象的特定属性或方法的，security policy 是全局的，所以 access rights 可以比 security policy 更严格，而不能更宽松)s9.2.7.2.3 Ciphered xDLMS APDUs加密的xDLMS APDUs只能在加密的应用程序上下文中使用。另一方面，在加密的应用程序上下文中，可以同时使用加密和未加密的 APDUs。general-ded-ciphering dedicated 专用的，使用专用密钥，AARQ时协商general-glo-ciphering global 全局的，使用全局密钥，比如GUEKs9.2.7.2.4 Encryption, authentication and compression在消息保护的情况下，要保护的信息是xDLMS APDU。在 COSEM数据保护的情况下，需要保护的信息是COSEM data数据，即COSEM属性值或方法调用/返回参数。 The security header $SH = SC || IC$ Bit 3…0: Security_Suite_Id, see 9.2.3.7; Bit 4: “A” subfield: 是否认证 Bit 5: “E” subfield: 是否加密 Bit 6: Key_Set subfield:0 = Unicast, 1 = Broadcast; Bit 7: 是否压缩 Plaintext and Additional Authenticated Data plaintext, P Additional Authenticated Data, A security control byte, SC authentication key, AK information, I P是一个关于加密的形参，可以为 I，如果不加密的话就是空的。 根据 SC 的不同，AAD 也会不同 Encryption key and authentication key Initialization vector 三种加密方式 Service-specific ciphering xDLMS APDUs Service-specific区别于general，可以使用部分变体 The general-glo-ciphering and geneal-ded-ciphering xDLMS APDUs The general-ciphering APDU 可以用于客户端和服务器之间，也可以用于第三方和服务器之间。这些APDU还携带了所使用密钥的必要信息。 Use of the fields of the ciphering xDLMS APDUs Encoding example: global-get-request xDLMS APDU s9.2.7.2.5 Digital signatures9.2.7.3 Multi-layer protection by multiple parties多重保护一般用于 third party-&amp;gt;client-&amp;gt;server 模型，即 third party 应用一层，client 应用一层。server 需要根据请求的保护状态以及 security policy and access rights 要求的保护来保护数据 TODO:很难理解，需要实例。对应9.2.2.5一起s9.2.7.4 HLS authentication mechanisms需要提前知道对方的证书和 systemtitle,不知道的话需要传递见原文示例s9.2.7.5 Protecting COSEM data需要保护的数据列表、需要保护的对象和保护参数由“Data protection”对象决定。s9.3 DLMS/COSEM application layer service specifications9.3.1 Service primitives and parameters REQUEST：请求原语从 N-用户传递到 N-层以请求启动服务； INDICATION：指示原语从 N-层传递给 N-用户，以指示对 N-用户重要的内部 N-层事件。 该事件可能逻辑上与远程服务请求有关，也可能是 N-层内部的事件引起的； RESPONSE：响应原语从 N-用户传递到 N-层，以完成先前由指示原语调用的过程。 CONFIRM：确认原语从 N-层传递给 N-用户，以传达一个或多个相关的先前服务请求的结果。（重要）命名规则s9.3.2 The COSEM-OPEN serviceCOSEM-OPEN 服务的作用是在对端 COSEM 应用实体(AEs)之间建立 AA。 AA 相关协商后参数，AL 会保存，比如密钥、加密策略、是否使用 GBT、最大接收 PDU 大小等，使用 ACSE 的 A-ASSOCIATE 服务 Protocol_Connection_Parameters 强制。 它包含使用通信配置文件层所必需的所有信息，包括通信配置文件（协议）标识符和所需的地址。 它确定了 AA 的参与者。 该参数的元素被传递给管理低层连接的实体，并酌情传递给低层。 ACSE_Protocol_Version 可选参数。如果存在，则应使用缺省值。 Application_Context_Name 强制。在请求原语中，它持有客户端提议的值。在响应原语中，它保存相同的值或服务器支持的值。(类似于 TLS 握手中的加密策略，是一个需要协商的值) Called_AP_Title, Called_AE_Qualifier, Called_AP_Invocation_Identifier, Called_AE_Invocation_Identifier 可选 Calling_AP_Title 有条件的。当建议的应用程序上下文和/或建议的HLS认证机制要求使用客户端system title，并且在注册过程中尚未传输时，Calling_AP_Title 应携带客户端 system title。见 4.3.4。 Calling_AE_Qualifier 有条件的。当 Application_Context_Name 为加密的应用上下文Application_Context_Name时，可能携带客户端的公共数字签名密钥证书。 Calling_AP_Invocation_Identifier 可选。 Calling_AE_Invocation_Identifier 可选。携带 AA 的客户端用户的标识符。 Local_or_Remote 强制。接收到 AARE APDU 生成的确认就是 Remote,本地确认就是 Local Result 强制。remote confirmation 下为 AA 是否被接受，local confirmation 下为本地低层协议栈是否接受请求 Failure_Type 强制。在远程确认的情况下，它携带服务器提供的信息。在局部和消极 negative 确认的情况下，表示失败的原因。 Responding_AP_Title 有条件的。当协商的应用程序上下文和/或协商的 HLS 认证机制要求使用服务器系统标题，并且在注册过程中尚未转移时，则 Responding_AP_Title 应携带服务器系统标题system title。 Responding_AE_Qualifier 有条件的。当 Application_Context_Name 为加密的应用上下文时，可能携带服务器的公共数字签名密钥证书。 Responding_AP_Invocation_Identifier and Responding_AE_Invocation_Identifier 可选 ACSE_Requirements 可选。用于选择认证功能单元。见 9.4.2.1 表格 81。DLMS 中的 ACSE 支持的 Authentication 功能模块（还有一个是 kernel 模块）为 AARQ 添加了一些参数 Lowest Level Security:无此参数 LLS：.request 有，.response 可能有 HLS: .request 和.response 都有 Security_Mechanism_Name 有条件的。 The Calling_Authentication_Value、the Responding_Authentication_Value 有条件的。 Implementation_Information 可选的 Proposed_xDLMS_Context xDLMS_Context 建议值。包含在AARQ APDU 中的user-information中的 xDLMS InitiateRequest APDU 中 Negotiated_xDLMS_Context 服务端接受 Proposed_xDLMS_Context 建议后回复。包含在AARE APDU 中的user-information中的 xDLMS InitiateRequest APDU 中 xDLMS_Initiate_Error 服务端不接受 Proposed_xDLMS_Context 建议，回复。包含在AARE APDU 中的user-information中的 xDLMS InitiateRequest APDU 中 User_Information 请不要将 COSEM-OPEN 服务的User_Information参数与 AARQ / AARE apdu 的user-information字段混淆。 Service_Class 强制的。指示服务是confirmed还是unconfirmed s9.3.2.3 Use confirmed AA – a unconfirmed AA – b pre-established AA – c原语发生在 AP 和 AL 之间，s9.3.3 The COSEM-RELEASE service优雅释放已经存在的 AA调用它的方式（Use_RLRQ_RLRE参数）决定了它是否使用 ACSE 的A-RELEASE服务。如果 Use_RLRQ_RLRE 为 FALSE，则 AL 层不能使用 A-RELEASE 服务中的RLRQ和RLRE（和 AARQ/AARE 相对，见 9.4.2.1），也就不能使用 RLRQ/RLRE 断链。可以通过断开支持层的方式断链s9.3.4 The COSEM-ABORT service指示支持协议层的主动断开,只有 COSEM-ABORT.indication 原语，，对应上图中的e情况COSEM-ABORT.indication 原语在客户端和服务器端本地生成，以指示 COSEM AP 下层连接以非请求的方式关闭。此类事件的起因可以是一个外部事件(例如物理线路断线)，或者在一些配置文件中出现的一个支持协议层连接管理器AP(层管理AP，非 COSEM AP)的动作，当支持的协议层连接不是由 DLMS/COSEM AL 管理时。这将导致 COSEM AP中止任何现有的 AA，除了在服务器端预连接 AA。s9.3.5 Protection and general block transfer parametersAdditional_Service_Parameters仅在使用加密或GBT时存在。 Invocation_Type:COMPLETE, FIRST-PART, ONE-PART and LAST-PART TODO:重要！这里又提到了 Partial service invocations，就是用 FIRST-PART 之类的分包，属于可选的 Additional_Service_Parameters 参数，与 GET 之类的原语的 service-specific block transfer 不一样，和 general block transfer（GBT）又不一样，那这三种分包方式可以同时存在吗 更新：1.Invocation_Type 的分包是针对本地 AL 和本地 AP 之间的，可能是用于 AL 接受缓存或 AP 发送缓存不够的情况。2.service-specific block transfer 是针对本地 AP 和对端 AP 之间的，用于解决超过 AP 接受或发送缓存的情况，这时候还没有 APDU,数据仅仅是原语的参数 3.GBT 是本地 AL 和对端 AL 之间的，这时候分割的 APDU，用于 APDU 过大的情况Partial service invocations在接收端时，AL 需要判断是否可以划分 PART，比如，因为 GBT 是流的形式传输，接收到的包都是按照字节分割的，所以接收端 APDU 需要判断是否可以完整解密、是否可以组成原语（如 ACTION-LIST，见 9.3.8 和 Figure 149，属性列表在前，参数列表在后，需要收全后才能组成原语），然后才能划分 PART。Block_Transfer_Streaming 指示是否允许 AL 使用流（GBT），见 9.4.6.13Block_Transfer_Window 指示最大接受窗口大小s9.3.6 The GET service其功能是读取一个或多个 COSEM 对象属性的值。结果可以在单个响应中交付，或者(如果它太长，不能在单个响应中交付)在多个响应中交付，使用块传输（没有指定是那种类型的块传输）。两个优先级 normal (FALSE) or high (TRUE).如果是 Request_Type=NEXT 就不用带 COSEM_Attribute_DescriptorREQUEST-WITH-LIST 会带多个 COSEM_Attribute_Descriptor，但不能超过 server-max-receive-pdu-size。原则：GET.request服务原语必须包含在单个APDU中,所以不能用分BLOCK方式发请求整个响应单个 APDU放得下就用 Response_Type == NORMAL or WITH-LIST，放不下就用 Response_Type == ONE-BLOCK，最后一包用 LAST-BLOCKCOSEM_Object_Attribute_Id == 0 (Attribute_0)的情况，表示读取所有的属性，返回一个包含所有数据的结构体，填充在Data区域，没权限的或访问出错的回 null-data successful confirmed GET – a unconfirmed GET – d unsuccessful attempt due to a local error – c 重要：关于编解码，AP 层并不负责对 APDU 的编解码（比如 A-XDR 编码），对于 AL 层原语的调用（如 COSEM-OPEN、GET 等），传递的只是参数（或者叫变量），关于参数的格式和定义就是设计的问题了（可以使用编程语言的基本变量类型或自定义变量类型）。 Table 60中包含了原语的很多参数，但只有部分是需要被包含进最终的APDU中的，所以 AP 编解码本身就解释不通，否则 AL 需要再进行解码再封装，多此一举。其中 Result 中的Data是一个octet-string格式的参数，其内部的值已经是编完码的了，因为 Data 编解码是业务层蓝皮书的部分，需要 AP 来进行，但这里仅仅作为一个 octet-string 类型的变量，和 AP 不对整个 APDU 进行编码的观点不冲突。AL 属于绿皮书范畴，是通信的协议层，APDU 是作为通信载体，应该属于绿皮书范畴，所以需要 AL 层编解码s9.3.7 The SET service写入一个或多个 COSEM 对象属性的值。要写入的数据可以在单个请求中发送，或者(如果数据太长，不能在单个请求中发送)在多个请求中使用块传输。(不同于 GET，SET 请求可以分包)仅 Request_Type == NORMAL, FIRST-BLOCK, WITH-LIST and FIRST-BLOCK-WITH-LIST 携带 COSEM_Attribute_Descriptor响应不能分包COSEM_Object_Attribute_Id == 0 (Attribute_0)的情况，同 GET，需要 SET 请求包含有全部公开属性的 Data 值的结构体。Result 将携带一个结果，如果写入了所有属性则为成功，或者只有一个失败原因。 TODO:部分成功的情况呢 successful confirmed SET – a unconfirmed SET – d unsuccessful attempt due to a local error – cs9.3.8 The ACTION service调用一个或多个 COSEM 对象方法请求响应都能分包,需要请求完整发完，响应才开始分包发送结果第一阶段：client AP 向 AL 发送 ACTION.request，server 的 AL 收到后向 AP 发送 ACTION.indication，server AP 回 ACTION.response，ACTION.confirm 由 AL 发送给 client AP,都是可以是分包的。直到收到完整的请求（LAST-BLOCK 发送后）。第二阶段：开始执行方法，执行完后返回结果，可以分包s9.3.9 The ACCESS service使用一个.request / .response 访问（access）多个COSEM 对象属性和/或方法，包括 GET / SET / ACTION 的组合ACCESS 好像就是 DSMR 里的 COSEM-ACCESSLong_Invoke_Id，区别于上面的 Invoke_Id自描述响应，不仅包含结果 data，也包含请求参数，可以不依赖于对应的请求直接解析响应。可选。对于 GET，Access_Request_List_Of_Data 中也包括 data,对于 GET 就是 null-data，需要由响应填充可以带时间戳，表示.request 和.response 调用时间，降低消耗 TODO:为什么可以降低消耗，原文是This further reduces overhead支持 list 访问，Access_Request_Specification 作为数组可以有多个元素s9.3.9.2 Service specificationAccess_Request_Specification: Access_Request_Get 不带选择性访问参数 Access_Request_Set 不带选择性访问参数 Access_Request_Action Access_Request_Get_With_Selection 带选择性访问参数，不能用于 Attribute_0 情况 Access_Request_Set_With_Selection 带选择性访问参数，不能用于 Attribute_0 情况优先判断 result，如果 result 失败直接丢弃 data。s9.3.10 The DataNotification service数据推送unsolicited 未经请求, unconfirmed 无需确认 或 confirmed 需确认request 支持分块传输Confirmed：收到 Data-Notification-Confirm APDUUnconfirmed：收到支持层确认服务原语通信模型：Figure 112 a), b) and d). TODO:这里的 d 是什么情况，按照描述，Unconfirmed 也需要支持层响应s9.3.11 The EventNotification serviceunconfirmed 无需确认request 支持分块传输Application_Addresses:可选，如果没有相应的AA，则包含全部识别信息(也就是允许没有 AA 的情况上报)服务原语通信模型：Figure 112 f), g)s9.3.12 The TriggerEventNotificationSending serviceEventNotification 的触发服务，由客户端发起，用于 EventNotification 不能自动触发的情况。不需要 AAs9.3.13 Variable access specifications9.3.14 The Read services9.3.15 The Write services9.3.16 The UnconfirmedWrite services9.3.17 The InformationReport services9.3.18 Client side layer management services: the SetMapperTable.request有关 SN 的跳过s9.4 DLMS/COSEM application layer protocol specifications9.4.1 The control function (CF)s9.4.1.1 State definitions of the client side control function带/的表示过程，也就是在转换过程中发生的，不带/的表示状态转换触发的起点。(可以这么理解，左右两个 pending 就是中间态，而 IDLE 和 ASSOCIATED 是起始态，从起始触发的就是不带/的)s9.4.1.2 State definitions of the server side control function TODO:图上的 EventNotification.reg 单词拼错了，应该是 reqs9.4.2 The ACSE services and APDUss9.4.2.1 ACSE functional units, services and service parametersDLMS/COSEM AL ACSE 基于 IEC 标准中的 connection-oriented ACSE支持Kernel、Authentication两个功能模块AARQ 和 AARE 中的acse-requirements(见 9.3.2)参数用于选择功能模块启用见文中 Table 81AARQ APDU 由 COSEM-OPEN.request 原语决定，AARE APDU 由 COSEM-OPEN.response 原语决定各个参数： TODO:用到的时候补充下 user-information:AARQ APDU 中携带xDLMS InitiateRequest APDU包含 Proposed_xDLMS_Context 参数。AARE APDU 中携带 an xDLMS InitiateResponse APDU 包含 Negotiated_xDLMS_Context 参数s9.4.2.2 Registered COSEM namesOSI分层架构中的ISO标准网络对象名，由DLMS UA分配。DLMS/COSEM中使用的对象名： COSEM_Application_Context_Name {joint-iso-ccitt(2) country(16) country-name(756) identified-organization(5) DLMS-UA(8) application-context(1) context_id(x)} application-context和context_id： COSEM_Authentication_Mechanism_Name {joint-iso-ccitt(2) country(16) country-name(756) identified-organization(5) DLMS-UA(8) authentication_mechanism_name(2) mechanism_id(x)} authentication_mechanism_name和mechanism_id： COSEM_Cryptographic_Algorithm_Id {joint-iso-ccitt(2) country(16) country-name(756) identified-organization(5) DLMS-UA(8) cryptographic-algorithms (3) algorithm_id(x)} cryptographic-algorithms和algorithm_id： s9.4.3 APDU encoding ruless9.4.3.1 Encoding of the ACSE APDUsACSE APDUs 编码：BERuser-information(xDLMS InitiateRequest APDU)内的内容因为是xDLMS格式的，所以需要用A-XDR编码s9.4.3.2 Encoding of the xDLMS APDUsxDLMS APDUs 编码：A-XDRs9.4.3.3 XMLDataNotification APDU 可以编码为 XML 格式。s9.4.4 Protocol for application association establishments9.4.4.1 Protocol for the establishment of confirmed application associationsclient AP 发送COSEM-OPEN.request原语（Service_Class == Confirmed），client CF（control function）进入ASSOCIATION PENDING状态（见 9.4.1），然后，CF 在 xDLMS ASE 和 ACSE 的帮助下组装包含从 AP 接收的 COSEM-OPEN.request 原语参数的 AARQ APDU，并将其发送到服务器。 xDLMS ASE是 InitiateRequest APDU 打包器（只和 xDLMS 相关，就是 AARQ 中的user-information），ACSE是 AARQ APDU 打包器（ACSE 中的Kernel和authentication functional 相关的参数,见 9.4.2.1）服务器 AL 的 CF 将收到的 AARQ APDU 提供给 ACSE, ACSE 提取 ACSE 相关参数，然后将控制权交还给 CF。然后，CF 将 AARQ APDU 的用户信息参数的内容（携带 xDLMS InitiateRequest APDU）传递给 xDLMS ASE,xDLMS ASE 检索此 APDU 的参数，然后将控制权交还给 CF。CF 使用收到的 APDU 参数生成 COSEM-OPEN.indication 给服务器 AP ，并进入“ASSOCIATION PENDING”状态。 总结：先 xDLMS ASE 层打包，再 ACSE 层打包，得到 AARQ APDU。AARQ APDU 先 ACSE 层解包，再 xDLMS ASE 层解包s9.4.4.2 Repeated COSEM-OPEN service invocationsAA 已经存在时，client AP 发的 COSEM-OPEN.request 直接由 client AL 回应确认s9.4.4.3 Establishment of unconfirmed application associationsService_Class == Unconfirmed本地 AL 不等待回应直接回.confirm一般用于单向通信或广播无需确认 AA 中只能使用无需确认 xDLMS 数据传输服务s9.4.4.4 Pre-established application associations无需 AA 建立和释放s9.4.5 Protocol for application association release 优雅 graceful 方式 断开 AL 的支持协议层 前提是面向连接的协议层（HDLC,TCP） the COSEM-RELEASE，Use_RLRQ_RLRE参数不存在或为FALSE(就是不使用 ACSE 的A-RELEASE服务，见 9.3.3) 使用 ACSE A-Release 服务 Use_RLRQ_RLRE参数为TRUE（就是使用 ACSE 的A-RELEASE服务），COSEM-RELEASE 服务可以包含加密的xDLMS InitiateRequest / InitiateResponse 在 RLRQ / RLRE APDUs 的user-information参数中，从而防止潜在的拒绝服务攻击(没有保护的话谁都可以断开连接)。 非优雅 Non-graceful 方式 当 AP 发生意外事件(如检测到物理连接中断)时，检测本地错误，等等 s9.4.6 Protocol for the data transfer servicess9.4.6.1 Negotiation of services and options – the conformance block一致性块，用于协商双方支持的功能COSEM-OPEN服务中：xDLMS InitiateRequest APDU 中的proposed-conformance参数和 xDLMS InitiateResponse APDU 中的negotiated-conformance 图中提到了只有 get、set、action 可以配置为使用 block-transfer,应该就是 service-specific block transfer，和 9.4.6.6 ACCESS 服务不支持 service-specific block transfer 相符s9.4.6.2 Confirmed and unconfirmed xDLMS service invocations client 发起： 在confirmed的 AAs 中 可以以 confirmed or unconfirmed 的方式调用 xDLMS 服务。 在unconfirmed的 AAs 中 只能以 unconfirmed 的方式调用 xDLMS 服务。这样，在多播 和/或 广播的情况下，由于潜在的多重响应而产生的冲突可以避免。 unconfirmed xDLMS services 三种目的地址： 单个地址 组地址 广播地址 如果 AA 没建立，服务端会丢弃 unconfirmed 请求。 服务端发起： unsolicited services： InformationReport; 只能以 unconfirmed 方式调用 EventNotification; 只能以 unconfirmed 方式调用 DataNotification. 1)unconfirmed，支持协议层失败重试;2)unconfirmed，丢失支持协议层确认重试;3)confirmed，丢失确认重试 详见 9.4.6.7 s9.4.6.3 Protocol for the GET service有多个属性的情况下，每个属性都要回对应的 Data 或 Data_Access_Result通过conformance block协商在APDU过长时是否使用GBT或service-specific block transfer结合 9.3.6 对 GET 的说明，AP 负责 Data 的编解码，同时可以对Data进行分块，也就是 service-specific block transfer 的基础。其中分块可以是按字节不按逻辑分，也可以按逻辑分(每块都能自解析)。这样的话服务端就可以分段生成回复，对于已经发送的块可以释放内存，减少内存占用 发送接收流程： 第一个.response 的 DataBlock_G(见 9.3.7)： Last_Block == FALSE; Block_Number == 1; Result (Raw_Data) == the first K bytes of the encoded data: B1, B2, B3,…., BK. 客户端 AP 继续发送 GET-REQUEST-NEXT,Block_Number和上一次接受到的回复相同，也就是 1（可以理解为客户端确认序号，表示 1 已确认）。服务端 AP 收到请求后继续发 Block_Number 为 2 的块 各种错误处理 NEXT 请求序号与上一条回应序号不匹配s9.4.6.4 Protocol for the SET service类似 GET即使分包，每一包的 Invoke_Id 和 Priority 必须是一样的，因为是同一个请求多了 ACK-BLOCK，用于中间块的接收响应各种错误处理s9.4.6.5 Protocol for the ACTION service请求响应都能分包，请求发完，再由响应分包。s9.4.6.6 Protocol for the ACCESS service TODO:ACCESS 是不支持 service-specific block transfer 吗，文中只给了 GBT 的例子，没有 更新：见 9.4.6.1，一致性块不包含，不支持图中的 FIRST 和 LAST 应该是partial service invocations部分服务调用（FIRST-PART,LAST-PART），不是 service-specific block transfer TODO:在这个例子中为什么客户端 AL 可以在不知道对方接收窗口的情况下发送 W=3 的 GBT，如果按照 AL 层的 GBT 参数必须由 AP 提供来看应该是错误的 更新：图片前有条件说明，Both parties know a priori that the other party supports streaming with window size = 3,已经知道是三个包 有个要注意的是对于GET\\SET\\ACTION\\ACCESS,客户端总是作为主动方，也就是管理重发的角色。服务端发出去的都不需要客户端回确认，超时也不重发s9.4.6.7 Protocol of the DataNotification service可以使用partial service invocations可以使用 GBTDataNotification.request 原语的Service_Class参数： unconfirmed，支持协议层回错误（及时）时重发 unconfirmed，支持协议层超时未回应时重发 AP 超时未收到回应直接进重发模式，开始重发等待，此时支持协议层返回的信息都忽略，不管成功还是失败， confirmed，未收到确认超时时重发 总是忽视本地确认，未收到远程 AP 确认前总是重发 s9.4.6.8 Protocol for the EventNotification service详见 10s9.4.6.9 Protocol for the Read services9.4.6.10 Protocol for the Write services9.4.6.11 Protocol for the UnconfirmedWrite services9.4.6.12 Protocol for the InformationReport serviceSN 相关的跳过s9.4.6.13 Protocol of general block transfer mechanismblock transfer块传输总结： Partial service invocations，9.3.5 service-specific block transfer，9.3.5，一般用于每包都独立，可以自解析的情况 general block transfer，由 AP 提供窗口和流参数，但如果没有参数会不会也触发 GBT 有待讨论.AA 握手时 AL 会保存相关参数，见 9.3.2.2 table 54由 AL 层实现，使用General-Block-Transfer (GBT) xDLMS APDUs传输任意长度APDUsAL 收到 AP 层.request / .response 服务原语： 打包 APDU 根据 Security_Options 打包加密 APDU 如果大于协商的最大 APDU 大小，使用 GBT 分包 区别于 AP 层的partial service invocations部分服务调用(9.3.5)，这个GBT是针对 APDU 的，两者没有直接关系原语参数： Block_Transfer_Streaming (BTS):用于 AP 指示 AL 是否可以用流方式(窗口)发送，（窗口的意思就是每发若干个包确认一次，结合 BTW 若为 0，表示无需确认，若为 1，表示 1 个包确认一次） Block_Transfer_Window (BTW)：用于 AP 指示 AL最大流窗口大小，但最终由 AL 决定，AL 可以设置的很小用于传输丢失包。 unconfirmed services固定 Block_Transfer_Streaming 为FALSE，以及 Block_Transfer_Window 为0.类似 UDP，可以尽可能的发，无需对方 AL 层确认GBT APDU 字段： the last-block (LB) ：是(LB = TRUE(1))否最后一包 streaming(STR) :对于一个窗口，在过程中(STR = TRUE(1))还是已结束(STR = FALSE(0)，一个窗口内的最后一包)。如果是已结束，需要对方回个确认，这个确认是对这个窗口的，如果是完整 APDU 的最后一包则不回(最后一个窗口不确认) TODO:怎么判断收全了 更新：通过发送权思路，就是谁是主动方，谁负责报文的送达确认，这里接受方是主动方，如果没收全，会在超时时重发请求，发送端无需保证自己的报文送达 window：发送该 APDU 的一方的接收窗口大小，发送unconfirmed services时为 0 block-number (BN)：block序号，第一个为 1 TODO:具体什么时候开始重新计数 更新：应该是last-block的时候，也就是一个完整的APDU发送完成后 block-number-acknowledged (BNA)：被确认块号，最后一个连续的被确认的块的块号（这个块之前的所有块也要已经被确认。这个是用于指示对方发送的块的确认，表明自己已确认） block-data (BD):数据域，xDLMS APDU 的一部分s9.4.6.13.2 The GBT procedureSend Queue SQ：:发送队列，对于 block:每收到AP调用原语，(和 partial service invocations 无关，不管 Invocation_Type 参数为 COMPLETE, FIRST-PART, ONE-PART or LAST-PART 等)，就分成一个或多个 blocks 放进 SQ 中:对于 SQ 内 blocks 的发送是个流过程（TODO:意思是不是已经和调用原语无关了 更新：与调用原语无关，也就是和 partial service invocations 无关）Receive Queue RQ:接收队列，对于 blocks9.4.6.13.3 GBT procedure state variables Gr: 接收到的对方参数 Gs: 发送的自己的参数 BNApeer：自己的发送被对方确认的数量，（被 Gr.BNA 修改） BNAself：对方的发送被自己确认的数量，（发给对方） NextBN：自己 SQ 发送队列的下个插入序号，（插入 SQ 时递增） STRpeer：对方是否支持 GBT 流，（被 Gr.STR 修改） STRself：自己是否支持 GBT 流，（被本地 AP 修改） Wpeer：对方接收窗口大小，（被 Gr.W 修改） Wself：自己接收窗口的大小，（被本地 AP 修改） TODO:其中 Wself 有默认值，是不是不需要 AP 提供，也可以有默认值 更新：有默认值的参数不需要 AP 提供也能使用，初始值就是默认值子过程： 9.4.6.13.4 Send GBT APDU stream Confirmed GBT stream send AP 调用原语参数BTW要大于 0，SQ 为空时填充一个空的 block,NextBN 递增 9.4.6.13.4.3.2 Last block management 最后一包管理。 client-server services 客户端发送请求，LB=0，直到最后一包，LB=1。此时SQ应该空了，如果收到服务端响应，需要向SQ填充空的确认包，再发送，LB=1，如此重复。 服务端发送的LB=0，直到收到客户端LB=1的包（请求发完后以及确认包的LB都为1）且是服务端的最后一包，LB=1。也就是说在响应请求的确认包LB都为0。印证了Figure 141中空的确认包的LB可以为0或1。 unsolicited, confirmed service 需确认的上报 服务端发送上报LB=0直到最后一包LB=1（因为服务端不需要对客户端的响应做确认） 客户端发送确认和响应都是LB=0，直到收到服务端LB=1且是客户端的最后一包 TODO:9.4.6.13.4.3.1 If the SQ is empty, an empty block is added to the SQ and Nex tBN is incremented.为什么要加入空的 block,这个空的好像是确认包 更新：9.4.6.13.4.3.2 Last block management中提到了如果客户端把请求的APDU全发完了，那发送队列就空了，这时候还需要对服务端的响应回确认，所以还需要空的block。或者当服务端在接收请求回确认时SQ也是空的，需要填充确认包 Gs.LB = B.LB, Gs.STR = STRself, Gs.W = Wself, Gs.BN = B.BN, Gs.BNA = BNAself and Gs.BD = B.BD 每个窗口最后一包以及LB=1时的包的Gs.STR都为0 被确认后才能从 SQ 删除，最后一包不需要对方确认，所以不能直接从 SQ 中删除。 TODO:应该什么时候删除，文中也没说，是否是超时 Unconfirmed GBT send AP 调用原语参数BTW要等于 0 全部发完就清空 SQ，不用确认 9.4.6.13.5 Process GBT APDU sub-procedure 这个过程是接收一个窗口的过程 判断GBT APDU是否被对方拒绝（是不是表明参数不合理） 如果收到的是Gr.BN=1且Gr.BNA=0，表示是初始化包，是由对方发起的GBT过程，需要初始化（是不是就是向AP请求参数） 是否是confirmed service 9.4.6.13.5.2 Processing GBT APDUs in a confirmed GBT procedure 判断合法性后将B放入RQ接收队列 配置窗口和对方确认序号，Wpeer = Gr.W, BNApeer = Gr.BNA 清空确认序号之前的SQ发送队列数据(已经确认) RQ内数量是否等于BTW（BTW是AP给的接收窗口大小上限，相等说明一个窗口满了），是的话说明一个窗口接收结束，否的话说明还有后续block 判断STRpeer，如果为0表示即使没有到窗口上限，该（流）窗口也结束了，为1表示该窗口还有后续block （一个窗口结束需要回确认） RQ中的报文回给AP，需要调用Check RQ and fill gaps sub-procedure. 9.4.6.13.5.3 Processing GBT APDUs in an unconfirmed GBT procedure 判断合法性后将B放入RQ接收队列 如果达到RQ上限，则结束（虽然没有窗口的概念，但RQ也有上限，达到上限强制中断） 如果是最后一包LB=1则结束，如果不是则等待下一包 如果在结束后收到新的包，将视为overflow，直接丢弃，本次结果回给AP层后，清空RQ，本次GBT结束 9.4.6.13.6 Check RQ and fill gaps 9.4.6.13.6.2 Confirmed GBT procedure RQ为空时全部重传，Wself（接收窗口大小）设置为BTW也就是最大窗口 RQ不为空时检查gaps，为空时表示无需重传，BNAself(己方确认)设置为B.BN(确认最后一包);不为空时表示还有需要重传的，此时Wself应设置为小于等于要重传的第一个gap大小（比如只丢了一个包或者说第一个gap只需要重传一个包，就重传一个包，接收窗口设为1就行，这样只要提供起始序号和窗口大小，对方就知道要补几个包了），开始请求重传。 gap可以理解为一个连续的丢包块 比如1x2x3√4x5√6√7√ 第一个gap大小就是2，第二个gap大小就是1 9.4.6.13.6.3 Unconfirmed GBT procedure 没有重传机制，没收全就是失败。 s9.4.6.13.7 GBT protocol examples TODO:图里的 GET.cnf NORMAL(FIRST-PART)是否是一种 AL 向 AP 请求 GBT 参数的机制，前提是 AL 不知道相关的参数，所以 GET.req NORMAL(COMPLETE)其实是个空的报文？结合 9.3.5 Additional service parameters，这个参数是否应该在这个原语里携带。更新：the client AP invokes a GET.request NORMAL service primitive, without additional service parameters. The client AL sends the request in a Get-Request-Normal APDU 明确提到了 GET 相关原语可以携带 Additional service parameters可以只补单个包，此时请求的 W 置 1，BNA 置 3，表示窗口大小变为 1，就是单个确认。然后 BNA 为 3 表示让对方补第 4 个包。 TODO:如果 4、5 两包都丢了，是不是就是先补 4，再补 5，不会两包一起补。更新：如果 4、5 丢了，就 W 置 2，BNA 置 3，可以表示丢了连续的两个包如果是最后一包 LB=1 的丢了，由客户端请求这一包 TODO:为什么 Action-Request-With-List 收到一半，服务端就可以回 Action-Response-With-List 更新：应该是一个错误，没有收全时是无法回复完整的，这里回个确认（空 BD）比较合理s9.4.6.13.8 Aborting the GBT procedure终止条件： an ABORT GBT APDU with LB = 1, STR = FALSE, BN = 0 and BNA = 0; 开始新的 GBT 过程。收到 BN = 1 and BNA = 0; 收到 APDU 而不是 GBT confirmed 服务超时未收到确认s9.4.6.14 Protocol of exception mechanismexception-response APDU 回应 GET, SET, ACTION and ACCESS services 表示无法处理的错误 TODO:错误是 AL 层直接打包还是 AP 层来通知的 更新：结合上下文，是 AL 层生成的s9.5 Abstract syntax of COSEM PDUsasn.1 格式描述文档pdf 格式s9.6 COSEM PDU XML schemaxml 格式描述文档s10 Using the DLMS/COSEM application layer in various communications profiless10.1 Communication profile specific elements在 DLMS/COSEM 中，只有COSEM-OPEN服务具有特定的通信配置文件参数。它们的值和用途被定义为通信概要文件规范的一部分。s10.2 The 3-layer, connection-oriented, HDLC based ommunication profiles10.2.2 The structure of the profile 应用层：DLMS/COSEM AL，章节 9 链路层：基于 HDLC 标准的，章节 8 物理层： 章节 5，光口和本地回环物理接口见章节 6s10.2.3 Identification and addressing schemeData Link SAP-s 提供服务给 AL客户端：只要定义客户端 AP，物理地址由 PhL 层填充服务端：因为多点网络寻址的原因，所以目的地址需要物理设备地址加上逻辑设备地址。例子：Client_01 (HDLC address = 16) and Server 2 in Host Device 02 (HDLC address = 2392)，客户端地址为 16，服务端地址为 2392，23 为 upper 地址，92 为 lower 地址s10.2.4 Supporting protocol layer services and service mapping DL 层连接管理 面向连接数据传输 无连接数据传输DL-CONNECT 和 DL-DISCONNECT 也是由 AL 管理的，用于 AL 在收到 COSEM-OPEN.request 调用时开启 DL 连接，PhL 层的连接是 AP 管理的，不是 DL 层管理的s10.2.5 Communication profile specific service parameters of the DLMS/COSEM AL servicesCOSEM-OPEN 携带 Communication profile 的参数 Protocol (Profile) Identifier 3-Layer, connection-oriented, HDLC based; Server_Lower_MAC_Address (COSEM Physical Device Address); Server_Upper_MAC_Address (COSEM Logical Device Address); Client_MAC_Address; Server_LLC_Address; Client_LLC_Address. 也就是 HDLC 及 PhL 的地址也是 AP 管理的s10.2.6 Specific considerations / constraintss10.2.6.1 Confirmed and unconfirmed AAs and data transfer service invocations, frame types usedConfirmed AARQ 用 I 帧携带Unconfirmed AARQ 用 UI 帧携带当通过网关访问服务端时，COSEM APDUs 总是使用I帧携带，包括 Unconfirmed 的 APDU 也是，此时服务端必须通过 xDLMS InitiateRequest APDU 的response-allowed（见 9.4.2.1）或 Invoke-Id-And-Priority / Long-Invoke-Id-And-Priority 的service-class bit（用于指示是否为 confirmed 见 381 页）判断请求是否是 Unconfirmed,s10.2.6.2 Correspondence between AAs and data link layer connections, releasing AAs释放AA连接的方式是A-RELEASE服务或断开支持层连接，因为本配置文件不需要任何下层连接，所以断开支持层连接方式不可用，如果 A-RELEASE 服务也不支持，就没有别的方式释放连接s10.2.6.3 Service parameters of the COSEM-OPEN / -RELEASE / -ABORT services由于SNRM和DISC可以透明传输高层参数，COSEM-OPEN 和 COSEM-RELEASE 中的User_Information将会可用s10.2.6.4 EventNotification service and protocol事件上报时，服务端角色为 Management Logical Device（upper HDLC 地址 0x01）,客户端角色为 Management AP（upper HDLC 地址 0x01）使用 UI 帧发送，发送机会在 8.4.5.4.7 说明了当客户端检测到一个成功的物理连接建立——并且没有其他原因接收一个传入的调用——它就假定这个调用是由打算发送事件通知请求 APDU 的服务器发起的。客户端必须首先使用第 5 章中描述的可选协议识别服务读取通信协议栈客户端发起 TriggerEventNotificationSending .request 原语，发送 UI 帧交出发送权，此时服务端才能上报s10.2.6.5 Transporting long messages使用 I_FRAGMENT，传输长消息，见 8.4.5.4.5s10.2.6.6 Supporting multi-drop configurations可以视为逻辑总线冲突避免一般使用主从模型，由主站控制发送权限上报时可能多个设备同时上报，需要解决两个问题： 总线上的冲突，冲突在物理层体现，由厂家解决（可以用 CSMA 之类的） 客户端不知道需要上报服务端的物理地址时，目的地址可以使用 CALLING Physical Device Address（只有要上报的客户端才会接受这个地址）s10.3 The TCP-UDP/IP based communication profiles (COSEM_on_IP)COSEM 物理设备通过 IP 地址唯一标识，区别于 HDLC 地址。逻辑设备 AP 识别需要额外的地址，由 wrap 层提供，wPort。AL 只监听一个 TCP/UDP 端口。TCP TL 层提供的服务： TCP connection manager AP: TCP-CONNECT.request, .indication, .response, .confirm; TCP-DISCONNECT.request, .indication, .response, .confirm; DLMS/COSEM AL: TCP-DATA .request, .indication, (. confirm). UDP TL 层提供的服务： DLMS/COSEM AL: UDP-DATA .request, .indication, (.confirm) TCP 连接的建立是独立于 DLMS/COSEM AP 的。AP 能够在 COSEM-OPEN 前向 TCP 管理 AP 获取参数Protocol_Connection_Parameters： Protocol (Profile) Identifier – TCP/IP or UDP/IP; Server_IP_Address – COSEM Physical Device Address; Server_TCP_or_UDP_Port – The TCP or UDP port used for DLMS/COSEM, see 7.2; Server_Wrapper_Port – COSEM Logical Device Address; Client_IP_Address – COSEM Client’s Physical Device Address; Client_TCP_or_UDP_Port – The TCP or UDP port used for DLMS/COSEM, see 7.2; Client_Wrapper_Port – COSEM application process (type) identifier.s10.3.6 Specific considerations / constraintsTCP 不支持使用 Unconfirmed AA,因为 TCP 不支持无连接访问，而 Unconfirmed AA 需要支持在不建立支持层连接情况下发送数据。两者矛盾释放 AA 只能使用 RLRQ/RLRE，不能使用通过断开支持层方式，因为一个 TCP/UDP 端口承载所有AA，一旦断开，所有AA都会断开，必须通过 RLRQ/RLRE 有选择的断开。还有 UDP 是无连接的，不能通过断开支持层连接断开AAUser_Information 不可用s10.3.6.6 Transporting long messageswrapper层需要包含完整APDU。如需分块在 AL 层分块。（就是 AL 调用 wrapper 服务时不支持分块）s10.3.6.7 Allowing COSEM servers to establish the TCP connection服务端发起 TCP 连接，长连接模式，适用于服务端没有公开地址可以连接时。s10.4 The CoAP based communication profile (DLMS/COSEM_on_CoAP)CoAP 可以提供可靠和不可靠服务CoAP 支持分段，合理分段后就不用IP层再根据 MTU分片了，详见文章动图图解！既然 IP 层会分片，为什么 TCP 层也还要分段？。AL 也支持引用层的分块传输，根据对方 AL 层支持的接收大小 receiver_max_pdu_size TODO:TCP/UDP IP 通信配置里好像没用到 UDP 支持广播的特性，可能是 UDP 广播只能在本地局域网中进行，不能跨路由器进行的原因s10.4.3 Identification and addressingCoAP URI：Uri-Host + Uri-Port + Uri-Path发送端 AL 需要知道对方的CoAP URI和 SAP，由于 CoAP 封装了 UDP，所以不需要知道ip地址和端口，可能会动态变化DLMS AE 通过唯一 systemtitle 标识，通过以下方式交换：(TODO:AE 是什么意思) 在明确建立 AA 的情况下，在 AA 建立期间使用 COSEM-OPEN 服务; 通过在“Security setup”对象写入 client_system_title 属性和读取的 server_system_title 属性。适用于预连接 AA 加密 APDU 交换，general-ciphering (originator and recipient system title)或 general-glo-ciphering (originator system title).CoAP-DATA 原语需要包含对端的ip地址和端口，如果 IP 是静态的，那可以静态绑定到system title。如果是动态的，需要动态更新绑定，可以通过服务端 ip 变更自动推送实现当客户端 AL 收到服务端上报 data 时，如果是动态 ip，客户端可以根据 system title 确认身份。s10.4.4 Supporting layer services and service mappings10.4.6 Specific considerations / constraintsunconfirmed AA 不能传 confirmed 消息,Reliable 可靠 CoAP 传输层配置不能传输广播消息CoAP 传输层无连接，不能通过断开传输层连接断开 AA,只能通过 RLRQ/RLRE 断开s10.8 LPWAN profile什么是 LPWAN？ LPWAN 技术有哪些？LPWAN(低功耗广域网)，也称为 LPWA)或 LPN，是一种用于物联网(例如，以电池为电源的传感器)的类型，这是一种能够以低比特率进行远距离通信的无线网络。LPWAN 可以同时满足覆盖和续航的要求。以最小的功耗提供最长的距离覆盖是 LPWAN 最大的技术优势。 NB-IoT是物联网领域的一项新兴技术，支持广域网中低功耗设备的蜂窝数据连接。它也称为低功耗广域网(LPWAN)。NB-IoT 支持设备有效连接，待机时间长，对网络连接要求高。据称，NB-IoT 设备的电池续航时间可以提高到至少 10 年。 eMTC作为物联网的一种应用场景。它具有超可靠和低延迟的特点。eMTC 主要应用在设备之间的通信需求上。 Lora是一项专有技术， Semtech 为其提供芯片。Lora 技术改变了以往在传输距离和功耗之间的折衷，为用户提供了一个简单的系统，可以实现远距离、长续航、大容量，进而扩展传感器网络。支持层固定使用了 UDP 和 IPV6LPWAN 提供了低层加密和 SCHC压缩/解压和分段/重组功能可以通过 DLMS/COSEM 对象配置 LPWAN 参数传输层还有 AA 和 UDP 通信配置差不多绿皮书没有介绍多少东西，基本都源于 RFC 8376，RFC 8724s10.9 Wi-SUN profileWi-SUN Field Area Network (FAN)是一种基于IEEE 802.15.4的 IPv6 无线网状网络，专为关键基础设施项目设计。每个个人区域网络(PAN)被设计成用一个边界路由器支持数千个路由器设备。一个 FAN 可以由多个 pan 组成，允许单个网络扩展到数百万个设备，见图 196。支持层固定使用了 UDP 和 IPV6，对传输层来说和 UDP profile 类似，wrapper 和 TCP-UDP/IP profile 相同s10.10 Gateway protocol Header 0xE6:请求（服务端发起 data notification 也算） 0xE7:响应 Network ID 目的网络 ID，可以理解为VLAN ID Address length L 目的物理地址长度 Physical device address 目的物理地址 只有网关设备处理该报文s11 AARQ and AARE encoding exampless12 Encoding examples: AARQ and AARE APDUs using a ciphered application contexts13 S-FSK PLC encoding exampless14 Data transfer service exampless14.4 Profile generic IC buffer attribute encoding examples压缩见蓝皮书4.1.6.3s14.4.3 Get-response with Profile generic null-data compressed encoding exampleprofile 支持使用空值 null-data 压缩，支持压缩基本类型数据（除数组结构体）s14.4.4 Get-response with Profile generic compact-array encoding example使用 compact-array 减少类型描述，也能压缩。compact-array:compact-array [19] IMPLICIT SEQUENCE{ contents-description [0] TypeDescription, array-contents [1] IMPLICIT OCTET STRING}先声明类型，后面的数据就无需类型了，包括结构体和基本类型，后面的数据是 octet string 类型的s14.4.5 Get-response with Profile generic null-data and delta-value encoding example使用递增量压缩，如每次递增 0x29，就使用 1F 类型，值为 29，解压时为上条记录的值加上递增量" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(七) 调度：比例份额", "url": "/posts/operating-systems-7/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2022-03-17 09:00:00 +0800", "snippet": "本章将介绍一种不同的调度方法–比例份额（proportional-share）调度，有时也称为公平份额（fair-share）调度程序。比例份额算法基于一个简单的想法：调 度程序的最终目标，是确保每个工作获得一定比例的 CPU 时间，而不是优化周转时间和响 应时间。比例份额调度程序有一个非常优秀的现代例子，由 Waldspurger 和 Weihl 发现，名为彩票调度（lottery scheduling）。基本思想很简 单：每隔一段时间，都会举行一次彩票抽奖，以确定接下来应该运行哪个进程。越是应该频繁运行的进程，越是应该拥有更多地赢得彩票的机会。基本概念：彩票数表示份额彩票调度背后是一个非常基本的概念：彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额。下面来看一个例子。假设有两个进程 A 和 B，A 拥有 75 张彩票，B 拥有 25 张。因此我们希望 A 占用 75%的 CPU 时间，而 B 占用 25%。通过不断定时地（比如，每个时间片）抽取彩票，彩票调度从概率上（但不是确定的） 获得这种份额比例。抽取彩票的过程很简单：调度程序知道总共的彩票数（在我们的例子中，有 100 张）。调度程序随机抽取中奖彩票，这是从 0 和 99 之间的一个数，拥有这个数对应 的彩票的进程中奖。假设进程 A 拥有 0 到 74 共 75 张彩票，进程 B 拥有 75 到 99 的 25 张，中奖的彩票就决定了运行 A 或 B。调度程序然后加载中奖进程的状态，并运行它。随机性决策优势： 避免最差情况 轻量，不需要记录过多状态，传统公平调度需要记录进程的大量状态 随机方法很快，决策也快下面是彩票调度程序输出的中奖彩票和对应的调度结果: 63 85 70 39 76 17 29 41 36 39 10 99 68 83 63 62 43 0 49 49 A   A A   A A A A A A   A   A A A A A A   B     B             B   B             从这个例子中可以看出，彩票调度中利用了随机性，这导致了从概率上满足期望的比例，但并不能确保。在上面的例子中，工作 B 运行了 20 个时间片中的 4 个，只是占了20%，而不是期望的25%。但是，这两个工作运行得时间越长，它们得到的 CPU 时间比例就会越接近期望。彩票机制彩票调度还提供了一些机制，以不同且有效的方式来调度彩票。一种方式是利用彩票货币（ticket currency）的概念。这种方式允许拥有一组彩票的用户以他们喜欢的某种货币， 将彩票分给自己的不同工作。之后操作系统再自动将这种货币兑换为正确的全局彩票。比如，假设用户 A 和用户 B 每人拥有 100 张彩票。用户 A 有两个工作 A1 和 A2，他以自己的货币，给每个工作 500 张彩票货币（共 1000 张）。用户 B 只运行一个工作，给它 10 张彩票货币（总共 10 张）。操作系统将进行兑换，将 A1 和 A2 拥有的 A 的彩票货币 500 张，兑换成彩票 50 张。类似地，兑换给 B1 的 10 张彩票货币兑换成彩票 100 张。然后会对全局彩票货币（共 200 张）举行抽奖，决定哪个工作运行。User A-&amp;gt; 500 (A&#39;s ticket currency) to A1 -&amp;gt; 50 (global currency)-&amp;gt; 500 (A&#39;s ticket currency) to A2 -&amp;gt; 50 (global currency)User B-&amp;gt; 10 (B&#39;s ticket currency) to B1 -&amp;gt; 100 (global currency)另一个有用的机制是彩票转让（ticket transfer）。通过转让，一个进程可以临时将自己的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用，在这种场景中，客户端进程向服务端发送消息，请求其按自己的需求执行工作，为了加速服务端的执行，客户端可以将自己的彩票转让给服务端，从而尽可能加速服务端执行自己请求的速度。服务端执行结束后会将这部分彩票归还给客户端。这在客户端和服务端在同一台机器上运行时有用。最后，彩票通胀（ticket inflation）有时也很有用。利用通胀，一个进程可以临时提升降低自己拥有的彩票数量。当然在竞争环境中，进程之间互相不信任，这种机制就没什么意义。一个贪婪的进程可能给自己非常多的彩票，从而接管机器。但是，通胀可以用于进程之间相互信任的环境。在这种情况下，如果一个进程知道它需要更多 CPU 时间，就可以增加自己的彩票，从而将自己的需求告知操作系统，这一切不需要与任何其他进程通信。实现假定我们用列表记录进程。下面的例子中有 A、B、C 这 3 个进程，每个进程有一定数量的彩票。在做出调度决策之前，首先要从彩票总数 400 中选择一个随机数（中奖号码）。假设 选择了 300。然后，遍历链表，用一个简单的计数器帮助我们找到中奖者// counter: used to track if we&#39;ve found the winner yetint counter = 0;// winner: use some call to a random number generator to get a value, between 0 and the total # of ticketsint winner = getrandom(0, totaltickets);// current: use this to walk through the list of jobsnode_t *current = head;// loop until the sum of ticket values is &amp;gt; the winnerwhile (current) { counter = counter + current-&amp;gt;tickets; if (counter &amp;gt; winner) break; // found the winner current = current-&amp;gt;next;}// &#39;current&#39; is the winner: schedule it...这段代码从前向后遍历进程列表，将每张票的值加到 counter 上，直到值超过 winner。A:100,B:50,C:250，总计 400 票，按照 A、B、C 的方式排序，如果摇到 1-100，则 A 中奖，101-150 则 B 中奖，151-400 则 C 中奖，符合概率分布。也就是 counter 递增的原理要让这个过程更有效率，建议将列表项按照彩票数递减排序。这个顺序并不会影响算法的正确性，但能保证用最小的迭代次数找到需要的节点，尤其当大多数彩票被少数进程掌握时。评估方法公平性我们定义了一个简单的不公平指标U（unfairness metric），将两个工作完成时刻相除得到 U 的值。比如，运行时间 R 为 10，第一个工作在时刻 10 完成，另一个在 20，U=10/20=0.5。如果两个工作几乎同时完成，U 的值将很接近于 1。在这种情况下，我们的目标是：完美的公平调度程序可以做到U=1。当工作执行时间很短时，平均不公平度非常糟糕。只有当工作执行非常多的时间片时，彩票调度算法才能得到期望的结果。步长调度假设，A:100,B:50,C:250，总计 400 票，使用 10000 除以票数，得到步长A:100,B:200,C:40。每次程序被调度，每个工作对应的计数器累加得到行程值。规则是总是调度行程值最低的工作，初始都是 0，则按顺序 A 执行，A 的行程值变为 100，BC 还为 0，则 B 运行，然后 C 运行，此时行程是 A:100,B:200,C:40，C 最小，则 C 再运行，直到 120，此时 A 为 100 最小，调度 A。这种调度可以保证每个周期内绝对公平，但无法处理新进程插入后的情况小结不能很好适应 I/O，票数分配规则没有好的方案作业参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "DLMS/COSEM Blue Book学习笔记", "url": "/posts/dlms-blue2/", "categories": "技术", "tags": "C++, DAO, database", "date": "2022-03-08 09:00:00 +0800", "snippet": "s4.1 基本概念s4.1.2 Referencing methodslogical names (LN referencing):The reference for an attribute is: class_id, value of the logical_name attribute, attribute_index.The reference for a method is: class_id, value of the logical_name attribute, method_index 关于index，规范内的属性或方法为1开始的正数，专有的属性或方法应该设置为负数 logical names中的OBIS的每个字段，A,B,C,D,E,F都有各自含义，在blue book1中给出Short names(SN referencing)：COSEM对象的每个属性和方法都用一个13位整数标识。短名称的语法与DLMS命名变量名称的语法相同。为了方便使用SN引用访问设备，一些short_name被保留为特殊COSEM对象的base_name(objectName)。保留base_names的范围是0xFA00到0xFFF8。这里的base_name就是cosem类的不包含偏移的短名，相当于每个类表格中的x，对应每个属性的短名叫short_name，是包含偏移的s4.1.4.6 Attributes(dyn.):对带有流程值的属性进行分类，流程值由仪表本身更新。(static):对一个属性进行分类，该属性不会由仪表本身更新(例如配置数据，但可通过外部通信方式修改)。s4.1.4.14 m/om (mandatory):The method is mandatory强制的.o (optional):The method is optional可选的.s4.1.4.17 Selective access部分属性支持选择性访问 “Profile generic” objects, buffer attribute; “Association SN” objects, object_list and access_rights_list attribute; “Association LN” objects, object_list attribute; “Compact data”, objects, compact_buffer attribute; “Push” objects, push_object_list attribute; “Data protection” objects, protection_object_list attribute get_protected_attributes method and set_protected_attributes method.s4.1.6.3 Null-data and delta-value encoding用于array内数据压缩空值表示该值可以从前一条记录中恢复，比如和上一条值相同增量值表示该值可以从前一条记录中通过递增方式恢复，第一条值必须是 integer 或 unsigned 类型，后面就可以一条条递增了s4.1.8 The COSEM logical devices4.1.8.2 COSEM logical device name (LDN)每个COSEM逻辑设备都可以由其唯一的COSEM LDN来标识。LDN定义为最多16个字节的字符串。前三个字节应携带制造商标识符。制造商应确保LDN，从标识制造商的3个字节开始，后面是最多13个字节，对每个制造的逻辑设备是唯一的。s4.1.8.3 The “association view” of the logical device为了访问服务器中的COSEM对象，首先要与客户端建立应用关联(AA，application association)。AAs标识partners，并描述AA将在其中通信的上下文。上下文主要内容是: the application context; the authentication mechanism;认证机制 the xDLMS context.根据客户端和服务器之间建立的AA关系，服务器可能会授予不同的访问权限。访问权限涉及一组COSEM对象(可见对象)，这些对象可以在给定的AA中被访问(“可见”)。此外，对这些COSEM对象的属性和方法的访问也可能在AA中受到限制(例如，某种类型的客户端只能读取COSEM对象的特定属性，但不能写入它)。访问权也可以规定所需的密码保护。s4.1.8.4 Mandatory contents of a COSEM logical device每个逻辑设备都应有： COSEM LDN对象 “Association” (LN or SN)对象 如果SAP Assignment对象存在，“Association” (LN or SN)对象非必选识别固件必选对象： active firmware identifier active firmware signature每个固件对应以上两个对象各一个s4.1.8.5 Management logical device管理角色的逻辑设备可以通过public client使用lowest level securty访问，作用是揭示物理设备内部结构以及上报事件需要包含一个“SAP assignment” object，可以被public client读取，包含物理设备内所有的逻辑设备对应的SAP信息s4.3 参数和测量数据的接口类Interface classes for parameters and measurement datas4.3.2 Register (class_id = 3, version = 0)包含值（value）和量纲（scaler_unit,包括精度(scaler)、单位(unit)）清除方法s4.3.3 Extended register (class_id = 4, version = 0)包含值、量纲、状态（厂家自定义）、寄存器捕获时间清除方法s4.3.4 Demand register (class_id = 5, version = 0)需量寄存器周期性测量某个值得到当前平均值与上次平均值,滑差式统计，统计窗口可以是1个或多个周期E3表示第三个周期内的电量增量,假设当前时间大于E3统计结束时间（第三周期结束时间），小于E4统计结束时间，电量记录值比E3统计结束时大Δe current_average_value 当前平均值，energy/3t,energy=E2+E3+Δe,t=period,3=周期个数 last_average_value 上一平均值，energy/3t,energy=E1+E2+E3,t=period,3=周期个数 scaler_unit 量纲 status 状态 capture_time last_average_value计算时间 start_time_current current_average_value统计开始时间, TODO:这个start_time必须是周期开始时间吗？图里显示这个值会跳变，说明start_time在跳变,结合next_period好像说得通，每到新的周期开始点执行next_period，start_time加一个周期的时间，导致分子急剧变小 period 周期 number_of_periods 周期个数，用于last_average_value计算，为1表示区间式(block)，大于1表示滑差式(sliding)方法： reset (data) 清除 next_period (data) 该方法用于触发一个时间段的正常终止(和重新启动)。关闭(终止)当前测量周期。更新capture_time和start_time，拷贝current_average_value到last_average_value，设置current_average_value为默认值。开始下一个测量周期。s4.3.5 Register activation (class_id = 6, version = 0)该 IC 允许对不同收费结构的处理进行建模。 为每个“Register activation”对象分配“Register”, “Extended register”或“Demand register”对象组，对不同类型的量（例如有功电量、有功需量、无功电量等）进行建模。 由激活标记定义的这些寄存器的子组定义了不同的收费结构（例如，白天收费、夜间收费）。 这些激活标记之一，active_mask，定义了分配给“Register activation”对象实例的寄存器子集是活动的。 默认情况下，未包含在任何“Register activation”对象的 register_assignment 属性中的寄存器始终处于启用状态。 register_assignment 寄存器列表，包括Register”,“Extended register” or “Demand register”等的类id和OBIS mask_list 标记列表，有多个register_act_mask，每个register_act_mask包含唯一的mask_name，每个register_act_mask中的index_list中的值顺序与register_assignment中的对象顺序一一对应，TODO:示例 active_mask 激活的标记，mask_list中的某个标记，使用mask_name决定，用于表示当前启用的mask，进一步表示启用的register方法： add_register (data) 向register_assignment中添加一个项，添加在数组尾部 add_mask (data) 添加或更新mask_list delete_mask (data) 从mask_list删除一个mask，使用mask_names4.3.6 Profile generic (class_id = 7, version = 1)允许存储、排序和访问称为捕获对象的数据组或数据系列。捕获对象是几个COSEM对象的几个适当属性或几个属性的几个元素的组合。捕获对象定期或不定期收集。曲线包含捕获对象，可通过值的范围或输入范围检索范围内所有记录捕获对象列表定义了要保存在buffer中的值，列表是静态的，保证每个记录都拥有相同的长度和结构修改捕获列表必须清空buffer中所有记录，buffer被其他profile使用也必须清空buffer。以保证它们的缓冲区条目的同质性记录可以按某个字段进行排序，如时间，或是按先进后出的栈的方式排序。例，按照Demand register中的last_average_value值来从小到大排序获得最大需量registers曲线数据大小限制参数 记录数entries_in_use 最大保留条数。当记录数满时，新捕获数据会覆盖最不重要的一条数据，重要度根据排序方式获得，如根据时间排序，最不重要的数据就是时间最早的数据 缓冲区物理限制s选择性访问 按照值的范围： 值可以是时间，或是某个捕获对象的值 按照排序后记录存储的顺序范围： 如从第一条记录（重要性最高）到第三条 如从某个值最大的记录到第三大的记录，需要重新临时排序 s属性 buffer 包含记录序列，每个记录包含若干捕获对象 capture_objects 捕获对象列表，数组形式 capture_period 自动捕获周期，以秒为单位，大于1表示达到周期捕获，等于0表示不自动捕获，需要手动触发 sort_method 排序方式，默认为先进先出排序。如果profile已经排序，插入新的记录时，将记录插入适当位置，移动该位置之后所有记录，最不重要记录可能在buffer满后丢失。如果新记录的重要度最低且buffer已满，则该记录不插入 sort_object 排序依据（对象）,此属性指定排序所基于的寄存器或时钟 entries_in_use 当前记录总数 profile_entries 记录上限s方法 reset (data) 清空buffer，entries_in_use清零，其他配置不变 capture (data) 手动触发捕获，读取每个捕获对象的值，生成记录插入buffer,同样不会改变捕获对象列表s修改捕获对象列表后行为调用使用了该捕获对象列表的profile的reset操作，需要清空buffers限制定义捕获对象列表时，避免相互或循环引用。TODO:实例？s4.3.7 Utility tables (class_id = 26, version = 0)允许封装 ANSI C12.19:2012 table 数据TODO:这是什么？s4.3.8 Register table (class_id = 61, version = 0)对同构条目、多个对象的相同属性进行分组，这些对象都是相同IC的实例,并且在它们的logical_name (OBIS代码)中，值组A到D和F中的值是相同的。属性： logical_name 当逻辑名为A.B.C.D.255.F时，只捕获一个属性，如value。当逻辑名为A.B.98.10.X.255时，可以捕获有关对象的不同属性 table_cell_values 保存捕获属性的值（可选CHOICE种类就是register对象的value属性的类型，因为保存的是多个对象，所以是一个数组），可压缩 压缩条件： 如果捕获的属性是attribute_0（index 0,表示捕获所有属性），冗余值可以被“null-data”替换，如果它们的值可以明确地恢复(例如scaler_unit)。 table_cell_definition Class_id定义捕获属性的对象的公共Class_id;logical_name包含对象的通用逻辑名，E = 255(通配符);group_E_values包含单元标识符列表，类型为unsigned，在DLMS UA 1000-1 Ed 15 Part 1:2021的相应表中定义;Attribute_index是指向对象内属性的指针。Attribute_index 0表示所有公共属性。 scaler_unit 量纲，当“Register”或“Extended Register”对象的“value”属性被捕获时，scaler_unit应为所有对象的公共属性。如果是其他属性或是其他IC，则该属性无用且禁止访问方法： reset (data) 清空table_cell_values capture (data) 捕获，将原IC对象中的值拷贝到table_cell_values中，如果table_cell_definition中的attribute_index为0，则捕获所有属性table_cell_definition被写入时的动作：自动调用reset方法清空原数据，如果需要捕获的属性的占用空间过大，table_cell_definition的写入会被拒绝s4.3.9 Status mapping (class_id = 63, version = 0)该IC允许将状态字中的位映射到引用表中的项。 status_word 状态字，n*8比特，最大65536比特 mapping_table 包含status_word到引用表中位置的映射。 ref_table_id 表示引用表的id ref_table_mapping（choice：long-unsigned或long-unsigned数组）：该值对应引用表(reference table，见6.2.45)中的一条记录，该记录对应status_word中的第一位，该记录的下一条记录对应status_word中的第二位，直到status_word的最后一位 如果该值选择long-unsigned，则表示对于引用表的引用起始指针 假设status_word为10000001，ref_table_mapping的long-unsigned值为3，对于引用表的第3条记录 status_word位值 引用表索引 1 3 0 4 0 5 … … 1 10 ref_table_mapping选择array：array中的每个值对应引用表中的一条记录，每条记录对应status_word中的对应位，如array第一个值对应status中的第一位，最后一个值代表最后一位 s4.3.10 Compact data (class_id: 62, version = 1)紧凑数据Compact数据IC的实例允许捕获由capture_objects属性确定的COSEM对象属性值。捕捉可以发生: 在外部触发器上(显式捕捉); 在读取compact_buffer属性时(隐式捕获)。由capture_method属性确定值保存在compact_buffer attribute中，以octet-string形式这组数据类型由template_id属性标识。捕获的每个属性的数据类型由template_description属性保存。客户端可以用未压缩的形式重新构造数据(解压)，即包括COSEM属性描述符、数据类型和使用capture_objects、template_id和template_description属性的数据值。属性： compact_buffer 捕获的属性的值，octet-string形式，当类型为octet-string, bit-string, visible-string, utf8-string or array时，长度也包含在内。（不同于profile，这个类中的compact_buffer就是个octet-string，不是array，也就是只有一条） capture_objects 指定分配给“Compact data”对象实例的COSEM对象属性列表，两种选择性访问方式： 相对选择性访问：相对当前的日期或当前的记录返回记录，由data_index元素控制 绝对选择性访问：根据明确的时间范围或记录范围返回记录，由restriction_element控制，列（columns）是由data_index的MS byte(Most Significant byte,意为最高有效字节)的低半字节（右边4位）决定的 data-index: MS-Byte MS-Byte LS-Byte   Upper nibble Lower nibble     0000 0000 00000000 data_index:是一个指针，它选择具有复杂数据类型(结构或数组)的属性的一个或几个特定元素: 如果属性的数据类型是简单类型，则该值无意义 如果属性的数据类型是结构体或数组（非profile generic对象的buffer），则该值指向该结构体或数组中的一个或多个特定元素 如果属性的数据类型是profile generic对象的buffer，该值包含相对选择性访问的参数，如当前日期或记录 0x0000 =标识整个属性; 0x0001到0x0FFF =标识复杂属性中的一个元素。复杂属性中的第一个元素由data_index 1标识; 0x1000到0xFFFF =对保存Profile generic对象的buffer的数组进行相对选择性访问。数据索引选择最近(最近)时间段内的条目，或最近(最近)条目内的条目，以及数组中的列。 参考Table 9 – Encoding of selective access parameters with data_index。例，0x830C，MS-Byte中的高4位为0x8，表示包括当前小时在内的最后一个完整小时数，低4位为0x3，表示前3列，LS-Byte为0x0C,表示12小时，综上，该值表示选择最后12个小时内的前3列数据 restriction_element：当属性的数据类型是profile generic对象时，该值用于表示绝对选择性访问的参数，时间范围，记录序号范围， 此时的data_index条件： MS Byte高4位为0（为1的话表示相对选择性访问） MS Byte低4位为0x0到0xF Lower byte为0 restriction_type表示选择性访问的方式 restriction_value表示选择性访问范围 template_id 包含模板的标识符。它应唯一标识“Compact data”IC的实例和 template_description。 template_description 每个被捕获的属性的数据类型，由服务端自动生成，根据capture_objects，包含以下结构体： 第一个字节是0x02结构体tag 后面是数量，变长，和capture_objects数量相同 后面是每个属性的数据类型，与capture_objects一一对应: 对于具有简单数据类型的属性，该值一个字节，包含类型tag，如bit-string[4] 对于array[1]，该值为0x01，后面是元素的类型（数组内所有元素都相同，所以就一个）。不记录数目是因为compact_buffer已经记录了 对于structure[2]，该值为0x02,后面是元素数目，后面是每个元素的类型 capture_method 定义compact_buffer更新的方式： 0：在调用Capture (data)方法时捕获。这可能发生在远程或本地(显式捕获) 1：读取compact_buffer属性时捕获(隐式捕获) 方法： reset(data) 仅清空compact_buffer capture(data) 将捕获对象的值填充至compact_buffer中，不会触发捕获对象内的任何其他操作，如capture()或reset()对capture_objects的任何修改，必须重置compact_buffer以及自动更新template_descriptions4.4 用于访问控制和管理的接口类Interface classes for access control and managements4.4.3 Association SN (class_id = 12, version = 4)COSEM logical devices能够在COSEM context中使用SN引用建立AAs，使用“Association SN”IC的实例建模AAs。一个COSEM logical devices可以对每个设备能够支持的AA拥有一个该IC的实例。属性： object_list 对象列表，数组形式，包含base_name,class_id,version,logical_name，base_name定义见文章开头 实际这里base_name和logical_name的含义重复了，不过base_name是是用来作为和access_rights_list关联的外键的 TODO:logical_name和base_name重复了 access_rights_list 包含对属性和方法的权限，数组形式，和object_list间通过base_name管理，相当于外键，元素数量需要相同，元素顺序最好也相同。包含base_name，attribute_access(可选)，method_access(可选) object_list支持以class_id，logical_name或base_name为条件选择性访问，access_rights_list支持以base_name为条件选择性访问 security_setup_reference 引用Security setup的logical_name，被引用的对象管理给定的”Association SN”对象实例的安全性 user_list 允许使用本对象管理的AA的用户列表 user_id表示user的id（AARQ中的calling-AE-invocation-id携带） user_name是用户的名字 如果数组为空，则任何用户都能使用AA；如果数组不为空，则仅有列表内用户可以建立AA，也就是AARQ中的calling-AE-invocation-id字段必须匹配列表中的user_id。 array user_list_entry user_list_entry ::= structure { user_id: unsigned, user_name CHOICE { visible-string [10], UTF-8-string [12] } } current_user 当前用户，若user_list为空，该值的user_id和user_name都为0（空）方法： read_by_logicalname (data) 读取指定对象的属性值，对象由class_id和logical_name指定，attribute_index表示索引，0表示全部属性，1表示第一个属性。回复的数据由属性类型决定 change_secret (data) 修改LLS密码或HLS密钥（不包括认证），可能包含校验信息或本身被加密，HLS with GMAC认证的密钥由Security setup管理。 reply_to_HLS_authentication (data) 此方法的远程调用将服务端对客户端的质询(change) f(StoC) 的客户端秘密处理的结果传递给服务端，作为通过参数化访问调用的 Read.request 原语的数据服务参数 服务端S 客户端C StoC-&amp;gt;     &amp;lt;-f(StoC)加密处理后的结果 data数据是客户端对服务端的回复TODO：请求和回复的数据是什么回应数据：如果认证被接受，则响应（Read.confirm 原语）包含 Result == OK 和服务器对客户端质询服务器的秘密处理结果，在 Read 的数据服务参数中 f(CtoS) 响应服务。data数据是服务端对客户的回复如果认证不被接受，则返回non-OK值，且不包括data add_user (data) 向user_list添加一个用户 remove_user (data) 从user_list移除一个用户s4.4.4 Association LN (class_id = 15, version = 3)COSEM logical devices能够使用 LN 引用在 COSEM context中建立 AA，通过“Association LN”IC 的实例对 AA 建模。 一个 COSEM logical devices件对于该器件能够支持的每个 AA 都有一个该 IC 的实例。属性： object_list 同Association SN中object_list和access_rights_list的整合 选择性访问支持null(所有),class_list,object_id_list,object_id(class_id+logical_name) associated_partners_id 包含COSEM客户端和服务端(逻辑设备，物理设备包含若干个逻辑设备)，属于由Association LN对象建模的AA。客户端范围为0x0-0x7F,服务端范围为0x0-0x3FFF application_context_name 在COSEM环境中，希望预先存在一个application context，并在AA建立期间通过其名称引用它。此属性包含该AA的application context的名称。见Green Book 4.5.2 application context，9.4.2.2.2 The COSEM application context。TODO:查看文档 xDLMS_context_info 包含关于给定AA的xDLMS context的所有必要信息 conformance element: 包含服务器支持的xDLMS一致性块,TODO:一致性块是什么 更新：见Gp322 Table 85，表示双方支持的功能列表，用于协商。位串的长度为24位; max_receive_pdu_size：包含xDLMS APDU的最大长度，客户端可以发送的字节数在AA过程中协商，受xDLMS initiateResponse APDU的server-max-receive-pdu-size参数的限制; max_send_pdu_size：在这个AA中服务器可以发送的xDLMS APDU的最大长度，以字节表示。它受到xDLMS initiateRequest APDU的client-max-receive-pdu-size参数的限制; dlms_version_number：包含服务端支持的DLMS版本 quality_of_service：未使用 cyphering_info：在一个活动的AA中，包含xDLMS initiateRequest APDU的专用关键参数，见GREEN BOOK 9.5 authentication_mechanism_name AA认证机构名称 secret LLS或HLS密钥，同上SN association_status AA当前状态 security_setup_reference 引用Security setup对象的logical name.该对象用于管理Association LN本对象实例 user_list 同上SN current_user 同上SN方法： reply_to_HLS_authentication (data) 同上SN change_HLS_secret (data) 同上SN add_object (data) 同上SN remove_object (data) 同上SN add_user (data) 同上SN remove_user (data) 同上SNs4.4.5 SAP assignment (class_id = 17, version = 0)该 IC 允许通过提供有关将逻辑设备分配给其 SAP 的信息来对物理设备的逻辑结构进行建模。 参见 DLMS UA 1000-2 Ed.11:2021，第 10 条。属性： SAP_assignment_list 包含物理设备上所有逻辑设备和他们的sap 逻辑设备名 sap 方法： connect_logical_device (data) 将逻辑设备连接到SAP。连接到SAP 0表示断开设备连接。一个SAP不能连接多个设备(SAP 0除外)。 逻辑设备：物理设备中的抽象实体，表示用COSEM对象建模的功能子集 s4.4.6 Image transfer (class_id = 18, version = 0)图像传输IC模型的实例是将二进制文件(称为image)传输到COSEM服务器的过程。 步骤1：(可选)获取ImageBlockSize 步骤2：客户端启动镜像传输 步骤3：客户端传输imageBlocks 步骤4：客户端检查确认传输完成 步骤5：服务端校验镜像完整性（客户端发起或服务端自行完成） 步骤6：（可选）客户端检查要激活的图像上的信息 步骤7：服务端激活镜像（客户端发起或服务端自行完成）属性： image_block_size 保存ImageBlockSize，一个镜像被分为若干块，这里是每个块大小，用八位字节表示，不能超过协商的ServerMaxReceivePduSize image_transferred_blocks_status 位图，提供关于每个ImageBlock的传输状态的信息。bit-string中的每一位提供了一个单独的ImageBlock的信息，0为未传输，1为已传输。 image_first_not_transferred_block_number 第一个未传输的块的编号，如果传输全部完成，该编号应该等于或大于image_block_size image_transfer_enabled 控制是否启用图像传输过程，只有置为true才能执行image transfer相关方法，为false是禁用所有方法的执行，返回错误 image_transfer_status 传输状态 image_to_activate_info 提供有关准备激活的映像的信息。这是一个数组，每个待激活的镜像都有独立信息，它是作为图像验证过程的结果生成的。客户端可以在激活映像之前检查这些信息（从服务端的这个属性中读出来后检查）。包括大小、标识（identification）和签名方法： image_transfer_initiate (data) 初始化传输过程，参数包括identifier和ImageSize（不是image block size）。在此之后，将image_transfer_status（传输状态）属性置为1，image_first_not_transferred_block_number置为0，对于该方法的调用会重置整个传输流程 image_block_transfer (data) 传输一个块到服务端，包括块序号和块内容，之后将image_transferred_blocks_status对应位置1，image_first_not_transferred_block_number更新 image_verify (data) 在激活之前验证映像的完整性(触发服务端自校验)。 调用这个方法的结果可能是success、temporary_failure或other_reason。如果不成功，则可以通过检索image_transfer_status属性的值来找到验证的结果。 如果成功，image_to_activate_info属性将保存要激活的图像的信息。 image_activate (data) 激活镜像。 如果传输的Image之前没有经过验证（没执行image_verify），那么这将作为Image_activate的一部分完成。调用此方法的结果可能是成功、暂时失败或其他原因。如果不是成功，那么可以通过检索image_transfer_status属性的值来了解激活的结果。 如果客户端不知道图像传输目标服务器可以处理的图像块的大小，那么在开始处理之前，客户端需要读取图像传输到的每个服务器的相关“image transfer”对象的image_block_size属性。客户端可以传输合适大小的ImageBlocks。如果图像块通过广播发送给一组COSEM服务端，图像块大小在组中的每个成员中应该是相同的。校验临时失败不是真正失败，可能是校验还未完成，客户端可以通过获取image_transfer_status属性的值来检查Image验证的结果。服务端内可以保存多个待激活的镜像sImage transfer for M-Bus devicess4.4.7 Security setup (class_id = 64, version = 1)“Security setup”IC的实例包含有关正在使用的安全套件(security suite)的必要信息，以及在客户机和服务器之间适用的安全策略(security policy)(由它们各自的系统标题标识)。它们还提供了提高安全性级别和管理对称密钥、非对称密钥对和证书的方法属性： security_policy 安全策略，使用安全套件中可用的安全算法强制身份验证和/或加密和/或数字签名。它独立地应用于请求和响应。 security_suite 安全套件，明确加密算法 (0) AES-GCM-128 authenticated encryption and AES-128 key wrap (1) AES-GCM-128 authenticated encryption, ECDSA P-256 digital signature, ECDH P-256 key agreement, SHA-256 hash, V.44 compression and AES-128 key wrap (2) AES-GCM-256 authenticated encryption, ECDSA P-384 digital signature, ECDH P-384 key agreement, SHA-384 hash, V.44 compression and AES-256 key wrap (3) … (15) reserved client_system_title 携带（当前）客户端system title，在已确认或未确认的AA建立过程中，由AARQ APDU的calling-AP-title字段承载; server_system_title 携带服务端的system_title，在确认AA建立时，由AARE APDU的response-AP-title字段进行 certificates 携带可用的X.509 v3证书信息，并存储在服务器中。服务端可以保存服务端证书、每个客户端的证书、CA证书。方法： security_activate (data) 激活和加强安全策略security_policy，新的值安全性必须高于或等于原值，也就是只能加强，不能减弱 key_transfer (data) 用于传输一个或多个密钥(EK,AK,BK,MK),包括密钥标识和封装后的密钥（key wrapped）。可以是数组，一次多个密钥。key wrap算法由加密套件指定 key_agreement (data) 用于使用安全套件指定的密钥协商算法对一个或多个对称密钥达成一致。在套件1和套件2的情况下，ECDH密钥协商算法与临时统一模型(Ephemeral Unified Model) C(2e, 0s, ECC CDH)方案一起使用。 generate_key_pair (data) 根据安全套件的要求生成非对称密钥对。data参数标识要生成的密钥对的用法: digital signature key pair 数字签名 key agreement key pair 密钥协商 TLS key pair TLS通信 以上每个用法的密钥对最多同时只能有一个，也就是最多有三个密钥对 generate_certificate_request (data) 当调用此方法时，服务器发送证书签名请求(CSR)数据，这是CA为服务器公钥生成证书所必需的。data参数为请求证书的密钥对类型 响应为CSR数据，PKCS #10格式DER编码的octet-string import_certificate (data) 导入X.509 V3格式证书，DER编码octet-string，无需指定类型，TODO：如何区分证书类型,自动识别？ export_certificate (data) 导出证书，根据类型或序列号 remove_certificate (data) 移除证书，参数同上导出证书s4.4.8 Push interface class在很多情况下，DLMS消息可以在没有明确请求的情况下“推送”到目的地，例如: 如果本地监控的值超过阈值; 由本地事件触发(如开机/关机，按下按钮，仪表盖打开)。DLMS/COSEM推送机制遵循发布/订阅模式。在DLMS/COSEM中，发布是由“Association”对象的object_list属性建模的，该属性提供了给定AA中可访问的COSEM对象列表和它们的属性。订阅是通过编写“Push setup”对象的适当属性来建模的。使用xDLMS DataNotification服务(在指定的触发器上)发送所需的数据。s4.4.8.2 Push setup (class_id = 40, version = 3)“Push setup”IC包含要推送的COSEM对象属性的引用列表。它还包含推送目的地和方法，以及通信时间窗口和重试处理Push在push方法被调用时启动，由push *Single action schedule*对象、alarm *Register monitor*对象、专用的内部事件或外部事件触发。push操作被触发后，根据给定的push setup对象中的设置执行。根据通信窗口的设置，push会在随机延迟后立即执行，或者在通信窗口激活后立即执行。如果push不成功，则会重试。重试可能在提示支持协议层失败或缺少确认时发生。属性： push_object_list 定义要推送的属性列表，在调用push (data)方法时，内容被发送到send_destination_and_method属性中定义的目标。 class_id 类 logical_name 对象 attribute_index 属性序号，0表示全部，如果attribute_index是0，则data_index为0且无意义，其他值也为空或null data_index 当属性是数组或结构体时(除profile generic)，0表示所有元素，0x0001-0x0FFF表示元素序号，其他值为空或null restriction,columns 当属性是profile generic对象的时，和data_index一起表示选择性访问参数 携带推送数据的DataNotification APDU受到安全套件suit、安全策略policy和安全材料material的保护，这些安全配置包含在”Security setup”对象中，由AA应用上下文中的Association SN/Association LN对象的security_setup_reference属性引用，与push_client_SAP属性相关联；以及push_protection_parameters属性也是如此。对于在该AA中没有被授予读取访问权的属性，或者由于任何其他原因不能被访问的属性，应该返回空数据。 send_destination_and_method 包含目标地址和传输服务(例如电话号码，电子邮件地址，IP地址)，用于发送push_object_list指定的数据 transport_service 传输服务类型，如TCP,HDLC,Gateway等 destination 目的地址，取决于transport_service，比如CoAP协议的目的地址时一个CoAP URI, message APDU编码类型 (0) A-XDR encoded xDLMS APDU (1) XML encoded xDLMS APDU (128…255) manufacturer specific 一个Push setup对象仅支持一个transport_service和destination，如果同一个内容需要上报给多个目的地，则需要多个不同对象 communication_window 通信窗口，包含开始时间和结束时间的区间，是个数组，每个元素为一个区间。如果没有元素，则不限制窗口，随时可以推送 randomisation_start_interval 发送第一包前的随机等待时间的最大值，为了防止大量同网络设备同时推送。 随机等待时间从0到最大值随机 仅在活动窗口内调用push生效，不在重试时生效（push失败后等待固定延迟时间重试，不应用随机等待时间） 在活动窗口外时push，到达窗口开始时间时计算随机值 随机延迟超出窗口结束时间，那要到下一个窗口才能push，见上一节的图片 未定义窗口时，所有push和重试都会应用随机等待 number_of_retries 最大重试次数 repetition_delay 重发延迟 最小时间 指数，用于计算下次延迟 最大时间 𝑟𝑒𝑝𝑒𝑡𝑖𝑡𝑖𝑜𝑛_𝑑𝑒𝑙𝑎𝑦 = 𝑟𝑒𝑝𝑒𝑡𝑖𝑡𝑖𝑜𝑛_𝑑𝑒𝑙𝑎𝑦_𝑚𝑖𝑛 × (𝑟𝑒𝑝𝑒𝑡𝑖𝑡𝑖𝑜𝑛_𝑑𝑒𝑙𝑎𝑦_𝑒𝑥𝑝𝑜𝑛𝑒𝑛𝑡 × 0.01)^(𝑛−1) n表示第几次，n=1表示第一次重试 push内容没有缓存，每次push重试，内容可能会变 port_reference 通信端口引用，引用通信端口setup对象的logical_name,TODO:查看对应章节 push_client_SAP 客户端SAP,推送目标，绑定对应的AA push_protection_parameters 数据保护参数，见Data Protection IC push_operation_method 定义是否使用 Service_Class == Unconfirmed 或 Confirmed 调用 DataNotification.request 服务原语以及推送重试的操作方式。 (0) unconfirmed, retry on supporting protocol layer failure。AL层无需确认（发送结果不用给AL层），也不会超时重发，只在支持层回失败时重发，条件最宽松 (1) unconfirmed, retry on missing supporting protocol layer confirmation。AL层无需确认（发送结果不用给AL层），但会在支持层超时未回confirm原语时重发，包含0的情况，失败也重发 (2) confirmed, retry on missing confirmation。必须由AL层确认，否则都会超时重发（即使支持层回了成功也一样），包含0和1的情况 confirmation_parameters 仅用于相对选择性访问时（见本节push_object_list中的data_index和restriction），该值定义选择的条件（已经被确认的条目，已经被确认的不再推送），防止推送较早的数据。如果没有条目被确认则所有条目都会被选择，全部推送 选择条目开始时间 当前时间开始的向后偏移时间，秒 last_confirmation_date_time 保存 AL 最近调用 DataNotification.confirm 服务原语并收到 Result == CONFIRMED 的日期和时间。方法：push (data) 激活一次推送，发送携带推送数据的DataNot ification APDUreset (data) 重置为初始状态s4.4.9 COSEM data protection (class_id = 30, version = 0)该IC的实例允许对COSEM数据，即属性值、方法调用和返回参数应用加密保护。这是通过 “Data protection”接口类的实例间接访问其他COSEM对象的属性和/或方法来实现的，该接口类提供必要的机制和参数来应用/验证/移除对COSEM数据的保护。保护参数总是由客户端控制，一些元素由服务器适当地填充。安全套件由“Security setup”对象决定，该对象来自当前的“Association SN”/“Association LN”对象。属性： protection_buffer 包含受保护的数据。读取时，捕获由protection_object_list指定的属性，然后根据protection_parameters_get应用保护。写入时，受保护的数据被放入protection_buffer中，然后根据protection_parameters_set验证/删除保护，并设置由protection_object_list指定的属性。 protection_object_list 定义在读取protection_buffer时要捕获的属性列表，或者在写入protection_buffer时要设置的属性列表。 关于选择性访问的描述见Compact data protection_parameters_get 包含所有必要的参数，用于指定读取protection_buffer时应用的保护。这个属性首先由客户端写入。服务器可能需要填写一些额外的元素，在这种情况下，客户端必须读回这个属性——如果需要的话，转发给第三方——以便他们可以使用这些参数来验证/删除保护 protection_parameters_set 包含所有必要的参数，用于在写入protection_buffer时验证/删除应用的保护。参数与get相同。此属性由客户端编写，并由服务器使用它来验证和删除保护。 required_protection 规定了通过“Data protection”对象访问的属性值/调用和方法的返回参数所需的保护。 对于request和response的保护方式 方法： get_protected_attributes (data) 获取object_list元素指定的属性的值，并应用get_protected_attributes_response中根据protection_parameters设置的保护 get_protected_attributes_response中的protection_parameters值是根据客户端参数get_protected_attributes_request中的得到的，服务端可能会有修改，所以可能会有不同 set_protected_attributes (data) 根据protection_parameters元素，在验证并移除protected_attributes元素上的保护之后，设置object_list元素指定的属性值。 invoke_protected_method (data) 以保护方式执行特定方法，方法的参数和返回值被保护。在根据invoke_protected_method_request中的protection_parameters验证并移除protected_method_invocation_parameters上的保护后，调用object_method元素指定的方法。 在调用由 object_method 元素指定的方法后，根据 invoke_protected_method_response 中的 protection_parameters 的保护（必须满足 required_protection）应用于返回参数，并且由 protection_parameters 和 protected_method_return_parameters 组成的 invoke_protected_method_response 返回。 invoke_protected_method_request ::= structure { object_method 要执行的方法 protection_parameters: 保护参数 object_method_definition： 被保护的参数 }invoke_protected_method_response ::= structure { protection_parameters: 保护参数 protected_method_return_parameters: 被保护的返回值（参数） } protection_parameters必须满足required_protection s4.4.10 Function control (class_id: 122, version: 0)IC“Function control”的实例允许启用和禁用服务端中的功能（Function）。每个可以启用/禁用的功能都由一个名称标识，并由引用的一组特定对象标识符定义。依赖“Single action schedule”和“Script table”对象实现按时间控制功能禁用启用属性： activation_status 显示function_list属性中定义的每个功能块的当前状态(启用或禁用) function_list 定义一个功能列表，可以通过调用set_function_status方法启用或禁用这些功能。通过class_id和logical_name指定，当功能不能对应特定的COSEM对象时，class_id为0，logical_name为特定描述文本。 这里的功能包含了若干个具体的关联对象，也就是是个抽象的概念，由不同的对象的合作实现的一个功能 方法： set_function_status (data) 启用或禁用一个或多个功能 add_function (data) 添加一个新功能，必须是服务端支持的 remove_function (data) 移除一个新功能s4.4.11 Array manager (class_id = 123, version = 0)“Array manager”IC的实例允许管理其他接口对象数组类型的属性 检索条目的数量; 选择性地阅读一系列条目; 插入新条目或更新现有条目; 删除一个范围的条目每个实例允许管理分配给它的数组类型的几个属性TODO：该对象有权限访问修改其他对象的属性？属性： array_object_list 定义可由该IC的实例管理的数组类型的属性列表方法： retrieve_number_of_entries(data) 返回一个数组中已标识的条目总数 retrieve_entries (data) 检索array_object_list数组中的一个数组项的范围数据。 m表示记录总数，from_entry和to_entry表示数组序号，序号为1到m from_entry &amp;lt; to_entry &amp;lt; m，返回from_entry 到 to_entry记录 from_entry &amp;lt; to_entry， to_entry &amp;gt; m，返回from_entry到m的记录 from_entry &amp;lt; to_entry， from_entry&amp;gt;m，返回元素个数为0的空数组 from_entry &amp;gt; to_entry,返回错误 insert_entry (data) 向一个数组插入一条新记录,插入到参数id标识的序号之后，特殊情况：0表示变第一个，大于m表示变最后一个 update_entry (data) 更新一个数组中的一天记录 remove_entries (data) 按范围删除数组，同retrieve_entriess4.4.12 Communication port protection (class_id = 124, version = 0)保护通信端口，防止恶意通信，如暴力破解属性： protection_mode 保护模式， 锁定 失败尝试后锁定 无锁定 allowed_failed_attempts 触发锁定机制之前允许的失败通信尝试次数。 initial_lockout_time 第一次触发锁定的锁定时间 steepness_factor 锁定时间递增步长 NCA=failed_attempts-allowed_failed_attempts CLT=initial_lockout_time x (steepness_factor^(NCA-1)) max_lockout_time 最大锁定时间,避免拒绝服务攻击(DDoS) port_reference 被保护端口对象的逻辑名 protection_status 当前保护状态，未锁定、临时锁定、已锁定 failed_attempts 失败总数，与保护机制触发无关，会被reset重置 cumulative_failed_attempts 失败总数，与保护机制触发无关，不会被重置方法： reset (data) 重置failed_attempts、current lockout time、protection_statuss4.5 时间和事件绑定控件的接口类Interface classes for time- and event bound controls4.5.1 Clock (class_id = 8, version = 0)该IC为设备时钟建模，管理所有与日期和时间相关的信息，包括由于时区和夏令时方案而导致的本地时间与通用时间参考(UTC)的偏差。IC还提供了各种调整时钟的方法日期信息包括“年”、“月”、“日”、“周”。时间信息包括小时、分钟、秒、百分之一秒以及本地时间与UTC的偏差。夏令时功能根据属性修改本地时间与UTC的偏差;参见图20所示。该函数的起始点和结束点通常设置一次。内部算法根据这些设置计算出真正的开关点属性： time 包含仪表的本地日期和时间，其与UTC的偏差和状态。格式为date-time。可只修改部分字段，如只修改日期，此时参数中时间字段需为”not specified” time_zone 时区 status 状态 daylight_savings_begin 夏令时开始日期时间 daylight_savings_end 夏令时结束日期时间 daylight_savings_deviation 夏令时偏移（分钟） daylight_savings_enabled 夏令时启用 clock_base 时钟信息依据 无 内部晶振 市电频率50Hz 市电频率60Hz GPS 无线电控制 方法： adjust_to_quarter (data) 将时间调整为最近(+/-)的整刻钟(*:00,*:15,*:30,*:45) adjust_to_measuring_period (data) 将时间调整为最近(+/-)测量周期的起点 adjust_to_minute (data) 将时间调整为最近(+/-)整分钟 adjust_to_preset_time (data) 和preset_adjusting_time配合，激活preset_time，执行时的时间必须是时间范围内的 preset_adjusting_time (data) 定义一个预设时间preset_time和一个允许执行生效时间范围 shift_time (data) 将时间移动n (-900 &amp;lt;= n &amp;lt;= 900) s。n为long类型s4.5.2 Script table (class_id = 9, version = 0)通过脚本执行一系列动作脚本可由同一个逻辑设备内其他COSEM对象或从外部激活同时执行时索引小的优先执行属性： scripts 脚本，操作列表 action_specification指向引用对象的动作（限制为不产生响应的动作），为一个数组，可以有多个动作 写属性 执行方法 service_id为1表示属性，2表示方法 方法： execute (data) 执行对应的脚本s4.5.3 Schedule (class_id = 10, version = 0)计划时间表属性： entries 给定时间执行的脚本 script_logical_name Script table对象的逻辑名 script_selector Script table对象中的script_identifier switch_time 执行时间，支持通配符，time格式 Validity_window 有效窗口（执行宽容时间），一个以分钟为单位的时间段。(switch_time和实际的power_up之间的时间，如果在开机前这个时间范围内触发则执行，否则不执行。触发时间switch_time到后在这个时间范围内必须执行，如果未及时上电导致执行不了，则不执行)。0xFFFF:脚本在任何时候都被处理; TODO:理解有待明确 exec_weekdays 定义每周执行的天 exec_specdays 见节日表“Special days table”, day_id Begin_date和end_date 定义了条目有效的日期范围(允许通配符) 方法： enable/disable (data) A范围内的禁用，B范围内的启用 insert (data) 插入一条新记录，已存在覆盖 delete (data) 按索引范围删除记录Time setting forward：向后调整时间，调整至更晚的时间，此时操作和掉电相同，根据Validity_window补执行Time setting backward：向前调整时间，调整至更早时间，会出现重复执行的情况夏令时向后则执行错过的脚本，向前则不执行重复的脚本s4.5.4 Special days table (class_id = 11, version = 0)定义特殊日期，特殊日期行为会覆盖通常的，与Schedule” 或 “Activity calendar” 同时执行为给定日期指定特殊的日期标识符。日期可能具有重复特殊日子的通配符，如圣诞节。属性：entries 数组，每个条目表示一个特殊日期，如圣诞节方法：insert (data) 向entires插入一条记录，会覆盖delete (data) 删除一条s4.5.5 Activity calendar (class_id = 20, version = 0)按计划执行脚本，遵循日历时间表方式，（和费率相关？）TODO：和Schedule的区别 更新：比Schedule更加具体，类似于cron表达式可与Schedule对象共存，重叠时Schedule对象优先执行被Special days table覆盖属性： calendar_name_active 标识符 season_profile_active 季节方案，包含季节开始时间和对应的week方案 week_profile_table_active 周方案，包括一周中每天的方案 day_profile_table_active 日方案，包含脚本执行时间、Script table对象内脚本的引用 calendar_name_passive 备用方案 season_profile_passive 备用方案 week_profile_table_passive 备用方案 day_profile_table_passive 备用方案 activate_passive_calendar_time 调用activate_passive_calendar的时间方法： activate_passive_calendar (data) 激活备用方案，将passive属性复制到active中s4.5.6 Register monitor (class_id = 21, version = 0)这个IC允许对 “Data” , “Register”,“Extended register” or “Demand register”对象的值进行建模监控。监控用于在特定条件下触发脚本。它允许指定阈值、监测的值和一组脚本，当监测的值超过阈值时，这些脚本将被执行。依赖于同一逻辑设备内的Script table对象属性： thresholds 提供将引用寄存器的属性与之比较的阈值。 monitored_value 定义监视对象的哪个属性。只允许具有简单数据类型的值 actions 定义被引用对象的监视属性超过相应阈值时要执行的脚本。属性操作具有与属性阈值完全相同的元素数量。action_items的顺序与阈值的顺序对应s4.5.7 Single action schedule (class_id = 22, version = 0)执行定时任务 TODO:和Schedule的区别 executed_script Script table对象的引用 type execution_time内时间是否相同，是否允许通配符 execution_time 脚本执行日期和时间s4.5.8 Disconnect control (class_id = 70, version = 0)拉合闸控制，管理电表的内部或外部断开装置（例如电闸、燃气阀），以便部分或全部地连接或断开用户的电源。三种方式： 远程Remotely，通过通信端口 手动Manually，如按按钮 本地Locally，电表内部功能触发，如limiter对象属性： output_state 设备supply实际的物理连接状态 control_state 内部控制连接状态 (0) Disconnected (1) Connected (2) Ready_for_reconnection control_mode 控制模式，每一条对应3种控制方式的控制权限方法： remote_disconnect (data) 远程断开连接，需要有权限 remote_reconnect (data) 远程恢复连接，需要有权限s4.5.9 Limiter (class_id = 71, version = 0)限制器，当“Data”, “Register”, “Extended Register”,“Demand Register”对象超过阈值一定时间时执行动作TODO:和4.5.6 Register monitor的区别，应该是比后者更加详细，这个是超过一定时间加上更多种阈值。阈值包括正常阈值和紧急阈值。紧急阈值通过emergency profile id, emergency activation time, and emergency duration定义的emergency_profile激活。emergency profile id元素与emergency profile group id匹配:这种机制只允许针对特定的emergency group激活紧急阈值。 monitored_value 定义要监控的对象的属性。只允许具有简单数据类型的属性。 threshold_active 活动阈值 threshold_normal 正常阈值 threshold_emergency 紧急阈值 min_over_threshold_duration 超过阈值最小持续时间，秒 min_under_threshold_duration 低于阈值的最小持续时间 emergency_profile 紧急配置,用于紧急阈值激活，当emergency_profile_id和emergency_profile_id中的匹配，且当前时间在从emergency_activation_time开始emergency_duration范围内时激活 emergency_profile_group_id_list emergency_profile_id列表 emergency_profile_active emergency_profile激活状态 actions 超过或低于阈值超过最小持续时间时的动作(script)s4.5.10 Parameter monitor (class_id = 65, version = 1)监控参数修改（某些COSEM对象的属性用于表示配置参数）可使用profile generic对象捕获，生成profile每个可以访问服务器的客户端都必须知道当前的参数设置，以便能够正确地与服务器交换数据。参数可以分组，每个组可以有一个名称。尽管最初的参数可能是已知的，但在电表的生命周期内可能会发生变化，例如它可能被另一个客户（如现场服务设备）改变。当前的配置可能总是通过在交换开始时读取配置参数来检索。这并不高效，而且在推送操作的情况下，这并不实用。需要一个解决方案，允许客户验证服务器的配置是否符合预期，或检测是否发生了任何变化。属性： changed_parameter 保存最近更新的参数及其值（一个属性和一个值）TODO:choice类型的数据的profile捕获如何保证数据等长 capture_time 捕获时间，记录何时捕获 parameter_list 本对象管理的参数列表 parameter_list_name 参数列表名 hash_algorithm_id 摘要算法 parameter_value_digest 参数值摘要，整个parameter_list内属性的值需要先转octet-string（如果不是octet-string） parameter_values parameter_list内属性的值,一个结构体，包含A-XDR编码的每个属性值方法： add_parameter (data) 向parameter_list添加一个 delete_parameter (data) 从parameter_list删除一个s4.5.11 Sensor manager (class_id = 67, version = 0)传感器和测量值监控（除了电表之外的其他计量设备用得比较多） 传感器装置的识别 传感器的连接和密封状态 传感器的配置 监测传感器的运行情况 对处理后的结果的监控属性： serial_number 序列号，标识传感器设备 metrological_identification 计量标识符，TODO:传感器的参数信息? output_type 输出类型 adjustment_method 调整方法 sealing_method 密封（保护）方式 物理方式（铅封、密封贴纸等） 电气方式（） 软件方式（密码） raw_value 原始记录值 scaler_unit 原始记录值的单位 status 状态（失败/启用/禁用） capture_time raw_value捕获时间 raw_value_thresholds raw_value阈值 raw_value_actions 超过阈值执行的脚本，参考Register monitor类 processed_value raw_value处理后的值 processed_value_thresholds processed_value阈值 processed_value_actions 超过阈值执行的脚本(如告警位置位)方法： reset (data) 重置raw_values4.5.12 Arbitrator (class_id = 68, version = 0)仲裁者，允许根据由权限和权重组成的预先配置的规则，在多个参与者可能请求可能相互冲突的操作来控制同一资源时，执行哪些操作。 配置可能被请求的、潜在冲突的动作; 配置每个参与者请求可能操作的权限; 为每个可能的请求配置每个参与者的权重。资源的例子是供应控制开关或仪表的气体阀门。可能的动作包括断开电源、使能重新连接、重新连接电源、防止断开连接、防止重新连接。属性： actions 动作，对script table对象的引用 permissions_table 每个参与者权限，数组每个元素对应每个用户的权限，是个位串，其中的位串中每一位对应每个动作权限（与actions对应） weightings_table 每个参与者权重，和permissions_table结构顺序一样，不过把位串换成了数组，元素是long-unsigned（最好是2的幂） most_recent_requests_table 记录每个用户的最近请求，与permissions_table结构相同，位串中已执行的置位，不一定只有一个。位的清除在下一次的request_action发生 last_outcome 最近一次请求结果，标识actions中的元素的序号，只针对actions，不针对用户方法： request_action (data) 封装动作执行请求，request_actor表示请求用户，request_action_list表示请求动作列表，一次可执行多个 为什么可以一次请求多个操作：例子，可以做出一连串操作如disconecting supply同时关闭reconnect功能，同时做这两个操作可以防止其他用户修改该状态 reset (data) 重置位（权限位，权重元素，最近执行位，最近请求结果） 当权限位都是0时，request_action调用总是不会成功，因为都没权限 TODO:两张示例分析当request_action方法被actor调用时，AP执行以下活动: 它检查给定actor的permissions_table属性条目，以确定请求的动作是否允许; 它更新most_recent_requests_table属性，通过设置或清除该actor的每个动作的位串中也被允许的位(位设置);或者没有请求/不允许(位被清除);相当于request_action请求参数和permissions_table的交集，有请求且允许才置位 它为most_recent_requests_table应用weightings_table:对于most_recent_requests_table中设置的每个位，每个actor的相应权重被应用;这里应该有个临时的表保持这个信息 每个动作的权重做统计，如果一个动作中有一个唯一的最高权重值，这个值会被写入last_outcome属性并执行相应的脚本。如果没有最高的唯一权重，那么什么也不会发生。 TODO:相同权重都不执行了吗？s4.6 支付计量相关接口类Payment metering related interface classess4.6.2 Account (class_id = 111, version = 0)用于计费，每个Account可以关联数个“Credit”,“Charge” and the “Token gateway”对象比如入口消耗电网的电用一个账户Account，家里有发电出口给电网是第二个账户Account，单独计费Credit: 信用额度，比如一个对象用来做token额度，一个用于紧急额度Charge：费用统计，比如一个用于能源使用，一个用于固定收费（月费），一个用于安装费用。统计方式： 基于能量消耗量和费率的 基于时间的，如月固定费用 手续费，每次充值时收取属性： account_mode_and_status 付费模式（后付费credit和预付费prepayment）和账户 current_credit_in_use 正在使用（In use）的credit对象的引用 current_credit_status 正在使用的credit对象状态 available_credit 总可用额度，只计算正值，本对象关联的可用的（status为Selected/Invoked或In use）Credit对象中current_credit_amount总和 amount_to_clear 和available_credit类似，是负值的总和 Credit对象中的所有current_credit_amount负值（credit_status = (4) Exhausted和credit_configuration bit 2未置位） Credit对象中的credit_configuration bit 2置位的（需要偿还）的额度的差值(和preset_credit_amount)的负值（value * -1） clearance_threshold的负值（value * -1） clearance_threshold amount_to_clear的阈值 aggregated_debt 合计欠款，Charge对象的total_amount_remaining的简单合计 credit_reference_list credit对象关联列表 charge_reference_list charge对象关联列表 credit_charge_configuration 这个属性映射出哪些Charge将从哪些Credits中收取。 无条目表示无限制 Credit必须搭配一个或多个Charge采集使用，否则不会被消耗 包含credit和charge对象的引用 collection_configuration： Bit 0 允许电源断开时采集 Bit 1 允许在负载限制期间采集 Bit 2 允许在友好信用期内采集 token_gateway_configuration 此属性用于配置如何分配来自“token_gateway”的新的充值token，以便将token数量的可配置百分比分配给每个“Credit”对象。 account_activation_time 调用activate_account的时间 account_closure_time 调用close_account的时间 currency 本对象的所有方法使用的单位，可以为货币单位、时间、计量单位等 low_credit_threshold 低额度阈值，引用credit的warning_threshold属性，可以用于低额度时告警 next_credit_available_threshold 下一个优先级(如果是优先级顺序)credit对象的available_credit阈值 TODO：等Credit看完 max_provision 最大规定，当Charge为(2) payment_event_based_collection TODO：什么意思 max_provision_period 最大规定周期方法： activate_account (data) 激活账户，本对象的account_mode_and_status和account_activation_time修改 close_account (data) 本对象的account_mode_and_status和account_closure_time修改 reset_account (data) account_status为close状态下重置所有属性,为1或2时不操作s4.6.3 Credit (class_id = 112, version = 0)可用额度，激活时用于抵扣Charge属性： current_credit_amount 本对象当前可用额度 credit_type 类型 (0) token_credit 预付费方式充值的余额，一般是token方式 (1) reserved_credit 特定情况可使用的信用额度 (2) emergency_credit 紧急额度，紧急额度使用后在下次重置的时候抵扣补充 (3) time_based_credit 按照时间产生的额度 (4) consumption_based_credit 预定义信用额度 priority 激活优先级，1为最高，255最低，1-255不允许重复，0表示永不激活，可重复。优先级为0的不会出现在Account对象的credit_reference_list中 warning_threshold 警告阈值，监控current_credit_amount，与Account对象中的low_credit_theshold关联 limit 耗尽阈值，当current_credit_amount小于阈值时credit_status变为耗尽Exhausted credit_configuration 配置本对象行为 Bit0 需要视觉指示(如液晶屏) Bit1 在credit_status切换到Selected/Invoked之前需要确认（如按键） Bit2 需要偿还的信用额度 Bit3 可重置 Bit4 能够从token接收信用额度 credit_status 预付费应用使用，指示状态 Enable: 启用，但还不能使用，会在credit_reference_list中 Selectable: 可选择的，需要其他命令才能激活，还不能使用 Selected/Invoked：已选择，已激活，处于排队状态 In use：正在使用中 Exhausted：额度已耗尽 preset_credit_amount 初始额度 会累加到current_credit_amount属性的情况： credit_status转换为(2)Selected/Invoked，且credit_configuration bit 1(切换需确认)置位，且被确认 credit_status从不为(4)Exhausted状态转换为(3)In use，且credit_configuration bit 1置位未置位 当调用invoke_credit方法时，且credit_configuration bit 2置位 period 里date_time发生时，这是隐式的 如果不需要初始额度就设置为0，这种情况下可以通过token充值或调用方法方式增加current_credit_amount 如果credit_type是emergency_credit： 该值preset_credit_amount需要被使用 只在以下情况可用token充值 status为(3) In use or (4) Exhausted 且部分或全部额度被使用 且credit_configuration bit 2(需要偿还)置位 当current_credit_amount达到limit时，credit_status属性将变成（4）Exhausted。如果credit_configuration bit 2（要求偿还的信用额度）被设置，那么使用的信用额度是preset_credit_amount和current_credit_amount之间的差值（正值），通常是通过增加一个token充值或通过调用一个方法来偿还。在偿还信贷后，current_credit_amount将变0（等待下次激活把preset_credit_amount加上），当amount_to_clear=0时credit_status将变（0）Enabled（还清了）;当amount_to_clear小于0时，credit_status将变（4）Exhausted(没还清) credit_available_threshold 与“Account”对象available_credit相关联的阈值。 当“Account”对象的available_credit缩减到下一个优先级的Credit对象的credit_available_threshold时（此时该对象还是enable状态，不在credit_reference_list属性里，不计入available_credit），credit_status设置为： Selectable (1) if the credit_configuration bit 1 (Requires confirmation) is set Selected/Invoked (2) if the credit_configuration bit 1 (Requires confirmation) is cleared period 在credit_type = 3 (time_based_credit)或credit_type = 4 (consumption_based_credit)时，该属性保存将current_credit_amount自动设置为preset_credit_amount的时间。方法： update_amount (data) 调整current_credit_amount属性的值,主要是正值，负值也允许 set_amount_to_value (data) 设置current_credit_amount属性的值，返回值为配置前的值 invoke_credit (data) 将“Credit”对象的credit_status改为(2)Selected/Invoked或(1) Selectable（取决于credit_configuration bit 1）s4.6.4 Charge (class_id = 113, version = 0) total_amount_paid 本对象总金额，一般不重置 charge_type 收费类型 (0) consumption_based_collection 按量计费 (1) time_based_collection 时间计费 (2) payment_event_based_collection 支付事件计费（手续费，比如用新的token充值需要手续费） priority 优先级和Credit类相同,大于0的必须出现在“Account”对象charge_reference_list中 unit_charge_active 根据相关的“Account”实例的货币属性，以及相关的由commodities _reference结构标识的对象的scaler_unit属性，定义有效价格，即每消耗量、每时间或每收到的付款所收取的金额。 charge_per_unit_scaling_type 每单位收费缩放，包含消耗量单位缩放（10的指数，如10^3kWh为一单位），单位价格缩放（关联Account中的currency_scale属性中currency元素，10的指数） commodity_reference_type 消耗量依据，只在charge_type = (0) consumption_based_collection时生效，标识一个寄存器对象的scaler_unit（量纲）属性的引用，如电量 charge_table charge_per_unit是基于charge_per_unit_scaling_type的缩放生成的每单位价格值，index表示在按量计费模式下不同的费率模式，其他模式为0 unit_charge_passive unit_charge的备用方案，和unit_charge_active结构相同，激活时拷贝到unit_charge_active中 unit_charge_activation_time 调用激活方法的时间 period 表示Charge采集周期，仅当charge_type = (0) consumption_based_collection 或 (1) time_based_collection charge_configuration 采集方式 bit 0: 比例方式，用于charge_type = (2) payment_event_based_collection bit 1: 不间断采集方式，置位后total_amount_remaining为0时依旧采集，否则不采集 last_collection_time 上次采集时间 last_collection_amount 上次收集金额 total_amount_remaining 总剩余金额 TODO:什么意思 proportion 手续费比例，仅当charge_type = (2) payment_event_based_collection有效方法： update_unit_charge (data) 更新unit_charge_passive activate_passive_unit_charge (data) 启用备用方案unit_charge_passive collect (data) charge_type 不为 (0) consumption_based_collection时生效，采集在unit_charge_active定义的数据 update_total_amount_remaining (data) 更新total_amount_remaining set_total_amount_remaining (data) 设置total_amount_remainings4.6.5 Token gateway (class_id = 115, version = 0)属性： token 包含最近接收到的未处理的octet string或用于在history profile中捕获的token。 token_time 最近接收和处理token的时间 token_description 最近接收和处理的token的描述 token_delivery_method 最近接收的token的接收方式 远程通信 本地通信 手动输入 token_status token状态（接收，处理，校验，认证）方法： enter (data) 以octet-string格式传入tokenMax credit limit: 达到可用额度上限，不能充值tokenMax vend limit: 达到单次充值上限，不能充值tokens4.6.6 IEC 62055-41 Attributes (class_id = 116, version =0)IEC 62055-41数据元素的选择，这些元素是管理在DLMS服务器中实现的STS功能所必需的。 meter_pan MeterPrimaryAccountNumber commodity 计量用途名称，“ELECTRICITY”, “WATER”, “GAS”, or “TIME” token_carrier_types encryption_algorithm supply_group_code tariff_index key_revision_number key_type key_expiry_number no_of_kct_supported sts_certificate_nos4.7 通过本地端口和调制解调器建立数据交换的接口类Interface classes for setting up data exchange via local ports and modemss4.7.1 IEC local port setup (class_id = 19, version = 1) default_mode 定义端口上仪表使用的协议 IEC 62056-21:2002 (modes A…E) IEC 62056-46:2002/AMD1:2006 协议未指定 default_baud 起始波特率 prop_baud 建议波特率 response_time 接收到请求到发送回复的最小时间 device_addr IEC 62056-21:2002定义 pass_p1 IEC 62056-21:2002定义 pass_p2 IEC 62056-21:2002定义 pass_w5 IEC 62056-21:2002定义s4.7.2 IEC HDLC setup (class_id = 23, version = 1) comm_speed 对应端口支持的通信速度 (0) 300 baud, (1) 600 baud, (2) 1 200 baud, (3) 2 400 baud, (4) 4 800 baud, (5) 9 600 baud, (6) 19 200 baud, (7) 38 400 baud, (8) 57 600 baud, (9) 115 200 baud window_size_transmit 发送窗口大小 window_size_receive 接收窗口大小 max_info_field_length_transmit 最大发送长度 max_info_field_length_receive 最大接受长度 inter_octet_time_out 接收超时，超时未接收到新字符时视为完整报文 inactivity_time_out 超时断开 device_address 物理设备地址s4.7.3 IEC twisted pair (1) setup (class_id = 24, version = 1)允许通过IEC 62056-3-1:2021中规定的带有载波信号的中绞线对建立数据交换。可配置多个通信通道s4.7.4 Modem configuration (class_id = 27, version = 1)和模块间的数据传输配置 comm_speed 通信速度，波特率 initialization_string 初始化命令 modem_profile 海斯命令集（Hayes standard commands，AT命令）映射s4.7.5 Auto answer (class_id = 28, version = 2)自动接听 mode 自动接听工作模式 (0) 设备专用线路 (1) 共享线路管理，允许有限数量的呼叫。一旦达到了调用的数量，窗口状态就变成不活动，直到下一个开始日期，无论调用的结果是什么 (2) 共享线路管理，允许有限数量的成功呼叫。一旦达到了成功通信的数量，窗口状态就会变得不活动，直到下一个开始日期 (3) 目前没有连接调制解调器 (200…255) 制造商特定的模式 listening_window 定义通信窗口活跃(start_time)和不活跃(end_time)的时间点。start_time隐式地定义周期。 允许not specified（0xFF）表示每月每日重复 status 通信窗口状态 (0)未激活:设备将不会管理新的来电。当下一次监听窗口启动时，该状态将自动重置为Active (1)主动:设备可以接听下一个来电 (2)锁定:该值可以由设备或特定的客户端自动设置，当该客户端完成其读取会话，并希望在窗口持续时间结束前将行返回给客户。当下一次监听窗口启动时，该状态将自动重置为Active number_of_calls mode为1或2时，最大呼叫数量 number_of_rings TODO:ring是什么意思？环数？响声？ list_of_allowed_callers 一个可选的主叫号码列表，包括呼叫和SMS短信 caller_id 号码，允许通配符 call_type 定义了调用的目的，例如，它是一个标准的CSD调用还是一个唤醒呼叫/唤醒消息。 (0) = normal CSD call:modem只有在主叫号码与列表中的条目匹配时才连接。这是在测试所有其他属性的同时进行的，例如number_of_rings, listening_windows等 电路交换数据（CSD）:属于2G技术,用于传输数据，类似GPRS，但更加老旧 (1) = wake-up request:来自该主叫号码的呼叫或消息将作为唤醒请求处理。唤醒请求将立即处理，而不考虑number_of_rings和listening_window等所有其他属性(除非主叫号码也出现在普通CSD调用列表中，请参见下面)。 需要为空，否则不被是为唤醒请求 如果不为空，且包含预连接AA客户端的可用xDLMS APDU消息,则视为xDLMS服务消息而非唤醒请求，否则不做任何反应 TODO：需要补充 s4.7.6 Auto connect (class_id = 29, version = 2)自动连接，自动拨号、发送消息等属性： mode 自动连接模式，根据时间、消息类型和要使用的基础设施来控制自动连接功能。 repetitions 连接失败最大尝试次数 repetition_delay 重试间隔，秒 calling_window 活动窗口，在窗口时间内允许自动连接，看mode的配置 destination_list 包含在特定条件下必须发送消息的目的地列表(例如电话号码、电子邮件地址或它们的组合)。这里没有定义数组元素的条件及其链接方法： connect (data) 根据mode属性定义的规则向通信网络发起连接进程。s4.7.7 GPRS modem setup (class_id = 45, version = 0)GPRS参数 APN APN名称 PIN_code 个人识别码（personal identification number） quality_of_service 指定服务质量参数（QoS）。它是一个由两个元素组成的结构: 默认值 请求值 s4.7.8 GSM diagnostic (class_id: 47, version: 2)“GSM diagnostic”类的一个实例存储了分析网络运行所必需的GSM/GPRS、UMTS、CDMA或LTE网络参数。蜂窝网络在注册状态、信号质量等方面都在不断变化。监控和记录相关参数是必要的，以便获得诊断信息，以便识别网络中的通信问题。可用“Profile generic”捕获 operator 运营商名称 status modem注册状态 cs_attachment 当前电路切换（CS,Circuit Switch）状态，见电路交换 ps_status 报文分组交换技术(PS,packet switch)状态，见报文分组交换 cell_info 蜂窝网络状态 adjacent_cells 临近节点状态 capture_time 捕获时间TODO：这个类没有捕获方法？s4.7.9 LTE monitoring (class_id: 151, version = 1)允许通过处理所有必要的数据来监控LTE调制解调器 LTE_network_parameters 网络参数 LTE_quality_of_service 服务质量s4.8 通过M-Bus建立数据交换的接口类Interface classes for setting up data exchange via M-Buss4.8.2 M-Bus slave port setup (class_id = 25, version = 0)M-Bus从设备端口设置 default_baud 起始波特率 avail_baud 协商波特率 addr_state 设备是否分配了地址 bus_address 总线上当前为设备分配的地址s4.8.3 M-Bus client (class_id = 72, version = 2)每个“M-Bus client”对象控制一个M-Bus从设备。方法可以实现M-Bus从设备的安装和卸载本对象可以向从设备采集数据，也可以发送数据（配置，动作，传密钥等）属性： mbus_port_reference “M-Bus master port setup”对象引用，每个接口允许与一个或多个M-Bus从设备交换数据。 capture_definition 捕获定义，TODO:需要看引用文档 capture_period 捕获周期 &amp;gt;=1: 自动捕获，秒 0：不自动捕获，需手动触发 primary_address M-Bus从设备的主地址（primary address），范围是0-250 有该值，表示可以立即通信，不允许还未准备就绪（安装）时写该值 identification_number 标识号，第一次通信时写入 manufacturer_id EN 137577:2018 version EN 137577:2018 device_type EN 137577:2018 access_number EN 137577:2018 status EN 137577:2018 alarm EN 137577:2018 configuration EN 137577:2018 encryption_key_status 加密密钥状态，设置、传输、使用 configuration_extension EN 137577:2018 invocation_status 携带未决（pending）M-Bus方法调用的调用状态。当invocation_status表示(1)成功时，结果携带在invocation_status的return-data中。如果没有返回数据可用，则return_data octet-string为空，即长度为0。当没有挂起的调用时，数组为空。方法： slave_install (data) 安装一个未配置的从设备（primary address 是 0） 检查M-Bus地址0上是否有新设备 没找到调用失败 方法参数表示primary address，如果不带参数调用，则自动取未使用的primary address，分配并传输给从设备 slave_deinstall (data) 卸载从设备。此服务的主要目的是卸载M-Bus从设备，并让主设备为安装新设备做好准备。执行以下操作: 从设备M-Bus地址设置为0 销毁之前传输的密钥，不影响默认密钥 encryption_key_status设为(0): no encryption_key primary address设为0 全部属性设置为默认值 capture (data) 捕获，和capture_definition属性关联 reset_alarm (data) 复位M-Bus从设备告警状态 synchronize_clock (data) 同步从设备时钟 data_send (data) 向从设备发送数据 set_encryption_key (data) 设置M-Bus客户端设备的加密密钥，从设备刚安装时客户端设备有个空密钥，且加密传输禁用，可以通过配置空密钥禁用加密传输 transfer_key (data) 传输加密密钥给从设备 在加密传输启用前，加密密钥通过从设备默认密钥（密钥加密密钥，MK）加密，传输给从设备，本次传输通道不加密，之后才开始加密传输。之后可以重复调用该方法更新密钥，同样使用默认密钥加密密钥，但这次传输通道为加密的 被卸载后，从设备内密钥销毁，但默认密钥不受影响，禁用加密传输 transfer_security_information (data) 向M-Bus从设备传输安全信息(security_information) invocations_reset(data) 将M-Bus从设备的方法调用重置为初始状态s4.8.4 Wireless Mode Q channel (class_id = 73, version = 1)使用模式Q接口进行通信的操作参数。参见EN 13757-5:2015。s4.8.5 M-Bus master port setup (class_id = 74, version = 0)如果设备作为M-bus master，该IC的实例定义了使用EN 13757-2接口进行通信的操作参数。s4.8.6 DLMS server M-Bus port setup (class_id = 76, version = 0)在M-Bus从设备托管的DLMS服务器中使用，使用DLMS/COSEM有线或无线M-Bus (wM-Bus)通信配置文件 M-Bus_profile_selection 引用M-Bus通信端口设置对象,“M-Bus slave port setup” object (class_id = 25)或 “Wireless Mode Q channel” object (class_id = 73). M-Bus_port_communication_state M-Bus node通信状态 (0)无接入:仪表无接入窗口(单向仪表)， (1)暂无接入:仪表一般支持双向接入，但本次传输后没有接入窗口(如为了保持占空比限制或限制能耗，暂无接入)， (2)有限的访问:仪表仅在传输后提供一个短的访问窗口(如电池供电仪表)， (3)无限接入:至少在下次传输(如市电供电设备)之前，仪表提供无限接入。 (4)此属性仅在wM-Bus中相关。 TODO:node是什么意思？ M-Bus_Data_Header_Type 报文头类型，派生自当前通信的CITL值。 primary_address EN 137577:2018 identification_number EN 137577:2018 manufacturer_id EN 137577:2018 version EN 137577:2018 device_type EN 137577:2018 max_pdu_size M-Bus低层pdu长度上限，对于长消息，可以使用DLMS/COSEM应用层提供的块传输或传输层提供的分段传输，也可以同时使用这两种机制。 listening_window 此属性仅在wM-Bus中相关，定义点对点通信窗口活动(start_time)和不活动(end_time)的时间点。start_time隐式地定义周期s4.8.7 M-Bus diagnostic (class_id = 77, version = 0)包含与M-Bus网络运行相关的信息，如当前信号强度、通道标识符、到M-Bus网络的链路状态以及与帧交换、传输和帧接收质量相关的计数器。 received-signal-strength 此属性仅与无线双向M-Bus（wM-Bus,wireless M-Bus）通信相关。 当使用wM-Bus配置文件时，这个属性保存了接收到的最后一个wM-Bus帧的信号强度值，用dBm表示。 channel_Id 此属性仅与wM-Bus通信相关。当使用wM-Bus配置文件时，此属性保存当前使用的通道的标识。缺省值为0。 link_status 此属性仅与wM-Bus通信相关。当使用wM-Bus配置文件时，此属性保存到M-Bus网络的链接的当前状态 (0)缺省值(未接收到数据) (1)链路正常运行 (2)链路暂时中断 broadcast_frames_counter 持有广播帧计数器的值，时间戳为接收到的最后一帧，并由客户端标识符区分 transmissions_counter 统计相关M-Bus端口传输的帧数。到达最大值归0。 FCS_OK_frames_counter 以正确的校验和计算接收到的帧数。到达最大值归0。 FCS_NOK_frames_counter 统计接收到的校验和(checksum)错误的帧数 capture_time 保存属性received-signal-strength、link_status、transmissions_counter、FCS_OK_frames_counter或FCS_NOK_frames_counter的值最近变化的时间戳。方法： reset (data) 清除所有计数器(counters)，received_signal_strength, link_status和capture_times4.9 用于在Internet上建立数据交换的接口类Interface classes for setting up data exchange over the Internets4.9.1 TCP-UDP setup (class_id = 41, version = 0)允许对基于TCP-UDP/IP的通信配置文件的TCP或UDP传输层的设置建模或基于DLMS/COSEM CoAP的DLMS/COSEM CoAP传输层的UDP子层的设置建模在基于TCP-UDP/IP的通信配置文件中，承载一个或多个COSEM客户端应用程序进程的物理设备和承载一个或多个COSEM服务器ap的物理设备之间的所有AAs都依赖于单个TCP或UDP连接。TCP或UDP实体封装在基于COSEM TCP-UDP的传输层中。在物理设备中，每个AP(客户端AP或服务器逻辑设备)都绑定到一个包装器端口(WPort)一个基于COSEM TCP或UDP的传输层可能能够支持一个物理设备和多个承载COSEM ap的对等物理设备之间的多个TCP或UDP连接。一个DLMS/COSEM CoAP传输层可以支持多个UDP连接，用于一个物理设备和一个或多个承载COSEM ap的对等物理设备之间的通信。当一个COSEM物理设备支持各种数据链路层时——例如以太网和PPP——每一个都需要一个TCP-UDP setup对象的实例。 TCP-UDP_port 监听端口号，4059 TCP/UDP IP_reference 引用“IP setup”对象 MSS 在最大段大小(MSS，Maximum Segment Size)选项的帮助下，TCP实体可以向它的对端指示最大的接收段大小。注意: 这个选项只能在初始连接请求中发送(即发送SYN控制位的分段); 如果这个选项不存在，通常MSS被认为是它的默认值，576; MSS是不可协商的;它的值由这个属性指示。 nb_of_sim_conn 基于COSEM TCP-UDP的传输层能够支持的最大同时连接数(maximum number of simultaneous connections) inactivity_time_out 接收超时释放，定义时间，以秒表示，如果没有从COSEM客户端收到帧，不活动的TCP连接将被中止。0表示永不中止注意，所有与管理非活动超时函数相关的操作，如测量非活动时间、在超时结束时终止TCP连接等，都在TCP-UDP层实现中进行管理。s4.9.2 IPv4 setup (class_id = 42, version = 0)IPv4信息，每个网口对应一个属性： DL_reference 引用数据链路层(如以太网或PPP)设置对象 IP_address 静态或动态的ip地址 IPv4地址192.168.0.1(点分十进制)对应C0A80001 (hexa)，得到3232235521 (double-long-unsigned)。 multicast_IP_address 组播地址，该数组中的IP地址应属于组播组地址范围(“D类”地址，包括224.0.0.0 - 239.255.255.255范围内的IP地址)。当设备接收到IP数据报时，如果目的IP地址字段属于数组中IP地址之一，它应该认为该数据报是给它自己的。 IP_options 包含支持所选IP选项的必要参数——例如数据报时间戳或安全服务(IPSec)。 标准的IP option RFC 791中的部分 Security: IP_Option_Type = 0x82, IP_Option_Length = 11 Loose Source and Record Route: IP_Option_Type = 0x83 宽松的源站选路（为数据报指定一系列必须经过的IP地址） Strict Source and Record Route: IP_Option_Type = 0x89 严格的源站选路选项。与宽松的源站选路类似，但是要求只能经过指定的这些地址，不能经过其他的地址。 Record Route: IP_Option_Type = 0x07 记录路径（让每个路由器都记下它的IP地址） Internet Timestamp: IP_Option_Type = 0x44 时间戳选项 subnet_mask 子网掩码 gateway_IP_address 网关IP use_DHCP_flag 是否启用dhcp，启用后IP_address, subnet_mask and gateway_IP_address变为动态 primary_DNS_address 主DNS secondary_DNS_address 备用DNS方法： add_mc_IP_address (data) 向multicast_IP_address数组添加一个新的ip delete_mc_IP_address (data) 从multicast_IP_address数组删除一个ip get_nbof_mc_IP_addresses (data) 获取multicast_IP_address数组元素数量s4.9.3 IPv6 setup (class_id = 48, version = 0)属性： DL_reference 同IPv4 address_config_mode IPv6地址配置模式 (0) Auto-configuration (default) (1) DHCPv6 (2) Manual (3) ND (Neighbour Discovery) unicast_IPv6_addresses 单播地址(唯一本地单播，链接本地单播 和/或 全球单播地址)，是数组 multicast_IPv6_addresses 组播地址, 数组 gateway_IPv6_addresses 网关IP，数组 primary_DNS_address 同IPv4 secondary_DNS_address 同IPv4 traffic_class 包含IPv6头的traffic class元素。RFC 2474:1998第3条规定，使用DSCP (Differentiated Services Codepoint)对报文进行分类，根据类型的不同QoS可以指定不同动作，如有些需要低延迟，有些需要大流量。 neighbor_discovery_setup 包含用于支持IPv6邻居发现协议NDP(rfc4861)的路由器和主机的配置。 RS_max_retry 给出一个节点在没有收到预期的路由器通告时执行的最大路由器请求重试次数。 RS_retry_wait_time 给出两个连续路由器请求重试之间的等待时间(以毫秒为单位)。 RA_send_period 给出路由器通告传输的周期，单位为秒 方法： add_IPv6_address (data) 添加IPv6地址，参数包括类型：单播、组播、网关 remove_IPv6_address (data) 移除IPv6地址，参数包括类型：单播、组播、网关s4.9.4 MAC address setup (class_id = 43, version = 0)从原来的“Ethernet setup”更名而来，说明这个类原来仅用于以太网。现在可以用于更广泛的用途，如PLC网络的MAC保存MAC地址属性： MAC_address MAC地址s4.9.5 PPP setup (class_id = 44, version = 0)通过处理与给定物理设备相关的PPP设置的所有信息，以及与使用这些设置的低层连接，该IC允许使用PPP协议模拟接口的设置。一个物理设备的每个网络接口都应该有一个该IC的实例。 PHY_reference 通过它的logical_name引用另一个对象。引用的对象包含具体物理层接口的信息，支持PPP层。 TODO:引用什么对象？ LCP_options LCP配置参数。 Maximum-Receive-Unit (MRU), LCP_Option_Type = 1. See RFC 1661. 最大接收单元。用于通知peer可以接收更大的包（如对方发的包比较小，可以告诉他自己最大能接收多少），也能通知peer发更小的包，太大处理不了 Async-Control-Character-Map (ACCM), LCP_Option_Type = 2. See RFC 1662. 异步控制字符映像 Authentication-Protocol, LCP_Option_Type = 3. See RFC 1661. 认证协议，PAP、CHAP、EAP。 Magic-Number, LCP_Option_Type = 5. See RFC 1661. 该配置选项提供了一种检测回环链路和其他数据链路层异常的方法; Protocol-Field-Compression (PFC), LCP_Option_Type = 7. See RFC 1661. 协议域压缩，这个配置选项提供了一种协商PPP协议字段压缩的方法 Address-and-Control-Field-Compression (ACFC), LCP_Option_Type = 8. See RFC 1661. 地址和控制字段压缩，这个配置选项提供了一种方法来协商数据链路层地址和控制字段的压缩; FCS-Alternatives, LCP_Option_Type = 9. See RFC 1570. FCS替换，可以指定对等端发送的另一种FCS格式，或者协商完全放弃FCS Callback, LCP_Option_Type = 13. See RFC 1570. 回拨，是指当通信一方拨号到另一方后，由另一方断开拨号连接并进行反向的拨号。更加安全，另一方可以在回叫前验证对方是否合法，如查数据库或查对方号码 IPCP_options 包含网际协议控制协议（IPCP）(PPP的网络控制协议模块)的必要参数，允许协商理想的互联网协议参数。有关IPCP的详情，请参阅RFC 1332。 PPP_authentication PPP认证参数，PAP、CHAP、EAP，见本文 PAP: 明文密码传输，客户端发送明文用户名密码 CHAP：服务端发个OTP(相当于盐)，客户端用OTP和密码计算哈希值，把明文的用户名和哈希值发送服务端，服务端用相同的OTP和密码计算哈希值，并比对。过程中密码没有明文传输 EAP: 服务器向客户端发送身份验证请求，包括它应使用的 40 种身份验证方法中的哪一种。客户端根据该方法加密用户名密码，发送给服务端 s4.9.6 SMTP setup (class_id = 46, version = 0)允许使用简单邮件传输协议(Simple Mail Transfer Protocol，SMTP)协议与远程服务器建立数据交换 server_port 服务器端口，25/TCP,UDP user_name 用户名，登录用 login_password 密码，登陆用 server_address 服务器ip sender_address 发送者ip地址s4.9.7 NTP setup (class_id = 100, version = 0)NTP协议时间同步属性： activated NTP时间同步是否激活 server_address NTP服务器地址 server_port 端口 authentication_method 认证方式 authentication_keys 认证密钥数组 client_key 客户端密钥，NTP服务端公钥，IFF方式方法： synchronize (data) 同步时间 add_authentication_key (data) 添加authentication_key delete_authentication_key (data) 删除authentication_keys4.9.8 CoAP setup (class_id = 152 version = 0)属性： UDP_reference 指向TCP-UDP setup对象,和UDP层相关 ack_timeout confirmable消息的最小初始ACK超时时间 ack_random_factor 初始ACK超时时间生成随机因子，初始ACK超时时间在ack_timeout - ack_timeout x ack_random_factor x 0.01之间 max_retransmit confirmable消息的最大重传次数 nstart 同时未完成的下列形式的CoAP请求消息的数量:未收到CoAP确认的CON CoAP消息或未收到CoAP响应消息的NON CoAP消息。 delay_ack_timeout CoAP消息传递层等待应用层返回响应的时间(单位为ms)，然后它将返回确认以防止来自对等体的虚假重传。 exponential_back_off 重发延迟因子 n表示第几次重发 retransmission_delay = initial_ack_timeout x (exponential_back_off x 0.01) ^ (n -1) probing_rate 定义一个端点在发送到另一个没有响应的端点时不应超过的平均数据速率(字节/秒)。 CoAP_uri_path uri-path transport_mode 传输方式 仅可靠 仅不可靠 同时支持 version DLMS/COSEM CoAP wrapper的版本 token_length token长度（CoAP协议中的token）s4.9.9 CoAP diagnostic (class_id = 153, version = 0)CoAP诊断属性： messages_counter 报文计数 request_response_counter CoAP请求响应的报文计数 coap_bt_counter CoAP Block-Wise transfer layer(块传输)，发起总数，完成总数，超时总数 capture_time 捕获时间（最近更新本对象相关属性的时间）方法： reset (data) 全部清空s6.2.5 Clock objects (class_id = 8)TODO:对图的疑问。表内时间实际上只有一份，通过D的不同区分不同的表现形式。而且可以用不同的类表示。说明obis和class间没有太大的联系s6.2.17 Payment metering related objectsC决定了大的功能模块，D区分这个功能模块需要用到的数据，可以是隶属于不同class的。如图，C=19表示payment相关功能，需要用到来自111、112、113、115、01、116类的数据" }, { "title": "C++实现的DAO(数据访问对象模式)", "url": "/posts/cpp-dao/", "categories": "技术", "tags": "C++, DAO, database", "date": "2022-03-08 09:00:00 +0800", "snippet": "本文将会介绍如何使用 C++实现设计模式中的 DAO(数据访问对象模式)DAO 介绍什么是 DAO在计算机软件中，数据访问对象（data access object，DAO）是为某种类型的数据库或其他持久性机制提供一个抽象接口的对象。通过映射应用程序对持久层的调用，DAO 提供一些特定的数据操作，而无需暴露数据库细节。这种隔离支持单一功能原则。数据访问对象模式（Data Access Object Pattern）或 DAO 模式用于把低级的数据访问 API 或操作从高级的业务服务中分离出来。以下是数据访问对象模式的参与者: 数据访问对象接口（Data Access Object Interface） - 该接口定义了在一个模型对象上要执行的标准操作。 数据访问对象实体类（Data Access Object concrete class） - 该类实现了上述的接口。该类负责从数据源获取数据，数据源可以是数据库，也可以是 xml，或者是其他的存储机制。 模型对象/数值对象（Model Object/Value Object, VO） - 该对象是简单的 POJO，包含了 get/set 方法来存储通过使用 DAO 类检索到的数据。DAO 的优势 数据存储逻辑的分离：一方面避免业务代码中混杂的数据库操作代码，另一方面，数据访问接口与数据访问实现相分离，这样精通数据库的人可以根据接口专注于数据库访问的最优化实现，而精通业务的人可以专注于业务逻辑编码。 数据访问底层实现的分离：DAO 模式将数据访问分为抽象层和实现层，分离了数据使用和数据访问的底层实现细节。这样可以在保持上层结构不变的情况下，通过更改底层实现来修改数据访问的机制，比如只要通过修改数据访问层实现，我们就可以部署在不同数据库平台上。 资源管理和调度的分离：数据访问逻辑从业务逻辑中脱离开来，使数据访问层实现统一的资源调度，通过数据库连接池和各种缓存机制的使用，可以保持上层系统不变的情况下来提高系统性能。 数据抽象：通过对底层数据的封装，开发人员可以使用面向对象思想对数据进行操作。比如通过调用方法获取数据比通过 SQL 语句访问数据库获取数据，在代码上更易于理解，清晰，对日后维护带来便利。 DAO 的劣势 抽象泄漏：尽管抽象层可以屏蔽底层细节，让开发者可以专注于高层次的领域相关的知识与技能，但一旦底层出了问题，开发者不可避免的需要了解底层细节来帮助分析问题。所以抽象机制虽然节省了工作的时间，不过学习的时间是省不掉的。 代码重复：将 DAO 作为常规对象的抽象会隐藏每个数据库访问的高成本，并且可能强迫开发人员触发多个数据库查询来检索普通 SQL 查询中一次就可取回的信息。如果一个应用程序需要多个 DAO，人们可能发现自己对每个 DAO 重复基本上相同的创建、读取、更新和删除代码 抽象反转(Abstraction inversion)：抽象反转是一种反模式，当构造的用户需要在其中实现但未由其接口公开的函数时， 会产生这种反模式。结果是用户在接口方面重新实现所需的功能，而接口又使用相同的功能的内部实现。这可能会导致在较高级别的特征中实现较低级别的特征 在什么情况下使用 DAODAO 最适用于单系统应用程序或小范围本地分布使用DAO 与当前业务的契合度集中器作为采集设备，需要频繁与数据库进行交互，用于存储和读取数据、参数等，当前集中器业务代码中包含大量直接调用 sqlite3 api 访问数据库的操作。 一方面让代码的维护更加复杂，每一位开发者都不得不具备专业的数据库相关知识，浪费大量时间精力 另一方面缺乏错误处理机制让数据库写入冲突更加频繁，程序稳定性大大降低而使用 DAO 设计模式可以解决上述两个问题，让代码维护分工更加明确，专人专职，错误处理绝大部分由底层完成，降低写入冲突集中器程序使用C++作为主要开发语言，作为支持面向对象的语言可以实现DAO。DAO 的实现2.0 平台将数据访问操作重新设计，使用设计模式中的 DAO(data access object)设计模式，为每个数据项设计访问接口，将原数据库访问操作封装为 DAO 数据访问层和服务接口，其他业务类需要获取或写入数据时直接调用服务接口，传递访问参数即可。数据库操作对应用程序是不可见的，业务层无需关心数据如何存储，存储在什么地方。Service 服务层实现了对于业务层开放的统一操作接口，对于一个接口的调用服务层会将多个原子性的 DAO 操作组合成一个完整的业务逻辑。服务层同时也实现了对数据记录的缓存，对于读取操作直接访问缓存，无需访问数据库，降低了 IO 操作，提升数据访问速度。DAO 层实现了对数据层访问的封装，包括执行增、删、改、查等原子性操作，数据层可以使用 sqlite3 或其他数据库，不会对服务层和业务层产生影响，使用 DAO 层可以使后续对数据库结构的修改和扩展更为便捷。同时可以单独对 DAO 层进行优化用于提升访问性能，提升可维护性。封装库同时完成数据库访问的冲突管理及持久化管理，避免了因多线程同时访问数据库产生的冲突，分层设计提高了程序的可扩展性，同时降低直接访问数据库的频率。整体提高软件稳定性、可维护性、可扩展性和可移植性。设计细节scale 2title config类型数据管理接口类图note left of ConfItem 实体类(VO)： 映射数据库记录end noteclass ConfItem { -int id -string key -string value -string remark +ConfItem() +ConfItem(Json::Value item_json) +ConfItem(int id, string key, string value, string remark) +~ConfItem() +{static} int json2item(Json::Value item_json, ConfItem* conf_item) +{static} int item2json(ConfItem conf_item, Json::Value* item_json) +int getValueInt() +string getValueString() +string getKey() +string getRemark() +int getId() +int setValueInt(int value_int) +int setValueString(string value_string) +int setKey(string key) +int setRemark(string remark) +int setId(int id)}note bottom of DBUtils 数据库底层接口类(单例模式)： 操作sqlite3数据库的接口， 同原DB和DB_Data类end noteclass DBUtils { +{static} DBUtils* instance() +int executeSQL(string sql) +SQLQuery execQuery(const string &amp;amp;szSQL) +Binder buildBinder(const string &amp;amp;szSQL) -sqlite3_stmt* compile(const char* szSQL) -void checkDB(int iRet)}note top of ConfBaseDAO DAO接口类(DAO) 用于定义数据库的原子化操作,增删查改：end notenote left of ConfBaseDAO::findByKey ConfItem中的key也为唯一键， 可以作为查询依据end noteabstract class ConfBaseDAO{ +{abstract} int add(ConfItem&amp;amp; conf_item) +{abstract} int update(ConfItem&amp;amp; conf_item) +{abstract} int updateValue(ConfItem&amp;amp; conf_item) +{abstract} int del(int id) +{abstract} int findById(ConfItem&amp;amp; conf_item) +{abstract} int findByKey(ConfItem&amp;amp; conf_item) +{abstract} int findAll(std::vector&amp;lt;ConfItem&amp;gt;&amp;amp; conf_item_list) +{abstract} int getAllConunt()}note top of ConfBaseDAOlmpl DAO基于sqlite3实现类(Impl)： 针对不同数据库工具给出DAO接口定义方法 的具体实现，此处为sqlite3实现 初始化时配置对应的数据库连接和表名， 可以使用事务保证原子性end noteclass ConfBaseDAOlmpl { DBUtils* db; std::string table_name;}note top of ConfBaseService 服务类(service)： DAO的封装， 扩展业务实现， 便于业务处理函数调用end notenote left of ConfBaseService::key_filter_set get自动模式下判断是否从数据库中获取end notenote left of ConfBaseService::conf_base_dao 指向其实现类ConfBaseDAOlmpl的对象end notenote left of ConfBaseService::jsonApi jsonApi接口(待实现) 可以通过json方式操作数据库end notenote left of ConfBaseService::updateValueByKey 通过key更新valueend notenote left of ConfBaseService::getValueByKey 通过key获取value, mode表示从数据库获取还是内存获取end noteclass ConfBaseService { #std::set&amp;lt;std::string&amp;gt; key_filter_set #std::map&amp;lt;std::string, ConfItem&amp;gt; conf_item_list #ConfBaseDAO* conf_base_dao #int getConfItemByKey(ConfItem&amp;amp; conf_item, const std::string&amp;amp; key, int getmode) +ConfBaseService() +ConfBaseService(DB* db, const std::string&amp;amp; table_name) +ConfBaseService(const std::string&amp;amp; table_name) +~ConfBaseService() +int jsonApi(Json::Value* root) +int add(const std::string&amp;amp; key, const std::string&amp;amp; value, const std::string&amp;amp; remark) +int updateValueByKey(const std::string&amp;amp; value,const std::string&amp;amp; key) +int updateValueByKey(int value,const std::string&amp;amp; key) +int getValueByKey(std::string&amp;amp; value, const std::string&amp;amp; key, int getmode = 0) +int getValueByKey(int&amp;amp; value, const std::string&amp;amp; key, int getmode = 0) +int deleteByKey(const std::string&amp;amp; key) +int syncAll() +int getSize()}note top of DCConfService dc_conf表的服务类(单例模式)： 由于数据库中部分表使用相同的结构， 可以让这些服务类继承同一个ConfBaseServiceend noteclass DCConfService { +{static} DCConfService* instance() +DCConfService() +~DCConfService()}note top of DCConfMainService dc_conf_main表的服务类：end noteclass DCConfMainService { +{static} DCConfMainService* instance() +DCConfMainService() +~DCConfMainService()}note top of DCStatusService dc_status表的服务类：end noteclass DCStatusService { +{static} DCStatusService* instance() +DCStatusService() +~DCStatusService()}ConfBaseDAOlmpl ..|&amp;gt; ConfBaseDAO :&quot;实现(多态)&quot;ConfBaseDAOlmpl --&amp;gt; DBUtils :&quot;关联&quot;ConfBaseDAO ..&amp;gt; ConfItem :&quot;依赖&quot;ConfBaseService --&amp;gt; ConfBaseDAO :&quot;关联&quot;ConfBaseService --&amp;gt; ConfItem :&quot;关联&quot;DCConfService --|&amp;gt; ConfBaseService :&quot;继承&quot;DCConfMainService --|&amp;gt; ConfBaseService :&quot;继承&quot;DCStatusService --|&amp;gt; ConfBaseService :&quot;继承&quot;部分代码示例数值对象,VO/** * @file conf_item.h * @author huangjinkai * @brief 声明ConfItem实体类（VO），映射数据库记录 * @version 1.0 * @date 2021-12-03 * * @copyright Copyright (c) 2021 * */#ifndef _CONF_ITEM_H#define _CONF_ITEM_H#include &amp;lt;string&amp;gt;#include &quot;json/json.h&quot;/** * @brief ConfItem实体类（VO），映射数据库记录 * */class ConfItem{private: /// 对应键id，主键 int id; /// 对应键key，唯一键 std::string key; /// 对应键value std::string value; /// 对应键remark std::string remark;public: /** * @brief 默认构造函数，为成员变量赋默认初值 * */ ConfItem(); /** * @brief 构造函数，使用json数据为成员变量赋初值 * * @param item_json */ ConfItem(Json::Value item_json); /** * @brief 构造函数，使用参数为成员变量赋初值 * * @param id * @param key * @param value * @param remark */ ConfItem(int id, std::string key, std::string value, std::string remark); /** * @brief 析构函数 * */ ~ConfItem(); /** * @brief json对象转ConfItem对象 * * @param item_json * @param conf_item * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ static int json2item(Json::Value item_json, ConfItem&amp;amp; conf_item); /** * @brief ConfItem对象转json对象 * * @param conf_item * @param item_json * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ static int item2json(ConfItem conf_item, Json::Value&amp;amp; item_json); /** * @brief Get the Value Int object * * @return int */ int getValueInt(); /** * @brief Get the Value String object * * @return std::string */ std::string getValueString(); /** * @brief Get the Key object * * @return std::string key */ std::string getKey(); /** * @brief Get the Remark object * * @return std::string remark */ std::string getRemark(); /** * @brief Get the Id object * * @return int id */ int getId(); /** * @brief Set the Value Int object * * @param value_int * @return int */ int setValueInt(int value_int); /** * @brief Set the Value String object * * @param value_string * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ int setValueString(std::string value_string); /** * @brief Set the Key object * * @param key * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ int setKey(std::string key); /** * @brief Set the Remark object * * @param remark * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ int setRemark(std::string remark); /** * @brief Set the Id object * * @param id * @return int 是否成功 * @retval 0 执行成功 * @retval other 执行失败 */ int setId(int id);};#endif // _CONF_ITEM_HDAO接口/** * @file conf_base_dao.h * @author huangjinkai * @brief * @version 1.0 * @date 2021-12-03 * * @copyright Copyright (c) 2021 * */#ifndef _CONF_BASE_DAO_H#define _CONF_BASE_DAO_H#include &quot;database/conf_item.h&quot;#include &quot;database/database.h&quot;#include &amp;lt;vector&amp;gt;/** * @brief DAO接口类 * 虚类，用于定义数据库的原子化操作增删改查 * */class ConfBaseDAO{protected:public: /** * @brief Construct a new ConfBaseDAO object * */ ConfBaseDAO(){}; /** * @brief Destroy the ConfBaseDAO object * */ virtual ~ConfBaseDAO(){}; /** * @brief 插入一条记录 * * @param conf_item ConfItem对象 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int add(ConfItem&amp;amp; conf_item){}; /** * @brief 通过id更新一条记录 * * @param conf_item ConfItem对象 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int update(ConfItem&amp;amp; conf_item){}; /** * @brief 通过key更新一条记录的value值 * * @param conf_item ConfItem对象 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int updateValue(ConfItem&amp;amp; conf_item){}; /** * @brief 通过id删除一条记录 * * @param id 记录的id键值 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int del(int id){}; /** * @brief 通过id查找一条记录 * * @param conf_item ConfItem对象，作为输入参数与返回值，包含待查找的id * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int findById(ConfItem&amp;amp; conf_item){}; /** * @brief 通过key查找一条记录 * * @param conf_item ConfItem对象，作为输入参数与返回值，包含待查找的key * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int findByKey(ConfItem&amp;amp; conf_item){}; /** * @brief 查找所有的记录 * * @param conf_item_list ConfItem数组，作为返回值 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ virtual int findAll(std::vector&amp;lt;ConfItem&amp;gt;&amp;amp; conf_item_list){}; /** * @brief 返回记录总数 * * @return int 记录总数 */ virtual int getAllConunt(){}; /** * @brief 清空所有记录 * * @return int * @retval 0 成功 * @retval -1 失败 */ virtual int clear(){};};#endif //_CONF_BASE_DAO_HDAO实现, impl/** * @file conf_base_dao_impl.h * @author huangjinkai * @brief * @version 1.0 * @date 2021-12-03 * * @copyright Copyright (c) 2021 * */#ifndef _CONF_BASE_DAO_IMPL_H#define _CONF_BASE_DAO_IMPL_H#include &quot;database/conf_base_dao.h&quot;#include &amp;lt;vector&amp;gt;/** * @brief DAO 实现类(Impl) * 继承自ConfBaseDAO，是对ConfBaseDAO的多态实现。针对不同数据库工具给出DAO接口定义方法的具体实现，此处为sqlite3实现 * 初始化时配置对应的数据库连接和表名，可以使用事务保证原子性 * */class ConfBaseDAOImpl: public ConfBaseDAO{private: /// 数据库访问工具实例指针 DB* db; /// 数据表名 std::string table_name;public: /** * @brief Construct a new ConfBaseDAOImpl object * */ ConfBaseDAOImpl(); /** * @brief Construct a new ConfBaseDAOImpl object * * @param db * @param table_name */ ConfBaseDAOImpl(DB *db, std::string table_name); /** * @brief Destroy the ConfBaseDAOImpl object * */ ~ConfBaseDAOImpl(); int add(ConfItem&amp;amp; conf_item); int update(ConfItem&amp;amp; conf_item); int updateValue(ConfItem&amp;amp; conf_item); int del(int id); int findById(ConfItem&amp;amp; conf_item); int findByKey(ConfItem&amp;amp; conf_item); int findAll(std::vector&amp;lt;ConfItem&amp;gt;&amp;amp; conf_item_list); int getAllConunt(); int clear();};#endif //_CONF_BASE_DAO_IMPL_H服务类，service/** * @file conf_base_service.h * @author huangjinkai * @brief * @version 1.0 * @date 2021-12-03 * * @copyright Copyright (c) 2021 * */#ifndef _CONF_BASE_SERVICE_H#define _CONF_BASE_SERVICE_H#include &quot;conf_base_dao.h&quot;#include &quot;conf_base_dao_impl.h&quot;#include &amp;lt;map&amp;gt;#include &amp;lt;set&amp;gt;class ConfBaseService{protected: /// key过滤器，get自动模式下判断是否从数据库中获取记录 std::set&amp;lt;std::string&amp;gt; key_filter_set; /// ConfItem对象和key的map映射表，在内存中保存数据 std::map&amp;lt;std::string, ConfItem&amp;gt; conf_item_list; /// ConfBaseDAO实例对象指针，需要在构造时赋值 ConfBaseDAO* conf_base_dao; /// conf_item_list的互斥锁 pthread_mutex_t conf_item_list_lock; /** * @brief 通过key获取ConfItem对象 * * @param[out] conf_item * @param[in] key * @param[in] getmode 获取模式，0：自动，1：从DAO获取，2：从conf_item_list获取 * @return int 是否成功 * @retval 0 成功 * @retval -1 不支持的模式getmode * @retval -2 未在conf_item_list中找到 * @retval other 其他错误 */ int getConfItemByKey(ConfItem&amp;amp; conf_item, const std::string&amp;amp; key, int getmode);public: /** * @brief Construct a new ConfBaseService object * */ ConfBaseService(); /** * @brief Construct a new ConfBaseService object * * @param[in] db 数据库访问工具实例 * @param[in] table_name 数据表名 */ ConfBaseService(DB* db, const std::string&amp;amp; table_name); /** * @brief Construct a new ConfBaseService object * * @param[in] table_name 数据表名 */ ConfBaseService(const std::string&amp;amp; table_name); /** * @brief Destroy the ConfBaseService object * */ ~ConfBaseService(); /** * @brief json访问接口 * * @todo 待实现 * @param root json对象 * @return int */ int jsonApi(Json::Value* root); /** * @brief 添加记录 * * @param[in] key 参数名 * @param[in] value 参数值 * @param[in] remark 参数说明 * @return int 是否成功 * @retval 0 成功 * @retval other 失败 */ int add(const std::string&amp;amp; key, const std::string&amp;amp; value, const std::string&amp;amp; remark); /** * @brief 添加记录 * * @param[in] key 参数名 * @param[in] value 参数值 * @param[in] remark 参数说明 * @return int 是否成功 * @retval 0 成功 * @retval other 失败 */ int add(const std::string&amp;amp; key, const int value, const std::string&amp;amp; remark); /** * @brief 通过key更新string类型value * * @param[in] value 参数值 * @param[in] key 参数名 * @return int 是否成功 * @retval 0 成功 * @retval other 失败 */ int updateValueByKey(const std::string&amp;amp; value,const std::string&amp;amp; key); /** * @brief 通过参数名更新int类型参数值 * * @param[in] value 参数值 * @param[in] key 参数名 * @return int 是否成功 * @retval 0 成功 * @retval other 失败 */ int updateValueByKey(int value,const std::string&amp;amp; key); /** * @brief 通过参数名获取string类型参数值 * * @param[out] value 参数值 * @param[in] key 参数名 * @param[in] getmode 获取模式，0：自动，1：从DAO获取，2：从conf_item_list获取 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ int getValueByKey(std::string &amp;amp;value, const std::string &amp;amp;key, int getmode = 0); /** * @brief 通过参数名获取int类型参数值 * * @param[out] value 参数值 * @param[in] key 参数名 * @param[in] getmode 获取模式，0：自动，1：从DAO获取，2：从conf_item_list获取 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ int getValueByKey(int &amp;amp;value, const std::string &amp;amp;key, int getmode = 0); /** * @brief 通过key删除记录 * * @param[in] key 参数名 * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ int deleteByKey(const std::string&amp;amp; key); /** * @brief 同步记录到conf_item_list中 * * @return int 是否成功 * @retval 0 成功 * @retval -1 失败 */ int syncAll(); /** * @brief 获取总记录数量 * * @return int 总记录数量 */ int getSize(); /** * @brief 删除所有记录 * * @return int 是否成功 * @retval 0 成功 * @retval other 失败 */ int clearAll();};#endif //_CONF_BASE_SERVICE_H派生实例，单例模式/** * @file dcconf_service.h * @author huangjinkai * @brief * @version 1.0 * @date 2021-12-03 * * @copyright Copyright (c) 2021 * */#ifndef _DCCONF_SERVICE_H#define _DCCONF_SERVICE_H#include &quot;database/conf_base_service.h&quot;class DCConfService: public ConfBaseService{public: /** * @brief Construct a new DCConfService object * */ DCConfService(); /** * @brief Destroy the DCConfService object * */ ~DCConfService(); /** * @brief 获取DCConfService实例 * * @return DCConfService* DCConfService实例指针 */ static DCConfService* instance();};class DCConfMainService: public ConfBaseService{public: /** * @brief Construct a new DCConfMainService object * */ DCConfMainService(); /** * @brief Destroy the DCConfMainService object * */ ~DCConfMainService(); /** * @brief 获取DCConfMainService实例 * * @return DCConfMainService* DCConfMainService实例指针 */ static DCConfMainService* instance();};class DCStatusService: public ConfBaseService{public: /** * @brief Construct a new DCStatusService object * */ DCStatusService(); /** * @brief Destroy the DCStatusService object * */ ~DCStatusService(); /** * @brief 获取DCStatusService实例 * * @return DCStatusService* DCStatusService实例指针 */ static DCStatusService* instance();};#endif //_DCCONF_SERVICE_H参考 数据访问对象 - 维基百科，自由的百科全书 数据访问对象模式 - 菜鸟教程" }, { "title": "容器,边缘计算与云原生", "url": "/posts/containers-edge-cloudnative/", "categories": "技术", "tags": "containers, edge computing, cloud native, 容器, 边缘计算", "date": "2021-11-02 09:00:00 +0800", "snippet": "本文将会介绍现代容器技术的原理，以及容器如何与边缘计算和云原生结合起来，实现基于容器技术的物联网框架容器定义操作系统层虚拟化（Operating system–level virtualization），亦称容器化（Containerization）,是一种虚拟化技术，这种技术将操作系统内核虚拟化，可以让我们在一个资源隔离的进程中运行应用及其依赖项运行应用程序所必需的组件都将打包成一个镜像并可以复用。执行镜像时，它运行在一个隔离环境中，并且不会共享宿主机的内存、CPU 以及磁盘，这就保证了容器内进程不能监控容器外的任何进程。容器作用可移植性在操作系统层虚拟化之后，容器封装了运行应用程序所必需的所有相关细节，如应用程序依赖性和操作系统，可以实现软件的即时迁移（Live migration），使一个软件容器中的实例，即时移动到另一个操作系统下，再重新运行起来。但是在这种技术下，软件即时迁移，只能在同样的操作系统下进行。隔离性与安全性容器将一个容器的进程与另一个容器以及底层基础架构隔离开来。因此，一个容器中的任何升级或更改都不会影响另一个容器。一个容器内的应用也无法获取宿主机或其他容器的信息。不过容器也提供了共享机制，可以指定允许被共享的资源资源限制部分容器应用支持为每个容器分配指定比例的资源（包括 CPU、内存和磁盘空间），防止某个应用程序占用全部的系统资源，影响其他应用程序的正常工作容器优缺点容器的优点 敏捷环境： 容器技术最大的优点是创建容器实例比创建虚拟机示例快得多，容器轻量级的脚本可以从性能和大小方面减少开销。 提高生产力： 容器通过移除跨服务依赖和冲突提高了开发者的生产力。每个容器都可以看作是一个不同的微服务，因此可以独立升级，而不用担心同步。 版本控制： 每一个容器的镜像都有版本控制，这样就可以追踪不同版本的容器，监控版本之间的差异等等。 运行环境可移植： 容器封装了所有运行应用程序所必需的相关的细节比如应用依赖以及操作系统。这就使得镜像从一个环境移植到另外一个环境更加灵活。比如，同一个镜像可以在 Windows 或 Linux 或者 开发、测试或 stage 环境中运行。 标准化： 大多数容器基于开放标准，可以运行在所有主流 Linux 发行版、Microsoft 平台等等。 安全： 容器之间的进程是相互隔离的，其中的基础设施亦是如此。这样其中一个容器的升级或者变化不会影响其他容器。 容器的缺点 复杂性增加： 随着容器及应用数量的增加，同时也伴随着复杂性的增加。在生产环境中管理如此之多的容器是一个极具挑战性的任务，可以使用 Kubernetes 和 Mesos 等工具管理具有一定规模数量的容器。 原生 Linux 支持： 大多数容器技术，比如 Docker，基于 Linux 容器（LXC），相比于在原生 Linux 中运行容器，在 Microsoft 环境中运行容器略显笨拙，并且日常使用也会带来复杂性。 不成熟： 容器技术在市场上是相对新的技术，需要时间来适应市场。开发者中的可用资源是有限的，如果某个开发者陷入某个问题，可能需要花些时间才能解决问题。 容器 vs 虚拟机虚拟机 特点: 虚拟机(VM)是一种创建于物理硬件系统(位于外部或内部)、充当虚拟计算机系统的虚拟环境，它模拟出了自己的整套硬件，包括 CPU、内存、网络接口和存储器。需要系统管理程序或虚拟机监视器(Hypervisor)作为中间层 不足: 镜像较大 启动较慢 资源消耗较大 容器 特点： 容器位于物理服务器及其主机操作系统（通常为 Linux 或 Windows）的顶部。每个容器共享主机 OS 内核，通常也共享二进制文件和库。 优点： 镜像较小 启动较快 资源消耗较小，甚至可以忽略不计 对比总览 虚拟机 容器 重量级 轻量级 性能有限 本机性能 每个 VM 都在自己的 OS 中运行 所有容器共享主机操作系统 硬件级虚拟化 操作系统虚拟化 启动时间（以分钟为单位） 启动时间（以毫秒为单位） 分配所需的内存 需要更少的内存空间 完全隔离，因此更安全 进程级隔离，可能不太安全 容器种类现代容器技术大致可以分为两类：系统容器与应用容器系统容器LXC，OpenVZ，Linux VServer，BSD Jails 和 Solaris为运行完整的系统而设计，可以在一个容器内运行多个应用，镜像会较大系统容器旨在运行多个进程和服务应用容器Docker 和 Rocket为运行单个应用而设计，启动应用容器时，一般只会运行一个应用进程。(docker 也是支持在一个容器内运行多个进程的，但这不符合 docker 的设计理念)应用程序容器旨在打包和运行单个服务LXC 简介LXC，其名称来自 Linux 软件容器（Linux Containers）的缩写，一种操作系统层虚拟化（Operating system–level virtualization）技术，为 Linux 内核容器功能的一个用户空间接口。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。Docker 简介docker 出现之初，便是采用了 lxc 技术作为 docker 底层，对容器虚拟化的控制。后来随着 docker 的发展，Docker 引擎自己封装了 libcontainer （golang 的库）来实现 Cgroup 和 Namespace 控制，从而消除了对 lxc 的依赖。Docker 发展到现在，已经不只是一项容器化技术那么简单。Docker 形成了一整套的平台，用于开发应用、交付（shipping）应用、运行应用、管理应用。Linux 容器原理Linux 内核提供了几项特性（chroot、Namespace、Cgroups）用于虚拟化，现代容器技术正是利用了这些特性实现的如果说 chroot 是用于隔离目录，那 namespace 就是用于隔离系统资源，cgroups 适用于物理资源分配chrootchroot 是在 Unix 和 Linux 系统的一个操作，针对正在运行的进程和它的子进程，改变它外显的根目录，让进程以为该目录即为根目录。一个运行在这个环境下，经由 chroot 设置根目录的程序，它不能够对这个指定根目录之外的文件进行访问动作，不能读取，也不能更改它的内容。NamespaceLinux Namespace 是 kernel 的一个功能，它可以隔离一系列系统的资源，比如 PID(Process ID)，User ID, Network 等等。一般看到这里，很多人会想到一个命令 chroot，就像 chroot 允许把当前目录变成根目录一样(被隔离开来的)，Namesapce 也可以在一些资源上，将进程隔离起来，这些资源包括进程树，网络接口，挂载点等等。在同一个 namespace 下的进程可以感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，认为自己置身于一个独立的系统中，从而达到隔离的目的。也就是说 linux 内核提供的 namespace 技术为 docker 等容器技术的出现和发展提供了基础条件。对于容器管理进程，在创建一个容器时，需要通过 clone()和 setns()等系统调用来创建属于同一个 namespace 的若干子进程，这样这些子进程就拥有一个与宿主机系统隔离的用户空间，其只能访问指定的参数，无法访问其他命名空间参数，隔离了诸如进程列表、网卡信息、用户列表、主机名等用户空间参数。涉及到的三个系统调用(system call)的 API： clone()：用来创建新进程，与 fork 创建新进程不同的是，clone 创建进程时候运行传递如 CLONE_NEW* 的 namespace 隔离参数，来控制子进程所共享的内容，更多内容请查看 clone 手册 setns()：让某个进程加入某个 namespace 之中 unshare()：让某个进程脱离某个 namespace以下是一些可以使用 namespace 进行隔离的系统参数： UTS 主机名和域名 Mount 挂载点 IPC(Inter-Process Communication) 每个用户空间的 IPC 专有通道 , 若是 2 个用户空间可以互相通信, 这就隔离没有了意义, 所以要确保 2 个用户空间的 IPC 是独立的 PID(Process ID) 一个系统运行是基于 2 颗”树”, 一个是进程树, 一个是文件系统树, 所以 在一个用户空间上,一个进程要么是 init , 一个是属于某个进程的子进程, 在虚拟用户空间上, 我们要营造一个假象, 让里面的进程以为自己是 init 或者是属于某个进程的子进程, 但是一个主机上又只能有一个 init, 其他进程都是 init 的子进程 或者子子进程, 进程的消灭也得由其父进程进行消灭, 所以, 在每个虚拟的用户空间上, 都得有一个 init 进程 , 但事实上 init 只能有一个, 那就是宿主机的 init, 所以只能在每个用户空间上做一个假的 init, 在这个用户空间上只有一个进程 , 那就是假的 init , 这个假的 init 消失, 所有进程也都得消失, 所以,在每个虚拟用户空间上得有自己专有的 PID User 一个虚拟的用户空间得有一个 root , 但是一个内核只能有一个 root , 那就是宿主机的 root , 所以我们只能在每个用户空间上虚造一个 root , 这个 root 在内核看来只是一个普通的进程而已 ,但是对于这个虚拟用户空间来说 , 他有全部权限,对这个虚拟用户空间的进程来说, 这个假的 root 就是真 root Network 每个虚拟的用户空间都以为自己是这个系统上的唯一的用户空间 , 所以对于虚拟用户空间来说 , 它得有自己的 ip , 网络协议栈 , 80 端口等 , 而且 2 个互相不同的虚拟用户空间还得互相通信调度 Linux Namespaces 功能参数和内核要求: namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机或域名 2.6.19 IPC(Inter-Process Communication) CLONE_NEWIPC 信号量,消息队列和共享内存 2.6.19 PID(Process ID) CLONE_NEWPID 进程编号 2.6.24 Network CLONE_NEWNET 网络设备,网络栈,端口等 2.6.29 Mount CLONE_NEWNS 挂载点(文件系统) 2.6.19 User CLONE_NEWUSER 用户和用户组 3.8 Cgroups(Control Groups)Cgroups(Control Groups) 是 Linux 内核提供的一种可以限制、记录、隔离进程组（process groups）所使用的物理资源（如：cpu,memory,IO 等等）的机制。可以对一组进程及将来的子进程的资源的限制、控制和统计的能力，这些资源包括 CPU，内存，存储，网络等。通过 Cgroups，可以方便的限制某个进程的资源占用，并且可以实时的监控进程的监控和统计信息。最初由 google 的工程师提出，后来被整合进 Linux 内核。Cgroups 也是 LXC 为实现虚拟化所使用的资源管理手段，可以说没有 Cgroups 就没有 LXC (Linux Container)。Cgroup 作用：1.限制进程组可以使用的资源数量（Resource limiting ）。比如：memory 子系统可以为进程组设定一个 memory 使用上限，一旦进程组使用的内存达到限额再申请内存，就会出发 OOM（out of memory）。2.进程组的优先级控制（Prioritization ）。比如：可以使用 cpu 子系统为某个进程组分配特定 cpu share。3.记录进程组使用的资源数量（Accounting ）。比如：可以使用 cpuacct 子系统记录某个进程组使用的 cpu 时间4.进程组隔离（isolation）。比如：使用 ns 子系统可以使不同的进程组使用不同的 namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间。5.进程组控制（control）。比如：使用 freezer 子系统可以将进程组挂起和恢复。通过 mount -t cgroup 命令或进入/sys/fs/cgroup 目录，我们看到目录中有若干个子目录，我们可以认为这些都是受 cgroups 控制的资源以及这些资源的信息： blkio - 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等。 cpu - 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。 cpuacct - 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。 cpuset - 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。 devices - 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。 freezer - 这个子系统挂起或者恢复 cgroup 中的任务。 memory - 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成内存资源使用报告。 net_cls - 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生。 net_prio - 这个子系统用来设计网络流量的优先级 hugetlb - 这个子系统主要针对于 HugeTLB 系统进行限制，这是一个大页文件系统。更多 Cgroups 信息详见: https://www.cnblogs.com/wjoyxt/p/9935098.html https://tech.meituan.com/2015/03/31/cgroups.html LXC 原理LXC，其名称来自 Linux 软件容器（Linux Containers）的缩写，一种操作系统层虚拟化（Operating system–level virtualization）技术，为 Linux 内核容器功能的一个用户空间接口。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。透过统一的名字空间和共享 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。在 Linux 内核中，提供了 cgroups 功能，来达成资源的区隔化。它同时也提供了名称空间区隔化的功能，使应用程序看到的操作系统环境被区隔成独立区间，包括行程树，网络，用户 id，以及挂载的文件系统。但是 cgroups 并不一定需要引导任何虚拟机。LXC 利用 cgroups 与 namespace 的功能，提供应用软件一个独立的操作系统环境。LXC 不需要 Hypervisor 这个软件层，软件容器（Container）本身极为轻量化，提升了创建虚拟机的速度。作为一个开源容器平台，Linux 容器项目（LXC）提供了一组工具、模板、库和语言绑定。LXC 采用简单的命令行界面，可改善容器启动时的用户体验。LXC 工作模式是这样的，使用 lxc-create 创建一个容器(名称空间)，然后通过模板(早期 shell 脚本，目前 yaml 脚本)，执行安装过程。这个模板，会自动实现安装过程，这个安装就是指向了你想创建的容器（名称空间）的系统发行版的仓库，利用仓库中的程序包下载至本地来完成安装过程。于是这个容器(名称空间)就像虚拟机一样使用。LXC 依赖于 Linux 内核提供的 cgroup，chroot，namespace 特性Docker 原理从 Docker 1.11 版本开始，Docker 容器运行就不是简单通过 Docker Daemon 来启动了，而是通过集成 containerd、runc 等多个组件来完成的。虽然 Docker Daemon 守护进程模块在不停的重构，但是基本功能和定位没有太大的变化，一直都是 CS 架构，守护进程负责和 Docker Client 端交互，并管理 Docker 镜像和容器。现在的架构中组件 containerd 就会负责集群节点上容器的生命周期管理，并向上为 Docker Daemon 提供 gRPC 接口。Docker 组件dockerdocker 的命令行工具，是给用户和 docker daemon 建立通信的客户端。dockerddockerd 是 docker 架构中一个常驻在后台的系统进程，称为 docker daemon，dockerd 实际调用的还是 containerd 的 api 接口（rpc 方式实现）,docker daemon 的作用主要有以下两方面： 接收并处理 docker client 发送的请求 管理所有的 docker 容器有了 containerd 之后，dockerd 可以独立升级，以此避免之前 dockerd 升级会导致所有容器不可用的问题。containerdcontainerd 是 dockerd 和 runc 之间的一个中间交流组件，docker 对容器的管理和操作基本都是通过 containerd 完成的。containerd 的主要功能有： 容器生命周期管理 日志管理 镜像管理 存储管理 容器网络接口及网络管理containerd-shimcontainerd-shim 是一个真实运行容器的载体，每启动一个容器都会起一个新的 containerd-shim 的一个进程， 它直接通过指定的三个参数：容器 id，boundle 目录（containerd 对应某个容器生成的目录，一般位于：/var/run/docker/libcontainerd/containerID，其中包括了容器配置和标准输入、标准输出、标准错误三个管道文件），运行时二进制（默认为 runC）来调用 runc 的 api 创建一个容器，上面的 docker 进程图中可以直观的显示。其主要作用是： 它允许容器运行时(即 runC)在启动容器之后退出，简单说就是不必为每个容器一直运行一个容器运行时(runC) 即使在 containerd 和 dockerd 都挂掉的情况下，容器的标准 IO 和其它的文件描述符也都是可用的 向 containerd 报告容器的退出状态有了它就可以在不中断容器运行的情况下升级或重启 dockerd，对于生产环境来说意义重大。runCrunC 是 Docker 公司按照 OCI 标准规范编写的一个操作容器的命令行工具，其前身是 libcontainer 项目演化而来，runC 实际上就是 libcontainer 配上了一个轻型的客户端，是一个命令行工具端，根据 OCI（开放容器组织）的标准来创建和运行容器，实现了容器启停、资源隔离等功能。Docker 启动过程当我们要创建一个容器的时候， Docker Daemon 请求  containerd  来创建一个容器，containerd 收到请求后，创建一个叫做  containerd-shim  的进程去操作容器，我们指定容器进程是需要一个父进程来做状态收集、维持 stdin 等 fd 打开等工作的，假如这个父进程就是 containerd，那如果 containerd 挂掉的话，整个宿主机上所有的容器都得退出了，而引入  containerd-shim  这个垫片就可以来规避这个问题了。然后创建容器需要做一些 namespaces 和 cgroups 的配置，以及挂载 root 文件系统等操作，这些操作其实已经有了标准的规范，那就是 OCI（开放容器标准），runc  就是它的一个参考实现（runc 的前身是 libcontainer），这个标准其实就是一个文档，主要规定了容器镜像的结构、以及容器需要接收哪些操作指令，比如 create、start、stop、delete 等这些命令。runc  就可以按照这个 OCI 文档来创建一个符合规范的容器，既然是标准肯定就有其他 OCI 实现，比如 Kata、gVisor 这些容器运行时都是符合 OCI 标准的。（ 2015 年 6 月 ，docker 公司将 libcontainer 捐出并改名为 runC 项目，交由一个完全中立的基金会管理，然后以 runC 为依据，大家共同制定一套容器和镜像的标准和规范 OCI。）所以真正启动容器是通过  containerd-shim  去调用  runc  来启动容器的，runc  启动完容器后本身会直接退出，containerd-shim  则会成为容器进程的父进程, 负责收集容器进程的状态, 上报给 containerd, 并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理, 确保不会出现僵尸进程。容器管理KubernetesKubernetes，又称为 k8s（首字母为 k、首字母与尾字母之间有 8 个字符、尾字母为 s，所以简称 k8s）或者简称为 “kube” ，是一种可自动实施 Linux 容器操作的开源平台。它可以帮助用户省去应用容器化过程的许多手动部署和扩展操作。也就是说，您可以将运行 Linux 容器的多组主机聚集在一起，由 Kubernetes 帮助您轻松高效地管理这些集群。而且，这些集群可跨公共云、私有云或混合云部署主机。因此，对于要求快速扩展的云原生应用而言（例如借助 Apache Kafka 进行的实时数据流处理），Kubernetes 是理想的托管平台。CRI 接口CRI（Container Runtime Interface 容器运行时接口）本质上就是 Kubernetes 定义的一组与容器运行时进行交互的接口，所以只要实现了这套接口的容器运行时都可以对接到 Kubernetes 平台上来。不过 Kubernetes 推出 CRI 这套标准的时候还没有现在的统治地位，所以有一些容器运行时可能不会自身就去实现 CRI 接口，于是就有了  shim（垫片）， 一个 shim 的职责就是作为适配器将各种容器运行时本身的接口适配到 Kubernetes 的 CRI 接口上，其中  dockershim  就是 Kubernetes 对接 Docker 到 CRI 接口上的一个垫片实现。Kubelet 通过 gRPC 框架与容器运行时或 shim 进行通信，其中 kubelet 作为客户端，CRI shim（也可能是容器运行时本身）作为服务器然后到了 containerd 1.1 版本后就去掉了  CRI-Containerd  这个 shim，直接把适配逻辑作为插件的方式集成到了 containerd 主进程中，现在这样的调用就更加简洁了。KubeEdgeKubeEdge 是一个开源的系统，可将本机容器化应用编排和管理扩展到边缘端设备。 它基于 Kubernetes 构建，为网络和应用程序提供核心基础架构支持，并在云端和边缘端部署应用，同步元数据。KubeEdge 还支持 MQTT 协议，允许开发人员编写客户逻辑，并在边缘端启用设备通信的资源约束。KubeEdge 包含云端和边缘端两部分。KubeEdge 特点 边缘计算 通过在边缘端运行业务逻辑，可以在本地保护和处理大量数据。KubeEdge 减少了边和云之间的带宽请求，加快响应速度，并保护客户数据隐私。 简化开发 开发人员可以编写常规的基于 http 或 mqtt 的应用程序，容器化并在边缘或云端任何地方运行。 Kubernetes 原生支持 使用 KubeEdge 用户可以在边缘节点上编排应用、管理设备并监控应用程序/设备状态，就如同在云端操作 Kubernetes 集群一样。 丰富的应用程序 用户可以轻松地将复杂的机器学习、图像识别、事件处理等高层应用程序部署到边缘端。 KubeEdge 架构 云上部分 CloudHub: CloudHub 是一个 Web Socket 服务端，负责监听云端的变化, 缓存并发送消息到 EdgeHub。 EdgeController: EdgeController 是一个扩展的 Kubernetes 控制器，管理边缘节点和 Pods 的元数据确保数据能够传递到指定的边缘节点。 DeviceController: DeviceController 是一个扩展的 Kubernetes 控制器，管理边缘设备，确保设备信息、设备状态的云边同步。 边缘部分 EdgeHub: EdgeHub 是一个 Web Socket 客户端，负责与边缘计算的云服务（例如 KubeEdge 架构图中的 Edge Controller）交互，包括同步云端资源更新、报告边缘主机和设备状态变化到云端等功能。 Edged: Edged 是运行在边缘节点的代理，用于管理容器化的应用程序。 EventBus: EventBus 是一个与 MQTT 服务器（mosquitto）交互的 MQTT 客户端，为其他组件提供订阅和发布功能。 ServiceBus: ServiceBus 是一个运行在边缘的 HTTP 客户端，接受来自云上服务的请求，与运行在边缘端的 HTTP 服务器交互，提供了云上服务通过 HTTP 协议访问边缘端 HTTP 服务器的能力。 DeviceTwin: DeviceTwin 负责存储设备状态并将设备状态同步到云，它还为应用程序提供查询接口。MetaManager: MetaManager 是消息处理器，位于 Edged 和 Edgehub 之间，它负责向轻量级数据库（SQLite）存储/检索元数据。 参考 虚拟机和容器有什么不同-ThinkWon 的博客-CSDN 博客 容器技术概览 - DockOne.io 操作系统容器与应用程序容器 - 技术记录栈 (xieyonghui.com) 操作系统层虚拟化 - 维基百科，自由的百科全书 (wikipedia.org) 什么是容器化？ (redhat.com) 容器核心技术–chroot,namespace,cgroups,LCX,和 docker Docker 容器技术基础入门-Hukey’s Blog 一文搞懂容器运行时 Containerd Linux Namespace 技术与 Docker 原理浅析 Linux 的 Namespace 与 Cgroups 介绍 Linux 资源管理之 cgroups 简介-美团技术团队 Docker 架构中的几个核心概念 Docker 实现原理/容器原理（LXC,Cgroups，Docker） 云原生在物联网中的应用【拜托了，物联网！】" }, { "title": "移植Docker到ARM嵌入式设备", "url": "/posts/docker-cross-compile/", "categories": "技术", "tags": "Docker, OS-level virtualization, container", "date": "2021-10-13 09:00:00 +0800", "snippet": "本文将会介绍如何对 Docker 源码进行交叉编译并将 Docker 相关组件移植到 arm 嵌入式设备上Docker 源码下载Docker 相关组件的源码已经移动到了 moby 库，在https://github.com/moby/moby获取源码，我这边使用的是moby-17.05.0-ce这个 tag，因为嵌入式设备的资源空间有限，而新版本的 Docker 由于集成了大量功能，导致耗费资源较多，可能跑不起来。下载Source code：wget https://github.com/moby/moby/archive/refs/tags/v17.05.0-ce.tar.gz解压到合适位置：tar -zxvf v17.05.0-ce.tar.gz解压后目录如下图：准备编译环境Docker 编译需要在专用的 Docker 容器内进行，官方已经提供了完整的编译脚本，不过对于交叉编译的适配并不好，这里不使用自带的编译脚本，而是通过手动配置的办法进行编译进入 Docker bash通过 vim 编辑 Makefile 脚本，找到cross:这个编译选项，将 Makefile 脚本修改为:cross: build ## cross build the binaries for darwin, freebsd and\\nwindows $(DOCKER_RUN_DOCKER) /bin/bash以上操作表示进入 Docker 容器的 bash，而不是通过脚本直接编译使用 make 命令（DOCKER_CROSSPLATFORMS这个编译参数好像不加也没事）：DOCKER_CROSSPLATFORMS=&quot;linux/arm&quot; make cross之后容器构建脚本会开始执行构建命令，国内的网络环境可能下载不了某些库，如果有必要，自行修改源码目录下的Dockerfile。构建完成后就会进入容器的 bash：安装交叉编译工具链使用 golang 交叉编译还是比较方便的，可惜只支持静态链接，二进制文件较大，动态链接还没试成功过对于armv5el平台，需要对应的交叉编译工具链arm-linux-gnueabi-gcc，当前容器默认是没安装的，需要手动安装安装交叉编译工具链：echo &quot;deb http://ftp.de.debian.org/debian sid main&quot; &amp;gt;&amp;gt; /etc/apt/sources.listapt-get updateapt-get install gcc-arm-linux-gnueabi交叉编译依赖库docker 编译会有两个选择，binary/dynbinary即静态编译与动态编译（dynbinary 好像不支持交叉编译，反正我没试成功），因此须要提供的 arm 库的数量也不一样：# 静态编译提供的dev如下： libapparmor-dev libdevmapper-dev libseccomp-dev# 动态编译提供的dev如下： libapparmor-dev libdevmapper-dev libseccomp-dev libltdl-dev libattr1-dev libcap-dev intltool libtinfo-dev util-linux expat dbus ffi zlib glib-2.0 libsystemd-dev不过每个库都交叉编译比较麻烦，这里提供两种更简单的方法： 直接通过 apt 安装 如过当前的 debian 版本较新，可以直接通过 apt 安装，安装时指定对应的平台即可，armv5 对应是armel apt install libapparmor-dev:armelapt install libdevmapper-dev:armelapt install libseccomp-dev:armel 去 debian 仓库网页下载 部分 debian 的版本较老，仓库内可能没有对应的库，这时就要去手动下载，下面是部分库的地址： https://packages.debian.org/buster/libdevmapper-dev (注意依赖) https://packages.debian.org/buster/libseccomp-dev https://packages.debian.org/buster/libapparmor-dev 下载完是 deb 包，传到容器里，安装即可。如果无法安装就解压后覆盖到根目录 dpkg --force-architecture -i libdevmapper-dev_1.02.155-3_armel.deb 注意：交叉编译时可能优先使用容器内自带的 x86 的库做链接，如果报了链接出错就把原来的库删了: /usr/local/lib/libseccomp.so: file not recognized: file format not recognizedcollect2: error: ld returned 1 exit status rm /usr/local/lib/libseccomp.arm /usr/local/lib/libseccomp.sorm /usr/lib/libdevmapper.sorm /usr/lib/libdevmapper.a 设置编译相关环境变量#由于docker是golang进行编译的因此直接声明目标平台架构export GOARCH=arm#打开CGO支持export CGO_ENABLED=1#声明目标平台系统export GOOS=linux#声明编译工具export CC=arm-linux-gnueabi-gcc#声明编译docker的版本export DOCKER_GITCOMMIT=89658be#Docker编译参数，这里禁用了一些组件export DOCKER_BUILDTAGS=&#39;no_btrfs no_cri no_zfs exclude_disk_quota exclude_graphdriver_btrfs exclude_graphdriver_zfs no_buildkit&#39;编译 docker 依赖组件moby项目只包含了docker-client和docker-daemon，其他的组件需要通过脚本单独下载编译：#清理x64环境下的执行程序rm -rf /usr/local/bin/docker-*#编译执行程序sh /go/src/github.com/docker/docker/hack/dockerfile/install-binaries.sh runc tini proxy containerd编译完的文件自动部署在容器的/usr/local/bin/目录，需要自行拷贝出来。当然也可以自行修改install-binaries.sh脚本把二进制文件保存到自己希望的目录编译 docker使用 hack/make.sh 脚本进行编译 docker 与 dockerd 执行程序。#编译静态包（成功）hack/make.sh binary#编译动态包（失败）hack/make.sh dynbinary编译完的二进制文件在/go/src/github.com/docker/docker/bundles/17.05.0-ce 目录，该目录是宿主机目录的映射，可以在宿主机目录/repo/moby-17.05.0-ce/bundles/17.05.0-ce 提取文件。别忘了上一节的依赖组件root@racknerd-ae2d96:~/repo/moby-17.05.0-ce/bundles/17.05.0-ce/binary-client# file docker-17.05.0-cedocker-17.05.0-ce: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, Go BuildID=78906b998b797bc6afd511082f0928b0bd4c70a0, BuildID[sha1]=a1da4f0f805fc199891bba9ccc22d5b697186994, for GNU/Linux 3.2.0, with debug_info, not stripped移植程序把所有文件打包放入目标设备合适的目录17.05.0-ce├── binary-client│ ├── docker -&amp;gt; docker-17.05.0-ce│ ├── docker-17.05.0-ce│ ├── docker-17.05.0-ce.md5│ └── docker-17.05.0-ce.sha256└── binary-daemon├── docker-containerd├── docker-containerd-ctr├── docker-containerd-ctr.md5├── docker-containerd-ctr.sha256├── docker-containerd.md5├── docker-containerd.sha256├── docker-containerd-shim├── docker-containerd-shim.md5├── docker-containerd-shim.sha256├── dockerd -&amp;gt; dockerd-17.05.0-ce├── dockerd-17.05.0-ce├── dockerd-17.05.0-ce.md5├── dockerd-17.05.0-ce.sha256├── docker-init├── docker-init.md5├── docker-init.sha256├── docker-proxy├── docker-proxy.md5├── docker-proxy.sha256├── docker-runc├── docker-runc.md5└── docker-runc.sha256扩展：balena-engine介绍：An engine purpose-built for embedded and IoT use cases, based on Moby Project technology from Docker官网：https://www.balena.io/engine/移植 docker 的过程中无意中发现了 balena-engine，根据官网介绍这个软件是专门为 IoT 定制的精简版 docker，比 docker 更快更小。整体的编译方法和 docker 相同，编译时使用hack/make.sh binary-balena就行，二进制文件只有一个，其他都是软链接。运行 Docker后面的介绍以 balena-engine 为例，Docker 也是一样的运行环境检查先下载检测脚本https://github.com/moby/moby/blob/master/contrib/check-config.sh找到内核编译时的.config文件，使用check-config.sh对.config 进行检测，该操作可以不在目标机运行。Generally Necessary表示必须满足的，如果有missing项一定要把功能启用了，重新编译内核$ ./check-config.shinfo: reading kernel config from ./.config ...Generally Necessary:- cgroup hierarchy: nonexistent?? (see https://github.com/tianon/cgroupfs-mount)- CONFIG_NAMESPACES: enabled- CONFIG_NET_NS: enabled- CONFIG_PID_NS: enabled- CONFIG_IPC_NS: enabled- CONFIG_UTS_NS: enabled- CONFIG_CGROUPS: enabled- CONFIG_CGROUP_CPUACCT: enabled- CONFIG_CGROUP_DEVICE: enabled- CONFIG_CGROUP_FREEZER: enabled- CONFIG_CGROUP_SCHED: enabled- CONFIG_CPUSETS: enabled- CONFIG_MEMCG: enabled- CONFIG_KEYS: enabled- CONFIG_VETH: enabled- CONFIG_BRIDGE: enabled- CONFIG_BRIDGE_NETFILTER: enabled- CONFIG_NF_NAT_IPV4: enabled- CONFIG_IP_NF_FILTER: enabled- CONFIG_IP_NF_TARGET_MASQUERADE: enabled- CONFIG_NETFILTER_XT_MATCH_ADDRTYPE: enabled- CONFIG_NETFILTER_XT_MATCH_CONNTRACK: enabled- CONFIG_NETFILTER_XT_MATCH_IPVS: enabled- CONFIG_IP_NF_NAT: enabled- CONFIG_NF_NAT: enabled- CONFIG_NF_NAT_NEEDED: enabled- CONFIG_POSIX_MQUEUE: enabled- CONFIG_DEVPTS_MULTIPLE_INSTANCES: enabledOptional Features:- CONFIG_USER_NS: missing- CONFIG_SECCOMP: missing- CONFIG_CGROUP_PIDS: missing- CONFIG_MEMCG_SWAP: missing- CONFIG_MEMCG_SWAP_ENABLED: missing- CONFIG_MEMCG_KMEM: missing- CONFIG_RESOURCE_COUNTERS: enabled- CONFIG_BLK_CGROUP: missing- CONFIG_BLK_DEV_THROTTLING: missing- CONFIG_IOSCHED_CFQ: enabled- CONFIG_CFQ_GROUP_IOSCHED: missing- CONFIG_CGROUP_PERF: enabled- CONFIG_CGROUP_HUGETLB: missing- CONFIG_NET_CLS_CGROUP: missing- CONFIG_NETPRIO_CGROUP: missing- CONFIG_CFS_BANDWIDTH: missing- CONFIG_FAIR_GROUP_SCHED: enabled- CONFIG_RT_GROUP_SCHED: enabled- CONFIG_IP_NF_TARGET_REDIRECT: enabled- CONFIG_IP_VS: missing- CONFIG_IP_VS_NFCT: missing- CONFIG_IP_VS_PROTO_TCP: missing- CONFIG_IP_VS_PROTO_UDP: missing- CONFIG_IP_VS_RR: missing- CONFIG_EXT3_FS: missing- CONFIG_EXT3_FS_XATTR: missing- CONFIG_EXT3_FS_POSIX_ACL: missing- CONFIG_EXT3_FS_SECURITY: missing (enable these ext3 configs if you are using ext3 as backing filesystem)- CONFIG_EXT4_FS: missing- CONFIG_EXT4_FS_POSIX_ACL: missing- CONFIG_EXT4_FS_SECURITY: missing enable these ext4 configs if you are using ext4 as backing filesystem- Network Drivers: - &quot;overlay&quot;: - CONFIG_VXLAN: missing Optional (for encrypted networks): - CONFIG_CRYPTO: enabled - CONFIG_CRYPTO_AEAD: enabled - CONFIG_CRYPTO_GCM: enabled - CONFIG_CRYPTO_SEQIV: enabled - CONFIG_CRYPTO_GHASH: enabled - CONFIG_XFRM: enabled - CONFIG_XFRM_USER: missing - CONFIG_XFRM_ALGO: missing - CONFIG_INET_ESP: missing - CONFIG_INET_XFRM_MODE_TRANSPORT: missing - &quot;ipvlan&quot;: - CONFIG_IPVLAN: missing - &quot;macvlan&quot;: - CONFIG_MACVLAN: missing - CONFIG_DUMMY: enabled - &quot;ftp,tftp client in container&quot;: - CONFIG_NF_NAT_FTP: enabled - CONFIG_NF_CONNTRACK_FTP: enabled - CONFIG_NF_NAT_TFTP: enabled - CONFIG_NF_CONNTRACK_TFTP: enabled- Storage Drivers: - &quot;aufs&quot;: - CONFIG_AUFS_FS: missing - &quot;btrfs&quot;: - CONFIG_BTRFS_FS: missing - CONFIG_BTRFS_FS_POSIX_ACL: missing - &quot;devicemapper&quot;: - CONFIG_BLK_DEV_DM: missing - CONFIG_DM_THIN_PROVISIONING: missing - &quot;overlay&quot;: - CONFIG_OVERLAY_FS: missing - &quot;zfs&quot;: - /dev/zfs: missing - zfs command: missing - zpool command: missingLimits:cat: /proc/sys/kernel/keys/root_maxkeys: No such file or directory./check-config.sh: line 351: [: -le: unary operator expectedcat: /proc/sys/kernel/keys/root_maxkeys: No such file or directory- /proc/sys/kernel/keys/root_maxkeys:挂载 cgroupDocker 使用依赖于 cgroup，通过以下 shell 脚本挂载 cgroup：#!/bin/bashset -eif grep -v &#39;^#&#39; /etc/fstab | grep -q cgroup; then echo &#39;cgroups mounted from fstab, not mounting /sys/fs/cgroup&#39; exit 0fi# kernel provides cgroups?if [ ! -e /proc/cgroups ]; then exit 0fi# 确保目录存在if [ ! -d /sys/fs/cgroup ]; then exit 0fi# mount /sys/fs/cgroup if not already doneif ! mountpoint -q /sys/fs/cgroup; then mount -t tmpfs -o uid=0,gid=0,mode=0755 cgroup /sys/fs/cgroupficd /sys/fs/cgroup# get/mount list of enabled cgroup controllersfor sys in $(awk &#39;!/^#/ { if ($4 == 1) print $1 }&#39; /proc/cgroups); do mkdir -p $sys if ! mountpoint -q $sys; then if ! mount -n -t cgroup -o $sys cgroup $sys; then rmdir $sys || true fi fidoneexit 0cgroup 挂载成功：安装 iptablesDocker 需要 iptables 配置网络，关于 iptables 的交叉编译，在我之前写的文章《strongSwan 与 Cisco CSR 1000V 建立 IPSec vpn 调试记录》里有提到配置环境变量需要配置 iptables 和 Docker 的运行环境变量关于 XTABLES_LIBDIR 的信息，见这篇文章《移植 iptables 扩展依赖问题》export PATH=$PATH:/media/disk/iptables/sbin:/media/disk/balena-engineexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/media/disk/iptables/libexport XTABLES_LIBDIR=/media/disk/iptables/lib/xtables修改 Docker 配置文件Docker 的配置文件名为daemon.json，主要是配置 storage-driver 和 data-root，分别是文件系统驱动和数据根目录daemon.json：{ &quot;storage-driver&quot;: &quot;devicemapper&quot;, &quot;data-root&quot;: &quot;/media/disk/balena-engine/lib/docker&quot;, &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;3&quot;, &quot;labels&quot;: &quot;production_status&quot;, &quot;env&quot;: &quot;os,customer&quot; }}运行 containerd 和 dockerd运行 dockerd 会自动拉起 containerd：balena-engine-daemon --config-file /media/disk/balena-engine/daemon.json编写 start-docker.sh 脚本：#/bin/sh./mountcgroup.shexport PATH=$PATH:/media/disk/iptables/sbin:/media/disk/balena-engineexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/media/disk/iptables/libexport XTABLES_LIBDIR=/media/disk/iptables/lib/xtablesbalena-engine-daemon --config-file /media/disk/balena-engine/daemon.json启动日志：[root@sx binary-balena]# ./start-docker.shWARN[2021-10-13T06:56:16.290000000Z] could not change group /var/run/balena-engine.sock to balena-engine: group balena-engine not foundINFO[2021-10-13T06:56:16.310000000Z] libcontainerd: started new balena-engine-containerd process pid=1351INFO[0000] starting containerd module=containerd revision= version=1.0.0+unknownINFO[0000] setting subreaper... module=containerdINFO[0000] changing OOM score to -500 module=containerdINFO[0000] loading plugin &quot;io.containerd.content.v1.content&quot;... module=containerd type=io.containerd.content.v1INFO[0000] loading plugin &quot;io.containerd.snapshotter.v1.overlayfs&quot;... module=containerd type=io.containerd.snapshotter.v1INFO[0000] loading plugin &quot;io.containerd.metadata.v1.bolt&quot;... module=containerd type=io.containerd.metadata.v1INFO[0000] loading plugin &quot;io.containerd.differ.v1.walking&quot;... module=containerd type=io.containerd.differ.v1INFO[0000] loading plugin &quot;io.containerd.gc.v1.scheduler&quot;... module=containerd type=io.containerd.gc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.containers&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.content&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.diff&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.events&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.healthcheck&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.images&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.leases&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.namespaces&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.snapshots&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.monitor.v1.cgroups&quot;... module=containerd type=io.containerd.monitor.v1INFO[0000] loading plugin &quot;io.containerd.runtime.v1.linux&quot;... module=containerd type=io.containerd.runtime.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.tasks&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.version&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] loading plugin &quot;io.containerd.grpc.v1.introspection&quot;... module=containerd type=io.containerd.grpc.v1INFO[0000] serving... address=/var/run/balena-engine/containerd/balena-engine-containerd-debug.sock module=containerd/debugINFO[0000] serving... address=/var/run/balena-engine/containerd/balena-engine-containerd.sock module=containerd/grpcINFO[0000] containerd successfully booted in 0.190000s module=containerdINFO[2021-10-13T06:56:17.900000000Z] Graph migration to content-addressability took 0.00 secondsWARN[2021-10-13T06:56:17.920000000Z] Your kernel does not support swap memory limitWARN[2021-10-13T06:56:17.920000000Z] Your kernel does not support kernel memory limitWARN[2021-10-13T06:56:17.920000000Z] Your kernel does not support cgroup cfs periodWARN[2021-10-13T06:56:17.920000000Z] Your kernel does not support cgroup cfs quotasWARN[2021-10-13T06:56:17.920000000Z] Unable to find blkio cgroup in mountsWARN[2021-10-13T06:56:17.940000000Z] mountpoint for pids not foundINFO[2021-10-13T06:56:17.960000000Z] Loading containers: start.WARN[2021-10-13T06:56:18.010000000Z] Running modprobe nf_nat failed with message: `modprobe: can&#39;t change directory to &#39;/lib/modules&#39;: No such file or directory`, error: exit status 1WARN[2021-10-13T06:56:18.060000000Z] Running modprobe xt_conntrack failed with message: `modprobe: can&#39;t change directory to &#39;/lib/modules&#39;: No such file or directory`, error: exit status 1WARN[2021-10-13T06:56:19.810000000Z] Could not load necessary modules for IPSEC rules: Running modprobe xfrm_user failed with message: `modprobe: can&#39;t change directory to &#39;/lib/modules&#39;: No such file or directory`, error: exit status 1INFO[2021-10-13T06:56:26.480000000Z] Default bridge (balena0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP addressINFO[2021-10-13T06:56:28.920000000Z] Loading containers: done.WARN[2021-10-13T06:56:28.920000000Z] Could not get operating system name: Error opening /usr/lib/os-release: open /usr/lib/os-release: no such file or directoryWARN[2021-10-13T06:56:30.450000000Z] failed to retrieve balena-engine-init version: exec: &quot;balena-engine-init&quot;: executable file not found in $PATHINFO[2021-10-13T06:56:30.450000000Z] Docker daemon commit=89658be graphdriver(s)=vfs version=devINFO[2021-10-13T06:56:30.450000000Z] Daemon has completed initializationINFO[2021-10-13T06:56:31.060000000Z] API listen on /var/run/balena-engine.sock查看 Docker 信息：[root@sx binary-balena]# ./balena-engine infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: devStorage Driver: vfsLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host null Log: journald json-fileSwarm: NodeID: Is Manager: false Node Address:Runtimes: bare runcDefault Runtime: runcInit Binary: balena-engine-initcontainerd version:runc version: 13e66eedaddfbfeda2a73d23701000e4e63b5471init version: N/A (expected: )Kernel Version: 3.10.108Operating System: &amp;lt;unknown&amp;gt;OSType: linuxArchitecture: armv5tejlCPUs: 1Total Memory: 57.15MiBName: sxID: W6OF:ZM5H:HNWK:YOLX:3KPV:S4ZX:5CKC:A5YE:NKEP:CMTK:2JIW:GFTNDocker Root Dir: /media/disk/balena-engine/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period support至此，Docker 已经启动完毕，后面就是通过 docker 命令安装镜像，启动容器之类的了，这里不在赘述。有关本地载入镜像的说明可以参考此博客《Docker 本地导入镜像/保存镜像/载入镜像/删除镜像》参考 在 mac 环境下交叉编译 ARM32 版 Docker 解决：dockerd: failed to start daemon: Devices cgroup isn‘t mounted Docker storage drivers Docker 之几种 storage-driver 比较 移植 iptables 扩展依赖问题 Docker 本地导入镜像/保存镜像/载入镜像/删除镜像" }, { "title": "软件设计模式——七大设计原则", "url": "/posts/design-patterns-principles/", "categories": "技术", "tags": "design patterns, design principles", "date": "2021-09-16 09:00:00 +0800", "snippet": " 概述 设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。 描述了在软件设计过程中的一些不断重复发生的问题，以及该问题的解决方案。 是解决特定问题的一系列套路，是前辈们的代码设计经验的总结，具有一定的普遍性，可以反复使用。 其目的是为了提高代码的可重用性、代码的可读性和代码的可靠性。 作用 提高思维能力、编程能力和设计能力。 使程序设计更加标准化、代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。 使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。 七种开发原则开闭原则 定义 Open Closed Principle，OCP 软件实体应当对扩展开放，对修改关闭。即, 当应用的需求改变时，在不修改软件实体的源代码或者二进制代码的前提下，可以扩展模块的功能，使其满足新的需求。 作用 对软件测试的影响 测试时只需要对扩展的代码进行测试就可以了，因为原有的测试代码仍然能够正常运行。 提高代码的可复用性 粒度越小，被复用的可能性就越大；在面向对象的程序设计中，根据原子和抽象编程可以提高代码的可复用性。 提高软件的可维护性 稳定性高和延续性强，从而易于扩展和维护。 里氏替换原则 定义 Liskov Substitution Principle，LSP 继承必须确保基类所拥有的性质在子类中仍然成立。即, 子类可以扩展父类的功能，但不能改变父类原有的功能。 作用 是实现开闭原则的重要方式之一。 克服了继承中重写父类造成的可复用性变差的缺点。 类的扩展不会给已有的系统引入新的错误，降低了代码出错的可能性。 依赖倒置原则 定义 Dependence Inversion Principle，DIP 要面向接口编程，不要面向实现编程。即, 高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。 作用 可以降低类间的耦合性。 可以减少并行开发引起的风险。 可以提高代码的可读性和可维护性。 单一职责原则 定义 Single Responsibility Principle，SRP 单一职责原则规定一个类应该有且仅有一个引起它变化的原因，否则类应该被拆分。 如果一个对象承担了太多的职责，至少存在以下两个缺点 一个职责的变化可能会削弱或者抑制这个类实现其他职责的能力； 当客户端需要该对象的某一个职责时，不得不将其他不需要的职责全都包含进来，从而造成冗余代码或代码的浪费。 作用 降低类的复杂度。一个类只负责一项职责，其逻辑肯定要比负责多项职责简单得多。 提高类的可读性。复杂性降低，自然其可读性会提高。 提高系统的可维护性。可读性提高，那自然更容易维护了。 变更引起的风险降低。变更是必然的，如果单一职责原则遵守得好，当修改一个功能时，可以显著降低对其他功能的影响。 接口隔离原则 定义 Interface Segregation Principle，ISP 客户端不应该被迫依赖于它不使用的方法 一个类对另一个类的依赖应该建立在最小的接口上 与单一职责原则的区别 单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。 单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。 作用 将臃肿庞大的接口分解为多个粒度小的接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。 接口隔离提高了系统的内聚性，减少了对外交互，降低了系统的耦合性。 使用多个专门的接口还能够体现对象的层次，因为可以通过接口的继承，实现对总接口的定义。 能减少项目工程中的代码冗余。过大的大接口里面通常放置许多不用的方法，当实现这个接口的时候，被迫设计冗余的代码。 迪米特法则 定义 Law of Demeter，LoD, 又叫作最少知识原则（Least Knowledge Principle，LKP) 如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。 作用 降低了类之间的耦合度，提高了模块的相对独立性。 由于亲合度降低，从而提高了类的可复用率和系统的扩展性。 合成复用原则 定义 Composite Reuse Principle，CRP, 又叫组合/聚合复用原则（Composition/Aggregate Reuse Principle，CARP）。 在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。 作用 通常类的复用分为继承复用和合成复用两种，继承复用虽然有简单和易实现的优点，但它也存在以下缺点: 继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。 子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与 它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。 采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点: 它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。 新旧类之间的耦合度低。这种复用所需的依赖较少，新对象存取成分对象的唯一方法是通过成分对象的接口。 复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。 总结 设计原则 一句话归纳 目的 开闭原则 对扩展开放，对修改关闭 降低维护带来的新风险 依赖倒置原则 高层不应该依赖低层，要面向接口编程 更利于代码结构的升级扩展 单一职责原则 一个类只干一件事，实现类要单一 便于理解，提高代码的可读性 接口隔离原则 一个接口只干一件事，接口要精简单一 功能解耦，高聚合、低耦合 迪米特法则 不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度 只和朋友交流，不和陌生人说话，减少代码臃肿 里氏替换原则 不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义 防止继承泛滥 合成复用原则 尽量使用组合或者聚合关系实现代码复用，少使用继承 降低代码耦合 实际上，这些原则的目的只有一个：降低对象之间的耦合，增加程序的可复用性、可扩展性和可维护性。 记忆口诀：访问加限制，函数要节俭，依赖不允许，动态加接口，父类要抽象，扩展不更改。在程序设计时，我们应该将程序功能最小化，每个类只干一件事。若有类似功能基础之上添加新功能，则要合理使用继承。对于多方法的调用，要会运用接口，同时合理设置接口功能与数量。最后类与类之间做到低耦合高内聚。参考 23 种经典设计模式(附 c++实现代码) | 王竹兴| Blob 软件设计模式概述 CS-Notes 设计模式" }, { "title": "简单证书注册协议(SCEP)详解", "url": "/posts/scep/", "categories": "技术", "tags": "linux, scep, ipsec", "date": "2021-09-09 09:00:00 +0800", "snippet": "本文将会介绍简单证书注册协议(Simple certificate enrollment protocol, SCEP)，并对整个证书签发流程做详细的分析概述SCEP(Simple certificate enrollment protocol)，简单证书注册协议，最初由 CISCO 起草，简而言之，就是一个用来注册数字证书的协议。RFC 8894描述了简单的证书注册协议(SCEP)。该协议的旧版本成为实际工业标准，用于实际提供数字证书，主要用于网络设备。该协议旨在使任何标准网络用户的要求和颁发的数字证书尽可能简单。这些流程通常需要网络管理员的密集输入，因此不适合大规模部署。简单的证书注册协议仍然是最受欢迎和广泛可用的证书注册协议，被许多网络设备和软件制造商使用，他们正在开发简化的处理证书的方法，以便向日常用户大规模实施。例如，思科 IOS 操作系统(即使思科正在推动功能稍多的 EST)和 iPhone 注册企业 PKI。大多数 PKI 软件(特别是 RA 实现)都支持它，包括活动目录证书服务的网络设备注册服务 (NDES)。历史SCEP 由 Verisign 为思科设计，作为 CMS (CMC)证书管理、以及功能强大但体积相当庞大的证书管理协议(CMP)的精益替代方案。2010 年左右，思科暂停了 SCEP 的工作，转而开发了 EST。2015 年， Peter Gutmann 恢复了互联网草案(Internet Draft)，原因是 SCEP 在工业和其他标准中广泛使用。 他用更现代的算法更新了草稿，纠正了原始规范中的许多问题。2020 年 9 月，该草案作为RFC 8894发布，SCEP 从草案到标准花费了近 20 年。 新版本还支持注册非 RSA 证书(例如ECC公钥)。RA 简介注册机构(Registration Authority, RA) 是公开密钥基础设施(Public Key Infrastructures, PKI)中使用的证书注册功能。它负责接收来自人员、服务器、事物或其他应用程序的证书签名请求(CSR)–初始注册或续订。注册机构验证这些请求并转发给证书颁发机构 (Certificate Authority, CA)。注册机构还负责接收其他证书生命周期管理职能。例如，撤销。RA 实施接受请求的业务逻辑，需要能够验证请求方和应具有证书的一方的来源。出于无障碍和安全原因，注册机构通常与证书颁发机构分开。通过用户友好型 GUI 或集成友好型 API 和标准协议访问 RA。在Cisco Systems’ Simple Certificate Enrollment Protocol draft-nourse-scep-22这篇文章中讲述了客户端如何通过 SCEP 协议访问 RA 接口，由于 SCEP 协议当时还处于草案阶段，所以该文章只能作为参考。SCEP 的正式标准是RFC 8894。但是由于草案的大规模使用，本文还是会以草案作为基础对 SCEP 协议做介绍SCEP 实体SCEP 中定义的实体类型： 请求者(Requester) 例如，IPSec 客户端 服务器(Server) 证书颁发机构 (Certificate Authority, CA)或注册机构(Registration Authority, RA) SCEP 的特点 基于HTTP的请求/响应模式(使用 GET 方法，POST 也可以支持) 只支持RSA加密(目前国际通用、使用广泛的公钥算法也就 RSA, ECC， 而 ECC 是没有公钥加密，私钥解密标准的，我猜这个特点有这个原因吧) 证书请求用PKCS #10标准(也就是 CSR 格式的一种标准) 采用PKCS #7标准传输签名/加密数据(HTTP 请求非常不安全，容易被拦截，篡改) 支持服务器异步授权，客户端定期轮询 具有有限的证书吊销列表(CRL)检索支持(首选方法是通过 CRL 分发点(CDP)查询，出于可伸缩性原因) 不支持在线证书吊销(必须通过其它方法执行脱机) 需要在证书签名请求(CSR)中使用质询密码(Challenge Password)字段，该字段必须仅在服务器和请求者之间共享证书注册过程简述 取得 CA 证书的副本，并对其进行验证 生成一个 CSR(Certificate Signing Reques)，并把它安全地传输到 CA 轮询 SCEP 服务器，检查证书是不是已经被签名了 根据需要重新注册，以便在当前证书到期之前获得新证书。 根据需要检索 CRL。证书注册流程CA 认证:获取 CA 证书SCEP 使用 CA 证书来加密 CSR 的消息交换。因此，必须获得 CA 证书的副本。使用 GetCACert 操作。请求请求被发送作为 HTTP GET 请求。请求的信息包获取看起来类似于此：GET /cgi-bin/pkiclient.exe?operation=GetCACert响应响应只是二进制编码的 CA 证书 (X.509)。客户端需要验证 CA 证书通过指纹/哈希的检查。这必须通过带外(out-of-band)方法(呼叫系统管理员或信任点内指纹的预配置)完成。客户注册请求注册请求作为 HTTP GET 请求发送。请求的包捕获看起来与此类似：/cgi-bin/pkiclient.exe?operation=PKIOperation&amp;amp;message=MIIHCgYJKoZIhvcNAQcCoIIG%2BzCCBvcCAQExDjA…… “message=”之后的文本是从 GET 请求字符串中提取的 URL 编码字符串。 然后，文本被 URL 解码为 ASCII 文本字符串。该文本字符串是 base64 编码的签名数据(SignedData) PKCS#7。 签名数据(SignedData) PKCS#7 由客户端使用以下证书中的一种签署;它被用来证明客户发送它，且没有在传输过程中被篡改： 自签证书(首次注册时使用) 制造商安装证书 (MIC) 即将到期的当前证书(重新注册) 签名数据(SignedData) PKCS#7 的”签名数据”部分是信封数据(EnvelopedData) PKCS#7。 信封数据(EnvelopedData) PKCS#7 是一个包含”加密数据”和”解密密钥”的容器。解密密钥使用收件人的公钥加密。在此特定情况下，收件人是 CA：因此。只有 CA 才能实际解密“加密数据”。 信封数据(EnvelopedData) PKCS#7 的”加密数据(Encrypted Data)”部分是 CSR (PKCS#10)。响应对 SCEP 注册请求的响应是三种类型之一： Reject 拒绝 - 管理员以任何原因拒绝请求，例如： 无效密钥长度 无效质询密码(Challenge Password) CA 无法验证请求 请求要求 CA 提供未授权的属性 请求由 CA 不信任的身份签署 Pending 待定 - CA 管理员尚未审核该请求。 Success 成功 - 接受请求并包含签名证书。签名证书在称为”仅限退化证书-仅限 PCCS#7(Degenerate Certificates-Only PKCS#7)”的特殊类型的 PKCS #7 中保存，这是一种特殊容器，可容纳一个或多个 X.509 或 CRL，但不包含已签名或加密的数据有效载荷。客户重新注册在证书到期之前，客户需要获得新的证书。续订(renewal)和展期(rollover)之间有轻微的行为差异。当客户 ID 证书接近到期时，其到期日期与 CA 证书的到期日期不同(早于 CA 证书到期时间)时，就会发生续订。当 ID 证书接近到期，且时其到期日期与 CA 证书到期日期相同，就会发生展期。续订随着 ID 证书到期日期的临近，SCEP 客户可能想要获得新证书。客户端生成 CSR，并完成注册过程(如以前定义的)。当前证书用于签署签名数据 PKCS#7，这反过来又向 CA 证明身份。重新获得新证书后，客户立即删除当前证书，代之以新证书，新证书的有效期立即开始。展期展期是 CA 证书过期并生成新 CA 证书的特殊情况。CA 生成新的 CA 证书，一旦当前 CA 证书过期，该证书将生效。CA 通常会在展期前一段时间生成此”阴影 CA”证书，因为需要该证书才能为客户生成”阴影 ID”证书。当 SCEP 客户 ID 证书即将到期时，SCEP 客户端会向 CA 查询”影子 CA”证书。此操作与 GetNextCACert 操作一起完成，如下图所示：GET /cgi-bin/pkiclient.exe?operation=GetNextCACert一旦 SCEP 客户拥有”影子 CA”证书，它会在正常注册程序后申请”影子 ID”证书。CA 在”阴影 ID”证书上签名，并标有”阴影 CA”证书。与正常的续订请求不同，退回的”阴影 ID”证书在 CA 证书到期(展期)时生效。因此，客户需要保留 CA 和 ID 证书的预展和后展期证书副本。在 CA 到期(展期)时，SCEP 客户端删除当前的 CA 证书和 ID 证书，并将其替换为”阴影”副本。附录PKCS#7PKCS#7 is a defined data format that allows data to be signed or encrypted. The data format includes the original data and the associated metadata necessary in order to perform the cryptographic operation.PKCS#7 是一种定义的数据格式，允许签名或加密数据。数据格式包括执行加密操作所需的原始数据和相关元数据。Signed Envelope (SignedData)The signed envelope is a format that carries data and confirms that the encapsulated data is not altered in transit via digital signatures. It includes this information:签名信封是一种携带数据并确认封装数据在传输中不会通过数字签名更改的格式。它包括此信息：SignedData &amp;amp;colon;:= SEQUENCE { version CMSVersion, digestAlgorithms DigestAlgorithmIdentifiers, encapContentInfo EncapsulatedContentInfo, certificates [0] IMPLICIT CertificateSet OPTIONAL, crls [1] IMPLICIT RevocationInfoChoices OPTIONAL, signerInfos SignerInfos } Version number - With SCEP, version 1 used.版本编号 - 使用 SCEP 版本 1。 List of Digest Algorithms Used - With SCEP, there is only one Signer and thus only one Hashing Algorithm.使用的文摘算法列表 - 使用 SCEP，只有一个签名者，因此只有一个哈希算法。 Actual data that is signed - With SCEP, this is a PKCS#7 Enveloped-data format (Encrypted Envelope).已签名的实际数据 - 与 SCEP 一起，这是一个 PKCS#7 信封数据格式(加密信封)。 List of certificates of the signers - With SCEP, this is a self-signed certificate on initial enrollment or the current certificate if you re-enroll.签名者证书列表 - 通过 SCEP，如果您重新注册，这是初始注册时的自签名证书或当前证书。 List of the signers and the fingerprint generated by each signer - With SCEP, there is only one signer.签名者名单和每个签名者生成的指纹 - 有了 SCEP，只有一个签名者。The data encapsulated is not encrypted or obfuscated. This format simply provides protection against the message that is altered.封装的数据不加密或混淆。此格式仅提供完整性保护，防止消息被篡改。Enveloped Data (EnvelopedData)The Enveloped Data format carries data that is encrypted and can only be decrypted by the specified recipient(s). It includes this information:信封数据格式携带的数据是加密的，只能由指定的收件人解密。它包括此信息：EnvelopedData &amp;amp;colon;:= SEQUENCE { version CMSVersion, originatorInfo [0] IMPLICIT OriginatorInfo OPTIONAL, recipientInfos RecipientInfos, encryptedContentInfo EncryptedContentInfo, unprotectedAttrs [1] IMPLICIT UnprotectedAttributes OPTIONAL } Version number - With SCEP, version 0 is used.版本编号 - 使用 SCEP 版本 0。 List of each of the recipients and the related encrypted data-encryption key - With SCEP, there is only one recipient (for requests: the CA server; for responses: the client).每个收件人的列表和相关的加密数据加密密钥 - 使用 SCEP，只有一个收件人(用于请求：CA 服务器; 用于响应：客户端)。 The encrypted data - This is encrypted with a randomly generated key (that has been encrypted with the recipient’s public key).加密数据 - 这是用随机生成的密钥(已与收件人的公钥加密)加密的。PKCS#10PKCS#10 describes the format of a CSR. A CSR contains the information that clients request be included within their certificates:PKCS#10 描述了 CSR 的格式。CSR 包含客户请求包含在其证书中的信息： Subject Name 主题名称 A copy of the public key 公共密钥副本 A challenge password (optional)质询密码(可选) Any certificate extensions reqested, such as:任何已重新访问的证书扩展，例如： Key Usage (KU)密钥用途 (KU) Extended Key Usage (EKU)扩展密钥使用 (EKU) Subject Alternative Name (SAN)主题替代名称 (SAN) Universal Principal Name (UPN)通用主名称 (UPN) A fingerprint of the request 请求的指纹Here is an example of a CSR:Certificate Request: Data&amp;amp;colon; Version: 0 (0x0) Subject: CN=scepclient Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (1024 bit) Modulus: 00:cd:46:5b:e2:13:f9:bf:14:11:25:6d:ff:2f:43: 64:75:89:77:f6:8a:98:46:97:13:ca:50:83:bb:10: cf:73:a4:bc:c1:b0:4b:5c:8b:58:25:38:d1:19:00: a2:35:73:ef:9e:30:72:27:02:b1:64:41:f8:f6:94: 7b:90:c4:04:28:a1:02:c2:20:a2:14:da:b6:42:6f: e6:cb:bb:33:c4:a3:64:de:4b:3a:7d:4c:a0:d4:e1: b8:d8:71:cc:c7:59:89:88:43:24:f1:a4:56:66:3f: 10:25:41:69:af:e0:e2:b8:c8:a4:22:89:55:e1:cb: 00:95:31:3f:af:51:3f:53:ad Exponent: 65537 (0x10001) Attributes: challengePassword : Requested Extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Subject Alternative Name: DNS:webserver.example.com Signature Algorithm: sha1WithRSAEncryption 8c:d6:4c:52:4e:c0:d0:28:ca:cf:dc:c1:67:93:aa:4a:93:d0: d1:92:d9:66:d0:99:f5:ad:b4:79:a5:da:2d:6a:f0:39:63:8f: e4:02:b9:bb:39:9d:a0:7a:6e:77:bf:d2:49:22:08:e2:dc:67: ea:59:45:8f:77:45:60:62:67:64:1d:fe:c7:d6:a0:c3:06:85: e8:f8:11:54:c5:94:9e:fd:42:69:be:e6:73:40:dc:11:a5:9a: f5:18:a0:47:33:65:22:d3:45:9f:f0:fd:1d:f4:6f:38:75:c7: a6:8b:3a:33:07:09:12:f3:f1:af:ba:b7:cf:a6:af:67:cf:47: 60:fcSCEP 请求请求消息格式请求以 HTTP GET 表格形式发送：GET CGI-path/pkiclient.exe?operation=operation&amp;amp;message=message HTTP/version分析 CGI-path - 依赖于服务器，并指向处理 SCEP 请求的共同网关接口 (CGI) 程序： 思科 IOS® CA 使用空路径字符串。 微软 CA 使用/certsrv/mscep/mscep.dll，它指向 MSCEP/网络设备注册服务 (NDES) IIS 服务。 operation - 识别执行的操作。 message - 携带该操作的其他数据(如果不需要实际数据，则可以为空)。使用 GET 方法，message部分可以是纯文本，或是由区分编码规则 (DER) 编码的 PKCS#7 转换的 Base64 格式数据。如果支持 POST方法，则可能以二进制格式取代的 GET 发送的 Base64 编码的内容。请求结构说明operation及其相关消息值的可能值： operation = PKIOperation时: message是一个 SCEP pkiMessage结构，基于 PKCS#7，并编码为 DER 和 Base64。 pkiMessage结构可以是这些类型的： PCCSReq：PCKCS#10 CSR GetCertInitial：CSR 签署状态的轮询 GetCert or GetCRL：证书或 CRL 检索 operation = GetCACert, GetNextCACert, or (optional)GetCACaps时 message可以被省略，也可以被设置为标识 CA 的名称。 SCEP 响应响应消息格式SCEP 响应将作为标准 HTTP 内容返回，Content-Type 取决于原始请求和返回的数据类型。DER 内容以二进制内容返回(不使用和请求一样的 Base64)。PKCS#7 内容可能包含或可能不包含加密/签名的信封数据(enveloped data);如果不包含(只包含一组证书)，它被称为退化的 PKCS#7。Content-TypeContent-Type 可能值： application/x-pki-message: 响应 PKIOperation 操作，这些请求附带 pkiMessage 类型：PKCSReq、GetCertInitial、GetCert 或 GetCRL 响应主体是 pkiMessage 类型：CertRep application/x-x509-ca-cert: 响应 GetCACert 操作 响应主体是 DER 编码的 X.509 CA 证书 application/x-x509-ca-ra-cert: 响应 GetCACert 操作 响应主体是包含 CA 和 RA 证书的 DER 编码的退化 PKCS#7 application/x-x509-next-ca-cert: 响应 GetNextCACert 操作 响应主体是 pkiMessage 类型的变体： CertRep pkiMessage 结构SCEP OIDs2.16.840.1.113733.1.9.2 scep-messageType2.16.840.1.113733.1.9.3 scep-pkiStatus2.16.840.1.113733.1.9.4 scep-failInfo2.16.840.1.113733.1.9.5 scep-senderNonce2.16.840.1.113733.1.9.6 scep-recipientNonce2.16.840.1.113733.1.9.7 scep-transId2.16.840.1.113733.1.9.8 scep-extensionReqSCEP pkiMessage PKCS#7 签名数据(SignedData) PKCS#7 信封数据(EnvelopedData)(称为 pkcsPKIEnvelope;可选，加密到消息接收者) messageData(CSR， 证书， CRL，…) 具有经过验证的属性的签名信息(SignerInfo with authenticatedAttributes)： transactionID, messageType, senderNonce pkiStatus, recipientNonce (response only) failInfo (response + failure only) SCEP messageType 请求： PCCSReq (19)： PCKCS#10 CSR GetCertInitial(20)：证书签署状态轮询 GetCert(21)： 证书检索 GetCRL (22)： CRL 检索 响应： CertRep(3)： 对证书或 CRL 请求的响应 SCEP pkiStatus SUCCESS (0)： 授予请求 (pkcsPKIEnvelope 中的响应) FAILURE(2)： 请求被拒绝 (失败信息属性中的详细信息) PENDING (3)： 请求等待人工批准参考 Simple Certificate Enrollment Protocol Overview - Cisco SCEP 协议简介_weixin_44966126 的博客-CSDN 博客 Cisco Systems’ Simple Certificate Enrollment Protocol draft-nourse-scep-22 Simple Certificate Enrollment Protocol - Wikipedia RFC 8894" }, { "title": "Linux系统中内存不足导致system()执行失败的问题", "url": "/posts/memory-fork-error/", "categories": "技术", "tags": "linux, system, fork", "date": "2021-09-08 09:00:00 +0800", "snippet": "在实际项目中遇到了现场大量设备升级后无法上线的问题，经过几天的分析发现是升级占用了大量内存导致system()函数执行失败，也就是无法通过C程序执行shell脚本，造成了设备异常。本文将对问题原因与解决方案做详细介绍问题简介现场设备挂网时间有1年多了，打算进行远程升级以支持更多功能与提高稳定性。首次选择了200个设备进行小批量验证，但升级成功率很低，有将近3/4的设备升级失败，且升级失败后大部分进入异常状态，无法进行通信，也就是处于离线状态。两天后离线的设备陆续上线，推测原因可能是异常时间较长导致主进程崩溃，随即触发了硬件看门狗复位设备，且重新上线后设备各项功能都正常。原因分析首先是分析日志，对于还可以正常通信的设备的日志进行分析，发现升级失败原因为升级包校验失败，升级包的传输应该是不会有问题的，校验失败应该另有隐情。仔细分析了报错信息后，发现频繁打印”script execute error.”，这个是应用里对system的一个封装函数的打印，发生条件是system()函数返回非0值。所以可以初步确定校验失败的原因就是校验脚本执行失败。实际上 system 函数内部干了三件事情： fork 创建一个子进程 在子进程中调用 exec 函数去执行 command 在父进程中调用 waitpid 去等待子进程结束关于fork的详细介绍，在我之前写的《Operating Systems: Three Easy Pieces》学习笔记(三) 插叙：进程 API一文里有介绍问题很有可能发生在fork阶段，从这方面入手进行了模拟测试，终于发现在系统内存占用较高时fork会有失败的现象。那又是什么导致现场占用内存这么高呢？问题肯定和校验脚本有关，因为每次发生问题都是在校验脚本开始执行之后。仔细检查了校验脚本，发现该脚本会解压一次升级文件并放在/tmp分区，tmp分区时tmpfs格式分区，也就是内存分区，将内存当作磁盘使用。tmpfs分区是动态分配的，做法是有多少占多少。当tmpfs分区占用太大时会导致内存不足。分析结果至此，问题已经明确，升级校验过程中执行的校验脚本在tmpfs分区解压了升级包，导致tmpfs分区占用过高，占用了部分内存。同时由于该设备是边缘网关，现场子节点较多，导致采集程序也占用了较高的内存，以上两者共同作用，导致了内存不足。内存不足引发fork失败，后续的升级脚本无法执行，通信模块复位也无法进行，导致升级失败和无法通信的现象解决方案 分析发现校验脚本不需要解压升级包，因为升级脚本会做这件事，把这步删了，可以省下很多内存 封装所有system()和fork()函数，对于调用失败的情况，复位设备，如果出现异常，统计到达一定次数后触发异常保护，比如关闭进程或重启系统下面是封装函数的源码：/** * @brief system函数封装 * * @param szCmd * @return int -1：执行失败; 0:执行成功; 其他:exit code */int systemcmd(const char *szCmd){ Log::Inf(&quot;systemcmd:&quot;); Log::Inf(&quot;%s&quot;, szCmd); pid_t status; status = pox_system(szCmd); if (time(NULL) - first_error_time &amp;gt; 3600) { system_exec_error = 0; } if (-1 == status) { Log::Err(&quot;system cmd exec error: -1&quot;); if (system_exec_error == 0) { first_error_time = time(NULL); } system_exec_error++; Log::Err(&quot;system cmd exec error times: %d&quot;, system_exec_error); if (system_exec_error &amp;gt;= MAX_EXEC_ERROR) { Log::Err(&quot;too many exec error, reboot dcu:%d&quot;, system_exec_error); saveErrorLog(); exit(0); } return -1; } else { Log::Inf(&quot;exit status value = [0x%x]&quot;, status); if (WIFEXITED(status)) { if (WEXITSTATUS(status) == 0) { Log::Inf(&quot;run shell script successfully.&quot;); } else { Log::Err(&quot;run shell script fail, script exit code: %d&quot;, WEXITSTATUS(status)); } return WEXITSTATUS(status); } else { Log::Err(&quot;exit status = [%d]&quot;, WIFEXITED(status)); return -1; } }}感想分析这个问题的过程其实走了很多弯路，比如还考虑过SIGCHLD信号的问题。在日志信息不全，时间紧迫的情况下，也能把问题分析出来，从这件事也印证出没有什么问题是解决不了的，遇到问题不要慌，按部就班一个个分析，总能有头绪的。当然还有程序设计上，对于系统函数要做一下封装，比如system()或者fork()函数，一是在执行异常时可以通过复位解决问题，二是防止分析日志的时候抓瞎。参考 fork之后父子进程的内存关系_Shreck66的专栏-CSDN博客 Linux 中 popen 函数与 system 函数的区别_胡小哲的博客-CSDN博客" }, { "title": "DHCPv6 relay的使用", "url": "/posts/dhcpv6-relay/", "categories": "技术", "tags": "dhcp, dhcpv6, relay", "date": "2021-09-08 09:00:00 +0800", "snippet": "本文将介绍如何使用DHCPv6 relay技术转发DHCPv6请求，包括widedhcpv6的交叉编译和配置DHCPv6简介在DHCPv6基础-曹世宏的博客一文对于DHCPv6协议做了详细的介绍，另可查看DHCPv6 IETF标准文档RFC8415，本文不再赘述。DHCPv6 relay(中继代理)的作用就是将原来的DHCPv6多播(multicast)方式转化为单播(unicast)报文，从而可以跨网关传输DHCPv6的请求响应，一般的使用场景是DHCPv6客户端与服务器不在同一个链路的情况工具 WIDE-DHCPv6 arm-none-linux-gnueabi-gcc(Sourcery CodeBench Lite 2014.05-29) 编译实现DHCPv6 relay功能的开源工具并不多，而且很多已经长时间没维护了，试了好几个工具后，最后选择了WIDE-DHCPv6作为项目中使用的工具。编辑configure修改configure文件echo &quot;$as_me: error: cannot check setpgrp when cross compiling&quot; &amp;gt;&amp;amp;2;}{ (exit 1); exit 1; };}为echo &quot;$as_me: error: cannot check setpgrp when cross compiling&quot; &amp;gt;&amp;amp;2;}#{ (exit 1); exit 1; };}执行配置脚本CFLAGS=&quot;-D_GNU_SOURCE&quot; ./configure --host=arm-none-linux-gnueabi --prefix=$PWD/build编辑cftoken.c添加int yywrap() {return 1;}执行编译与安装WIDE-DHCPv6不需要额外依赖，可直接编译，生成的目标文件为单独的二进制文件。执行以下命令即可：make &amp;amp; make install使用WIDE-DHCPv6的使用非常简单，甚至不需要配置文件，参数说明如下：NAME dhcp6relay — DHCPv6 relay agentSYNOPSIS dhcp6relay [-Ddf] [-b boundaddr] [-H hoplim] [-r relay-IF] [-s serveraddr] [-S script-file] [-p pid-file] interface ...DESCRIPTION dhcp6relay acts as an intermediary to deliver DHCPv6 messages between clients and servers, and is on the same link as a client. dhcp6relay needs command line arguments interface ..., which specifies the list of links accommodating clients. Options supported by dhcp6relay are: -d Print debugging messages. -D Even more debugging information is printed. -f Foreground mode (useful when debugging). Although dhcp6relay usually prints warning, debugging, or error messages to syslog(8), it prints the messages to standard error if this option is specified. -b boundaddr Specifies the source address to relay packets to servers (or other agents). -H hoplim Specifies the hop limit of DHCPv6 Solicit messages forwarded to servers. -r relay-IF Specifies the interface on which messages to servers are sent. When omitted, the same interface as interface will be used. When multiple interface are specified, this option cannot be omitted. -s serveraddr Specifies the DHCPv6 server address to relay packets to. If not specified, packets are relayed to ff05::1:3 (All DHCPv6 servers). -S script-file Specifies the script file to be executed when dhcp6relay receives a RELAY-REPLY message from a DHCPv6 server. Further detail of the script file syntax is available in dhcp6c(8) -p pid-file Use pid-file to dump the process ID of dhcp6relay.FILES /var/run/dhcp6relay.pid is the default file that contains pid of the currently running dhcp6relay.SEE ALSO dhcp6c(8), dhcp6s(8) Ralph Droms, Editor, Dynamic Host Configuration Protocol for IPv6 (DHCPv6), RFC 3315, 2003.HISTORY The dhcp6relay command first appeared in WIDE/KAME IPv6 protocol stack kit.根据该配置说明进行配置即可，其中-s参数比较重要，用于指定服务端的地址；最后需要加上网口用于监听客户端DHCPv6请求示例./dhcp6relay -dD -s fd12::58 tun0参考 DHCPv6基础-曹世宏的博客 RFC3315 RFC8415 Ubuntu Manpage:dhcp6relay—DHCPv6 relay agent" }, { "title": "使用PlantUML绘制类图", "url": "/posts/plantuml-vscode/", "categories": "技术", "tags": "PlantUML, UML, vscode, C++", "date": "2021-08-04 09:00:00 +0800", "snippet": "本文基于 vscode 的 PlantUML 插件绘制类图。类的 UML 表示使用 UML 表示一个类，主要由三部分组成。类名、属性、方法。其中属性和方法的访问修饰符用 - 、# 、+ 表示 private、protected、public。如图所示，表示A类有一个private属性，protected 构造函数和public方法。@startumlclass A{ - String field + A() # void method()}note right: 这是测试类 A@enduml类的关系在面向对象语言中，类的关系有很多种，可以概括为三类：泛化、依赖、关联。泛化泛化指父类跟子类的关系,表示is-a的关系。如父类是抽象类或普通类，则这种关系叫继承。如，父类是接口，则这种关系叫实现。UML 中，继承和实现由不同的标记表示。继承PlantUML 用 --|&amp;gt; 表示继承关系。实线和三角形的抽象表示，指向谁，即继承谁。@startuml class A abstract B &#39; A 继承 B A --|&amp;gt; B@enduml实现PlantUML 用 ..|&amp;gt; 表示实现关系。虚和三角形的抽象表示，指向谁，即实现谁。@startuml class A interface C &#39; A 实现 C A ..|&amp;gt; C@enduml依赖类之间，最弱的关联方式。常用于在 A 类的方法中使用 B 类的对象作为参数、局部变量或者对 B 类静态方法的调用。PlantUML 用 ..&amp;gt; 表示依赖关系。虚线和箭头的抽象表示，指向谁，即依赖谁。@startuml class A class B &#39; A 依赖 B A ..&amp;gt; B@enduml关联关联关系，即对象之间的引用关系。常使用类的属性表达。单向关联B 类作为 A 类的属性，表示 A 类与 B 类有关联。 PlantUML 用 --&amp;gt; 表示单向关联。实线线和箭头的抽象表示，指向谁，即关联谁。@startuml class A{ - B b } class B &#39; A 关联 B A --&amp;gt; B@enduml双向关联B 类作为 A 类的属性同时，A 类也是 B 类的属性，表示双向关联。 PlantUML 用 -- 表示双向关联。或者用&amp;lt;--&amp;gt;。@startuml class A{ - B b } class B{ - A a } &#39; A 关联 B A -- B@enduml自关联A 类关联 A 类自身。常见于单例模式。@startuml class A{ - A a } &#39; A 关联 A A --&amp;gt; A@enduml聚合在关联关系的基础上，延伸出聚合关系，强的关联关系，表示has-a关系。整体与部分的关系，部分不依赖于整体，可独立存在。常用于成员变量。如；汽车和轮胎的关系，轮胎可作为独立的商品出售。PlantUML 用 o-- 表示聚合关系。实线和空心菱形的抽象表示，指向谁，表示谁是整体。@startuml class Car{ - List&amp;lt;Wheel&amp;gt; wheels } class Wheel &#39; Car 关联 Wheel Car &quot;1&quot; o-- &quot;4&quot; Wheel@enduml图中数字1和4也表示一对多关联。N对N同理。组合在关联关系的基础上，延伸出另外一种关联关系，组合关系，表示contains-a关系。整体与部分的关系，部分依赖于整体，不可独立存在。常用于成员变量。如：身体和动作的关系。PlantUML 用 *-- 表示聚合关系。实线和实心菱形的抽象表示，指向谁，表示谁是整体。@startuml class Body{ - List&amp;lt;Action&amp;gt; actions } class Action &#39; Body 关联 Action Body &quot;1&quot; *-- &quot;N&quot; Action@endumlPlantUML 排版相比较其他的 UML 软件或插件。PlantUML 的优势在于，存储的是文本文件，可以方便的进行团队协作以及高度可定制化的依赖关系。但是，最大的缺点在于，排版是通过插件自动生成的，排版效果不尽人意。因此，PlantUML 提供四个关键字 up down left right。指定类与类之间的相对关系。default@startumlclass A1class B1A1 --&amp;gt; B1class A2class B2A2 &amp;lt;-- B2@enduml箭头向左时，被指向对象在上； 箭头向右时，被指向对象在下。up@startumlclass A1class B1A1 -up-&amp;gt; B1class A2class B2A2 &amp;lt;-up- B2@enduml使用 up 时，被指向对象在上。down@startumlclass A1class B1A1 -down-&amp;gt; B1class A2class B2A2 &amp;lt;-down- B2@enduml使用 down 时，被指向对象在下。left@startumlclass A1class B1A1 -left-&amp;gt; B1class A2class B2A2 &amp;lt;-left- B2@enduml使用 left 时，被指向对象在左。right@startumlclass A1class B1A1 -right-&amp;gt; B1class A2class B2A2 &amp;lt;-right- B2@enduml使用 right 时，被指向对象在右。问题汇总找不到dot.exe路径下载Graphviz，配置环境变量参考这里，配置vscode参数。&quot;plantuml.commandArgs&quot;: [ &quot;-DGRAPHVIZ_DOT=C:\\\\Program Files (x86)\\\\Graphviz\\\\bin\\\\dot.exe&quot;,]总结画类图，只是 PlantUML 的功能之一，还可以使用它画时序图、用例图、活动图等。更多用法，请关注后续博客或访问官网。参考 使用PlantUML绘制类图 PlantUML官网" }, { "title": "strongSwan与Cisco CSR 1000V建立IPSec vpn调试记录", "url": "/posts/strongswan-cisco-ipsecvpn/", "categories": "技术", "tags": "strongSwan, Cisco, IPSec, VPN", "date": "2021-07-28 09:00:00 +0800", "snippet": "因项目需要，要让边缘计算网关与 Cisco CSR 1000V 连接，连接方式为 IPSec VPN，在本文记录下调试过程环境介绍客户端信息本次使用的客户端设备为一台边缘计算网关设备，运行 Linux 系统，使用 strongSwan 工具进行 vpn 连接 参数 值 MCU SCM601L216UE model ARM926EJ-S rev 5 (v5l) flash 256MB RAM 64MB OS Linux 3.10.108 strongswan 5.9.2 busybox 1.29.3 toolchain arm-none-linux-gnueabi-gcc 4.8.3 ip 公网 ipv4 服务端信息本次使用的服务端设备为一台服务器，运行 Cisco Cloud Services Router (CSR) 1000V 路由软件，部署在巴西，网络环境为 IPv4 NATCisco Cloud Services Router (CSR) 1000V 是一款软件路由器，企业或云提供商可将其作为虚拟机 (VM) 部署在提供商托管云中，提供路由器相关功能等。IPSec VPN 软件有几个开源项目支持互联网密钥交换 （IKE） 和 IPSec 协议来构建安全的 L2L 隧道： Free Secure Wide-Area Networking (freeS/WAN):版本较老，未积极维护 ipsec-tools:racoon - 不支持 Ikev2， 旧的 Linux kernel 2.6 Openswan:非常基本的 IKEv2 支持，旧的 Linux kernel 2.6 和更早的 API，不积极维护 strongSwan:支持 IKEv2 和 EAP/mobility，新的 Linux kernel 3.x 及之后的版本，使用 NETKEY API（这是 kernel 2.6 及以后的原生 IPSec 实现名称），积极维护，记录良好目前，最好的选择通常是 strongSwan。strongSwan 移植由于网关设备上并不包含 strongSwan 工具，需要从源码执行交叉编译，并移植strongSwan 下载从官网下载界面下载最新版本，当前最新版本为 5.9.2，https://download.strongswan.org/strongswan-5.9.2.tar.gzstrongSwan 交叉编译 解压下载的文件，进入 strongswan 目录，输入配置命令./configure --host=arm-none-linux-gnueabi --prefix=/media/disk/strongswan \\LDFLAGS=&quot;-Wl,-rpath,/root/repo/openssl/lib -L/root/repo/openssl/lib/&quot; \\CFLAGS=-I/root/repo/openssl-1.0.2l/include --disable-gmp --disable-aes \\--disable-hmac --enable-openssl --disable-ikev1 --disable-des \\--disable-vici --disable-swanctl --disable-curve25519 --disable-pkcs1 \\--disable-pkcs7 --disable-pkcs12 --disable-rc2 --enable-save-keys –host: 指定交叉编译工具的 prefix –prefix: 指定 install 目录 LDFLAGS: 指定 openssl 的库目录 CFLAGS: 指定 openssl 的头文件目录 –disable-gmp: 关闭 gmp 插件，gmp 提供 RSA/DH 加解密后端 –disable-aes：关闭自带的 aes 功能，使用 openssl 提供的 aes 功能 –disable-hmac: 关闭自带的 hmac 功能，使用 openssl 提供的 hmac 功能 –enable-openssl: 启用 openssl 插件，提供 RSA/ECDSA/DH/ECDH/ciphers/hashers/HMAC/X.509/CRL/RNG 加解密后端 –enable-save-keys: 启用密钥保存功能，能够在 esp 建立时保存密钥，仅作为调试使用有关 strongSwan 插件的相关信息，可在https://wiki.strongswan.org/projects/strongswan/wiki/Pluginlist查看执行后会显示如下内容 strongSwan will be built with the following plugins-----------------------------------------------------libstrongswan: sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs8 pgp dnskey sshkey pem openssl fips-prf xcbc cmac drbglibcharon: attr kernel-netlink resolve save-keys socket-default stroke updown counterslibtnccs:libtpmtss: 输入 make &amp;amp; make install，程序文件会放在 prefix 对应的目录下注意：程序运行时的环境地址就是 prefix 指定的地址，程序会从该地址读取配置文件，所以移植程序时，需要放在和 prefix 相同的目录下启用内核功能需要的内核组件已在官网给出https://wiki.strongswan.org/projects/strongswan/wiki/KernelModules由于网关设备是嵌入式设备，就不使用模块化编译了，直接编译进内核就行Include the following modules: Networking ---&amp;gt; Networking options ---&amp;gt; Transformation user configuration interface [CONFIG_XFRM_USER] TCP/IP networking [CONFIG_INET] IP: advanced router [CONFIG_IP_ADVANCED_ROUTER] IP: policy routing [CONFIG_IP_MULTIPLE_TABLES] IP: AH transformation [CONFIG_INET_AH] IP: ESP transformation [CONFIG_INET_ESP] IP: IPComp transformation [CONFIG_INET_IPCOMP] The IPv6 protocol ---&amp;gt; [CONFIG_IPV6] IPv6: AH transformation [CONFIG_INET6_AH] IPv6: ESP transformation [CONFIG_INET6_ESP] IPv6: IPComp transformation [CONFIG_INET6_IPCOMP] IPv6: Multiple Routing Tables [CONFIG_IPV6_MULTIPLE_TABLES] Network packet filtering framework (Netfilter) ---&amp;gt; [CONFIG_NETFILTER] Core Netfilter Configuration ---&amp;gt; Netfilter Xtables support [CONFIG_NETFILTER_XTABLES] IPsec &quot;policy&quot; match support [CONFIG_NETFILTER_XT_MATCH_POLICY]Note: For kernel versions before 5.2, the required IPsec modes have to be enabled explicitly (they are built-in for newer kernels). Networking ---&amp;gt; Networking options ---&amp;gt; TCP/IP networking [CONFIG_INET] IP: IPsec transport mode [CONFIG_INET_XFRM_MODE_TRANSPORT] IP: IPsec tunnel mode [CONFIG_INET_XFRM_MODE_TUNNEL] IP: IPsec BEET mode [CONFIG_INET_XFRM_MODE_BEET] The IPv6 protocol ---&amp;gt; [CONFIG_IPV6] IPv6: IPsec transport mode [CONFIG_INET6_XFRM_MODE_TRANSPORT] IPv6: IPsec tunnel mode [CONFIG_INET6_XFRM_MODE_TUNNEL] IPv6: IPsec BEET mode [CONFIG_INET6_XFRM_MODE_BEET]Note: For kernel versions 4.2-4.5, you will have to select Encrypted Chain IV Generator manually in order to use any encryption algorithm in CBC mode. Cryptographic API Select algorithms you want to use... Encrypted Chain IV Generator [CRYPTO_ECHAINIV]相关工具移植openssl 交叉编译strongSwan 需要 openssl 作为加解密后端，来支持更多特性 ./config no-zlib no-asm shared -DOPENSSL_THREADS -pthread \\ -D_REENTRANT -D_THREAD_SAFE -D_THREADSAFE --prefix=$PWD/install \\ --cross-compile-prefix=arm-none-linux-gnueabi-# 需要手动删除Makefile中的-m64选项make &amp;amp; make installiproute2 交叉编译需要使用 iproute2 工具查看一些 IPSec 相关的信息，busybox 提供的功能不太全，所以也移植一下从官网下载https://www.kernel.org/pub/linux/utils/net/iproute2/，我这边使用的是 4.1.0 版本，太高的版本编译器不支持编辑 Makefile，修改CC = arm-none-linux-gnueabi-gcc，以及HOSTCC = arm-none-linux-gnueabi-gcc，只启用 ip 功能SUBDIRS=ip执行 make 命令，可执行文件在 ip 目录下iptables 交叉编译网关设备不带 iptables 工具，需要移植从官网下载 1.8.7 版本，https://www.netfilter.org/pub/iptables/./configure --host=arm-none-linux-gnueabi --prefix=$PWD/build --disable-nftablesmake &amp;amp; make installtcpdump 交叉编译tcpdump 是 Linux 平台的抓包工具，纯命令行界面，抓到的 pcap 格式数据可以在 wireshark 中展示去 tcpdump 官网https://www.tcpdump.org/下载最新版本，我下载的是4.99.1，同时下载libpcap最新版本，我下载的是1.10.1解压到同一父目录下，进入 tcpdump 目录，输入./configure --host=arm-none-linux-gnueabi --prefix=$PWD/build这里会自动找到父目录下的 libpcap 目录make &amp;amp; make install 使用方法： tcpdump -i eth0 -w /var/tcpdump/eth0.pcapisc-dhcp 移植isc-dhcp 是一个 dhcp 工具箱，包含了 dhcp client，dhcp server 和 dhcp relay agent，支持 ipv6，可以说是功能最全面的一款 DHCP 工具了 前往官网https://www.isc.org/dhcp/下载最新稳定版本，我用的是 4.2.6 版本 配置 ./configure BUILD_CC=gcc --host=arm-none-linux-gnueabi --prefix=$PWD/build ac_cv_file__dev_random=yes进入 bind 目录，解压 bind.tar.gzcd bindtar -zxvf bind.tar.gz进入 bind-9.9.5 目录，编辑 vim lib/export/dns/Makefile.incd bind-9.9.5vim lib/export/dns/Makefile.in将gen: ${srcdir}/gen.c ${CC} ${ALL_CFLAGS} ${LDFLAGS} -o $@ ${srcdir}/gen.c ${LIBS}改为gen: ${srcdir}/gen.c ${BUILD_CC} ${ALL_CFLAGS} ${LDFLAGS} -o $@ ${srcdir}/gen.c ${LIBS} 回到 dhcp 目录make &amp;amp; make installstrongSwan 配置移植后的 strongSwan 在/media/disk/strongswan 目录下，配置文件都在 etc 目录下，正常情况下只需修改 etc 目录下的配置即可etc 目录结构：.├── ipsec.conf├── ipsec.d│   ├── aacerts│   ├── acerts│   ├── cacerts│   ├── certs│   ├── crls│   ├── ocspcerts│   ├── private│   └── reqs├── ipsec.secrets├── strongswan.conf└── strongswan.d ├── charon │   ├── attr.conf │   ├── cmac.conf │   ├── constraints.conf │   ├── counters.conf │   ├── dnskey.conf │   ├── drbg.conf │   ├── fips-prf.conf │   ├── kernel-netlink.conf │   ├── md5.conf │   ├── nonce.conf │   ├── openssl.conf │   ├── pem.conf │   ├── pgp.conf │   ├── pkcs8.conf │   ├── pubkey.conf │   ├── random.conf │   ├── resolve.conf │   ├── revocation.conf │   ├── sha1.conf │   ├── sha2.conf │   ├── socket-default.conf │   ├── sshkey.conf │   ├── stroke.conf │   ├── updown.conf │   ├── x509.conf │   └── xcbc.conf ├── charon.conf ├── charon-logging.conf ├── pki.conf ├── scepclient.conf └── starter.conf设置环境变量strongSwan 依赖 lib 目录下的库文件，由于网关设备使用了 ramfs 无法将库文件放入 lib 目录下，需要在运行前手动配置export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/media/disk/strongswan/libexport PATH=$PATH:/media/disk/strongswan/sbinipsec.conf 配置ipsec.conf 是老版本的配置文件，但比较直观，教程用的也比较多，还是选择用这个关于 ipsec.conf 的详细介绍，请看官网链接： 配置参数https://wiki.strongswan.org/projects/strongswan/wiki/ConfigSetupSection 连接参数https://wiki.strongswan.org/projects/strongswan/wiki/connsection贴一下个人配置：config setup # strictcrlpolicy=yes uniqueids = yes #charondebug=&quot;ike 3, knl 3, cfg 3, chd 3, lib 3, esp 3, tls 3&quot; # 调试信息等级 charondebug=&quot;ike 3, knl 3, cfg 3, esp 1, lib 3, chd 3, net 1, enc 1&quot;conn %default ikelifetime=24h keylife=8h rekeymargin=3m keyingtries=1 #authby=secret keyexchange=ikev2 mobike=no# 连接名称，host-host表示主机-主机，site-site表示子网-子网conn host-host type=transport left=%any # pem格式的客户端证书 leftcert=client.crt leftid=223.94.60.86 # 使用GRE协议 leftprotoport=47 right=128.201.18.34 # %any表示不指定，允许任何对端信息，一般用在right rightid=%any rightprotoport=47 keyexchange=ikev2 # ike握手加密算法 ike=aes256-sha256-modp1536 # esp加密算法 esp=aes256-sha256 auto=start # 自动重连 #dpdaction=restartipsec.secrets 配置ipsec.secrets 用于配置密钥密码信息 https://wiki.strongswan.org/projects/strongswan/wiki/Ipsecsecrets# PSK密码，安全等级较低，与ipsec.conf中的leftid,rightid对应223.94.60.86 : PSK &quot;#*SsG@Dq^@&amp;amp;DCr&quot;128.201.18.34 : PSK &quot;#*SsG@Dq^@&amp;amp;DCr&quot;10.230.93.19 : PSK &quot;#*SsG@Dq^@&amp;amp;DCr&quot;# 私钥位置，在etc/ipsec.d/private目录下: RSA client.keystrongswan.conf 配置strongswan.conf 是配置 strongSwan 这个应用相关的配置文件，包括插件启用，插件参数等 https://wiki.strongswan.org/projects/strongswan/wiki/strongswanconf# strongswan.conf - strongSwan configuration file## Refer to the strongswan.conf(5) manpage for details## Configuration changes should be made in the included filescharon { load_modular = yes multiple_authentication = no #install_routes = no plugins { include strongswan.d/charon/*.conf #kernel-netlink { #fwmark = !0x42 #} #socket-default { #fwmark = 0x42 #} kernel-libipsec { #allow_peer_ts = yes load = no } save-keys { esp = yes ike = yes load = yes wireshark_keys = /media/disk/tcpdump/keys } }}ipsec.d 目录ipsec.d 目录用于存放私钥与证书文件├── ipsec.d│   ├── aacerts│   ├── acerts│   ├── cacerts│   ├── certs│   ├── crls│   ├── ocspcerts│   ├── private│   └── reqsstrongswan.d 目录strongswan.d 目录用于存放应用与插件的精细配置strongSwan 运行strongSwan 的运行很简单，在完成配置后，只需在控制台运行ipsec start日志默认打印在syslog中查看状态ipsec statusall连接成功应该是这样的[root@sx sbin]# ./ipsec statusallStatus of IKE charon daemon (strongSwan 5.9.2, Linux 3.10.108, armv5tejl): uptime: 3 hours, since Aug 03 01:59:51 2021 malloc: sbrk 528384, mmap 0, used 195960, free 332424 worker threads: 11 of 16 idle, 5/0/0/0 working, job queue: 0/0/0/0, scheduled: 2 loaded plugins: charon save-keys sha2 sha1 md5 random nonce x509 revocation constraints pubkey pkcs8 pgp dnskey sshkey pem openssl fips-prf xcbc cmac drbg attr kernel-netlink resolve socket-default stroke updown countersListening IP addresses: 223.94.60.86 2001:db8:100::1 fd50:2000::2 fd25::3 fd24::3Connections: host-host: %any...128.201.18.34 IKEv2 host-host: local: [C=BR, ST=MG, O=Nansen, OU=Medicao, CN=strongs-01] uses public key authentication host-host: cert: &quot;C=BR, ST=MG, O=Nansen, OU=Medicao, CN=strongs-01&quot; host-host: remote: uses public key authentication host-host: child: dynamic[47] === dynamic[47] TRANSPORTSecurity Associations (1 up, 0 connecting): host-host[1]: ESTABLISHED 3 hours ago, 223.94.60.86[C=BR, ST=MG, O=Nansen, OU=Medicao, CN=strongs-01]...128.201.18.34[serialNumber=918UD8IEJZU, unstructuredName=CEMIGHER01A.ami.cemig.ad] host-host[1]: IKEv2 SPIs: 9f30ecd4bb9d05f6_i* d9ef0a0774caacba_r, public key reauthentication in 20 hours host-host[1]: IKE proposal: AES_CBC_256/HMAC_SHA2_256_128/PRF_HMAC_SHA2_256/MODP_1536 host-host{4}: INSTALLED, TRANSPORT, reqid 1, ESP in UDP SPIs: ce0100b2_i f84857bb_o host-host{4}: AES_CBC_256/HMAC_SHA2_256_128, 4350 bytes_i (51 pkts, 8s ago), 10403 bytes_o (103 pkts, 0s ago), rekeying in 7 hours host-host{4}: 223.94.60.86/32[47] === 128.201.18.34/32[47][root@sx sbin]#GRE 隧道本项目采用的是 host-host + GRE 模式，是为了 ip 的更换更加方便，GRE 可以实现 ipv6 in ipv4 的模式，从而让只支持 ipv4 的 vpn 隧道变为 ipv6 隧道。GRE 介绍通用路由封装（英语：Generic Routing Encapsulation，缩写：GRE）是一种可以在虚拟点对点链路中封装多种网络层协议的隧道协议。由思科系统开发，在RFC 2784中定义。GRE tun模式协议栈: OSI 模型分层 协议 5.会话层 X.225 4.传输层 UDP 3.网络层 (GRE 封装) IPv6 封装 GRE 3.网络层 IPv4 2.数据链路层 以太网 1.物理层 以太物理层 从上面的图表可以看出，协议封装（非特指 GRE）打破了 OSI 模型中定义的分层。这可以被看成两个不同协议栈中间的分割器，一个承载另一个。GRE 环境搭建在上面搭建好 host-host 隧道的基础上创建 GRE 隧道，这里需要注意下，GRE 隧道默认是位于三层（Layer 3）网络，不带 mac 信息的，在需要用到二层网络的地方需要使用 tap 模式 GRE tun 模式ip tunnel add gre1 mode gre remote 128.201.18.34 local 223.94.60.86 ttl 255ip link set gre1 upip addr add fd24::3/16 dev gre1 GRE tap 模式./ip link add gre1 type gretap remote 128.201.18.34 local 223.94.60.86 ttl 255./ip link set gre1 up./ip addr add fd24::3/16 dev gre1由于边缘计算网关 busybox 自带的 ip 命令功能不太全，所以用了iproute2工具此处的 ttl 值一定要设置，默认是根据包裹的协议的 ttl 来的，比如包的是 dhcp 协议，ttl 就变成 1 了，会导致问题添加路由默认 GRE 协议在创建的时候就配好路由，对端的路由需要配置配置到对端地址的路由ip -6 route add fd12::/16 dev gre1 metric 256如果使用的是 GRE-TAP，需要 mac 层信息，默认在发送报文前会发送 NDP 协议查找邻居，但是在 GRE 上不可行，所以要强制配好网关，网关地址即为对端 GRE 绑定地址ip -6 route add 2002:db8:1::/64 via fd25::1 dev gre2 metric 1024DHCPv6后续我会专门写一篇 DHCPv6 协议的介绍IKE协议ESP协议实例GRE-over-ipsec-tunnel 成功.zip参考 移植 dhcp-4.2.6 到 ARM-linux 通用路由封装 - 维基百科，自由的百科全书 strongSwan官网" }, { "title": "无线通信技术的变革与详解", "url": "/posts/wireless-comm/", "categories": "技术", "tags": "5G, QAM", "date": "2021-06-15 09:00:00 +0800", "snippet": "无线通信架构声音在无线网络中的传输这是一张关于无线通信过程的架构图，讲述了声音信号如何从发声人到接收人进行传递。 首先发送者的信号传递到了麦克风，由于人声的频率较低（100Hz 到 10000Hz），而无线通信频率较高（850/900/1800/1900MHz），需要通过调制器，将人声变成高频信号 之后通过功率放大器和发送天线，将信号发送出去 在对端接收到该信号后，通过逆过程，将信号转变为声音信号无线基站架构The baseband unit (BBU) is the baseband processing unit of telecom systems. The BBU has the advantage of modular design, small size, high integration, low power consumption and easy deployment. A typical wireless base station consists of the baseband processing unit (BBU) and the RF processing unit (remote radio unit - RRU). The BBU is placed in the equipment room and connected with the RRU via optical fiber. The BBU is responsible for communication through the physical interface.基带单元（BBU）是电信系统的基带处理单元。 BBU 具有模块化设计、体积小、集成度高、功耗低、部署方便等优点。 一个典型的无线基站由基带处理单元（BBU）和射频处理单元（远程无线电单元-RRU）组成。 BBU 放置在机房内，通过光纤与 RRU 相连。 BBU 负责通过物理接口进行通信。现代无线通信技术总览 蜂窝移动通信 调制技术(基带信号 → 高频信号) 通信方式(用来区分用户的技术) 1G FM/2FSK FDMA/频分多址 2G FSK/QPSK TDMA/时分多址 3G BPSK/QPSK/8PSK CDMA/码分多址 4G QAM/16QAM/64QAM OFDM/正交频分多址 调制技术介绍 发送端的原始电信号通常具有频率很低的频谱分量，一般不适宜直接在信道中进行传输。 通过调制可以将多个基带信号搬移到高频载波，实现频谱搬移。数字调制 幅移键控 ASK： 有幅度表示 1，无幅度表示 0 频移键控 FSK： 频率高表示 1，频率低表示 0 相移键控 PSK： 用不同相位表示不同信息 二进制相移键控 BPSK： 相移键控的特殊形式，只能用两个特定的相位表示 0 和 1 两个数字 正交相移键控 QPSK： 相移键控的特殊形式，可以使用 4 种相位，表示 4 种信息（两个比特），抗干扰能力减弱但速率提升 8 相移键控 8PSK： 相移键控的特殊形式，可以使用 8 种相位，表示 8 种信息（3 个比特），抗干扰能力进一步减弱但速率进一步提升 正交振幅调制 QAM： 如果期望混合后的信号的幅度和相位都能发生变化，用幅度和相位一起区分来区分不同波形，这就是 QAM 调制。当多进制调制中 N&amp;gt;=4, 不再采用 PSK 调制仅仅控制相位，而采用 QAM 调制控制相位与幅度，QAM 调制又称为高阶调制。 不同调制方式的比较 BPSK：2 进制相位调制，每个子载波携带 1 个比特的二进制数据，主要用于信道质量非常差的场景以及用于物联网应用的场景。 QPSK：4 进制相位调制, 每个子载波携带 2 个比特的二进制数据。 16QAM：16 进制相位幅度调制, 每个子载波携带 4 个比特的二进制数据。 64QAM：64 进制相位幅度调制, 每个子载波携带 6 个比特的二进制数据。 256QAM：256 进制相位幅度调制, 每个子载波携带 8 个比特的二进制数据。 1024QAM：1024 进制相位幅度调制, 每个子载波携带 10 个比特的二进制数据。主要应用在 5G.多址技术多址技术是用来区分用户的技术，先进的多址技术能让一个基站为更多用户服务移动通信是以多址技术来划分时代的FDMA-频分多址模拟信号(1G)是通过频率的不同来区分不同的用户（每个用户专属一段频率）TDMA-时分多址GSM(2G) 是通过及其微小的时隙来区别不同的用户（每个用户专属一段时间），类似于 CPU 调度策略中的时间片轮转(RR)CDMA-码分多址码分多址是指利用码序列相关性实现的多址通信;码分多址(CDMA)的基本思想是靠不同的地址码来区分的地址。每个配有不同的地址码，用户所发射的载波(为同一载波)既受基带数字信号调制，又受地址码调制。(类似于广播机制，同一频段客户端的都能收到，但只有属于自己的报文才会处理)接收时，只有确知其配给地址码的接收机，才能解调出相应的基带信号，而其他接收机因地址码不同，无法解调出信号。划分是根据码型结构不同来实现和识别的。一般选择伪随机码(PN 码)作地址码。由于 PN 码的码元宽度远小于 PCM 信号码元宽度(通常为整数倍)，这就使得加了伪随机码的信号频谱远大于原基带信号的频谱，因此，码分多址也称为扩频多址。 运营商 编码 联通 CDMA2000 Walsh 码（同步正交码） 移动 TD-SCDMA OVSF 码 电信 WCDMA OVSF 码 （正交可变扩频因子码） 虽然已有正交频分复用（OFDM） 的技术，但仍发展CDMA的原因主要为调制/解调并不需要太精确的频谱分析。而OFDM使用DFT需做复数运算，较CDMA使用Walsh Transform复杂。 CDMA 的优点条列如下： 运算量相对于频分多工减少很多 可以减少噪声及干涉的影响 可以应用在保密和安全传输上 就算只接收部分的信号，也有可能把原来的信号还原回来 相邻的区域的干扰问题可以减少OFDM-正交频分复用正交频分复用，英文原称 Orthogonal Frequency Division Multiplexing，缩写为OFDM，实际上是 MCM Multi-CarrierModulation 多载波调制的一种。其主要思想是：将信道分成若干正交子信道，将高速数据信号转换成并行的低速子数据流，调制到在每个子信道上进行传输。正交信号可以通过在接收端采用相关技术来分开，这样可以减少子信道之间的相互干扰 ICI。每个子信道上的信号带宽小于信道的相关带宽，因此每个子信道上的可以看成平坦性衰落，从而可以消除符号间干扰。而且由于每个子信道的带宽仅仅是原信道带宽的一小部分，信道均衡变得相对容易。在过去的频分复用（FDM）系统中，整个带宽分成 N 个子频带，子频带之间不重叠，为了避免子频带间相互干扰，频带间通常加保护带宽，但这会使频谱利用率下降。为了克服这个缺点，OFDM 采用 N 个重叠的子频带，子频带间正交，因而在接收端无需分离频谱就可将信号接收下来。OFDM 系统的一个主要优点是正交的子载波可以利用快速傅利叶变换（FFT/IFFT）实现调制和解调。OFDMA-正交频分多址正交频分多址 Orthogonal Frequency Division Multiple Access(OFDMA):OFDMA 是 OFDM 技术的演进，将 OFDM 和 FDMA 技术结合。在利用 OFDM 对信道进行副载波化后，在部分子载波上加载传输数据的传输技术。OFDM 是一种调制方式；OFDMA 是一种多址接入技术，用户通过 OFDMA 共享频带资源，接入系统。OFDMA 又分为子信道（Subchannel）OFDMA 和跳频 OFDMA。OFDMA技术与OFDM技术相比，用户可以选择条件较好的子载波进行数据传输，而不像OFDM技术那样，一个用户在整个频带内发送，从而保证了子载波都被对应信道条件较优的用户使用，获得了频率上的分集增益。在OFDMA中，一组用户可以同时接入到某一子载波。目前使用OFDMA的无线通信技术有：IEEE 802.16、Wi-Fi 6。参考 OFDMA-百度百科 正交频分复用-百度百科" }, { "title": "传输层安全(TLS)相关技术详解", "url": "/posts/tls-tech/", "categories": "技术", "tags": "DH, SSL/TLS, https", "date": "2021-06-09 09:00:00 +0800", "snippet": "TLS的目标传输层安全(TLS)是网络安全的主力。它允许网站向 Web 浏览器证明其身份，并保护所有交换的信息被加密且免受窥探。TLS 有两个主要目标：保密性和身份验证。两者对于在互联网上进行安全通信都至关重要。保密性主要由密钥安全交换技术和AES加密算法实现，身份验证主要由数字签名技术实现保密性对称密钥像RSA和DH这样的公共关键算法使用大量的CPU，是TLS握手中最慢的部分。笔记本电脑每秒只能执行几百个 RSA 加密，而对称密码 AES 的加密量约为 1000 万/秒。所以应用报文的加密使用的是对称加密技术，而RSA和DH仅用于对称密钥的交换。在 TLS 中，这种对称加密通常使用强大的块密码（如AES）完成。较旧的浏览器和平台可能会使用密码，如3DES或流密码RC4，这在现在被认为是不安全的。RSA密钥交换RSA密钥交换是目前最主流的密钥交换方式，握手方式如下：RSA密钥交换主要是用公钥加密对称密钥后传输，对方用私钥解密的过程RSA算法的本质是利用了一个数学原理：将两个大质数相乘非常容易，但要对其乘积进行因式分解却非常困难，详见RSA加密算法维基百科Diffie-Hellman密钥交换DH算法解决了密钥在双方不直接传递密钥的情况下完成密钥交换，这个神奇的交换原理完全由数学理论支持。我们来看DH算法交换密钥的步骤。假设甲乙双方需要传递对称密钥，他们之间可以这么做：甲首选选择一个素数p，例如509，底数g，任选，例如5，随机数a，例如123，然后计算A=g^a mod p，结果是215，然后，甲发送p＝509，g=5，A=215给乙；乙方收到后，也选择一个随机数b，例如，456，然后计算B=g^b mod p，结果是181，乙再同时计算s=A^b mod p，结果是121；乙把计算的B=181发给甲，甲计算s＝B^a mod p的余数，计算结果与乙算出的结果一样，都是121。所以最终双方协商出的密钥s是121。注意到这个密钥s并没有在网络上传输。而通过网络传输的p，g，A和B是无法推算出s的，因为实际算法选择的素数是非常大的。所以，更确切地说，DH算法是一个密钥协商算法，双方最终协商出一个共同的密钥，而这个密钥不会通过网络传输。DH算法的安全性数字可以分为两大部分：不可再分的数：prime number 质数可以再分的数：composite number 和数每个数字可以描述为一个“锁”每个数字有且只有一种质因数分解，把质因数分解看做是“钥匙”，任何两个数的质因数分解都不同。对于锁，有一个基本的要求：朝一个方向容易，朝反方向难。one-way function单向函数。在数学中，模算术（时钟算术）就是一个单向函数 X MOD P，如果P选择为质数，那么其值会在时钟上（1到P-1上）等可能均匀分布。正向计算3^x mod 17 = ？很容易反向计算3^? mod 17 = 12不容易，比如说P选择一个数百位的质数，那么想求出？只能采用试错法在DH算法握手的过程中，指数不会被传递，也就是说在网络攻击中指数是需要被破解的对象详见迪菲-赫爾曼密鑰交換维基百科DHE密钥交换固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。ECDHE密钥交换DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— ECDHE 算法。ECDHE 算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。小红和小明使用 ECDHE 密钥交换算法的过程：双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；双方各自随机生成一个随机数作为私钥d，并与基点 G相乘得到公钥Q(Q = dG)，此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；双方交换各自的公钥，最后小红计算点(x1，y1) = d1Q2，小明计算点(x2，y2) = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥。这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。具体算法详见椭圆曲线迪菲-赫尔曼金钥交换维基百科身份验证数字签名RSA算法和DH算法都需要交换公钥，如何保证公钥没有被中间人篡改，也是握手过程中需要解决的问题。TODO:签名算法涉及的东西也很多，现在还没有学习完，等待后续补充RSA签名常用数字签名算法有： MD5withRSA SHA1withRSA SHA256withRSA它们实际上就是指定某种哈希算法进行RSA签名的方式。DSA签名除了RSA可以签名外，还可以使用DSA算法进行签名。DSA是Digital Signature Algorithm的缩写，它使用ElGamal数字签名算法。DSA只能配合SHA使用，常用的算法有： SHA1withDSA SHA256withDSA SHA512withDSA和RSA数字签名相比，DSA的优点是更快。ECDSA签名椭圆曲线签名算法ECDSA：Elliptic Curve Digital Signature Algorithm也是一种常用的签名算法，它的特点是可以从私钥推出公钥。比特币的签名算法就采用了ECDSA算法，使用标准椭圆曲线secp256k1。参考 Keyless SSL: The Nitty Gritty Technical Details 图解 ECDHE 密钥交换算法 迪菲-赫爾曼密鑰交換维基百科 RSA加密算法维基百科 椭圆曲线迪菲-赫尔曼金钥交换维基百科" }, { "title": "关于VSCode使用Remote SSH时git gutter(代码差异装饰器)无法显示的问题", "url": "/posts/vscode-git-gutter/", "categories": "技术", "tags": "vscode, git, gutter", "date": "2021-05-08 09:00:00 +0800", "snippet": "diff decorations gutter介绍diff decorations gutter中文翻译为代码差异装饰器，就是在使用git或svn插件时代码编辑器序号旁边显示的彩色装饰条，点击可以看到改动后的内容和最后一次提交内容的差异这玩意看似简单，却是版本管理的利器，没有它我都不敢写代码了无法显示问题在使用Remote SSH进行远程开发时发现代码差异装饰器无法显示，通过查找发现是软链接的问题，就是打开的文件夹是软链接后的文件夹，导致VSCode无法识别。解决方法不要打开软链接文件夹，直接打开软链接指向的目录，问题解决" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(六) 调度：多级反馈队列", "url": "/posts/operating-systems-6/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-18 09:00:00 +0800", "snippet": "本章将介绍一种著名的调度方法–多级反馈队列（Multi-level Feedback Queue，MLFQ）。1962 年，Corbato 首次提出多级反馈队列，应用于兼容时分共享系统（CTSS）。Corbato 因在 CTSS 中的贡献和后来在 Multics 中的贡献，获得了 ACM 颁发的图灵奖（Turing Award）。该调度程序经过多年的一系列优化，出现在许多现代操作系统中。 提示：从历史中学习 多级反馈队列是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术（同样存在于计算机科学领域的很多其他地方，比如硬件的分支预测及缓存算法）。如果工作有明显的阶段性行为，因此可以预测，那么这种方式会很有效。当然，必须十分小心地使用这种技术，因为它可能出错，让系统做出比一无所知的时候更糟的决定。MLFQ：基本规则MLFQ 中有许多独立的队列（queue），每个队列有不同的优先级（priority level）。任何时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较高级队列中的工作）。对于同一个队列中的任务，采用轮转调度。MLFQ中工作优先级并不是固定的，而是会根据进程的行为动态调整优先级。例如，如果一个工作不断放弃 CPU 去等待键盘输入，这是交互型进程的可能行为，MLFQ 因此会让它保持高优先级。相反，如果一个工作长时间地占用 CPU，MLFQ 会降低其优先级。MLFQ 的两条基本规则: 规则 1：如果 A 的优先级 &amp;gt; B 的优先级，运行 A（不运行 B）。 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B 。尝试 1：如何改变优先级我们必须决定，在一个工作的生命周期中，MLFQ 如何改变其优先级（在哪个队列中）。要做到这一点，我们必须记得工作负载：既有运行时间很短、频繁放弃 CPU 的交互型工作，也有需要很多 CPU 时间、响应时间却不重要的长时间计算密集型工作。下面是我们第一次尝试优先级调整算法。 规则 3 ：工作进入系统时，放在最高优先级（最上层队列）。 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。 规则 4b：如果工作在其时间片以内主动释放 CPU，则优先级不变。实例 1：单个长工作从这个例子可以看出，该工作首先进入最高优先级（Q2）。执行一个 10ms 的时间片后，调度程序将工作的优先级减 1，因此进入 Q1。在 Q1 执行一个时间片后，最终降低优先级进入系统的最低优先级（Q0），并一直留在那里。实例 2：加入一个短工作B 在 T=100 时到达如果不知道工作是短工作还是长工作，那么就在开始的时候假设其是短工作，并赋予最高优先级。如果确实是短工作，则很快会执行完毕，否则将被慢慢移入低优先级队列，而这时该工作也被认为是长工作了。通过这种方式，MLFQ 近似于 SJF(最短任务优先)。实例 3：如果有 I/O 呢交互型工作 B（用灰色表示）每执行 1ms 便需要进行 I/O 操作，它与长时间运行的工作 A（用黑色表示）竞争 CPU。MLFQ 算法保持 B 在最高优先级，因为 B 总是让出 CPU。如果 B 是交互型工作，MLFQ 就进一步实现了它的目标，让交互型工作快速运行当前 MLFQ 的一些问题 饥饿（starvation）问题。如果系统有“太多”交互型工作，就会不断占用 CPU，导致长工作永远无法得到 CPU（它们饿死了）。 愚弄调度程序（game the scheduler）。愚弄调度程序指的是用一些卑鄙的手段欺骗调度程序，让它给你远超公平的资源。上述算法对如下的攻击束手无策：进程在时间片用完之前，调用一个 I/O 操作（比如访问一个无关的文件），从而主动释放 CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。 一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间需要作为一个交互型的进程。用我们目前的方法，它不会享受系统中其他交互型工作的待遇。因为优先级一旦下降就无法提升尝试 2：提升优先级为解决[1]饥饿问题 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。 左边没有优先级提升，长工作在两个短工作到达后被饿死。 右边每 50ms 就有一次优先级提升（这里只是举例，这个值可能过小），因此至少保证长工作会有一些进展，每过 50ms 就被提升到最高优先级，从而定期获得执行。添加时间段 S 导致了明显的问题：S 的值应该如何设置？德高望重的系统研究员 John Ousterhout 曾将这种值称为“巫毒常量（voo-doo constant）”，因为似乎需要一些黑魔法才能正确设置。如果 S 设置得太高，长工作会饥饿；如果设置得太低，交互型工作又得不到合适的 CPU 时间比例。尝试 3：更好的计时方式为解决[2]愚弄调度程序问题起因是规则 4a 和 4b 不合理，调度程序应该记录一个进程在某一层中消耗的总时间，而不是在调度时重新计时。重写规则 4： 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）。没有规则 4的保护时，进程可以在每个时间片结束前发起一次 I/O 操作，从而垄断 CPU 时间。有了这样的保护后，不论进程的 I/O 行为如何，都会慢慢地降低优先级，因而无法获得超过公平的 CPU 时间比例。同时由于规则 5的存在，原来的交互性进程还是可以在之后提升优先级。MLFQ 调优及其他问题关于 MLFQ 调度算法还有一些问题。其中一个大问题是如何配置一个调度程序，例如： 配置多少队列？ 每一层队列的时间片配置多大？ 为了避免饥饿问题以及进程行为改变，应该多久提升一次进程的优先级？这些问题都没有显而易见的答案，因此只有利用对工作负载的经验，以及后续对调度程序的调优，才会导致令人满意的平衡。例如，大多数的 MLFQ 变体都支持不同队列可变的时间片长度。高优先级队列通常只有较短的时间片（比如 10ms 或者更少），因而这一层的交互工作可以更快地切换。相反，低优先级队列中更多的是 CPU 密集型工作，配置更长的时间片会取得更好的效果。图 8.7 展示了一个例子，两个长工作在高优先级队列执行 10ms，中间队列执行 20ms，最后在最低优先级队列执行 40ms。Solaris 的 MLFQ 实现（时分调度类 TS）很容易配置。它提供了一组表来决定进程在其生命周期中如何调整优先级，每层的时间片多大，以及多久提升一个工作的优先级。管理员可以通过这些表，让调度程序的行为方式不同。该表默认有 60 层队列，时间片长度从 20ms（最高优先级），到几百 ms（最低优先级），每一秒左右提升一次进程的优先级。其他一些 MLFQ 调度程序没用表，甚至没用本章中讲到的规则，有些采用数学公式来调整优先级。例如，FreeBSD 调度程序（4.3 版本），会基于当前进程使用了多少 CPU，通过公式计算某个工作的当前优先级。另外，使用量会随时间衰减，这提供了期望的优先级提升，但与这里描述方式不同。阅读 Epema 的论文，他漂亮地概括了这种使用量衰减（decay-usage）算法及其特征最后，许多调度程序有一些我们没有提到的特征。例如，有些调度程序将最高优先级队列留给操作系统使用，因此通常的用户工作是无法得到系统的最高优先级的。有些系统允许用户给出优先级设置的建议（advice），比如通过命令行工具 nice，可以增加或降低工作的优先级（稍微），从而增加或降低它在某个时刻运行的机会。更多信息请查看 man 手册。 提示：尽可能多地使用建议 操作系统很少知道什么策略对系统中的单个进程和每个进程算是好的，因此提供接口并允许用户或管理员给操作系统一些提示（hint）常常很有用。我们通常称之为建议（advice），因为操作系统不一定要关注它，但是可能会将建议考虑在内，以便做出更好的决定。这种用户建议的方式在操作系统中的各个领域经常十分有用，包括调度程序（通过 nice）、内存管理（madvise），以及文件系统（通知预取和缓存[P+95]）MLFQ：小结本章介绍了一种调度方式，名为多级反馈队列（MLFQ）。本章包含了一组优化的 MLFQ 规则。为了方便查阅，我们重新列在这里。 规则 1：如果 A 的优先级 &amp;gt; B 的优先级，运行 A（不运行 B）。 规则 2：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。 规则 3：工作进入系统时，放在最高优先级（最上层队列）。 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）。 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。MLFQ 有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，MLFQ 可以同时满足各种工作的需求：对于短时间运行的交互型工作，获得类似于 SJF/STCF 的很好的全局性能，同时对长时间运行的 CPU 密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的 MLFQ 作为自己的基础调度程序，包括类 BSD UNIX 系统、Solaris以及 Windows NT 和其后的 Window 系列操作系统。作业程序 mlfq.py 允许你查看本章介绍的 MLFQ 调度程序的行为。详情请参阅 README 文件。 只用两个工作和两个队列运行几个随机生成的问题。针对每个工作计算 MLFQ 的执行记录。限制每项作业的长度并关闭 I/O，让你的生活更轻松。 如何运行调度程序来重现本章中的每个实例？ 将如何配置调度程序参数，像轮转调度程序那样工作？ 设计两个工作的负载和调度程序参数，以便一个工作利用较早的规则 4a 和 4b（用-S 标志打开）来“愚弄”调度程序，在特定的时间间隔内获得 99%的 CPU。 给定一个系统，其最高队列中的时间片长度为 10ms，你需要如何频繁地将工作推回到最高优先级级别（带有-B 标志），以保证一个长时间运行（并可能饥饿）的工作得到至少 5%的 CPU？ 调度中有一个问题，即刚完成 I/O 的作业添加在队列的哪一端。-I 标志改变了这个调度模拟器的这方面行为。尝试一些工作负载，看看你是否能看到这个标志的效果。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(五) 进程调度：介绍", "url": "/posts/operating-systems-5/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-17 09:00:00 +0800", "snippet": "假设为了方便概念的描述，对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：工作负载 每一个工作运行相同的时间。 所有的工作同时到达。 一旦开始，每个工作保持运行直到完成。 所有的工作只是用 CPU（即它们不执行 IO 操作）。 每个工作的运行时间是已知的。调度指标任务的周转时间定义为任务完成时间减去任务到达系统的时间。更正式的周转时间定义 T_{周转时间} 是：T_{周转时间} = T_{完成时间}−T_{到达时间}因为我们假设所有的任务在同一时间到达，那么 T_{到达时间} = 0，因此 T_{周转时间}= T_{完成时间}。随着我们放宽上述假设，这个情况将改变先进先出（FIFO）先进先出（First In First Out 或 FIFO）调度，有时候也称为先到先服务（First Come First Served 或 FCFS）。假设有三个几乎同时到达的进程，到达顺序为 A,B,C，B 和 C 执行 10s，A 有执行 10s 和执行 100s 的情况，调度结果如下图：两者的平均周转周期 左：(10 + 20 + 30)/3 = 20 右：(100 + 110 + 120)/3 = 110 这个问题通常被称为护航效应（convoy effect），一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后。最短任务优先（SJF）最短任务优先（Shortest Job First，SJF）：先运行最短的任务，然后是次短的任务，如此下去左图是在上一节条件下使用 SJF 策略时的表现，右图是在到达时间间隔 10s 条件下使用 SJF 策略时的表现：两者的平均周转周期 左：(10 + 20 + 120)/3 = 50 右：(100+(110−10)+(120−10))/3 = 103.33 从图中可以看出，当 ABC 几乎同时到达时，SJF 相较于 FIFO 有较好的表现，但当 B 和 C 在 A 之后不久到达，由于 SJF 无法抢占，它们仍然被迫等到 A 完成，从而遭遇同样的护航问题。最短完成时间优先(STCF)我们放宽第一节提出的假设条件 3（工作必须保持运行直到完成），也就是允许抢占向 SJF 添加抢占，称为最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First ，PSJF）调度程序每当新工作进入系统时，它就会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作:平均周转周期为：(120 + 10 + 20)/3 = 50新度量指标：响应时间响应时间定义为从任务到达系统到首次运行的时间。更正式的定义是：T_{响应时间} = T_{首次运行} − T_{到达时间}用户将会坐在终端前面，同时也要求系统的交互性和响应性好，所以响应时间是有意义的例如，如果我们有上面的调度（A 在时间 0 到达，B 和 C 在时间 10 达到），每个作业的响应时间如下：作业 A 为 0，B 为 0，C 为 10（平均：3.33），STCF 和相关方法在响应时间上并不是很好，对用户来说，打开 C 软件后可能要 10s 后才会有响应时间片轮转轮转（Round-Robin，RR）调度：在一个时间片（time slice，有时称为调度量子，scheduling quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。因此，RR 有时被称为时间切片（time-slicing）。请注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms 中断一次，则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数。来看一个例子：假设 3 个任务 A、B 和 C 在系统中同时到达，并且它们都希望运行 5s。平均响应时间： SJF：(0 + 5 + 10)/ 3 = 5 RR：(0 + 1 + 2)/3 = 1 SJF 调度程序必须运行完当前任务才可运行下一个任务。相比之下，1s 时间片的 RR 可以快速地循环工作时间片长度时间片长度对于 RR 是至关重要的。时间片长度越短，RR 在响应时间上表现越好。然而，时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使系统不及时响应 请注意，上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序运行时，它们在CPU 高速缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可能导致显著的性能成本。结合 I/O首先，我们将放宽假设 4：所有程序都不执行 I/O。一种常见的方法是将 A 的每个 10ms 的子工作视为一项独立的工作。因此，当系统启动时，它的选择是调度 10ms 的 A，还是 50ms 的 B。对于 最短完成时间优先(STCF)，选择是明确的：选择较短的一个，在这种情况下是 A。然后，A 的工作已完成，只剩下 B，并开始运行。然后提交 A 的一个新子工作，它抢占 B 并运行 10ms。这样做可以实现重叠（overlap），一个进程在等待另一个进程的 I/O 完成时使用 CPU，系统因此得到更好的利用小结我们开发了两种调度程序。 第一种类型（SJF、STCF）优化周转时间，但对响应时间不利。 第二种类型（RR）优化响应时间，但对周转时间不利。 作业以后再做参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(四) 机制：受限直接执行", "url": "/posts/operating-systems-4/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-16 09:00:00 +0800", "snippet": "本文中文版翻译质量堪忧，有不少名词翻译不知所云，建议对照英文版阅读前言在构建这样的虚拟化机制时存在一些挑战。 第一个是性能：如何在不增加系统开销的情况下实现虚拟化？ 第二个是控制权：如何有效地运行进程，同时保留对 CPU 的控制？ 控制权对于操作系统尤为重要，因为操作系统负责资源管理。如果没有控制权，一个进程可以简单地无限制运行并接管机器，或访问没有权限的信息直接运行协议（无限制）直接执行指的是直接在 CPU 上运行程序，该操作没有任何限制。 操作系统 程序 在进程列表上创建条目为程序分配内存将程序加载到内存中根据 argc/argv 设置程序栈   清除寄存器执行 call main() 方法     执行 main()从 main 中执行 return 释放进程的内存将进程从进程列表中清除   直接运行性能肯定最高，但带来两个问题： 受限制的操作：操作系统怎么能确保程序不做任何我们不希望它做的事，同时仍然高效地运行它 进程间切换： 操作系统如何让一个进程停下来并切换到另一个进程，从而实现虚拟化 CPU 所需的时分共享问题 1：受限制的操作 提示：采用受保护的控制权转移 硬件通过提供不同的执行模式来协助操作系统。在用户模式（user mode）下，应用程序不能完全访问硬件资源。在内核模式（kernel mode）下，操作系统可以访问机器的全部资源。还提供了陷入（trap）内核和从陷阱返回（return-from-trap）到用户模式程序的特别说明，以及一些指令，让操作系统告诉硬件陷阱表（trap table）在内存中的位置。我们采用的方法是引入新的处理器模式:用户模式（user mode）在用户模式下运行的代码会受到限制。例如，在用户模式下运行时，进程不能发出 I/O 请求。这样做会导致处理器引发异常，操作系统可能会终止进程。内核模式（kernel mode）操作系统（或内核）就以这种模式运行。在此模式下，运行的代码可以做它喜欢的事，包括特权操作，如发出 I/O 请求和执行所有类型的受限指令。系统调用系统调用允许内核小心地向用户程序暴露某些关键功能，例如访问文件系统、创建和销毁进程、与其他进程通信，以及分配更多内存。大多数操作系统提供几百个调用（详见 POSIX 标准）。早期的 UNIX 系统公开了更简洁的子集，大约 20 个调用。如果用户希望执行某种特权操作（如从磁盘读取），可以借助硬件提供的系统调用功能。要执行系统调用，程序必须执行特殊的陷阱（trap）指令。该指令同时跳入内核并将特权级别提升到内核模式。一旦进入内核，系统就可以执行任何需要的特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，如你期望的那样，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。执行陷阱时，硬件需要小心，因为它必须确保存储足够的调用者寄存器，以便在操作系统发出从陷阱返回指令时能够正确返回。例如，在 x86 上，处理器会将程序计数器、标志和其他一些寄存器推送到每个进程的内核栈（kernel stack）上。从返回陷阱将从栈弹出这些值，并恢复执行用户模式程序（有关详细信息，请参阅英特尔系统手册）。其他硬件系统使用不同的约定，但基本概念在各个平台上是相似的。 补充：为什么系统调用看起来像过程调用 你可能想知道，为什么对系统调用的调用（如 open()或 read()）看起来完全就像 C 中的典型过程调用。也就是说，如果它看起来像一个过程调用，系统如何知道这是一个系统调用，并做所有正确的事情？原因很简单：它是一个过程调用，但隐藏在过程调用内部的是著名的陷阱指令。更具体地说，当你调用 open()（举个例子）时，你正在执行对 C 库的过程调用。其中，无论是对于 open()还是提供的其他系统调用，库都使用与内核一致的调用约定来将参数放在众所周知的位置（例如，在栈中或特定的寄存器中），将系统调用号也放入一个众所周知的位置（同样，放在栈或寄存器中），然后执行上述的陷阱指令。库中陷阱之后的代码准备好返回值，并将控制权返回给发出系统调用的程序。因此，C 库中进行系统调用的部分是用汇编手工编码的，因为它们需要仔细遵循约定，以便正确处理参数和返回值，以及执行硬件特定的陷阱指令。现在你知道为什么你自己不必写汇编代码来陷入操作系统了，因为有人已经为你写了这些汇编。陷阱表（trap table）内核通过在启动时设置陷阱表（trap table）来实现陷阱地址的初始化。当机器启动时，系统在特权（内核）模式下执行，因此可以根据需要自由配置机器硬件。操作系统做的第一件事，就是告诉硬件在发生某些异常事件时要运行哪些代码。例如，当发生硬盘中断，发生键盘中断或程序进行系统调用时，应该运行哪些代码？操作系统通常通过某种特殊的指令，通知硬件这些陷阱处理程序的位置。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。受限直接运行协议LDE 背后的想法很简单：让程序运行的大部分指令直接访问硬件，只在一些关键点（如进程发起系统调用或发生时钟中断）由操作系统介入来确保“在正确时间， 正确的地点，做正确的事”。为了实现高效的虚拟化，操作系统应该尽量让程序自己运行，同时通过在关键点的及时介入（interposing），来保持对硬件的控制。LDE 协议有两个阶段:第一阶段： 操作系统@启动（内核模式） 硬件   初始化陷阱表       记住系统调用处理程序的地址   第一个阶段（在系统引导时），内核初始化陷阱表，并且 CPU 记住它的位置以供随后使用。内核通过特权指令来执行此操作（所有特权指令均以粗体突出显示）。第二阶段： 操作系统@运行（内核模式） 硬件 程序（应用模式） 在进程列表上创建条目为程序分配内存将程序加载到内存中根据 argv 设置程序栈用寄存器/程序计数器填充内核栈从陷阱返回       从内核栈恢复寄存器转向用户模式跳到 main       运行 main ……调用系统调用陷入操作系统   将寄存器保存到内核栈转向内核模式跳到陷阱处理程序   处理陷阱做系统调用的工作从陷阱返回       从内核栈恢复寄存器转向用户模式跳到陷阱之后的程序计数器       ……从 main 返回陷入（通过 exit()） 释放进程的内存将进程从进程列表中清除     第二个阶段（运行进程时），在使用从陷阱返回指令开始执行进程之前，内核设置了一些内容（例如，在进程列表中分配一个节点，分配内存）。这会将 CPU 切换到用户模式并开始运行该进程。当进程希望发出系统调用时，它会重新陷入操作系统，然后再次通过从陷阱返回，将控制权还给进程。该进程然后完成它的工作，并从 main()返回。这通常会返回到一些存根代码，它将正确退出该程序（例如，通过调用 exit()系统调用，这将陷入 OS 中）。此时，OS 清理干净，任务完成了。问题 2：在进程之间切换 关键问题：如何重获 CPU 的控制权 操作系统如何重新获得 CPU 的控制权（regain control），以便它可以在进程之间切换？协作方式：等待系统调用在协作调度系统中，OS 通过等待系统调用，或某种非法操作发生，从而重新获得 CPU 的控制权。过去某些系统采用的一种方式（例如，早期版本的 Macintosh 操作系统或旧的 Xerox Alto 系统）称为协作（cooperative）方式。在这种风格下，操作系统相信系统的进程会合理运行。运行时间过长的进程被假定会定期放弃 CPU，以便操作系统可以决定运行其他任务。大多数进程通过进行系统调用，将 CPU 的控制权转移给操作系统，例如打开文件并随后读取文件，或者向另一台机器发送消息或创建新进程如果应用程序执行了某些非法操作，也会将控制转移给操作系统。例如，如果应用程序以 0 为除数，或者尝试访问应该无法访问的内存，就会陷入（trap）操作系统。操作系统将再次控制 CPU（并可能终止违规进程）。非协作方式：时钟中断时钟中断（timer interrupt）。时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序（interrupt handler）会运行。此时，操作系统重新获得 CPU 的控制权，因此可以做它想做的事：停止当前进程，并启动另一个进程。请注意，硬件在发生中断时有一定的责任，尤其是在中断发生时，要为正在运行的程序保存足够的状态，以便随后从陷阱返回指令能够正确恢复正在运行的程序。该操作可以视为隐式的操作，与显式的系统调用很相似。保存和恢复上下文当操作系统通过上述两种方式获取控制权后，就可以决定是否切换进程，这个决定是由调度程序（scheduler）做出当操作系统决定切换进程时，需要首先进行上下文切换（context switch），就是为当前正在执行的进程保存一些寄存器的值（例如，到它的内核栈），并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。这样一来，操作系统就可以确保最后执行从陷阱返回指令时，不是返回到之前运行的进程，而是继续执行另一个进程。 上下文切换并不仅仅保存和恢复寄存器，还包含了其他操作，如页表的切换等，在后续章节会提到受限直接执行协议（时钟中断）第一阶段： 操作系统@启动（内核模式） 硬件 初始化陷阱表     记住以下地址： -系统调用处理程序 -时钟处理程序 启动中断时钟     启动时钟每隔 x ms 中断 CPU 第二阶段： 操作系统@运行（内核模式） 硬件 程序（应用模式）     进程 A……   时钟中断将用户寄存器（A）保存到内核栈（A）转向内核模式跳到陷阱处理程序   处理陷阱调用 switch()例程 -保存内核寄存器（A）-&amp;gt;进程结构（A） -恢复内核寄存器（B）&amp;lt;-进程结构（B）-切换到内核栈（B）从陷阱返回（进入 B）       恢复用户寄存器（B）&amp;lt;-内核栈（B）转向用户模式跳到 B 的程序计数器       进程 B…… 该表展示了整个过程的时间线。在这个例子中，进程 A 正在运行，然后被中断时钟中断。硬件保存它的用户寄存器（到内核栈中），并进入内核（切换到内核模式）。在时钟中断处理程序中，操作系统决定从正在运行的进程 A 切换到进程 B。此时，它调用 switch()例程，该例程仔细保存当前内核寄存器的值（保存到 A 的进程结构(process structure)），恢复内核寄存器进程 B（从它的进程结构(process structure)），然后切换上下文（switch context），具体来说是通过改变栈指针来使用 B 的内核栈（而不是 A 的）。最后，操作系统从陷阱返回，恢复 B 的用户寄存器并开始运行它。请注意，在此协议中，有两种类型的寄存器保存/恢复: 第一种是发生时钟中断的时候。在这种情况下，运行进程的用户寄存器由硬件隐式保存，使用该进程的内核栈。 原文：the user registers of the running process are implicitly saved by the hardware, using the kernel stack of that process 根据英文原文，此处确实是保存到了内核栈中 扩展：内核栈与用户栈 内核在创建进程时，会同时创建 task_struct 和进程相应堆栈。每个进程都会有两个堆栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，CPU 堆栈寄存器(SP)的内容是用户堆栈地址，使用用户栈。当进程在内核空间时，CPU 堆栈寄存器(SP)的内容是内核栈地址，使用的是内核栈。 第二种是当操作系统决定从 A 切换到 B。在这种情况下，A 的用户寄存器先被硬件保存到内核栈(A)，之后进入内核态，此时，用户寄存器切换成内核寄存器，存放系统和进程 A 相关的值，操作系统接管后，调用 switch()通过软件方式将内核寄存器中的值保存到 A 的进程结构，之后从 B 的进程结构恢复值到内核寄存器，并切换到进程 B 的内核栈(B)，然后从陷阱返回，从内核栈(B)恢复 B 的用户寄存器，运行 B 进程 原文：the kernel registers are explicitly saved by the software (i.e., the OS), but this time into memory in the process structure of the process. The latter action moves the system from running as if it just trapped into the kernel from A to as if it just trapped into the kernel from B. 为了理解这个逻辑，首先把切换这步去掉，假设 A 不切换成 B，即 A 的用户寄存器先被硬件保存到内核栈(A)，此时，包括PC寄存器（需要执行的下一条指令地址）在内的寄存器都被压入内核栈(A)，从陷阱返回后，从内核栈(A)恢复 A 的用户寄存器，将包括 PC 寄存器在内的寄存器恢复，此时继续执行 PC 寄存器保存的下一条指令。然后加上switch()操作，保存/恢复内核寄存器到对应的进程结构中。 TODO:此处后面再用实际操作系统的例子补充 分享：在 µC/OS-III 中遇到的上下文切换问题在实际项目中使用 µC/OS-III 系统时遇到过一个问题，某个进程的值在没有任何修改的情况下变为了异常值。问题说明：wlm_do()-&amp;gt;the_wlm_routine[the_wlm.status].func()-&amp;gt;wlm_chk_baudrate()-&amp;gt;atcmd(serfd(), &quot;AT\\r&quot;, E_OK, 500, NULL, 0)-&amp;gt;memset(prbuf, 0, rbuf_len)rbuf_len 的值变为了 536890260，显然是个异常值。问题分析：通过分析后排除了程序本身的问题，打算从操作系统角度进行问题。在关闭 GCC 优化的情况下，该值正常，也就是说可能和 GCC 的优化有关。GCC 优化会将部分常用的变量保持到寄存器中，从而提高读写速度。通过内存和寄存器跟踪工具，定位了该变量确实被保存在了寄存器中，也就是说寄存器出现了问题，和寄存器操作相关的就极有可能是上下文切换操作。通过跟踪发现寄存器的值在进程切换后出现了异常，导致该变量的值改变查看上下文切换实现源码：OS_CPU_PendSVHandler: CPSID I @ Prevent interruption during context switch MRS R0, PSP @ PSP is process stack pointer CMP R0, #0 BEQ OS_CPU_PendSVHandler_nosave @ equivalent code to CBZ from M3 arch to M0 arch @ Except that it does not change the condition code flags SUBS R0, R0, #0x10 @ Adjust stack pointer to where memory needs to be stored to avoid overwriting STM R0!, {R4-R7} @ Stores 4 4-byte registers, default increments SP after each storing SUBS R0, R0, #0x10 @ STM does not automatically call back the SP to initial location so we must do this manually LDR R1, =OSTCBCur @ OSTCBCur-&amp;gt;OSTCBStkPtr = SP; LDR R1, [R1] STR R0, [R1] @ R0 is SP of process being switched out @ At this point, entire context of process has been saved此处仅保存了 r4-r7 寄存器，少了对 r8-r11 寄存器的保存查看官网更新说明µC/OS-III v3.06.00 Changelog，有如下信息：bug 修复后的上下文切换源码如下：PendSV_Handler: CPSID I @ Prevent interruption during context switch MRS R0, PSP @ PSP is process stack pointer CMP R0, #0 BEQ OS_CPU_PendSVHandler_nosave @ equivalent code to CBZ from M3 arch to M0 arch @ Except that it does not change the condition code flags SUBS R0, R0, #0x24 @ Adjust SP to make space for Low, High &amp;amp; LR registers LDR R1, =OSTCBCur @ OSTCBCur-&amp;gt;OSTCBStkPtr = SP; LDR R1, [R1] STR R0, [R1] @ R0 is SP of process being switched out STMIA R0!, {R4-R7} @ Store R4-R7(Low Registers) on process stack MOV R4, R8 @ Move R8-R11 values to R4-R7 registers. MOV R5, R9 MOV R6, R10 MOV R7, R11 STMIA R0!, {R4-R7} @ Store R8-R11(High Registers) on process stack MOV R3, R14 @ R3 is LR of process being switched out STMIA R0!, {R3} @ Store LR (EXC_RETURN) on process stack. @ At this point, entire context of process has been saved此处保存了 r4-r11 寄存器至此，问题原因已明确问题原因：代码优化时将 rbuf_len 保存在了寄存器 r8 上，在进行上下文切换时，r8 寄存器没有被保存，导致 r8 寄存器的值被其他进程修改，切换回本进程后，r8 的值也无法恢复。思考：并发对中断的影响处理一个中断时发生另一个中断，会发生什么？一种方法是，在中断处理期间禁止中断（disable interrupt）。这样做可以确保在处理一个中断时，不会将其他中断交给 CPU。当然，操作系统这样做必须小心。禁用中断时间过长可能导致丢失中断，这（在技术上）是不好的。操作系统还开发了许多复杂的加锁（locking）方案，以保护对内部数据结构的并发访问。这使得多个活动可以同时在内核中进行，特别适用于多处理器，在下一部分关于并发的章节中将会看到思考：上下文切换的消耗你可能有一个很自然的问题：上下文切换需要多长时间？甚至系统调用要多长时间？如果感到好奇，有一种称为 lmbench的工具，可以准确衡量这些事情，并提供其他一些可能相关的性能指标。随着时间的推移，结果有了很大的提高，大致跟上了处理器的性能提高。例如，1996 年在 200-MHz P6 CPU 上运行 Linux 1.3.37，系统调用花费了大约 4μs，上下文切换时间大约为 6μs。现代系统的性能几乎可以提高一个数量级，在具有 2 GHz 或 3 GHz 处理器的系统上的性能可以达到亚微秒级。应该注意的是，并非所有的操作系统操作都会跟踪 CPU 的性能。正如 Ousterhout 所说的，许多操作系统操作都是内存密集型的，而随着时间的推移，内存带宽并没有像处理器速度那样显著提高。因此，根据你的工作负载，购买最新、性能好的处理器可能不会像你希望的那样加速操作系统。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(三) 插叙：进程 API", "url": "/posts/operating-systems-3/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-12 17:00:00 +0800", "snippet": "fork()系统调用在执行函数 fork()时，创建了一个子进程，此时是两个进程同时运行#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(int argc, char *argv[]){ printf(&quot;hello world (pid:%d)\\n&quot;, (int)getpid()); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int)getpid()); } else { // parent goes down this path (main) printf(&quot;hello, I am parent of %d (pid:%d)\\n&quot;, rc, (int)getpid()); } return 0;}输出如下：prompt&amp;gt; ./p1hello world (pid:29146)hello, I am parent of 29147 (pid:29146)hello, I am child (pid:29147)prompt&amp;gt;上面这段程序执行了一次 fork 操作，fork()函数是一个神奇的操作，它只被调用了一次，却产生了两个返回值。对于父进程来说，其返回值是子进程的 pid；对于子进程来说，其返回值为 0。子进程并不是完全拷贝了父进程，所以子进程不会从 main 开始执行，该程序的首行打印并未被子进程执行。它拥有自己的地址空间（即拥有自己的私有内存）、寄存器、程序计数器等。此处父进程与子进程的执行顺序并不是绝对的，取决于 cpu 的调度算法，子进程也可能比父进程先执行完 TODO: fork()函数的具体原理还有待进一步学习wait()系统调用wait()函数用于使父进程（也就是调用 wait()的进程）阻塞，直到一个子进程结束或者该进程接收到了一个指定的信号为止。#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ printf(&quot;hello world (pid:%d)\\n&quot;, (int)getpid()); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int)getpid()); } else { // parent goes down this path (main) int wc = wait(NULL); printf(&quot;hello, I am parent of %d (wc:%d) (pid:%d)\\n&quot;, rc, wc, (int)getpid()); } return 0;}prompt&amp;gt; ./p2hello world (pid:29266)hello, I am child (pid:29267)hello, I am parent of 29267 (wc:29267) (pid:29266)prompt&amp;gt;本例中，子进程却优先于父进程执行完毕，这是因为父进程调用了wait()操作当父进程先执行时，会等待子进程结束，才会继续执行exec()系统调用exec()这个系统调用可以让子进程执行与父进程不同的程序 关于exec函数族的更多相关内容，可以查看Linux 多任务编程（三）—exec 函数族及其基础实验#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ printf(&quot;hello world (pid:%d)\\n&quot;, (int)getpid()); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child (new process) printf(&quot;hello, I am child (pid:%d)\\n&quot;, (int)getpid()); char *myargs[3]; myargs[0] = strdup(&quot;wc&quot;); // program: &quot;wc&quot; (word count) myargs[1] = strdup(&quot;p3.c&quot;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count printf(&quot;this shouldn&#39;t print out&quot;); } else { // parent goes down this path (main) int wc = wait(NULL); printf(&quot;hello, I am parent of %d (wc:%d) (pid:%d)\\n&quot;, rc, wc, (int)getpid()); } return 0;}prompt&amp;gt; ./p3hello world (pid:29383)hello, I am child (pid:29384) 29 107 1030 p3.chello, I am parent of 29384 (wc:29384) (pid:29383)prompt&amp;gt;在这个例子中，子进程调用 execvp()来运行字符计数程序 wc。实际上，它针对源代码文件 p3.c 运行 wc，从而告诉我们该文件有多少行、多少单词，以及多少字节。给定可执行程序的名称（如 wc）及需要的参数（如 p3.c）后，exec()会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段（以及静态数据），堆、栈及其他内存空间也会被重新初始化。然后操作系统就执行该程序，将参数通过 argv 传递给该进程。因此，它并没有创建新进程，而是直接将当前运行的程序（以前的 p3）替换为不同的运行程序（wc）。子进程执行 exec()之后，几乎就像 p3.c 从未运行过一样。对 exec()的成功调用永远不会返回。如果 exec 函数执行失败, 它会返回失败的信息, 而且进程继续执行后面的代码。 注意：此时子进程的 pid 号并没有变，且还是该父进程的子进程，所以并不会影响 wait()操作，等待该进程的操作（统计字节）完成后，wait()才会返回，父进程同时退出阻塞状态为什么这样设计 API事实证明，这种分离 fork()及 exec()的做法在构建 UNIX shell 的时候非常有用，因为这给了 shell 在 fork 之后 exec 之前运行代码的机会，这些代码可以在运行新程序前改变环境，从而让一系列有趣的功能很容易实现。shell 也是一个用户程序，它首先显示一个提示符（prompt），然后等待用户输入。你可以向它输入一个命令（一个可执行程序的名称及需要的参数），大多数情况下，shell 可以在文件系统中找到这个可执行程序，调用 fork()创建新进程，并调用 exec()的某个变体来执行这个可执行程序，调用 wait()等待该命令完成。子进程执行结束后，shell 从 wait()返回并再次输出一个提示符，等待用户输入下一条命令。fork()和 exec()的分离，让 shell 可以方便地实现很多有用的功能。比如：prompt&amp;gt; wc p3.c &amp;gt; newfile.txt在上面的例子中，wc 的输出结果被重定向（redirect）到文件 newfile.txt 中（通过 newfile.txt 之前的大于号来指明重定向）。shell 实现结果重定向的方式也很简单，当完成子进程的创建后，shell 在调用 exec()之前先关闭了标准输出（standard output），打开了文件 newfile.txt。这样，即将运行的程序 wc 的输出结果就被发送到该文件，而不是打印在屏幕上。扩展阅读：重定向重定向的工作原理，是基于对操作系统管理文件描述符方式的假设，首先看实例：#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file close(STDOUT_FILENO); open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU); // now exec &quot;wc&quot;... char *myargs[3]; myargs[0] = strdup(&quot;wc&quot;); // program: &quot;wc&quot; (word count) myargs[1] = strdup(&quot;p4.c&quot;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count } else { // parent goes down this path (main) int wc = wait(NULL); } return 0;}prompt&amp;gt; ./p4prompt&amp;gt; cat p4.output 32 109 846 p4.cprompt&amp;gt;要看懂上面的例子，首先要补充点Unix文件描述符的知识 每个 Unix 进程（除了可能的守护进程）应均有三个标准的 POSIX 文件描述符，对应于三个标准流： 整数值 名称 &amp;lt;unistd.h&amp;gt;符号常量 &amp;lt;stdio.h&amp;gt;文件流 0 Standard input STDIN_FILENO stdin 1 Standard output STDOUT_FILENO stdout 2 Standard error STDERR_FILENO stderr UNIX 系统从 0 开始寻找可以使用的文件描述符，进程启动后默认打开了标准输出STDOUT_FILENO输出到屏幕，此时所有的对标准输出文件描述符的输出，如 printf()，都会打印的屏幕上： root@hjk:~/repo/os_test# ./a.out33 113 864 p4.c 如果使用close(STDOUT_FILENO)关闭了这个描述符，再去调用printf()，系统会提示找不到文件描述符 root@hjk:~/repo/os_test# ./a.outwc: write error: Bad file descriptor 此时再打开新的文件描述符，会将所有的对标准输出文件描述符的输出定向到该文件描述符上 open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU) 因为 Unix 系统会从 0 开始寻找可用的文件描述符，当找不到STDOUT_FILENO自然会去找新打开的文件描述符 扩展阅读：管道UNIX管道也是用类似的方式实现的，但用的是 pipe()系统调用。在这种情况下，一个进程的输出被链接到了一个内核管道（pipe）上（队列），另一个进程的输入也被连接到了同一个管道上。因此，前一个进程的输出无缝地作为后一个进程的输入，许多命令可以用这种方式串联在一起，共同完成某项任务。比如通过将 grep、wc 命令用管道连接可以完成从一个文件中查找某个词，并统计其出现次数的功能：grep -o foo file | wc -l作业 编写一个调用 fork()的程序。在调用 fork()之前，让主进程访问一个变量（例如 x）并将其值设置为某个值（例如 100）。子进程中的变量有什么值？当子进程和父进程都改变 x 的值时，变量会发生什么？ 答：父进程在 fork 之前修改的值会同步到子进程中（fork 前子进程并不存在），当 fork 完成后，两个进程相互独立，修改 fork 前定义的变量时也是独立的。 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(int argc, char *argv[]){ int x = 1; printf(&quot;hello world (pid:%d)\\n&quot;, (int)getpid()); x = 3; int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child (new process) x=4; printf(&quot;hello, I am child (pid:%d),x:%d\\n&quot;, (int)getpid(),x); } else { // parent goes down this path (main) wait(NULL); printf(&quot;hello, I am parent of %d (pid:%d),x:%d\\n&quot;, rc, (int)getpid(),x); } return 0;} 结果如下，两个进程的 x 独立，即便是子进程修改了 x，父进程中的 x 还是 fork 前的值 root@hjk:~/repo/os_test# ./a.outhello world (pid:17699)hello, I am child (pid:17700),x:4hello, I am parent of 17700 (pid:17699),x:3 编写一个打开文件的程序（使用 open()系统调用），然后调用 fork()创建一个新进程。子进程和父进程都可以访问 open()返回的文件描述符吗？当它们并发（即同时）写入文件时，会发生什么？ 答：都可以访问。并发时无影响。 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ close(STDOUT_FILENO); int fd = open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file // now exec &quot;wc&quot;... printf(&quot;child\\n&quot;); } else { // parent goes down this path (main) // int wc = wait(NULL); printf(&quot;father\\n&quot;); } // if(fd&amp;gt;=0) // { // close(fd); // } return 0;} p4.output 文件输出如下： fatherchild 使用 fork()编写另一个程序。子进程应打印“hello”，父进程应打印“goodbye”。你应该尝试确保子进程始终先打印。你能否不在父进程调用 wait()而做到这一点呢？ 答：使用 sleep 函数时父进程休眠一段时间 现在编写一个程序，在父进程中使用 wait()，等待子进程完成。wait()返回什么？如果你在子进程中使用 wait()会发生什么？ 答：wait()返回子进程的 pid，子进程中调用无影响，返回值为-1。 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ close(STDOUT_FILENO); int fd = open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file // now exec &quot;wc&quot;... int wc=wait(NULL); printf(&quot;child,pid:%d,wc:%d\\n&quot;,getpid(),wc); } else { // parent goes down this path (main) int wc = wait(NULL); // sleep(1); printf(&quot;father,pid:%d,wc:%d\\n&quot;,getpid(),wc); } // if(fd&amp;gt;=0) // { // close(fd); // } return 0;} p4.output 输出结果为： child,pid:4577,wc:-1father,pid:4576,wc:4577 对前一个程序稍作修改，这次使用 waitpid()而不是 wait()。什么时候 waitpid()会有用？ waitpid()参数值 说明 pid&amp;lt;-1 等待进程组号为 pid 绝对值的任何子进程。 pid=-1 等待任何子进程，此时的 waitpid()函数就退化成了普通的 wait()函数。 pid=0 等待进程组号与目前进程相同的任何子进程，也就是说任何和调用 waitpid()函数的进程在同一个进程组的进程。 pid&amp;gt;0 等待进程号为 pid 的子进程。 使用getpgrp()获取当前进程组号 答：当 pid 为0(pid=0),-1(pid=-1),child_pid(pid&amp;gt;0),getpgrp()*-1(pid&amp;lt;-1)时，waitpid()有用 编写一个创建子进程的程序，然后在子进程中关闭标准输出（STDOUT_FILENO）。如果子进程在关闭描述符后调用 printf()打印输出，会发生什么？ 答：子进程无法打印，父进程无影响 #include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;string.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/wait.h&amp;gt;int main(int argc, char *argv[]){ // close(STDOUT_FILENO); // int fd = open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU); int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file // now exec &quot;wc&quot;... // int wc=wait(NULL); close(STDOUT_FILENO); printf(&quot;child,pid:%d,wc:%d\\n&quot;,getpid()); } else { // parent goes down this path (main) // int wc = waitpid(getpgrp(),NULL,0); // sleep(1); printf(&quot;father,pid:%d,wc:%d\\n&quot;,getpid()); } // if(fd&amp;gt;=0) // { // close(fd); // } return 0;} 输出为： root@hjk:~/repo/os_test# ./a.outfather,pid:11189,wc:0 编写一个程序，创建两个子进程，并使用 pipe()系统调用，将一个子进程的标准输出连接到另一个子进程的标准输入。 答：该程序将子进程2中的输出通过管道连接到子进程1的输入中 #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;sys/wait.h&amp;gt; int main(int argc, char *argv[]) { // close(STDOUT_FILENO); // int fd = open(&quot;./p4.output&quot;, O_CREAT | O_WRONLY | O_TRUNC, S_IRWXU); int fds[2]; if(pipe(fds)==-1) { fprintf(stderr, &quot;open pipe failed\\n&quot;); exit(1); } int rc = fork(); if (rc &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file // int wc=wait(NULL); printf(&quot;child1,pid:%d\\n&quot;,getpid()); int len; char buf[10]; // 从pipe中读取 if((len=read(fds[0],buf,6))==-1) { perror(&quot;read from pipe&quot;); exit(1); } printf(&quot;buf:%s\\n&quot;,buf); exit(0); } else { // parent goes down this path (main) // wait(NULL); //创建第二个子进程 int rc2 = fork(); if (rc2 &amp;lt; 0) { // fork failed; exit fprintf(stderr, &quot;fork failed\\n&quot;); exit(1); } else if (rc2 == 0) { // child: redirect standard output to a file // int wc=wait(NULL); printf(&quot;child2,pid:%d\\n&quot;,getpid()); char buf[]= &quot;12345&quot;; // 写入pipe if(write(fds[1],buf,sizeof(buf))!=sizeof(buf)) { perror(&quot;write to pipe&quot;); exit(1); } exit(0); } } return 0; } 补充：有趣的小知识在做作业时发现，有时子进程打印的结果会在shell显示提示符后才打印出来，如下：root@hjk:~/repo/os_test# ./a.out father,pid:92505root@hjk:~/repo/os_test# child,pid:92506在本文的[为什么这样设计 API]一节中有提到shell执行程序的逻辑，下面解释下： shell 也是一个用户程序，它首先显示一个提示符（prompt） 运行程序时shell进程会fork一个子进程 子进程使用exec替换程序为要执行的程序，如a.out 此时shell进入wait状态，直到子进程退出 由于作业中编写的程序又创建了一个子进程，如果父进程先执行完，那么对于shell进程来说，它的子进程就已经结束了，shell结束wait状态，打印一行提示符。此时用户进程的子进程还未结束，又继续在标准输出上打印了信息，那就会有这种现象参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(二) 抽象：进程", "url": "/posts/operating-systems-2/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-12 09:00:00 +0800", "snippet": "本系列文章将按照《Operating Systems: Three Easy Pieces》一书的章节顺序编写，结合原文与自己的感悟，以作笔记之用，如有不足之处，恳请在评论区指出进程 API创建（create）操作系统必须包含一些创建新进程的方法。在 shell 中键入命令或双击应用程序图标时，会调用操作系统来创建新进程，运行指定的程序。销毁（destroy）由于存在创建进程的接口，因此系统还提供了一个强制销毁进程的接口。当然，很多进程会在运行完成后自行退出。但是，如果它们不退出，用户可能希望终止它们，因此停止失控进程的接口非常有用。等待（wait）有时等待进程停止运行是有用的，因此经常提供某种等待接口。其他控制（miscellaneous control）除了杀死或等待进程外，有时还可能有其他控制。例如，大多数操作系统提供某种方法来暂停进程（停止运行一段时间），然后恢复（继续运行）。状态（statu）通常也有一些接口可以获得有关进程的状态信息，例如运行了多长时间，或者处于什么状态。进程创建 加载数据到内存 操作系统运行程序必须做的第一件事是将代码和所有静态数据（例如初始化变量）从磁盘加载（load）到内存中，加载到进程的地址空间中。 在早期的（或简单的）操作系统中，加载过程尽早（eagerly）完成，即在运行程序之前全部完成。现代操作系统惰性（lazily）执行该过程，即仅在程序执行期间需要加载的代码或数据片段，才会加载。 为栈分配空间 将代码和静态数据加载到内存后，必须为程序的运行时栈（run-time stack 或 stack）分配一些内存。C 程序使用栈存放局部变量、函数参数和返回地址。操作系统也可能会用参数初始化栈。具体来说，它会将参数填入 main()函数，即 argc 和 argv 数组。 为堆分配空间 操作系统也可能为程序的堆（heap）分配一些内存。程序通过调用 malloc()来请求这样的空间，并通过调用 free()来明确地释放它。数据结构（如链表、散列表、树和其他有趣的数据结构）需要堆。 I/O 初始化 操作系统还将执行一些其他初始化任务，特别是与输入/输出（I/O）相关的任务。例如，在 UNIX 系统中，默认情况下每个进程都有 3 个打开的文件描述符（file descriptor），用于标准输入、输出和错误。这些描述符让程序轻松读取来自终端的输入以及打印输出到屏幕。 运行程序入口 通过将代码和静态数据加载到内存中，通过创建和初始化栈以及执行与 I/O 设置相关的其他工作，完成准备后，接下来就是启动程序，在入口处运行，即 main()。 进程状态进程的三种状态 运行（running） 在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。 就绪（ready） 在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。 阻塞（blocked） 在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞，因此其他进程可以使用处理器 可以根据操作系统的载量，让进程在就绪状态和运行状态之间转换。从就绪到运行意味着该进程已经被调度（scheduled）。从运行转移到就绪意味着该进程已经取消调度（descheduled）。一旦进程被阻塞（例如，通过发起 I/O 操作），OS 将保持进程的这种状态，直到发生某种事件（例如，I/O 完成）。此时，进程再次转入就绪状态（也可能立即再次运行，如果操作系统这样决定）。关于调度的策略，原文写得过于仔细，我总结下，就是一个进程阻塞或停止时，就会去调度另一个就绪的进程，从而让 cpu 一直保持在满负荷状态数据结构为了跟踪每个进程的状态，操作系统可能会为所有就绪的进程保留某种进程列表（process list），以及跟踪当前正在运行的进程的一些附加信息。操作系统还必须以某种方式跟踪被阻塞的进程。当 I/O 事件完成时，操作系统应确保唤醒正确的进程，让它准备好再次运行。// the registers xv6 will save and restore// to stop and subsequently restart a processstruct context{ int eip; int esp; int ebx; int ecx; int edx; int esi; int edi; int ebp;};// the different states a process can be in// 可以看到实际操作系统对于进程状态的定义远不止上面介绍的3种enum proc_state{ UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE};// the information xv6 tracks about each process// including its register context and statestruct proc{ char *mem; // Start of process memory uint sz; // Size of process memory char *kstack; // Bottom of kernel stack // for this process enum proc_state state; // Process state int pid; // Process ID struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for the // current interrupt};该数据结构展示了 OS 需要跟踪 xv61 内核中每个进程的信息类型[CK+08]。“真正的”操作系统中存在类似的进程结构，如 Linux、macOS X 或 Windows。对于停止的进程，寄存器上下文将保存其寄存器的内容。除了运行、就绪和阻塞之外，还有其他一些进程可以处于的状态： 初始（initial）状态 有时候系统会有一个初始（initial）状态，表示进程在创建时处于的状态。 最终（final）状态 另外，一个进程可以处于已退出但尚未清理的最终（final）状态（在基于 UNIX 的系统中，这称为僵尸状态）。这个最终状态非常有用，因为它允许其他进程（通常是创建进程的父进程）检查进程的返回代码，并查看刚刚完成的进程是否成功执行（通常，在基于 UNIX 的系统中，程序成功完成任务时返回零，否则返回非零）。完成后，父进程将进行最后一次调用（例如，wait()），以等待子进程的完成，并告诉操作系统它可以清理这个正在结束的进程的所有相关数据结构 作业关于作业，本文只摘取部分我认为比较重要的部分 另一个重要的行为是 I/O 完成时要做什么。利用-I IO_RUN_LATER，当 I/O 完成时，I/O 完成的进程不会被优先调度，而是按照排队顺序来。相反，当时运行的进程一直运行。当你运行这个进程组合时会发生什么？（./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -p）系统资源是否被有效利用？ $ ./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -pTime PID: 0 PID: 1 PID: 2 PID: 3 CPU IOs 1 RUN:io READY READY READY 1 2 WAITING RUN:cpu READY READY 1 1 3 WAITING RUN:cpu READY READY 1 1 4 WAITING RUN:cpu READY READY 1 1 5 WAITING RUN:cpu READY READY 1 1 6 WAITING RUN:cpu READY READY 1 1 7* READY DONE RUN:cpu READY 1 8 READY DONE RUN:cpu READY 1 9 READY DONE RUN:cpu READY 1 10 READY DONE RUN:cpu READY 1 11 READY DONE RUN:cpu READY 1 12 READY DONE DONE RUN:cpu 1 13 READY DONE DONE RUN:cpu 1 14 READY DONE DONE RUN:cpu 1 15 READY DONE DONE RUN:cpu 1 16 READY DONE DONE RUN:cpu 1 17 RUN:io_done DONE DONE DONE 1 18 RUN:io DONE DONE DONE 1 19 WAITING DONE DONE DONE 1 20 WAITING DONE DONE DONE 1 21 WAITING DONE DONE DONE 1 22 WAITING DONE DONE DONE 1 23 WAITING DONE DONE DONE 1 24* RUN:io_done DONE DONE DONE 1 25 RUN:io DONE DONE DONE 1 26 WAITING DONE DONE DONE 1 27 WAITING DONE DONE DONE 1 28 WAITING DONE DONE DONE 1 29 WAITING DONE DONE DONE 1 30 WAITING DONE DONE DONE 1 31* RUN:io_done DONE DONE DONE 1Stats: Total Time 31Stats: CPU Busy 21 (67.74%)Stats: IO Busy 15 (48.39%)在本题中，进程 0 首先进入 IO，此时由于-S SWITCH_ON_IO参数，进程 0 进入阻塞状态，cpu 被切换到运行进程 1，当进程 0 的 IO 完成后，进程 1 继续执行，直到完成。也就是 IO 完成事件不会被立即处理，由于进程 0 的 IO 动作较为频繁，会使它长时间处于 IO 完成等待状态，导致后续的 IO 操作时 cpu 已经无事可做了，在本例条件下降低了效率 现在运行相同的进程，但使用-I IO_RUN_IMMEDIATE 设置，该设置立即运行发出 I/O 的进程。这种行为有何不同？为什么运行一个刚刚完成 I/O 的进程会是一个好主意？$ ./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_IMMEDIATE -c -pTime PID: 0 PID: 1 PID: 2 PID: 3 CPU IOs 1 RUN:io READY READY READY 1 2 WAITING RUN:cpu READY READY 1 1 3 WAITING RUN:cpu READY READY 1 1 4 WAITING RUN:cpu READY READY 1 1 5 WAITING RUN:cpu READY READY 1 1 6 WAITING RUN:cpu READY READY 1 1 7* RUN:io_done DONE READY READY 1 8 RUN:io DONE READY READY 1 9 WAITING DONE RUN:cpu READY 1 1 10 WAITING DONE RUN:cpu READY 1 1 11 WAITING DONE RUN:cpu READY 1 1 12 WAITING DONE RUN:cpu READY 1 1 13 WAITING DONE RUN:cpu READY 1 1 14* RUN:io_done DONE DONE READY 1 15 RUN:io DONE DONE READY 1 16 WAITING DONE DONE RUN:cpu 1 1 17 WAITING DONE DONE RUN:cpu 1 1 18 WAITING DONE DONE RUN:cpu 1 1 19 WAITING DONE DONE RUN:cpu 1 1 20 WAITING DONE DONE RUN:cpu 1 1 21* RUN:io_done DONE DONE DONE 1Stats: Total Time 21Stats: CPU Busy 21 (100.00%)Stats: IO Busy 15 (71.43%)在本例中，由于使用了-I IO_RUN_IMMEDIATE设置，IO 完成事件被立即处理，此时进程 0 继续运行，对于 IO 操作较为频繁的进程 0 来说这是一件好事思考：立即处理阻塞完成的进程是否是一个好主意?参考 Operating Systems: Three Easy Pieces 中文版 xv6 是在 ANSI C 中针对多处理器 x86 系统的 Unix 第六版的现代重新实现。它足够简单，是上手操作系统的一个不错选择 &amp;#8617; " }, { "title": "《Operating Systems: Three Easy Pieces》学习笔记(一) 操作系统介绍", "url": "/posts/operating-systems-1/", "categories": "学习笔记", "tags": "Operating Systems, 操作系统导论", "date": "2021-03-11 09:00:00 +0800", "snippet": "本系列文章将按照《Operating Systems: Three Easy Pieces》一书的章节顺序编写，结合原文与自己的感悟，以作笔记之用，如有不足之处，恳请在评论区指出虚拟化 CPU首先看个例子#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;sys/time.h&amp;gt;#include &amp;lt;assert.h&amp;gt;#include &quot;common.h&quot;int main(int argc, char *argv[]){ if (argc != 2) { fprintf(stderr, &quot;usage: cpu &amp;lt;string&amp;gt;\\n&quot;); exit(1); } char *str = argv[1]; while (1) { Spin(1); printf(&quot;%s\\n&quot;, str); } return 0;}该程序每秒打印一次输入参数，是个死循环，不会退出prompt&amp;gt; ./cpu A &amp;amp; ; ./cpu B &amp;amp; ; ./cpu C &amp;amp; ; ./cpu D &amp;amp;[1] 7353[2] 7354[3] 7355[4] 7356ABDCABDCACBD...当同时执行运行 4 个程序的命令时，打印几乎是同时运行的，而不是等待第一个程序运行结束才运行下个程序对应单核的处理器，同时运行 4 个进程是不可能的，所有这里就要介绍 CPU 的虚拟化事实证明，在硬件的一些帮助下，操作系统负责提供这种假象（illusion），即系统拥有非常多的虚拟 CPU 的假象。将单个 CPU（或其中一小部分）转换为看似无限数量的 CPU，从而让许多程序看似同时运行，这就是所谓的虚拟化 CPU（virtualizing the CPU）当然运行不同进程时的策略，如优先级等也是需要讨论的知识点：时分共享，上下文切换虚拟化内存#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &quot;common.h&quot;int main(int argc, char *argv[]){ int *p = malloc(sizeof(int)); // a1 assert(p != NULL); printf(&quot;(%d) memory address of p: %08x\\n&quot;, getpid(), (unsigned)p); // a2 *p = 0; // a3 while (1) { Spin(1); *p = *p + 1; printf(&quot;(%d) p: %d\\n&quot;, getpid(), *p); // a4 } return 0;}这是一个访问内存的程序（mem.c）该程序做了几件事。首先，它分配了一些内存（a1 行）。然后，打印出内存的地址（a2 行），然后将数字 0 放入新分配的内存的第一个空位中（a3 行）。最后，程序循环，延迟一秒钟并递增 p 中保存的值。在每个打印语句中，它还会打印出所谓的正在运行程序的进程标识符（PID）（a4 行）。该 PID 对每个运行进程是唯一的。该程序的输出如下：prompt&amp;gt; ./mem(2134) memory address of p: 00200000(2134) p: 1(2134) p: 2(2134) p: 3(2134) p: 4(2134) p: 5ˆC当只运行一个程序时，p 递增，一切正常prompt&amp;gt; ./mem &amp;amp;; ./mem &amp;amp;[1] 24113[2] 24114(24113) memory address of p: 00200000(24114) memory address of p: 00200000(24113) p: 1(24114) p: 1(24114) p: 2(24113) p: 2(24113) p: 3(24114) p: 3(24113) p: 4(24114) p: 4...当同时运行多个相同的程序时，分配的内存地址竟然是相同的，先抛开虚拟化的概念，以物理内存的角度看待，这几个程序分配的内存指针指向了同一块内存空间，也就是修改其中一个程序修改内存也会导致另一个程序中的值改变但是从结果来看这两块内存相互独立，并不影响，就好像每个正在运行的程序都有自己的私有内存，而不是与其他正在运行的程序共享相同的物理内存实际上，这正是操作系统虚拟化内存（virtualizing memory）时发生的情况。每个进程访问自己的私有虚拟地址空间（virtual address space）（有时称为地址空间，address space），操作系统以某种方式映射到机器的物理内存上。一个正在运行的程序中的内存引用不会影响其他进程（或操作系统本身）的地址空间。对于正在运行的程序，它完全拥有自己的物理内存。但实际情况是，物理内存是由操作系统管理的共享资源。知识点：(等待补充)并发#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &quot;common.h&quot;volatile int counter = 0;int loops;void *worker(void *arg){ int i; for (i = 0; i &amp;lt; loops; i++) { counter++; } return NULL;}int main(int argc, char *argv[]){ if (argc != 2) { fprintf(stderr, &quot;usage: threads &amp;lt;value&amp;gt;\\n&quot;); exit(1); } loops = atoi(argv[1]); pthread_t p1, p2; printf(&quot;Initial value : %d\\n&quot;, counter); Pthread_create(&amp;amp;p1, NULL, worker, NULL); Pthread_create(&amp;amp;p2, NULL, worker, NULL); Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(&quot;Final value : %d\\n&quot;, counter); return 0;}主程序利用 Pthread_create()创建了两个线程（thread），每个线程中循环了 loops 次来递增全局变量counter。理想情况下，counter 最终的值应该为 2xloops，因为两个线程各把 counter 递增了 loops 次prompt&amp;gt; ./thread 100000Initial value : 0Final value : 143012 // huh??prompt&amp;gt; ./thread 100000Initial value : 0Final value : 137298 // what the??当运行时，发现值每次各不相同，且小于 2xloops。事实证明，这些奇怪的、不寻常的结果与指令如何执行有关，指令每一执行一条。遗憾的是，上面的程序中的关键部分是增加共享计数器的地方，它需要 3 条指令： 一条将计数器的值从内存加载到寄存器 一条将其递增 一条将其保存回内存。因为这 3 条指令甚不是以原子方式（atomically）执行（所有的指令一一性执行）的，所以奇怪的事情可能会发生。知识点:原子操作,持久性操作系统中管理磁盘的软件通常称为文件系统（file system）。因此它负责以可靠和高效的方式，将用户创建的任何文件（file）存储在系统的磁盘上。#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;assert.h&amp;gt;#include &amp;lt;fcntl.h&amp;gt;#include &amp;lt;sys/types.h&amp;gt;int main(int argc, char *argv[]){ int fd = open(&quot;/tmp/file&quot;, O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU); assert(fd &amp;gt; -1); int rc = write(fd, &quot;hello world\\n&quot;, 13); assert(rc == 13); close(fd); return 0;}为了完成这个任务，该程序向操作系统发出 3 个调用。第一个是对 open()的调用，它打开文件并创建它。第二个是 write()，将一些数据写入文件。第三个是 close()，只是简单地关闭文件，从而表明程序不会再向它写入更多的数据。这些系统调用（system call）被转到称为文件系统（file system）的操作系统部分，然后该系统处理这些请求，并向用户返回某种错误代码。首先确定新数据将驻留在磁盘上的哪个位置，然后在文件系统所维护的各种结构中对其进行记录。这样做需要向底层存储设备发出 I/O 请求，以读取现有结构或更新（写入）它们。所有写过设备驱动程序（device driver）的人都知道，让设备现表你执行某项操作是一个复杂而详细的过程。它需要深入了解低级别设备接口及其确切的语义。幸运的是，操作系统提供了一种通过系统调用来访问设备的标准和简单的方法。因此，OS 有时被视为标准库（standard library）。出于性能方面的原因，大多数文件系统首先会延迟这些写操作一段时间，希望将其批量分组为较大的组。为了处理写入期间系统崩溃的问题，大多数文件系统都包含某种复杂的写入协议，如日志（journaling）或写时复制（copy-on-write），仔细排序写入磁盘的操作，以确保如果在写入序列期间发生故障，系统可以在之后恢复到合理的状态。为了使不同的通用操作更高效，文件系统采用了许多不同的数据结构和访问方法，从简单的列表到复杂的 B 树。设计目标一个最基本的目标，是建立一些抽象（abstraction），让系统方便和易于使用。抽象对我们在计算机科学中做的每件事都很有帮助。抽象使得编写一个大型程序成为可能，将其划分为小而且容易理解的部分设计和实现操作系统的一个目标，是提供高性能（performance）。换言之，我们的目标是最小化操作系统的开销（minimize the overhead）。但是虚拟化的设计是为了易于使用，无形之中会增大开销，比如虚拟页的切换，cpu 的调度等等，所以尽可能的保持易用性与性能的平衡至关重要另一个目标是在应用程序之间以及在 OS 和应用程序之间提供保护（protection）。因为我们希望让许多程序同时运行，所以要确保一个程序的恶意或偶然的不良行为不会损害其他程序。保护是操作系统基本原理之一的核心，这就是隔离（isolation）。让进程彼此隔离是保护的关键，因此决定了 OS 必须执行的大部分任务操作系统也必须不间断运行。当它失效时，系统上运行的所有应用程序也会失效。由于这种依赖性，操作系统往往力求提供高度的可靠性（reliability）。参考 Operating Systems: Three Easy Pieces 中文版" }, { "title": "Makefile和SHELL中$及$$的区别", "url": "/posts/makefile-shell/", "categories": "技术", "tags": "Makefile, shell", "date": "2021-03-10 09:00:00 +0800", "snippet": "最近在看linux内核代码时看到在Makefile中用到了$$()的使用方式，虽然能猜到什么意思，但不知道使用方法和具体含义，于是查找资料，在此写一个总结SHELL中的$说明在shell中，$的一种用法是引用shell变量，执行脚本时，$引用的变量会被替换为相应的字符串。当然shell中$的用法远不止于此，此处就不多做展开，想要了解更多，可以阅读Linux Shell中’$’符号的N种用法Makefile中的$说明Makefile中的$用法和shell中的大体类似，只不过在Makefile中，$仅能用于引用Makefile声明的变量，无法引用shell的变量。这里要注意下，使用make命令执行Makefile时并不是shell环境，当执行到Makefile的某个操作时才会执行shell，例：checkstack: $(OBJDUMP) -d vmlinux $$(find . -name &#39;*.ko&#39;) | \\ $(PERL) $(src)/scripts/checkstack.pl $(CHECKSTACK_ARCH)kernelrelease: @echo &quot;$(KERNELVERSION)$$($(CONFIG_SHELL) $(srctree)/scripts/setlocalversion $(srctree))&quot;kernelversion: @echo $(KERNELVERSION) 注：makefile中对变量的引用需要使用$()这种带括号的方式，否则只会识别$后的一个字母只有执行对应的Makefile命令的shell语句时才会进入shell环境，每行命令独立，每行都是单独的shell，所以上一行定义的shell变量并不适用于下一行。当然如果是使用了\\来合并行就可以摆脱这个限制了，比如例子中的checkstack命令下的shell命令虽然是两行但在同一个shell环境中执行Makefile中的$$说明Makefile命令中的shell语句也并非直接用于shell环境，make会对该语句进行预处理，如果想要引用shell中的变量，就要使用$号来把Makefile变量转换成shell变量$$的用法就是把Makefile引用转化为shell引用，可以理解为此时的$是一个转义符，也可以理解为去掉一个$后直接带入shell脚本中例1LIST = one two threeall: for i in $(LIST); do \\ echo $i; \\ done通过make预处理后转化为shell:for i in one two three; do \\ echo ; \\ done# 输出为空本例中，$i和$(LIST)会被先当成Makefile变量，LIST变量在Makefile中有定义，被转换为了one two three，由于i变量未在Makefile中定义，所以转化为了空。例2LIST = one two threeall: for i in $(LIST); do \\ echo $$i; \\ done通过make预处理后转化为shell:for i in one two three; do \\ echo $i; \\ done# 输出为# one# two# three例2中，$$i命令被make翻译成了shell命令中的$i，此时shell脚本可以正常执行，输出正确结果例3help: @echo &#39; (default: $$(INSTALL_MOD_PATH)/lib/firmware)&#39;输出结果为： (default: $(INSTALL_MOD_PATH)/lib/firmware) 注：Makefile中的@符号表示该行shell命令不回显，否则执行时make会把转化后的shell脚本打印一遍 注：单引号在shell中表示不执行转义或引用，按照原样字符串输出，此处$(INSTALL_MOD_PATH)不会被理解为变量例3中，$$(INSTALL_MOD_PATH)被翻译成$(INSTALL_MOD_PATH)，但由于存在单引号，导致shell变量不会被引用例4VERSION = 3PATCHLEVEL = 10SUBLEVEL = 108EXTRAVERSION =# kernel 版本号，为四个版本号的组合KERNELVERSION = $(VERSION)$(if $(PATCHLEVEL),.$(PATCHLEVEL)$(if $(SUBLEVEL),.$(SUBLEVEL)))$(EXTRAVERSION)# 从shell环境变量中提取shell的执行环境CONFIG_SHELL := $(shell if [ -x &quot;$$BASH&quot; ]; then echo $$BASH; \\ else if [ -x /bin/bash ]; then echo /bin/bash; \\ else echo sh; fi ; fi)# 选取脚本的目录，如果KBUILD_SRC未定义，则选择$(CURDIR)，$(CURDIR)表示当前目录绝对路径srctree := $(if $(KBUILD_SRC),$(KBUILD_SRC),$(CURDIR))KBUILD_VERBOSE = 1# 是否在控制台回显，如果有@则不回显ifeq ($(KBUILD_VERBOSE),1) quiet = Q =else quiet=quiet_ Q = @endifversion: $(Q)echo &quot;$(KERNELVERSION)$$($(CONFIG_SHELL) $(srctree)/scripts/setlocalversion $(srctree))&quot; &amp;gt; $@转化后的shell为：echo &quot;3.10.108$(/bin/bash /root/repo/makefile_test/scripts/setlocalversion /root/repo/makefile_test)&quot; &amp;gt; version# 假定setlocalversion脚本存在，且会输出一个&#39;+&#39;号，输出结果为：# 3.10.108+# 该值会被写入version文件例4为比较实际的例子，选自linux kernel的makefile中，相关变量的注释已经添加，结合前三个例子应该很好理解总结Makefile中的$用于引用Makefile变量，shell中的$用于引用shell变量，Makefile中的$$用于把Makefile引用转化为shell引用参考 Makefile中$$使用" }, { "title": "VSCode远程SSH连接方法", "url": "/posts/vscode-ssh-remote/", "categories": "技术", "tags": "vscode, ssh", "date": "2021-03-01 09:00:00 +0800", "snippet": "安装Remote-SSH在商店搜索Remote-SSH，并安装如需要连接windows自带的wsl虚拟机，可以使用Remote-WSL插件修改配置文件 打开远程资源管理器标签 选择设置图标 编辑ssh config文件使用私钥登录使用ssh-keygen生成公私钥对: 私钥id_rsa放置在Windows(SSH客户端)的用户.ssh目录下 公钥id_rsa.pub放置在ssh服务器的.ssh目录下，Linux下需重命名为authorized_keys完成后可直接登录，无需输入密码SSH频繁断开问题连接成功后会发现SSH频繁断开，且速度很慢原因Windows自带openSSH版本较老，与Linux中的版本不兼容使用ssh -V查看版本:解决方法使用git中自带的openSSH编辑环境变量，将C:\\Program Files\\Git\\usr\\bin添加至Path环境变量，并置于上层重新查看版本号,如显示版本为新版，则设置成功C:\\Users\\huangjinkai&amp;gt;ssh -VOpenSSH_8.3p1, OpenSSL 1.1.1g 21 Apr 2020关闭所有VSCode窗口后，重新打开，可以发现SSH使用流畅，不会有掉线现象使用代理连接可以使用socks5或http代理连接Remote SSH,从而绕开防火墙限制打开配置文件，为要添加代理的配置添加一行ProxyCommandHost myhost HostName 192.168.1.1 Port 22 User dev IdentityFile &quot;C:\\Users\\admin\\Documents\\dev_ecdsa&quot; TCPKeepAlive yes ProxyCommand &quot;C:\\Program Files\\Git\\mingw64\\bin\\connect.exe&quot; -S 127.0.0.1:10808 %h %p这里使用了Git自带的mingw64工具箱中的connect工具，-S表示socks代理，当然也可以使用自己特定的代理工具参考 【工程调试记录】vscode远程连接卡顿、频繁掉线的一个解决方法 Connect over a proxy #117 Debug C++ in Visual Studio Code" }, { "title": "STL getline读入\r问题", "url": "/posts/cpp-stl-getline/", "categories": "技术", "tags": "stl, c++, getline", "date": "2021-02-25 09:00:00 +0800", "snippet": "getline说明std::getline (string) istream&amp;amp; getline (istream&amp;amp; is, string&amp;amp; str, char delim); istream&amp;amp; getline (istream&amp;amp; is, string&amp;amp; str);Get line from stream into stringExtracts characters from is and stores them into str until the delimitation character delim is found (or the newline character, ‘\\n’, for (2)). 读取到’\\n‘作为结束The extraction also stops if the end of file is reached in is or if some other error occurs during the input operation.If the delimiter is found, it is extracted and discarded (i.e. it is not stored and the next input operation will begin after it).Note that any content in str before the call is replaced by the newly extracted sequence.Each extracted character is appended to the string as if its member push_back was called.Parameters is - istream object from which characters are extracted. str - string object where the extracted line is stored.The contents in the string before the call (if any) are discarded and replaced by the extracted line. Return ValueThe same as parameter is.A call to this function may set any of the internal state flags of is if: flag error eofbit The end of the source of characters is reached during its operations. failbit The input obtained could not be interpreted as a valid textual representation of an object of this type. In this case, distr preserves the parameters and internal data it had before the call.Notice that some eofbit cases will also set failbit. badbit An error other than the above happened. (see ios_base::iostate for more info on these)Additionally, in any of these cases, if the appropriate flag has been set with is’s member function ios::exceptions, an exception of type ios_base::failure is thrown.出现的错误使用vscode编辑txt格式文件时，默认的换行符为CRLF，即\\r\\n，而getline的默认分隔符为\\n，导致\\r也被读入string，造成乱码参考 getline (string) - C++ Reference" }, { "title": "SOAP,WSDL,DSMR详解", "url": "/posts/soap-wsdl-dsmr/", "categories": "技术", "tags": "SOAP, WSDL, DSMR", "date": "2021-02-23 10:00:00 +0800", "snippet": "前置阅读： XML命名空间 Schema 教程前言SOAP是我们Web Service中很常见的一个协议，SOAP确定了一种通过XML实现跨语言、跨机器传输调用的协议，WSDL更像是所提供服务的一个规范、一个文档，本篇文章介绍梳理一下他们的规则与逻辑，更好的认识一下SOAP协议及WSDL描述文件。SOAP简单对象访问协议SOAP(Simple Object Access Protocol)简单对象访问协议是交换数据的一种规范，在Web Service中，交换带结构信息。可基于HTTP等协议，使用XML格式传输，抽象于语言实现、平台和硬件。即多语言包括PHP、Java、.Net均可支持。优点是跨语言，非常适合异步通信和针对松耦合的C/S，缺点是必须做很多运行时检查。相关概念 SOAP封装(envelop),定义了一个框架，描述消息中的内容是什么，是谁发送的，谁应当接受并处理。 SOAP编码规则(encoding rules),定义了一种序列化的机制，表示应用程序需要使用的数据类型的实例。 SOAP RPC表示(RPC representation)，定义了一个协定，用于表示远程过程调用和应答。 SOAP绑定(binding)，定义了SOAP使用哪种协议交换信息。使用HTTP/TCP/UDP协议都可以。基本结构示例：&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&amp;lt;soap:Envelope xmlns:soap=&quot;http://www.w3.org/2001/12/soap-envelope&quot; soap:encodingStyle=&quot;http://www.w3.org/2001/12/soap-encoding&quot;&amp;gt;     &amp;lt;soap:Header&amp;gt;      ...      ...    &amp;lt;/soap:Header&amp;gt;     &amp;lt;soap:Body&amp;gt;          ...          ...          &amp;lt;soap:Fault&amp;gt;            ...            ...          &amp;lt;/soap:Fault&amp;gt;    &amp;lt;/soap:Body&amp;gt;&amp;lt;/soap:Envelope&amp;gt;一条SOAP消息就是一个普通的XML文档，Envelope元素与Body元素（包含调用和响应信息）必须存在，Header元素（包含头部信息）和Fault元素（提供有关在处理此消息所发生的错误的信息）可以作为可选存在SOAP封装(envelop)SOAP消息的根元素，可把XML文档定义为SOAP消息命名空间xmlns：SOAP命名空间,固定不变。 在WSDL中，SOAP命名空间为http://www.w3.org/2003/05/soap-envelopeSOAP在默认命名空间中定义了3个属性：actor，mustUnderstand，encodingStyle。这些被定义在SOAP头部的属性可定义容器如何对SOAP消息进行处理。 在WSDL中主要用到了mustUnderstand属性 mustUnderstand属性——用于标识标题项对其进行处理的接受者来说是强制的还是可选的。（0可选1强制）soap:mustUnderstand=&quot;0/1&quot; actor属性可用于将Header元素寻址到一个特定的端点 soap:actor=&quot;URI&quot; encodingStyle属性用于定义在文档中使用的数据类型。此属性可出现在任何SOAP元素中，并会被应用到元素的内容及元素的所有子元素上。SOAP消息没有默认的编码方式。soap:encodingstyle=&quot;URI&quot;SOAP Header元素可选的SOAP Header元素可包含有关SOAP消息的应用程序专用信息。如果Header元素被提供，则它必须是Envelope元素的第一个子元素&amp;lt;soap:Header&amp;gt;   &amp;lt;m:Trans xmlns:m=&quot;http://www.w3schools.com/transaction/&quot; soap:mustUnderstand=&quot;1&quot;&amp;gt; &amp;lt;!-- mustUnderstand表示处理此头部的接受者必须认可此元素，假如此元素接受者无法认可此元素，则在处理此头部时必须失效 --&amp;gt; 234   &amp;lt;/m:Trans&amp;gt; &amp;lt;/soap:Heaser&amp;gt;SOAP Body元素必须的SOAP Body元素可包含打算传送到消息最终端点的实际SOAP消息。SOAP Body元素的直接子元素可以使合格的命名空间SOAP Fault元素用于存留SOAP消息的错误和状态消息，可选的SOAP Fault元素用于指示错误消息。如果已提供了Fault元素，则它必须是Body元素的子元素，在一条SOAP消息中，Fault元素只能出现一次。SOAP Fault子元素： 供识别障碍的代码 可供人阅读的有关障碍的说明 有关是谁引发故障的信息 存留涉及Body元素的应用程序的专用错误信息faultcode值描述： versionMismatch SOAP Envelope的无效命名空间被发现 mustUnderstand Header元素的一个直接子元素(mustUnderstand=”1′)无法被理解 Client 消息被不正确的构成，或包含不正确的信息 Server 服务器有问题，因此无法处理进行下去与Restful协议对比TODOWSDL网络服务描述语言WSDL(Web Services Description Language)网络服务描述语言，WSDL 是一种使用 XML 编写的文档。这种文档可描述某个 Web Service。文档的后缀名为一般为wsdl 官网：http://schemas.xmlsoap.org/wsdl/ WS-RT的WSDL描述：http://schemas.xmlsoap.org/ws/2006/08/resourceTransfer/wsrt.wsdl基本结构&amp;lt;definitions&amp;gt;    &amp;lt;types&amp;gt;       definition of types........    &amp;lt;/types&amp;gt;    &amp;lt;message&amp;gt;       definition of a message....    &amp;lt;/message&amp;gt;    &amp;lt;portType&amp;gt;       definition of a port.......    &amp;lt;/portType&amp;gt;    &amp;lt;binding&amp;gt;       definition of a binding....    &amp;lt;/binding&amp;gt;    &amp;lt;service&amp;gt;       definition of a service....    &amp;lt;/service&amp;gt;&amp;lt;/definitions&amp;gt;一个WSDL文档通常包含7个重要的元素，即types、import、message、portType、operation、binding、service元素。这些元素嵌套在definitions元素中，definitions是WSDL文档的根元素。实例以盛付通的一个接口为例，介绍一下整个wsdl描述文件，网址如下http://cardpay.shengpay.com/api-acquire-channel/services/receiveOrderService?wsdlDefinitionsWSDL文档中对于definitions的描述：&amp;lt;xs:element name=&quot;definitions&quot; type=&quot;wsdl:tDefinitions&quot; &amp;gt; &amp;lt;xs:key name=&quot;message&quot; &amp;gt; &amp;lt;xs:selector xpath=&quot;wsdl:message&quot; /&amp;gt; &amp;lt;xs:field xpath=&quot;@name&quot; /&amp;gt; &amp;lt;/xs:key&amp;gt; &amp;lt;xs:key name=&quot;portType&quot; &amp;gt; &amp;lt;xs:selector xpath=&quot;wsdl:portType&quot; /&amp;gt; &amp;lt;xs:field xpath=&quot;@name&quot; /&amp;gt; &amp;lt;/xs:key&amp;gt; &amp;lt;xs:key name=&quot;binding&quot; &amp;gt; &amp;lt;xs:selector xpath=&quot;wsdl:binding&quot; /&amp;gt; &amp;lt;xs:field xpath=&quot;@name&quot; /&amp;gt; &amp;lt;/xs:key&amp;gt; &amp;lt;xs:key name=&quot;service&quot; &amp;gt; &amp;lt;xs:selector xpath=&quot;wsdl:service&quot; /&amp;gt; &amp;lt;xs:field xpath=&quot;@name&quot; /&amp;gt; &amp;lt;/xs:key&amp;gt; &amp;lt;xs:key name=&quot;import&quot; &amp;gt; &amp;lt;xs:selector xpath=&quot;wsdl:import&quot; /&amp;gt; &amp;lt;xs:field xpath=&quot;@namespace&quot; /&amp;gt; &amp;lt;/xs:key&amp;gt;&amp;lt;/xs:element&amp;gt;Types数据类型定义的容器，它使用某种类型系统(一般地使用XML Schema中的类型系统)。&amp;lt;xs:element name=&quot;receB2COrderRequest&quot; type=&quot;tns:ReceB2COrderRequest&quot;/&amp;gt;  &amp;lt;xs:element name=&quot;receB2COrderResponse&quot; type=&quot;tns:ReceB2COrderResponse&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;ReceB2COrderRequest&quot;&amp;gt;     &amp;lt;xs:sequence&amp;gt;       &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;buyerContact&quot; type=&quot;xs:string&quot;/&amp;gt;        .......    &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt;   &amp;lt;xs:complexType name=&quot;receiveB2COrder&quot;&amp;gt;         &amp;lt;xs:sequence&amp;gt;           &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;arg0&quot; type=&quot;tns:ReceB2COrderRequest&quot;/&amp;gt;         &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt;  Message通信消息的数据结构的抽象类型化定义。使用Types所定义的类型来定义整个消息的数据结构。&amp;lt;wsdl:message name=&quot;receiveB2COrder&quot;&amp;gt;     &amp;lt;wsdl:part element=&quot;tns:receiveB2COrder&quot; name=&quot;parameters&quot;/&amp;gt; &amp;lt;/wsdl:message&amp;gt; Operation &amp;amp; PortTypeOperation 对服务中所支持的操作的抽象描述，一般单个Operation描述了一个访问入口的请求/响应消息对。 PortType 对于某个访问入口点类型所支持的操作的抽象集合，这些操作可以由一个或多个服务访问点来支持。&amp;lt;wsdl:portType name=&quot;ReceiveOrderAPI&quot;&amp;gt;     &amp;lt;wsdl:operation name=&quot;receiveB2COrder&quot;&amp;gt;       &amp;lt;wsdl:input message=&quot;tns:receiveB2COrder&quot; name=&quot;receiveB2COrder&quot;/&amp;gt;        &amp;lt;wsdl:output message=&quot;tns:receiveB2COrderResponse&quot; name=&quot;receiveB2COrderResponse&quot;/&amp;gt;        &amp;lt;wsdl:fault message=&quot;tns:MasAPIException&quot; name=&quot;MasAPIException&quot;/&amp;gt;     &amp;lt;/wsdl:operation&amp;gt; &amp;lt;/wsdl:portType&amp;gt;  Binding特定端口类型的具体协议和数据格式规范的绑定。&amp;lt;wsdl:binding name=&quot;ReceiveOrderAPIExplorterServiceSoapBinding&quot; type=&quot;tns:ReceiveOrderAPI&quot;&amp;gt;     &amp;lt;soap:binding style=&quot;document&quot; transport=&quot;http://schemas.xmlsoap.org/soap/http&quot;/&amp;gt;      &amp;lt;wsdl:operation name=&quot;receiveB2COrder&quot;&amp;gt;       &amp;lt;soap:operation soapAction=&quot;&quot; style=&quot;document&quot;/&amp;gt;        &amp;lt;wsdl:input name=&quot;receiveB2COrder&quot;&amp;gt;         &amp;lt;soap:body use=&quot;literal&quot;/&amp;gt;       &amp;lt;/wsdl:input&amp;gt;        &amp;lt;wsdl:output name=&quot;receiveB2COrderResponse&quot;&amp;gt;         &amp;lt;soap:body use=&quot;literal&quot;/&amp;gt;       &amp;lt;/wsdl:output&amp;gt;        &amp;lt;wsdl:fault name=&quot;MasAPIException&quot;&amp;gt;         &amp;lt;soap:fault name=&quot;MasAPIException&quot; use=&quot;literal&quot;/&amp;gt;       &amp;lt;/wsdl:fault&amp;gt;     &amp;lt;/wsdl:operation&amp;gt; &amp;lt;/wsdl:binding&amp;gt;  Port&amp;amp;ServicePort 定义为协议/数据格式绑定与具体Web访问地址组合的单个服务访问点。 Service 相关服务访问点的集合。&amp;lt;wsdl:service name=&quot;ReceiveOrderAPIExplorterService&quot;&amp;gt;     &amp;lt;wsdl:port binding=&quot;tns:ReceiveOrderAPIExplorterServiceSoapBinding&quot; name=&quot;ReceiveOrderAPIExplorterPort&quot;&amp;gt;       &amp;lt;soap:address location=&quot;http://cardpay.shengpay.com/api-acquire-channel/services/receiveOrderService&quot;/&amp;gt;     &amp;lt;/wsdl:port&amp;gt; &amp;lt;/wsdl:service&amp;gt;WS-AddressingWeb服务寻址（WS-Addressing）是一个W3C推荐标准，为Web服务提供一种与传输层无关的，传送寻址信息的机制。规范主要由两部分组成：传送Web服务端点的引用的数据结构，以及一套能够在特定的消息上关联寻址信息的消息寻址属性。WS-Addressing是将消息路由数据包含在SOAP头中的一种标准方法。利用WS-Addressing的消息可以在标准化的SOAP头中包含自己的包含发送元数据，而不是依赖于网络层传输来传送路由信息。网络级传输只负责将消息发送到能够读取WS-Addressing元数据的分配器那里。一旦消息抵达了URI所制定的分配器，网络层传输的工作就完成了。通过在标准的SOAP头中(wsa:ReplyTo)指定应答消息应该发送到哪里的端点引用，WS-Addressing可以支持异步交互方式。 服务提供者使用另一个连接，将应答消息发送给wsa:ReplyTo所指定的端点。这就将SOAP请求/应答消息的交互与HTTP请求/应答协议分离，这样，跨越任意时间的长时间运行的交互成为可能。端点引用端点引用（Endpoint Reference，速写EPR）是一个XML结构，封装了对访问Web服务的消息寻址有用的信息。这包括了消息的目的地地址，任何其他路由消息到目的地所需的参数（称作引用参数），以及有关服务的任选的元数据（例如WSDL或WS-Policy）。消息寻址属性消息寻址属性表明与将消息传送到Web服务有关的寻址信息，包括： 目的地(To) – 该消息的目的地的URI。 源端点(From) – 发出该消息的服务端点（EPR） 应答端点(ReplyTo) – 应答消息接收者的端点（EPR） 故障端点(FaultTo) – 故障消息接收者的端点（EPR） 动作(Action) – 指示该消息的语义（可能有助于该消息的寻址）的URI 消息ID(MessageID) – 唯一消息标识符URI 关系(RelatesTo) – 与之前消息的关系(一对URI)DSMR示例Example “Delete” operation:&amp;lt;s:Envelope xmlns:s=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:wsa=&quot;http://www.w3.org/2005/08/addressing&quot; xmlns:p32=&quot;http://www.energiened.nl/Content/Publications/dsmr/P32&quot;&amp;gt; &amp;lt;s:Header&amp;gt; &amp;lt;wsa:To&amp;gt; http://10.0.1.2/services/Resources &amp;lt;/wsa:To&amp;gt; &amp;lt;wsa:Action s:mustUnderstand=&quot;true&quot;&amp;gt; http://schemas.xmlsoap.org/ws/2004/09/transfer/Delete &amp;lt;/wsa:Action&amp;gt; &amp;lt;wsa:MessageID&amp;gt; uuid:ddacc64d-c64d-1dac-acbc-017f00000001 &amp;lt;/wsa:MessageID&amp;gt; &amp;lt;p32:ResourceURI wsa:IsReferenceParameter=&quot;true&quot;&amp;gt; http://www.energiened.nl/Content/Publications/dsmr/P32/meterAccess &amp;lt;/p32:ResourceURI&amp;gt; &amp;lt;p32:SelectorSet&amp;gt; &amp;lt;p32:Selector Name=&quot;ResourceID&quot;&amp;gt;MeterAccess-1&amp;lt;/p32:Selector&amp;gt; &amp;lt;/p32:SelectorSet&amp;gt; &amp;lt;/s:Header&amp;gt; &amp;lt;s:Body&amp;gt; &amp;lt;DeleteRequest xmlns=&quot;http://schemas.xmlsoap.org/ws/2004/09/transfer&quot;/&amp;gt; &amp;lt;/s:Body&amp;gt;&amp;lt;/s:Envelope&amp;gt;Example “Delete” response:&amp;lt;s:Envelope xmlns:s=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:wsa=&quot;http://www.w3.org/2005/08/addressing&quot;&amp;gt; &amp;lt;s:Header&amp;gt; &amp;lt;wsa:ReplyTo&amp;gt; &amp;lt;wsa:Address&amp;gt; http://www.w3.org/2005/08/addressing/anonymous &amp;lt;/wsa:Address&amp;gt; &amp;lt;/wsa:ReplyTo&amp;gt; &amp;lt;wsa:From&amp;gt; &amp;lt;wsa:Address&amp;gt; http://10.0.1.2/services/Resources &amp;lt;/wsa:Address&amp;gt; &amp;lt;wsa:ReferenceParameters/&amp;gt; &amp;lt;/wsa:From&amp;gt; &amp;lt;wsa:MessageID&amp;gt; uuid:C986EEAA-484B-4b94-AB46-743EE560B5F9 &amp;lt;/wsa:MessageID&amp;gt; &amp;lt;wsa:Action&amp;gt; http://schemas.xmlsoap.org/ws/2004/09/transfer/DeleteResponse &amp;lt;/wsa:Action&amp;gt; &amp;lt;wsa:RelatesTo wsa:RelationshipType=&quot;wsa:Reply&quot;&amp;gt; uuid:ddacc64d-c64d-1dac-acbc-017f00000001 &amp;lt;/wsa:RelatesTo&amp;gt; &amp;lt;/s:Header&amp;gt; &amp;lt;s:Body&amp;gt; &amp;lt;DeleteResponse xmlns=&quot;http://schemas.xmlsoap.org/ws/2004/09/transfer&quot;/&amp;gt; &amp;lt;/s:Body&amp;gt;&amp;lt;/s:Envelope&amp;gt;WS-RT (Web Services Resource Transfer)This specification defines extensions to WS-Transfer primarily to provide fragment-based access to resources.WS-RT是WS-Transfer的扩展，主要用于基于片段的资源的访问 官网：https://www.w3.org/TR/2010/NOTE-ws-resource-transfer-20100713/ 协议：http://schemas.xmlsoap.org/ws/2006/08/resourceTransfer/介绍This specification is intended to form an essential core component of a unified resource access protocol for the Web services space.The operations described in this specification constitute an extension to the WS-Transfer specification, which defines standard messages for controlling resources using the familiar paradigms of “get”, “put”, “create”, and “delete”. The extensions deal primarily with fragment-based access to resources.This document constitutes WS-ResourceTransfer, hereafter referred to as WS-RT.主要用于资源传输，定义了”get”, “put”, “create”, “delete“四个方法，类似于HTTP请求，包含了WSDL的说明更多内容详见官网WS-Transfer (Web Services Transfer) 官网：https://www.w3.org/Submission/WS-Transfer/ 协议：http://schemas.xmlsoap.org/ws/2004/09/transfer/介绍与WS-RT类似，不再过多介绍DSMRDSMR协议是由荷兰Energie-Nederland协会编写的能源管理与通信标准，以下是Energie-Nederland协会的简介： Energie-Nederland is de branchevereniging voor alle partijen die stroom, gas en warmte produceren, leveren en verhandelen. Samen vertegenwoordigen wij circa 80% van de markt. Onze ruim 60 leden zijn actief in zowel ‘groene’ als ‘grijze’ energie en allerlei soorten dienstverlening. Onder hen zijn ook veel nieuwkomers op de markt, innovatieve spelers en duurzame initiatieven. Energie-Nederland gaat voor een duurzame, betrouwbare en betaalbare energievoorziening; wij zijn een van de trekkers van het Klimaatakkoord.简介是荷兰语的，我也看不懂，只能找Google机翻一下： Energie-Nederland是所有生产，供应和贸易电，气和热的各方的贸易协会。 我们共同代表了约80％的市场。 我们的60多个成员活跃于“绿色”和“灰色”能源以及各种服务中。 他们还包括许多新进入市场的人，创新参与者和可持续发展倡议。 Energie-Nederland致力于可持续，可靠和负担得起的能源供应； 我们是《气候协定》的发起人之一。ScopeThis part provides a companion standard for an Automatic Meter Reading (AMR) system for electricity thermal, (heat &amp;amp; cold), gas and water meters.The scope of this standard is on: Residential electricity meters Residential thermal (heat &amp;amp; cold) meters Residential gas meters and gas valve Residential water metersThis companion standard focuses on the P3 interface for Electricity meters.System architectureThe P3.2 interface is introduced because a Data Concentrator (DC) can be placed between the CS and the meter(s). With this, the DC divides P3 into two parts, P3.1 and P3.2. However since P3 and P3.1 are functionally the same these terms are interchangeable. Where P3 is mentioned this can also be read as P3.1 (when a DC is involved). Where P3.2 is mentioned this deals exclusively with the interface between the CS and the DC. Where gas meters are mentioned this could also be replaced with thermal and water meters.The communication interface P3 and P3.1 (see figure 1.2) is based on the DLMS/COSEM standard. Communication interface P3.2 is based on Web Services standards compliant with WS-I Basic Profile 1.1 or WS-I Basic Profile 1.2.P3和P3.1基于DLMS/COSEM标准，P3.2基于Web Services标准，符合WS-I Basic Profile 1.1或WS-I Basic Profile 1.2。 本文主要介绍P3.2部分DSMR协议中的Resource TransferDSMR中的Resource Transfer符合WS-ResourceTransfer规范，WS-ResourceTransfer是WS-Transfer的扩展。WS-Transfer定义了Get，Put，Create和Delete资源表示形式的操作，而WS-ResourceTransfer扩展了这些操作，以增加对资源表示片段进行操作的能力。GetWS-Transfer Get操作用于整体检索现有资源表示。 WS-ResourceTransfer扩展了Get操作，以检索现有表示的片段。 可以返回其完整表示形式的资源还必须支持wxf:Get(即WS-Transfer Get操作)，而无需使用WS-ResourceTransfer扩展即可返回整个资源表示形式。wsrt:Get的[Body]包含一个标识目标片段的表达式。 按照我的理解，Get操作与HTTP中的GET请求类似，是通过UUID获取资源wsrt:Get的概述是：[Headers] &amp;lt;wsrt:ResourceTransfer s:mustUnderstand=&quot;true&quot;? /&amp;gt;[Action] http://schemas.xmlsoap.org/ws/2004/09/transfer/Get[Body] &amp;lt;wsrt:Get Dialect=&quot;xs:anyURI&quot;?&amp;gt; . &amp;lt;wsrt:Expression ...&amp;gt;xs:any&amp;lt;/wsrt:Expression&amp;gt; * &amp;lt;/wsrt:Get&amp;gt;PutWS-Transfer Put 操作用于通过提供替换XML表示(XML representation)来更新现有资源表示。 WS-ResourceTransfer扩展了 Put 操作，通过提供XML表示的片段(fragments of the XML representation)来更新现有资源表示。 可以更新其完整表示形式的资源还必须支持wxf:Put(即WS-Transfer Put操作)以更新整个资源表示形式，而无需使用WS-ResourceTransfer扩展。 按照我的理解，Put操作是SET操作Put操作的概括为：[Headers] &amp;lt;wsrt:ResourceTransfer s:mustUnderstand=&quot;true&quot;/&amp;gt;[Action] http://schemas.xmlsoap.org/ws/2004/09/transfer/Put[Body] &amp;lt;wsrt:Put Dialect=&quot;xs:anyURI&quot;?&amp;gt; &amp;lt;wsrt:Fragment Mode=&quot;xs:anyURI&quot;&amp;gt; &amp;lt;wsrt:Expression&amp;gt;xs:any&amp;lt;/wsrt:Expression&amp;gt; ? &amp;lt;wsrt:Value ...&amp;gt;xs:any&amp;lt;/wsrt:Value&amp;gt; ? &amp;lt;/wsrt:Fragment&amp;gt; + &amp;lt;/wsrt:Put&amp;gt;CreateWS-Transfer Create操作用于通过初始表示(initial representation)来创建资源。 接收到Create请求的资源工厂将分配一个新资源，该资源根据显示的表示(presented representation)进行了初始化。 将为新资源分配工厂服务(factory-service-determined)确定的端点引用，该端点引用在响应消息中返回。 在许多情况下，创建资源所需的信息可能与初始表示（通过随后的Get操作实现的值）明显不同，并且提供初始表示是不可行的。WS-ResourceTransfer扩展了Create操作，以从零个或多个指定的XML表示形式的片段中创建资源。 WS-ResourceTransfer进一步扩展了Create操作，从而可以在资源创建过程中创建任何资源元数据。 按照我的理解，Create操作是开辟资源存储的空间，创建资源对应的UUID，等待之后填充或获取Create操作的扩展概要为：[Headers] &amp;lt;wsrt:ResourceTransfer s:mustUnderstand=&quot;true&quot;/&amp;gt;[Action] http://schemas.xmlsoap.org/ws/2004/09/transfer/Create[Body] &amp;lt;wsrt:Create Dialect=&quot;xs:anyURI&quot;?&amp;gt; &amp;lt;wsmex:Metadata&amp;gt;resource metadata&amp;lt;/wsmex:Metadata&amp;gt; ? &amp;lt;wsrt:Fragment&amp;gt; &amp;lt;wsrt:Expression&amp;gt;xs:any&amp;lt;/wsrt:Expression&amp;gt; ? &amp;lt;wsrt:Value ...&amp;gt;xs:any&amp;lt;/wsrt:Value&amp;gt; &amp;lt;/wsrt:Fragment&amp;gt; * &amp;lt;/wsrt:Create&amp;gt;DeleteWS-Transfer Delete操作用于整体删除资源。 WSResourceTransfer没有单独定义或扩展WS-Transfer中的Delete操作，而是直接使用WS-Transfer定义的Delete。 按照我的理解，Delete操作与Create对应，为删除资源并释放空间Delete请求消息必须采用以下格式：&amp;lt;s:Envelope …&amp;gt; &amp;lt;s:Header …&amp;gt; &amp;lt;wsa:Action&amp;gt; http://schemas.xmlsoap.org/ws/2004/09/transfer/Delete &amp;lt;/wsa:Action&amp;gt; &amp;lt;wsa:MessageID&amp;gt;xs:anyURI&amp;lt;/wsa:MessageID&amp;gt; &amp;lt;wsa:To&amp;gt;xs:anyURI&amp;lt;/wsa:To&amp;gt; … &amp;lt;/s:Header&amp;gt; &amp;lt;s:Body … /&amp;gt;&amp;lt;/s:Envelope&amp;gt;示例本部分包含WS-RTGet，Put，Create和Delete操作的示例。 这些示例旨在举例说明MeterAccess资源的基本WS-RT操作。 MeterAccess资源是用于访问仪表对象的资源。 出于本示例的目的，MeterAccess资源模型访问单个能量寄存器COSEM对象。 表1显示了激活并填充结果后的MeterAccess资源。Web Service 安全原文： Security for Data Concentrator requires protection against attacks on the P3.2 Interface with providing Confidentiality, Integrity and Authentication for the services provided with Web Services. Authentication is required for communicating parties. WS-I Basic Profile 1.1 and 1.2 adopt HTTP secured with TLS 1.0 or SSL 3.0 (HTTPS) for security of Web Services. HTTPS is transport level of security and provides mature and most widely used standard for secured connections for HTTP based transports. Higher levels of Web Services Security defined with WS-Security are out of the scope of this specificationData Concentrator的安全性要求为Web服务提供的服务提供机密性，完整性和身份验证，以防止P3.2接口受到攻击。 通信方需要身份验证。WS-I基本配置文件1.1和1.2采用HTTP协议，该协议受TLS 1.0或SSL 3.0(HTTPS)保护，以确保Web服务的安全。 HTTPS是传输的安全级别，它为基于HTTP的传输的安全连接提供了成熟且使用最广泛的标准。用WS-Security定义的更高级别的Web服务安全性不在本规范范围内附录1：P3.2 XML Schema&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;xs:schema xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:wsa=&quot;http://schemas.xmlsoap.org/ws/2004/08/addressing&quot; elementFormDefault=&quot;qualified&quot; attributeFormDefault=&quot;unqualified&quot;&amp;gt; &amp;lt;xs:import namespace=&quot;http://schemas.xmlsoap.org/ws/2004/08/addressing&quot; schemaLocation=&quot;http://schemas.xmlsoap.org/ws/2004/08/addressing&quot;/&amp;gt; &amp;lt;xs:import namespace=&quot;http://www.w3.org/XML/1998/namespace&quot; schemaLocation=&quot;http://www.w3.org/2001/xml.xsd&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;attributableURI&quot;&amp;gt; &amp;lt;xs:simpleContent&amp;gt; &amp;lt;xs:extension base=&quot;xs:anyURI&quot;&amp;gt; &amp;lt;xs:anyAttribute namespace=&quot;##other&quot; processContents=&quot;lax&quot;/&amp;gt; &amp;lt;/xs:extension&amp;gt; &amp;lt;/xs:simpleContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;ResourceURI&quot; type=&quot;attributableURI&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;SelectorType&quot; mixed=&quot;true&quot;&amp;gt; &amp;lt;xs:annotation&amp;gt; &amp;lt;xs:documentation&amp;gt;Instances of this type can be only simple types or EPRs, not arbitrary mixed data.&amp;lt;/xs:documentation&amp;gt; &amp;lt;/xs:annotation&amp;gt; &amp;lt;xs:complexContent mixed=&quot;true&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:anyType&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element ref=&quot;wsa:EndpointReference&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;xs:attribute name=&quot;Name&quot; type=&quot;xs:NCName&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;xs:anyAttribute namespace=&quot;##other&quot; processContents=&quot;lax&quot;/&amp;gt; &amp;lt;/xs:restriction&amp;gt; &amp;lt;/xs:complexContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;Selector&quot; type=&quot;SelectorType&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;SelectorSetType&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element ref=&quot;Selector&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;xs:anyAttribute namespace=&quot;##other&quot; processContents=&quot;lax&quot;/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;attributableAny&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ResourceURI&quot; type=&quot;xs:anyURI&quot;/&amp;gt; &amp;lt;xs:element name=&quot;SelectorSet&quot; type=&quot;SelectorSetType&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ResourceEventResult&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:any namespace=&quot;##other&quot; processContents=&quot;lax&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;xs:anyAttribute namespace=&quot;##other&quot; processContents=&quot;lax&quot;/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;ResourceEventType&quot;&amp;gt; &amp;lt;xs:complexContent&amp;gt; &amp;lt;xs:extension base=&quot;attributableAny&quot;/&amp;gt; &amp;lt;/xs:complexContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;ResourceEvent&quot; type=&quot;ResourceEventType&quot;/&amp;gt; &amp;lt;xs:simpleType name=&quot;bitString&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;octetString&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:complexType name=&quot;NULL&quot; final=&quot;#all&quot;/&amp;gt; &amp;lt;xs:simpleType name=&quot;ISO646String&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:token&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;visibleString&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;ISO646String&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Integer8&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:byte&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Integer16&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:short&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Integer32&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:int&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Integer64&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:long&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Unsigned8&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:unsignedByte&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Unsigned16&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:unsignedShort&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Unsigned32&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:unsignedInt&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;Unsigned64&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;xs:unsignedLong&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;actionResult&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:simpleType name=&quot;dataAccessResult&quot;&amp;gt; &amp;lt;xs:restriction base=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;/xs:simpleType&amp;gt; &amp;lt;xs:complexType name=&quot;typeDescription&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;N&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;A&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;NumberOfElements&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;TypeDescription&quot; type=&quot;typeDescription&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;S&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:element name=&quot;TypeDescription&quot; type=&quot;typeDescription&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;B&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BS&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DL&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DLU&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;FP&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;OS&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;VS&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BCD&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;I&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;U&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;LU&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L64&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L64U&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;E&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F32&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F64&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DT&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;D&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;T&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DC&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;sequenceOfData&quot;&amp;gt; &amp;lt;xs:choice maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:element name=&quot;N&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;A&quot; type=&quot;sequenceOfData&quot;/&amp;gt; &amp;lt;xs:element name=&quot;S&quot; type=&quot;sequenceOfData&quot;/&amp;gt; &amp;lt;xs:element name=&quot;B&quot; type=&quot;xs:boolean&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BS&quot; type=&quot;bitString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DL&quot; type=&quot;Integer32&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DLU&quot; type=&quot;Unsigned32&quot;/&amp;gt; &amp;lt;xs:element name=&quot;FP&quot; type=&quot;xs:float&quot;/&amp;gt; &amp;lt;xs:element name=&quot;OS&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;VS&quot; type=&quot;visibleString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BCD&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;I&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L&quot; type=&quot;Integer16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;U&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;LU&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;CA&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ContentsDescription&quot; type=&quot;typeDescription&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ArrayContents&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;L64&quot; type=&quot;Integer64&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L64U&quot; type=&quot;Unsigned64&quot;/&amp;gt; &amp;lt;xs:element name=&quot;E&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F32&quot; type=&quot;xs:float&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F64&quot; type=&quot;xs:double&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DT&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;D&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;T&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DC&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;data&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;N&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;xs:element name=&quot;A&quot; type=&quot;sequenceOfData&quot;/&amp;gt; &amp;lt;xs:element name=&quot;S&quot; type=&quot;sequenceOfData&quot;/&amp;gt; &amp;lt;xs:element name=&quot;B&quot; type=&quot;xs:boolean&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BS&quot; type=&quot;bitString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DL&quot; type=&quot;Integer32&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DLU&quot; type=&quot;Unsigned32&quot;/&amp;gt; &amp;lt;xs:element name=&quot;FP&quot; type=&quot;xs:float&quot;/&amp;gt; &amp;lt;xs:element name=&quot;OS&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;VS&quot; type=&quot;visibleString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;BCD&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;I&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L&quot; type=&quot;Integer16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;U&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;LU&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;CA&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ContentsDescription&quot; type=&quot;typeDescription&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ArrayContents&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;L64&quot; type=&quot;Integer64&quot;/&amp;gt; &amp;lt;xs:element name=&quot;L64U&quot; type=&quot;Unsigned64&quot;/&amp;gt; &amp;lt;xs:element name=&quot;E&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F32&quot; type=&quot;xs:float&quot;/&amp;gt; &amp;lt;xs:element name=&quot;F64&quot; type=&quot;xs:double&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DT&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;D&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;T&quot; type=&quot;xs:hexBinary&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DC&quot; type=&quot;NULL&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;actionAccessResult&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Result&quot; type=&quot;actionResult&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ReturnParameters&quot; type=&quot;dataAccessResult&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;setAccessResult&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Result&quot; type=&quot;dataAccessResult&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;getAccessResult&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;Data&quot; type=&quot;data&quot;/&amp;gt; &amp;lt;xs:element name=&quot;DataAccessResult&quot; type=&quot;dataAccessResult&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;imageTransferResult&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Result&quot; type=&quot;xs:boolean&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageTransferStatus&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemAccessResult&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;GetAccessResult&quot; type=&quot;getAccessResult&quot;/&amp;gt; &amp;lt;xs:element name=&quot;SetAccessResult&quot; type=&quot;setAccessResult&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ActionAccessResult&quot; type=&quot;actionAccessResult&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageTransferResult&quot; type=&quot;imageTransferResult&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;selectiveAccessDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;AccessSelector&quot; type=&quot;Unsigned8&quot;/&amp;gt; &amp;lt;xs:element name=&quot;AccessParameters&quot; type=&quot;data&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;getAccessDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;CosemAttributeDescriptor&quot; type=&quot;cosemAttributeDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;AccessSelection&quot; type=&quot;selectiveAccessDescriptor&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;setAccessDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;CosemAttributeDescriptor&quot; type=&quot;cosemAttributeDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;AccessSelection&quot; type=&quot;selectiveAccessDescriptor&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Value&quot; type=&quot;data&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;actionAccessDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;CosemMethodDescriptor&quot; type=&quot;cosemMethodDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;MethodInvocationParameters&quot; type=&quot;data&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;imageTransferDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ImageReference&quot; type=&quot;imageReference&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageTransferObjectReference&quot; type=&quot;cosemObjectReference&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageTransferSchedule&quot; type=&quot;imageTransferSchedule&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemMethodDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ClassId&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;InstanceId&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;MethodId&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemAttributeDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ClassId&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;InstanceId&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;AttributeId&quot; type=&quot;Integer8&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemObjectReference&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ClassId&quot; type=&quot;Unsigned16&quot;/&amp;gt; &amp;lt;xs:element name=&quot;InstanceId&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;imageReference&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ImageIdentifier&quot; type=&quot;octetString&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageLocation&quot; type=&quot;xs:anyURI&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;imageTransferSchedule&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Activation&quot; type=&quot;xs:dateTime&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageActivationObjectReference&quot; type=&quot;cosemObjectReference&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemAccessDesciptor&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;GetAccessDescriptor&quot; type=&quot;getAccessDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;SetAccessDescriptor&quot; type=&quot;setAccessDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ActionAccessDescriptor&quot; type=&quot;actionAccessDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ImageTransferDescriptor&quot; type=&quot;imageTransferDescriptor&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;cosemAccess&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;CosemAccessDescriptor&quot; type=&quot;cosemAccessDesciptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;CosemAccessResult&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:complexContent&amp;gt; &amp;lt;xs:extension base=&quot;cosemAccessResult&quot;&amp;gt; &amp;lt;xs:attribute name=&quot;MeterID&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:attribute name=&quot;Activated&quot; type=&quot;xs:dateTime&quot;/&amp;gt; &amp;lt;/xs:extension&amp;gt; &amp;lt;/xs:complexContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;meterReference&quot;&amp;gt; &amp;lt;xs:attribute name=&quot;MeterID&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;meterAccess&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;MeterReferenceList&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;MeterReference&quot; type=&quot;meterReference&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;CosemAccessList&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;CosemAccess&quot; type=&quot;cosemAccess&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;Activates&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Expires&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Created&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Updated&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;packageTransferResult&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Result&quot; type=&quot;xs:boolean&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;packageTransferDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;PackageReference&quot; type=&quot;packageReference&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;keyValueType&quot;&amp;gt; &amp;lt;xs:simpleContent&amp;gt; &amp;lt;xs:extension base=&quot;xs:base64Binary&quot;/&amp;gt; &amp;lt;/xs:simpleContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;keyContextType&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:any namespace=&quot;##any&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;xs:attribute name=&quot;Name&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;meterSecurityKey&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;KeyValue&quot; type=&quot;keyValueType&quot;/&amp;gt; &amp;lt;xs:element name=&quot;KeyContext&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;xs:attribute name=&quot;KeyIdent&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;xs:attribute name=&quot;KeyType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;meterSecurityTransferDescriptor&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;MeterReference&quot; type=&quot;meterReference&quot;/&amp;gt; &amp;lt;xs:element name=&quot;MeterSecurityKey&quot; type=&quot;meterSecurityKey&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;securityTransferResult&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Result&quot; type=&quot;xs:boolean&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;securityTransferDescriptor&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;MeterSecurityTransferDescriptor&quot; type=&quot;meterSecurityTransferDescriptor&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;packageReference&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;PackageIdentifier&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element name=&quot;PackageLocation&quot; type=&quot;xs:anyURI&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;serviceAccessDescriptor&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;PackageTransferDescriptor&quot; type=&quot;packageTransferDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;SecurityTransferDescriptor&quot; type=&quot;securityTransferDescriptor&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;serviceAccessResult&quot;&amp;gt; &amp;lt;xs:choice&amp;gt; &amp;lt;xs:element name=&quot;PackageTransferResult&quot; type=&quot;packageTransferResult&quot;/&amp;gt; &amp;lt;xs:element name=&quot;SecurityTransferResult&quot; type=&quot;securityTransferResult&quot;/&amp;gt; &amp;lt;/xs:choice&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;serviceAccess&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ServiceAccessDescriptor&quot; type=&quot;serviceAccessDescriptor&quot;/&amp;gt; &amp;lt;xs:element name=&quot;ServiceAccessResult&quot; type=&quot;serviceAccessResult&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;concentratorServiceAccess&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ServiceAccessList&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ServiceAccess&quot; type=&quot;serviceAccess&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;Activates&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Expires&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Created&quot; type=&quot;xs:dateTime&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Updated&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;eventLogEntry&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;EventSource&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:simpleContent&amp;gt; &amp;lt;xs:extension base=&quot;xs:string&quot;&amp;gt; &amp;lt;xs:attribute name=&quot;Name&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;xs:attribute name=&quot;Ident&quot; type=&quot;xs:string&quot; use=&quot;required&quot;/&amp;gt; &amp;lt;/xs:extension&amp;gt; &amp;lt;/xs:simpleContent&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;EventIdent&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element name=&quot;EventLevel&quot; type=&quot;xs:short&quot;/&amp;gt; &amp;lt;xs:element name=&quot;EventDateTime&quot; type=&quot;xs:dateTime&quot;/&amp;gt; &amp;lt;xs:element name=&quot;EventDetail&quot; type=&quot;xs:string&quot; minOccurs=&quot;0&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;eventLog&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;EventLogEntry&quot; type=&quot;eventLogEntry&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;concentratorStatus&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;Ident&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Status&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;metersDirectory&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;RegisteredMetersList&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:element name=&quot;RegisteredMeter&quot; type=&quot;meterReference&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;RevokedMetersList&quot; minOccurs=&quot;0&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:element name=&quot;RevokedMeter&quot; type=&quot;meterReference&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;AllowedMetersList&quot; minOccurs=&quot;0&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence maxOccurs=&quot;unbounded&quot;&amp;gt; &amp;lt;xs:element name=&quot;AllowedMeter&quot; type=&quot;meterReference&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;MeterAccess&quot; type=&quot;meterAccess&quot;&amp;gt; &amp;lt;xs:annotation&amp;gt; &amp;lt;xs:documentation&amp;gt;MeterAccess provides access to Meters registered on the Concentrator&amp;lt;/xs:documentation&amp;gt; &amp;lt;/xs:annotation&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;MetersDirectory&quot; type=&quot;metersDirectory&quot;&amp;gt; &amp;lt;xs:annotation&amp;gt; &amp;lt;xs:documentation&amp;gt;MetersDirectory provides acecss to Directory of Meters registered on the Concentrator&amp;lt;/xs:documentation&amp;gt; &amp;lt;/xs:annotation&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;ConcentratorAccess&quot;&amp;gt; &amp;lt;xs:annotation&amp;gt; &amp;lt;xs:documentation&amp;gt;ConcentratorAccess provides access to services of the Concentrator&amp;lt;/xs:documentation&amp;gt; &amp;lt;/xs:annotation&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ConcentratorService&quot;&amp;gt; &amp;lt;xs:complexType&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element name=&quot;ConcentratorServiceAccess&quot; type=&quot;concentratorServiceAccess&quot; minOccurs=&quot;0&quot; maxOccurs=&quot;unbounded&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt; &amp;lt;xs:element name=&quot;EventLog&quot; type=&quot;eventLog&quot;/&amp;gt; &amp;lt;xs:element name=&quot;Status&quot; type=&quot;concentratorStatus&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:element&amp;gt;&amp;lt;/xs:schema&amp;gt;附录2：盛付通接口实例&amp;lt;wsdl:definitions xmlns:ns1=&quot;http://schemas.xmlsoap.org/soap/http&quot; xmlns:soap=&quot;http://schemas.xmlsoap.org/wsdl/soap/&quot; xmlns:tns=&quot;http://www.sdo.com/mas/api/receive/&quot; xmlns:wsdl=&quot;http://schemas.xmlsoap.org/wsdl/&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; name=&quot;ReceiveOrderAPIExplorterService&quot; targetNamespace=&quot;http://www.sdo.com/mas/api/receive/&quot;&amp;gt; &amp;lt;wsdl:types&amp;gt; &amp;lt;xs:schema xmlns:tns=&quot;http://www.sdo.com/mas/api/receive/&quot; xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot; attributeFormDefault=&quot;unqualified&quot; elementFormDefault=&quot;unqualified&quot; targetNamespace=&quot;http://www.sdo.com/mas/api/receive/&quot;&amp;gt; &amp;lt;xs:element name=&quot;receB2COrderRequest&quot; type=&quot;tns:ReceB2COrderRequest&quot;/&amp;gt; &amp;lt;xs:element name=&quot;receB2COrderResponse&quot; type=&quot;tns:ReceB2COrderResponse&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;ReceB2COrderRequest&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;buyerContact&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;buyerId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;buyerIp&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;buyerName&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;cardPayInfo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;cardValue&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;currency&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;depositId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;depositIdType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;expireTime&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;extension&quot; type=&quot;tns:extension&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;header&quot; type=&quot;tns:header&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;instCode&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;language&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;notifyUrl&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderAmount&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderTime&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;pageUrl&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payChannel&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payeeId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payerAuthTicket&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payerId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;payerMobileNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;productDesc&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;productId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;productName&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;productNum&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;productUrl&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;sellerId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;signature&quot; type=&quot;tns:signature&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;terminalType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;unitPrice&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;extension&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;ext1&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;ext2&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;ext3&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;header&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;charset&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;sendTime&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;sender&quot; type=&quot;tns:sender&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;service&quot; type=&quot;tns:service&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;traceNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;sender&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;senderId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;service&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;serviceCode&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;version&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;signature&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;signMsg&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;signType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;ReceB2COrderResponse&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;customerLogoUrl&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;customerName&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;customerNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;extension&quot; type=&quot;tns:extension&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;header&quot; type=&quot;tns:header&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderAmount&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;orderType&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;returnInfo&quot; type=&quot;tns:returnInfo&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;sessionId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;signature&quot; type=&quot;tns:signature&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;tokenId&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;transNo&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;transStatus&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;transTime&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:complexType name=&quot;returnInfo&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;errorCode&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;errorMsg&quot; type=&quot;xs:string&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;MasAPIException&quot; type=&quot;tns:MasAPIException&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;MasAPIException&quot;&amp;gt; &amp;lt;xs:sequence/&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;receiveB2COrder&quot; type=&quot;tns:receiveB2COrder&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;receiveB2COrder&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;arg0&quot; type=&quot;tns:ReceB2COrderRequest&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;xs:element name=&quot;receiveB2COrderResponse&quot; type=&quot;tns:receiveB2COrderResponse&quot;/&amp;gt; &amp;lt;xs:complexType name=&quot;receiveB2COrderResponse&quot;&amp;gt; &amp;lt;xs:sequence&amp;gt; &amp;lt;xs:element minOccurs=&quot;0&quot; name=&quot;return&quot; type=&quot;tns:ReceB2COrderResponse&quot;/&amp;gt; &amp;lt;/xs:sequence&amp;gt; &amp;lt;/xs:complexType&amp;gt; &amp;lt;/xs:schema&amp;gt; &amp;lt;/wsdl:types&amp;gt; &amp;lt;wsdl:message name=&quot;receiveB2COrder&quot;&amp;gt; &amp;lt;wsdl:part element=&quot;tns:receiveB2COrder&quot; name=&quot;parameters&quot;&amp;gt;&amp;lt;/wsdl:part&amp;gt; &amp;lt;/wsdl:message&amp;gt; &amp;lt;wsdl:message name=&quot;receiveB2COrderResponse&quot;&amp;gt; &amp;lt;wsdl:part element=&quot;tns:receiveB2COrderResponse&quot; name=&quot;parameters&quot;&amp;gt;&amp;lt;/wsdl:part&amp;gt; &amp;lt;/wsdl:message&amp;gt; &amp;lt;wsdl:message name=&quot;MasAPIException&quot;&amp;gt; &amp;lt;wsdl:part element=&quot;tns:MasAPIException&quot; name=&quot;MasAPIException&quot;&amp;gt;&amp;lt;/wsdl:part&amp;gt; &amp;lt;/wsdl:message&amp;gt; &amp;lt;wsdl:portType name=&quot;ReceiveOrderAPI&quot;&amp;gt; &amp;lt;wsdl:operation name=&quot;receiveB2COrder&quot;&amp;gt; &amp;lt;wsdl:input message=&quot;tns:receiveB2COrder&quot; name=&quot;receiveB2COrder&quot;&amp;gt;&amp;lt;/wsdl:input&amp;gt; &amp;lt;wsdl:output message=&quot;tns:receiveB2COrderResponse&quot; name=&quot;receiveB2COrderResponse&quot;&amp;gt;&amp;lt;/wsdl:output&amp;gt; &amp;lt;wsdl:fault message=&quot;tns:MasAPIException&quot; name=&quot;MasAPIException&quot;&amp;gt;&amp;lt;/wsdl:fault&amp;gt; &amp;lt;/wsdl:operation&amp;gt; &amp;lt;/wsdl:portType&amp;gt; &amp;lt;wsdl:binding name=&quot;ReceiveOrderAPIExplorterServiceSoapBinding&quot; type=&quot;tns:ReceiveOrderAPI&quot;&amp;gt; &amp;lt;soap:binding style=&quot;document&quot; transport=&quot;http://schemas.xmlsoap.org/soap/http&quot;/&amp;gt; &amp;lt;wsdl:operation name=&quot;receiveB2COrder&quot;&amp;gt; &amp;lt;soap:operation soapAction=&quot;&quot; style=&quot;document&quot;/&amp;gt; &amp;lt;wsdl:input name=&quot;receiveB2COrder&quot;&amp;gt; &amp;lt;soap:body use=&quot;literal&quot;/&amp;gt; &amp;lt;/wsdl:input&amp;gt; &amp;lt;wsdl:output name=&quot;receiveB2COrderResponse&quot;&amp;gt; &amp;lt;soap:body use=&quot;literal&quot;/&amp;gt; &amp;lt;/wsdl:output&amp;gt; &amp;lt;wsdl:fault name=&quot;MasAPIException&quot;&amp;gt; &amp;lt;soap:fault name=&quot;MasAPIException&quot; use=&quot;literal&quot;/&amp;gt; &amp;lt;/wsdl:fault&amp;gt; &amp;lt;/wsdl:operation&amp;gt; &amp;lt;/wsdl:binding&amp;gt; &amp;lt;wsdl:service name=&quot;ReceiveOrderAPIExplorterService&quot;&amp;gt; &amp;lt;wsdl:port binding=&quot;tns:ReceiveOrderAPIExplorterServiceSoapBinding&quot; name=&quot;ReceiveOrderAPIExplorterPort&quot;&amp;gt; &amp;lt;soap:address location=&quot;http://cardpay.shengpay.com/api-acquire-channel/services/receiveOrderService&quot;/&amp;gt; &amp;lt;/wsdl:port&amp;gt; &amp;lt;/wsdl:service&amp;gt;&amp;lt;/wsdl:definitions&amp;gt;参考 SOAP与WSDL详解 WS-Addressing - 维基百科" }, { "title": "XML命名空间", "url": "/posts/xml-namespace/", "categories": "技术", "tags": "xml, namespace, 命名空间", "date": "2021-02-23 09:00:00 +0800", "snippet": "xmlns 属性当在 XML 中使用前缀时，一个所谓的用于前缀的命名空间必须被定义。命名空间是在元素的开始标签的 xmlns 属性中定义的。命名空间声明的语法如下。xmlns:前缀=&quot;URI&quot;。 示例：&amp;lt;root&amp;gt;&amp;lt;h:table xmlns:h=&quot;http://www.w3.org/TR/html4/&quot;&amp;gt;&amp;lt;h:tr&amp;gt;&amp;lt;h:td&amp;gt;Apples&amp;lt;/h:td&amp;gt;&amp;lt;h:td&amp;gt;Bananas&amp;lt;/h:td&amp;gt;&amp;lt;/h:tr&amp;gt;&amp;lt;/h:table&amp;gt;&amp;lt;f:table xmlns:f=&quot;http://www.w3cschool.cc/furniture&quot;&amp;gt;&amp;lt;f:name&amp;gt;African Coffee Table&amp;lt;/f:name&amp;gt;&amp;lt;f:width&amp;gt;80&amp;lt;/f:width&amp;gt;&amp;lt;f:length&amp;gt;120&amp;lt;/f:length&amp;gt;&amp;lt;/f:table&amp;gt;&amp;lt;/root&amp;gt;在上面的实例中，&amp;lt;table&amp;gt; 标签的 xmlns 属性定义了 h: 和 f: 前缀的合格命名空间。当命名空间被定义在元素的开始标签中时，所有带有相同前缀的子元素都会与同一个命名空间相关联。命名空间，可以在他们被使用的元素中或者在 XML 根元素中声明：&amp;lt;root xmlns:h=&quot;http://www.w3.org/TR/html4/&quot;xmlns:f=&quot;http://www.w3cschool.cc/furniture&quot;&amp;gt;&amp;lt;h:table&amp;gt;&amp;lt;h:tr&amp;gt;&amp;lt;h:td&amp;gt;Apples&amp;lt;/h:td&amp;gt;&amp;lt;h:td&amp;gt;Bananas&amp;lt;/h:td&amp;gt;&amp;lt;/h:tr&amp;gt;&amp;lt;/h:table&amp;gt;&amp;lt;f:table&amp;gt;&amp;lt;f:name&amp;gt;African Coffee Table&amp;lt;/f:name&amp;gt;&amp;lt;f:width&amp;gt;80&amp;lt;/f:width&amp;gt;&amp;lt;f:length&amp;gt;120&amp;lt;/f:length&amp;gt;&amp;lt;/f:table&amp;gt;&amp;lt;/root&amp;gt; 注释：命名空间 URI 不会被解析器用于查找信息。其目的是赋予命名空间一个惟一的名称。不过，很多公司常常会作为指针来使用命名空间指向实际存在的网页，这个网页包含关于命名空间的信息。请访问 http://www.w3.org/TR/html4/。统一资源标识符统一资源标识符（URI，全称 Uniform Resource Identifier），是一串可以标识因特网资源的字符。最常用的 URI 是用来标识因特网域名地址的统一资源定位器（URL）。另一个不那么常用的 URI 是统一资源命名（URN）。在我们的实例中，我们仅使用 URL。 注意URI和URL是不同的概念，URI是用于标识的，URL是一串链接，只不过URI常用URL作为表示显示默认的命名空间为元素定义默认的命名空间可以让我们省去在所有的子元素中使用前缀的工作。它的语法如下：xmlns=&quot;namespaceURI&quot; 使用默认命名空间时，xmlns就无需指定命名空间名称，也不用在对应的标签前添加命名空间名称这个 XML 携带 HTML 表格的信息：&amp;lt;table xmlns=&quot;http://www.w3.org/TR/html4/&quot;&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td&amp;gt;Apples&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;Bananas&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/table&amp;gt;这个XML携带有关一件家具的信息：&amp;lt;table xmlns=&quot;http://www.w3schools.com/furniture&quot;&amp;gt;&amp;lt;name&amp;gt;African Coffee Table&amp;lt;/name&amp;gt;&amp;lt;width&amp;gt;80&amp;lt;/width&amp;gt;&amp;lt;length&amp;gt;120&amp;lt;/length&amp;gt;&amp;lt;/table&amp;gt;参考 XML 命名空间（XML Namespaces）" }, { "title": "在移动硬盘上使用btrfs文件系统", "url": "/posts/btrfs-harddisk/", "categories": "技术", "tags": "btrfs, linux, 文件系统", "date": "2021-02-22 09:00:00 +0800", "snippet": "前言对于移动硬盘，在空间和便携性上取舍是个比较麻烦的问题，即想要便携又要大的存储空间时怎么办？这时就要考虑带有透明压缩的文件系统，btrfs就是个很好的选择，在拥有诸多现代文件系统特性的基础上增加了透明压缩功能，压缩率能达到50%以上，让移动硬盘能塞下更多文件但同时btrfs也是有缺陷的，就是主流的操作系统支持性并不好，Windows和Macos需要安装驱动，Linux4.14后的版本才可支持zstd压缩算法。介绍Btrfs（B-tree文件系统，通常念成Butter FS，Better FS或B-tree FS），一种支持写入时复制（COW）的文件系统，运行在Linux操作系统，采用GPL授权。Oracle于2007年对外宣布这项计划，并发布源代码，在2014年8月发布稳定版。目标是取代Linux目前的ext3文件系统，改善ext3的限制，特别是单个文件的大小，总文件系统大小或文件检查和加入ext3未支持的功能，像是可写快照（writable snapshots）、快照的快照（snapshots of snapshots）、内建磁盘阵列（RAID），以及子卷（subvolumes）。Btrfs也宣称专注在“容错、修复及易于管理”。btrfs特性 联机碎片整理 联机卷生长和收缩 联机块设备增加和删除 联机负载均衡（块设备间的对象移动以达到平衡） 文件系统级的镜像（类RAID-1）、条带（类RAID-0） 子卷（一个或多个单独可挂载基于每个物流分区） 透明压缩（目前支持zlib、LZO和ZSTD (从 4.14 开始支持)） 快照（只读和可写，写复制，子卷复制） 文件克隆 数据和元数据的校验和（目前是CRC-32C） 就地转换（带回滚）ext3/4 文件系统种子 用户定义的事务 块丢弃支持分区fdisk /dev/sdb&amp;gt;Command (m for help): n&amp;gt;Command action #这里可以选择是作为扩展分区还是主分区。这里作为主分区，则选择pe extendedp primary partition (1-4)p&amp;gt;Partition number (1-4): 1 #做第一块主分区&amp;gt;First cylinder (1-130, default 1):Using default value 1&amp;gt;Last cylinder, +cylinders or +size{K,M,G} (1-130, default 130): +500M #分区大小为K，M，G。制作分区的大小，这里选择第一块分区大小为500M&amp;gt;Command (m for help): p #输入p可以查看刚才分区的情况Disk /dev/sdb: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x06194404Device Boot Start End Blocks Id System/dev/sdb1 1 65 522081 83 Linux&amp;gt;Command (m for help): w # 最好输入w 保存我们刚才从sdb分区出来的sdb1The partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.格式化使用mkfs.btrfs命令格式化分区:mkfs.btrfs /dev/sdb1挂载获取UUID:lsblk -f修改/etc/fstab:UUID=f4f459e9-48df-445e-94f1-96c98a68e78e /mnt/btrfs btrfs defaults,noauto,nofail,noatime,compress-force=zstd:1 0 0 noatime已经包含了nodiratime，不用同时指定 zstd:1表示使用level1的zstd压缩算法，较为快速，不同level压缩率差距很小，详见BTRFS ZSTD level compression benchmark使用mount命令挂载:mount /mnt/btrfscompress-force与compress 使用compress-force可以带来更高的压缩比，但会影响性能 compress的采样算法在4.15有优化，但没有实质变化 经过实测，19092520KB的原始数据在两种策略下的压缩率实际表现如下: raw compress compress-force 19092520 11827572 11532752 压缩算法Btrfs文件系统目前支持ZLIB、LZO、ZSTD(从 4.14 开始支持)算法，ZSTD是目前btrfs最好的压缩策略参考 Btrfs (简体中文) - ArchWiki Linux使用fdisk创建分区详解" }, { "title": "HTTPS双向认证原理与测试环境搭建", "url": "/posts/mutual-authentication/", "categories": "技术", "tags": "SSL, 双向认证, goahead, HTTPS", "date": "2021-01-22 09:00:00 +0800", "snippet": "原理双向认证(mutual authentication)，顾名思义，客户端和服务器端都需要验证对方的身份，在建立 HTTPS 连接的过程中，握手的流程比单向认证多了几步。单向认证的过程，客户端从服务器端下载服务器端公钥证书进行验证，然后建立安全通信通道。双向通信流程，客户端除了需要从服务器端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务器端给服务器端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。本文所提到的认证流程都是基于RSA的方式，TLS1.0还支持DH(Diffie-Hellman)方式认证，详见《传输层安全(TLS)相关技术详解》单向认证流程(RSA)单向认证流程中，服务器端保存着公钥证书和私钥两个文件，整个握手过程如下： 客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务器端； 服务器端将本机的公钥证书（server.crt）发送给客户端； 客户端读取公钥证书 (server.crt)，取出了服务端公钥； 客户端生成一个随机数（密钥 R），用刚才得到的服务器公钥去加密这个随机数形成密文，发送给服务端； 服务端用自己的私钥 (server.key) 去解密这个密文，得到了密钥 R 服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了双向认证流程(RSA) 客户端发起建立 HTTPS 连接请求，将 SSL 协议版本的信息发送给服务端； 服务器端将本机的公钥证书 (server.crt) 发送给客户端； 客户端读取公钥证书 (server.crt)，取出了服务端公钥； 客户端将客户端公钥证书 (client.crt) 发送给服务器端； 服务器端解密客户端公钥证书，拿到客户端公钥； 客户端发送自己支持的加密方案给服务器端； 服务器端根据自己和客户端的能力，选择一个双方都能接受的加密方案，使用客户端的公钥加密后发送给客户端； 客户端使用自己的私钥解密加密方案，生成一个随机数 R，使用服务器公钥加密后传给服务器端； 服务端用自己的私钥去解密这个密文，得到了密钥 R 服务端和客户端在后续通讯过程中就使用这个密钥R进行通信了。证书生成使用openssl生成CA自签名根证书 使用以下命令生成无密码的2048位rsa密钥 openssl genrsa -out ca.key 2048 或加上-des3命令生成使用des3算法加密的rsa密钥 openssl genrsa -des3 -out ca.key 2048 生成x509格式的CA自签名根证书 openssl req -new -x509 -days 365 -key ca.key -out ca.crt 依次填入csr信息，Common Name表示颁发者 Country Name (2 letter code) [AU]:CN State or Province Name (full name) [Some-State]:zhejiang Locality Name (eg, city) []:ningbo Organization Name (eg, company) [Internet Widgits Pty Ltd]:SX Organizational Unit Name (eg, section) []:tech Common Name (e.g. server FQDN or YOUR name) []:test Email Address []: 至此，CA自签名根证书已生成完成，后续需要用到CA密钥和证书签发子证书，注意密钥的保存与保密签发客户端证书 使用以下命令生成无密码的2048位rsa密钥 openssl genrsa -out client.key 2048 或加上-des3命令生成使用des3算法加密的rsa密钥 openssl genrsa -des3 -out client.key 2048 生成客户端csr文件 openssl req -new -key client.key -out client.csr 依次填入csr信息，Common Name表示使用者，不能与颁发者相同 Country Name (2 letter code) [AU]:CN State or Province Name (full name) [Some-State]:zhejiang Locality Name (eg, city) []:ningbo Organization Name (eg, company) [Internet Widgits Pty Ltd]:SX Organizational Unit Name (eg, section) []:tech Common Name (e.g. server FQDN or YOUR name) []:client1 Email Address []: Please enter the following &#39;extra&#39; attributes to be sent with your certificate request A challenge password []:147258369 An optional company name []:sanxing 使用CA签发客户端x509证书 openssl x509 -req -days 365 -in client.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out client.crt 将客户端密钥和证书打包成pfx文件，用于浏览器或系统导入 openssl pkcs12 -export -out client.pfx -inkey client.key -in client.crt 或加上CA证书保证证书被信任 openssl pkcs12 -export -out client.pfx -inkey client.key -in client.crt -certfile ca.crt 签发服务端证书 服务端证书生成过程与客户端相同，此处不再赘述证书部署本次配置以GoAhead-openssl为例，GoAhead还能使用mbedtls实现https，这里不做介绍，关于GoAhead的介绍如下： GoAhead is the world’s most popular, tiny embedded web server. It is compact, secure and simple to use. GoAhead is deployed in hundreds of millions of devices and is ideal for the smallest of embedded devices.以上步骤完成后，将会生成如下文件：ca.key ca.crt client.crt client.key client.pfx server.key server.crt (可选)server.key和server.crt部署在服务器证书路径下 对于GoAhead，ca.crt需部署在服务器证书路径下，用于验证客户端证书 client.pfx安装到客户端，windows下直接下一步默认即可配置GoAhead客户端证书认证功能 将me.h中的宏ME_GOAHEAD_SSL_VERIFY_PEER置为1，启用客户端证书认证 将me.h中的宏ME_GOAHEAD_SSL_AUTHORITY配置为CA证书的绝对路径，用于校验客户端证书 重新编译GoAhead库与服务端程序测试windows客户端安装完客户端证书后访问服务端，此时浏览器会提示选择客户端证书，选择证书后能正常访问，如证书错误或未提供证书则访问失败，即测试通过参考 巧用 Nginx 快速实现 HTTPS 双向认证 Using Client-Certificate based authentication with NGINX on Ubuntu" }, { "title": "我的第一篇博客", "url": "/posts/first-blog/", "categories": "浮世杂谈", "tags": "生活", "date": "2021-01-21 00:00:00 +0800", "snippet": "此刻，新生" } ]
